---
layout: post
title: "[3주차] 확률과 통계"
date: 2025-09-23 16:01:00 +0900
categories: ["확률과 통계"]
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. 신뢰구간(CI)  
  
$(E, \left(P_{\theta}\right)_{\theta \in \Theta})$
는 관측치 $X_{1}, \dots, X_{n}$에 기반한 통계모델이라 하고, 모수 공간 $\Theta$는 $\mathbb{R}$의 부분집합이라고 가정하자.  

**정의**  

$\alpha \in (0,1)$이라고 하자.  

- **모수 $\theta$에 대한 신뢰수준 $1-\alpha$의 신뢰구간 (Confidence Interval, C.I. of level $1-\alpha$ for $\theta$):**  
  경계가 $\theta$에 의존하지 않고 (예: $X_{1}, \dots, X_{n}$ 등에 의존하는), 다음을 만족하는 임의의 구간 $\mathcal{I}$:  
  $$
  \mathbb{P}_{\theta}[\theta \in \mathcal{I}] \geq 1 - \alpha, \quad \forall \theta \in \Theta
  $$  

- **모수 $\theta$에 대한 점근적 신뢰수준 $1-\alpha$의 신뢰구간 (C.I. of asymptotic level $1-\alpha$ for $\theta$):**  
  경계가 $\theta$에 의존하지 않고, 다음을 만족하는 임의의 구간 $\mathcal{I}$:  
  $$
  \lim_{n \to \infty} \mathbb{P}_{\theta}[\theta \in \mathcal{I}] \geq 1 - \alpha, \quad \forall \theta \in \Theta
  $$  
  
<img src="/assets/img/probstat/3/image_1.png" alt="image" width="360px">

---

>**보충설명**
>
>1. **경계가 $\theta$에 의존하지 않는다는 의미**  
>
>   - **정의**  
>     신뢰구간의 경계(boundary)는 표본 $(X_{1}, \dots, X_{n})$의 함수로 정의된다.  
>     “$\theta$에 의존하지 않는다”는 것은, 그 **표현식(expression)** 안에 모수 $\theta$가 명시적으로 포함되지 않는다는 의미이다.  
>
>   - **예시**  
>     - 표본평균과 표본표준편차를 이용한 구간:  
>       $$
>       \mathcal{I} = \left[\overline{X}_{n} - 1.96 \cdot \frac{S}{\sqrt{n}}, \ \overline{X}_{n} + 1.96 \cdot \frac{S}{\sqrt{n}}\right]
>       $$  
>       이때 구간의 경계는 $\overline{X}_{n}$과 $S$에만 의존하며, 모수 $\theta$는 직접 나타나지 않는다.  
>
>   - **정리**  
>     따라서 신뢰구간의 경계는 “표본만을 입력으로 하는 함수”라는 점에서 모수 $\theta$에 직접적으로 의존하지 않는다.  
>
>2. **점근적 신뢰수준의 의미**  
>
>   - **정의**  
>     첫 번째 정의는 모든 유한한 표본 크기 $n$에서 신뢰구간이 모수 $\theta$를 포함할 확률이 항상 $1-\alpha$ 이상임을 요구한다.  
     두 번째 정의는 $n \to \infty$일 때, 신뢰구간이 모수 $\theta$를 포함할 확률이 $1-\alpha$ 이상으로 수렴하는 경우를 다룬다.  
>
>   - **예시**  
>     - **유한 표본에서의 신뢰구간:**  
>       모든 $n$에서 조건을 만족해야 하므로, “엄밀한 신뢰구간”이 된다.  
>     - **무한 표본에서의 신뢰구간 (점근적):**  
>       유한 $n$에서는 $1-\alpha$ 수준을 정확히 보장하지 않더라도, $n$이 커짐에 따라 $1-\alpha$에 수렴한다.  
>
>   - **정리**  
>     첫 번째 정의는 유한 $n$에서의 엄밀한 신뢰구간,  
>     두 번째 정의는 $n \to \infty$에서 성립하는 **점근적 신뢰구간**이다.  
>     따라서 “점근적(asymptotic)”이라는 표현은 **표본 크기를 무한대로 보냈을 때 얻어지는 성질**을 의미한다.  

---

## p3. 총분산거리(TV)  

$(E, (P_{\theta})_{\theta \in \Theta})$를 i.i.d.인 확률변수 $X_{1}, \dots, X_{n}$의 표본과 연관된 통계모형이라고 하자.  
$X_{1} \sim P_{\theta^{*}}$인 $\theta^{*} \in \Theta$가 존재한다고 가정하자:  
이때 $\theta^{*}$는 참(true) 모수이다.  

**통계학자의 목표:**  
$X_{1}, \dots, X_{n}$가 주어졌을 때, 참 모수 $\theta^{*}$에 대해  
$P_{\hat{\theta}}$가 $P_{\theta^{*}}$에 근접하도록 하는 추정량  
$\hat{\theta} = \hat{\theta}(X_{1}, \dots, X_{n})$을 찾는 것.  

이는 곧, 모든 $A \subset E$에 대해  
$$
|P_{\hat{\theta}}(A) - P_{\theta^{*}}(A)|
$$  
가 작다는 것을 의미한다.  

**정의**  
두 확률측도 $P_{\theta}, P_{\theta'}$ 사이의 **총분산거리 (Total Variation Distance)**는 다음과 같이 정의된다.  

$$
TV(P_{\theta}, P_{\theta'}) = \max_{A \subset E} \, \big| P_{\theta}(A) - P_{\theta'}(A) \big|
$$  

---

>**보충설명**
>
>- **왜 max가 필요한가?**  
>  총분산거리 정의에서 고려하는 $A \subseteq E$는 무수히 많다.  
>  각각의 사건 $A$에 대해 $|P_{\theta}(A) - P_{\theta'}(A)|$ 값을 계산하면, 무수히 많은 값이 나온다.  
>  따라서 이 모든 값 중에서 가장 큰 값을 잡아야 두 분포 사이의 차이를 하나의 수치로 요약할 수 있다.  
>
>- **정리**  
>  $$
>  TV(P_{\theta}, P_{\theta'}) = \max_{A \subseteq E} |P_{\theta}(A) - P_{\theta'}(A)|
>  $$  
>  총분산거리는 두 분포가 어떤 사건에 대해 줄 수 있는 **최대 확률 차이**를 의미한다.  
  
---

> **comment**  
>  
> - $\theta^{*}$는 optimal 모수를 나타내는 기호로, 참 모수(true parameter)와 동일시된다.  
> - $X \sim P_{\theta}$는 "distributed as"를 의미한다.  
> - $\hat{\theta}$는 모수의 **추정량(estimator)**으로, 표본으로부터 참 모수를 추정하는 함수이다.  
> - $|P_{\hat{\theta}}(A) - P_{\theta^{*}}(A)|$는 두 분포가 같은 사건 $A$에 대해 주는 확률 차이를 의미한다.  
>   이는 밀도 함수가 존재할 때 적분 형태로  
>   $$
>   \left| \int_{A} p_{\hat{\theta}}(x)\, dx - \int_{A} p_{\theta^{*}}(x)\, dx \right|
>   $$  
>   로 표현할 수 있다.  
> - 나아가 총분산거리는 다음과 같이 전체 공간에서의 차이를 적분하여 정의할 수도 있다.  
>   $$
>   TV(P_{\hat{\theta}}, P_{\theta^{*}}) = \tfrac{1}{2} \int |p_{\hat{\theta}}(x) - p_{\theta^{*}}(x)|\, dx
>   $$  
> - $A \subset E$ 전체에 대해 비교하는 것은 수학적으로 정의되지만, 실제로는 어려울 수 있다. (예: $E$가 수십억 차원일 수도 있음)  
> - 수식의 $\theta$와 $\theta'$는 단순히 이름만 다른 모수이다.  
> - 결국 우리가 하는 일은 확률측도 $P$에 대해, 추정량 $\hat{\theta}$가 optimal 모수 $\theta^{*}$에 얼마나 가까운지를 평가하는 것이다.  

---

## p4. 총분산거리(TV)  

$E$가 연속형 공간이라고 가정하자. (예: Gaussian, Exponential 등)  

$X$가 모든 $A \subset E$에 대해 밀도 $P_{\theta}(X \in A) = \int_{A} f_{\theta}(x)\, dx$ 를 가진다고 가정하자.  

$$
f_{\theta}(x) \geq 0, \quad \int_{E} f_{\theta}(x)\, dx = 1
$$  

두 확률측도 $P_{\theta}$와 $P_{\theta'}$ 사이의 **총분산거리 (Total Variation Distance)**는  
밀도함수 $f_{\theta}, f_{\theta'}$의 단순한 함수이다.  

$$
TV(P_{\theta}, P_{\theta'}) = \tfrac{1}{2} \int_{E} | f_{\theta}(x) - f_{\theta'}(x) | \, dx
$$  

---

>**보충설명**
>  
>**p3와 p4의 총분산거리 정의가 동치임을 보이는 과정**  
>
>1. **출발점: p3의 정의**  
>   $$
>   TV(P_{\theta}, P_{\theta'}) = \max_{A \subset E} |P_{\theta}(A) - P_{\theta'}(A)|
>   $$  
>   이는 “두 분포가 같은 사건 $A$에 대해 할당하는 확률의 차이 중 최댓값”을 의미한다.  
>
>2. **밀도 표현으로 바꾸기**  
>   두 분포가 밀도 $f_{\theta}, f_{\theta'}$를 가진다고 하면, 임의의 사건 $A$에 대해  
>   $$
>   P_{\theta}(A) - P_{\theta'}(A) = \int_A (f_{\theta}(x) - f_{\theta'}(x))\, dx
>   $$  
>   따라서  
>   $$
>   |P_{\theta}(A) - P_{\theta'}(A)| = \left|\int_A g(x)\, dx\right|,
>   $$
>   $$
>   g(x) := f_{\theta}(x) - f_{\theta'}(x).
>   $$  
>
>3. **$g$의 전체 적분은 0**  
>   밀도함수는 전체 공간에서 1로 적분되므로,  
>   $$
>   \int_E g(x)\, dx
>   $$
>   $$
>   = \int_E f_{\theta}(x)\, dx - \int_E f_{\theta'}(x)\, dx
>   $$
>   $$
>   = 1 - 1 = 0.
>   $$  
>   따라서 $g(x)$의 양수 영역 적분과 음수 영역 적분의 크기는 같다.  
>
>4. **최댓값을 주는 사건 $A$**  
>   - $A$를 $g(x) > 0$인 영역으로 택하면 $\int_A g(x)\, dx$가 최대 양수가 된다.  
>   - $A$를 $g(x) < 0$인 영역으로 택하면 $\int_A g(x)\, dx$가 최대 음수가 되고, 절댓값을 취하면 똑같이 큰 양수가 된다.  
>   - 따라서  
>     $$
>     \max_{A} \left|\int_A g(x)\, dx\right| = \int_{\{g > 0\}} g(x)\, dx.
>     $$  
>
>5. **양·음 부분 분해를 통한 절반 공식**  
>   $$
>   g^+(x) = \max(g(x),0),
>   $$
>   $$
>   g^-(x) = \max(-g(x),0)
>   $$  
>   라 정의하면  
>   $$
>   g = g^+ - g^-, \quad |g| = g^+ + g^-.
>   $$  
>   또한 $\int_E g = 0 \Rightarrow \int g^+ = \int g^-.$  
>   따라서  
>   $$
>   \int_{\{g>0\}} g(x)\, dx =\int g^+(x)\, dx
>   $$
>   $$
>   = \tfrac{1}{2}\int |g(x)|\, dx.
>   $$  
>
>6. **최종 결론: p4의 공식**  
>   $$
>   TV(P_{\theta}, P_{\theta'}) = \tfrac{1}{2} \int_E |f_{\theta}(x) - f_{\theta'}(x)|\, dx.
>   $$  
>
>---
>
>✅ **요약**  
>- p3: 사건별 확률 차이의 최댓값  
>- p4: 밀도 차이의 절댓값 적분의 절반  
>- 두 표현은 밀도함수가 존재할 때 **완전히 동치**이다.  

---

> **comment**  
>  
> - 3페이지 수식에서 형태만 바뀐 것
> - 이 형식을 더 기억해야 함

---

## p5. 총분산거리(TV) 

**총분산거리(Total Variance Distance)의 성질**  

- **대칭성 (Symmetry):**  
  $$
  TV(P_{\theta}, P_{\theta'}) = TV(P_{\theta'}, P_{\theta})
  $$  

- **비음수성 (Non-negativity):**  
  $$
  TV(P_{\theta}, P_{\theta'}) \geq 0
  $$  

- **확정성 (Definiteness):**  
  $$
  TV(P_{\theta}, P_{\theta'}) = 0 \quad \Rightarrow \quad P_{\theta} = P_{\theta'}
  $$  

- **삼각 부등식 (Triangle inequality):**  
  $$
  TV(P_{\theta}, P_{\theta'}) \leq TV(P_{\theta}, P_{\theta''}) + TV(P_{\theta''}, P_{\theta'})
  $$  
 
이것은 총분산거리(Total Variation Distance)가 확률분포들 사이의 하나의 **거리(distance)** 라는 것을 의미한다.  

---

>**보충설명**
>
>1. **확정성 (Definiteness)**  
>
>   - **정의**  
>     총분산거리 $TV(P_{\theta}, P_{\theta'})$가 0이라는 것은  
>     $$
>     \max_{A \subset E} |P_{\theta}(A) - P_{\theta'}(A)| = 0
>     $$  
>     임을 의미한다. 즉, 모든 사건 $A$에 대해  
>     $$
>     P_{\theta}(A) = P_{\theta'}(A)
>     $$  
>     가 성립한다.  
>
>   - **예시**  
>     - 만약 두 분포가 다르다면, 반드시 어떤 사건 $A$에서는 $P_{\theta}(A) \neq P_{\theta'}(A)$가 되어야 한다.  
>     - 하지만 총분산거리는 “모든 사건에서의 차이 중 가장 큰 값”을 취한다. > 
>     - 그 값이 0이라는 것은 **가장 큰 차이조차 0이므로, 다를 수가 없다**는 뜻이다.  
>
>   - **정리**  
>     따라서  
>     $$
>     TV(P_{\theta}, P_{\theta'}) = 0 \quad \Leftrightarrow \quad P_{\theta} = P_{\theta'}
>     $$  
>     즉, 총분산거리는 **같은 분포일 때만 0이 된다**는 성질을 만족한다. 이 때문에 거리(metric)의 조건 중 하나인 “0이면 두 원소가 같다”를 충족한다.  
>
>---
>
>2. **삼각부등식 (Triangle inequality)**  
>
>   - **정의**  
>     임의의 세 분포 $P_{\theta}, P_{\theta'}, P_{\theta''}$에 대해  
>     $$
>     TV(P_{\theta}, P_{\theta'}) \leq TV(P_{\theta}, P_{\theta''}) + TV(P_{\theta''}, P_{\theta'})
>     $$  
>     가 성립한다. 이는 거리(metric)의 기본 성질 중 하나이다.  
>
>   - **예시**  
>     - 분포 $P_{\theta}$와 $P_{\theta'}$가 직접 비교하면 멀리 떨어져 있을 수 있다.  
>     - 그러나 중간에 제3의 분포 $P_{\theta''}$를 경유하면,  
>       “$P_{\theta}$에서 $P_{\theta''}$까지의 거리 + $P_{\theta''}$에서 $P_{\theta'}$까지의 거리”가 항상 직접 거리보다 크거나 같다.  
>     - 이는 유클리드 공간에서 점 사이의 거리가 삼각형의 두 변의 합보다 작거나 같다는 사실과 유사하다.  
>
>   - **정리**  
>     삼각부등식이 성립한다는 것은 총분산거리가 단순한 유사도 척도가 아니라, 수학적으로 **타당한 거리(metric)**로 기능함을 보장한다.  

---

## p6. 총분산거리(TV): 예시(1/2)  

**두 정규분포와 정의**  

$$
f_{\theta} = \mathcal{N}(\mu_{1}, \sigma^{2})
$$  

$$
f_{\theta'} = \mathcal{N}(\mu_{2}, \sigma^{2})
$$  

**평균 차이와 기준점**  

$$
\Delta = |\mu_{1} - \mu_{2}|
$$  

$$
m = \frac{(\mu_{1} + \mu_{2})}{2}
$$  

---

**수식 전개 과정**  

$$
TV(P_{\theta}, P_{\theta'}) = \frac{1}{2} \int_{-\infty}^{\infty} | f_{\mu_{1}}(x) - f_{\mu_{2}}(x) | \, dx
$$  

$$
= \frac{1}{2} \left( \int_{-\infty}^{m} (f_{\mu_{2}}(x) - f_{\mu_{1}}(x)) dx + \int_{m}^{\infty} (f_{\mu_{1}}(x) - f_{\mu_{2}}(x)) dx \right)
$$  

$$
= \int_{-\infty}^{m} f_{\mu_{1}}(x) dx - \int_{-\infty}^{m} f_{\mu_{2}}(x) dx
$$  

$$
= \frac{1}{\sqrt{2\pi}\sigma} \left[ \int_{-\infty}^{m} \exp\left(-\frac{(x-\mu_{1})^{2}}{2\sigma^{2}}\right) dx - \int_{-\infty}^{m} \exp\left(-\frac{(x-\mu_{2})^{2}}{2\sigma^{2}}\right) dx \right]
$$  

$$
= \frac{1}{\sqrt{2\pi}} \left[ \int_{-\infty}^{\frac{m-\mu_{1}}{\sigma}} e^{-t^{2}/2} dt - \int_{-\infty}^{\frac{m-\mu_{2}}{\sigma}} e^{-t^{2}/2} dt \right]
$$  

$$
= \frac{1}{\sqrt{2\pi}} \left[ \int_{-\Delta/(2\sigma)}^{0} e^{-t^{2}/2} dt - \int_{-\infty}^{-\Delta/(2\sigma)} e^{-t^{2}/2} dt \right]
$$  

$$
= \frac{1}{\sqrt{2\pi}} \int_{-\Delta/(2\sigma)}^{\Delta/(2\sigma)} e^{-t^{2}/2} dt
$$  

$$
= \frac{2}{\sqrt{2\pi}} \int_{0}^{\Delta/(2\sigma)} e^{-t^{2}/2} dt
$$  

---

>**보충설명**
>
>1. **두 분포의 가정**  
>
>   - **정의**  
>     같은 분산을 갖는 두 정규분포(여기서는 $\mu_1>\mu_2$)  
>     $$
>     f_{\theta}=\mathcal{N}(\mu_{1},\sigma^{2}),\qquad
     f_{\theta'}=\mathcal{N}(\mu_{2},\sigma^{2})
>     $$
>   - **표현식**  
>     $$
>     \Delta=\mu_{1}-\mu_{2}>0,\qquad
     m=\frac{\mu_{1}+\mu_{2}}{2}
>     $$
>   - **정리**  
>     모양(분산)은 같고, 중심(평균)만 다르다.
>
>---
>
>2. **적분 구간 나누기 (절댓값 처리)**  
>
>   - **표현식**  
>     $$
>     TV(P_{\theta},P_{\theta'})
     =\tfrac{1}{2}\!\int_{-\infty}^{\infty}\!\!\big|f_{\mu_1}(x)-f_{\mu_2}(x)\big|\,dx
>     $$
>     $$=\tfrac{1}{2}\!\left[\int_{-\infty}^{m}\!\!\big(f_{\mu_1}(x)-f_{\mu_2}(x)\big)\,dx
     +\int_{m}^{\infty}\!\!\big(f_{\mu_2}(x)-f_{\mu_1}(x)\big)\,dx\right]
>     $$
>   - **정리**  
>     교차점 $m$을 기준으로 절댓값을 제거한다.
>     
>**교차점 m을 기준으로 절대값 제거가 가능한 이유**
><img src="/assets/img/probstat/3/image_2.png" alt="image" width="500px">
>
>---
>
>3. **CDF 성질을 이용한 중간 정리**  
>
>   - **아이디어**  
>     pdf의 총적분이 1이므로, 임의의 $i \in \{1,2\}$에 대해
>     $$
>     \int_{m}^{\infty} f_{\mu_i}(x)\,dx \;=\; 1-\int_{-\infty}^{m} f_{\mu_i}(x)\,dx.
>     $$
>
>   - **정리 과정**  (앞의 **첫 적분만** $1-$적분으로 치환, **뒷부분은** $m\!\to\!\infty$ **그대로 유지**)  
>     $$
>     \begin{aligned}
     TV
     &=\tfrac{1}{2}\!\left[
       \int_{-\infty}^{m}\!\big(f_{\mu_2}(x)-f_{\mu_1}(x)\big)\,dx
       \;+\;
       \int_{m}^{\infty}\!\big(f_{\mu_1}(x)-f_{\mu_2}(x)\big)\,dx
     \right]\\[4pt]
     &=\tfrac{1}{2}\!\left[
       \Big(1-\!\!\int_{m}^{\infty}\!f_{\mu_2}(x)\,dx\Big)
       -\Big(1-\!\!\int_{m}^{\infty}\!f_{\mu_1}(x)\,dx\Big)
       \;+\;
       \int_{m}^{\infty}\!f_{\mu_1}(x)\,dx
       -\int_{m}^{\infty}\!f_{\mu_2}(x)\,dx
     \right]\\[4pt]
     &=\tfrac{1}{2}\!\left[
       \int_{m}^{\infty}\!f_{\mu_1}(x)\,dx-\int_{m}^{\infty}\!f_{\mu_2}(x)\,dx
       \;+\;
       \int_{m}^{\infty}\!f_{\mu_1}(x)\,dx-\int_{m}^{\infty}\!f_{\mu_2}(x)\,dx
     \right]\\[4pt]
     &=\int_{m}^{\infty}\!f_{\mu_1}(x)\,dx \;-\;\int_{m}^{\infty}\!f_{\mu_2}(x)\,dx.
     \end{aligned}
>     $$
>
>   - **단순화**  
>     결과가 **“꼬리 확률의 차이”**로 정리된다:
>     $$
>     TV \;=\; \big(1-F_{\mu_1}(m)\big) \;-\; \big(1-F_{\mu_2}(m)\big).
>     $$
>
>---
>
>4. **정규분포 밀도 대입**  
>
>   - **표현식**  
>     $$
>     TV
     =\frac{1}{\sqrt{2\pi}\sigma}\!\left[
       \int_{m}^{\infty}\!\exp\!\Big(-\frac{(x-\mu_{1})^{2}}{2\sigma^{2}}\Big)\,dx
       \;-\;
       \int_{m}^{\infty}\!\exp\!\Big(-\frac{(x-\mu_{2})^{2}}{2\sigma^{2}}\Big)\,dx
     \right].
>     $$
>
>---
>
>5. **변수 치환을 통한 표준화(및 $\sigma$ 약분)**  
>
>   - **치환 및 약분**  
>     각각 $t=\dfrac{x-\mu_i}{\sigma}$, $dx=\sigma\,dt$ 이므로
>     $$
>     \frac{1}{\sqrt{2\pi}\sigma}\!\int_{m}^{\infty}
     \exp\!\Big(-\frac{(x-\mu_i)^2}{2\sigma^2}\Big)\,dx
     \;=\;
     \frac{1}{\sqrt{2\pi}}\!\int_{\frac{m-\mu_i}{\sigma}}^{\infty}
     e^{-t^2/2}\,dt.
>     $$
>   - **표현식**  
>     $$
>     TV
     =\frac{1}{\sqrt{2\pi}}\!\left[
       \int_{\frac{m-\mu_{1}}{\sigma}}^{\infty}\!e^{-t^{2}/2}\,dt
       \;-\;
       \int_{\frac{m-\mu_{2}}{\sigma}}^{\infty}\!e^{-t^{2}/2}\,dt
     \right].
>     $$
>
>---
>
>6. **적분 구간 변환(차 = 구간 적분)**  
>
>   - **항등식**  
>     임의의 적분가능한 \(g\)와 실수 \(a,b\)에 대해
>     $$
>     \int_{a}^{\infty}\!g(t)\,dt \;-\; \int_{b}^{\infty}\!g(t)\,dt
     \;=\; \int_{a}^{b}\!g(t)\,dt.
>     $$
>   - **적용**  
>     $$
>     TV
     =\frac{1}{\sqrt{2\pi}}
     \int_{\frac{m-\mu_{1}}{\sigma}}^{\frac{m-\mu_{2}}{\sigma}}
     e^{-t^{2}/2}\,dt.
>     $$
>
>---
>
>7. **중점 치환 및 대칭성 ($\mu_1>\mu_2$)** 
>
>   - **치환**  
>     $$
>     m-\mu_{1}=-\frac{\Delta}{2},\qquad
     m-\mu_{2}= \frac{\Delta}{2}\quad(\Delta=\mu_1-\mu_2>0)
>     $$
>   - **표현식**  
>     $$
>     TV
     =\frac{1}{\sqrt{2\pi}}
     \int_{-\Delta/(2\sigma)}^{\Delta/(2\sigma)} e^{-t^{2}/2}\,dt.
>     $$
>
>---
>
>8. **최종 간단화(짝함수 이용)**  
>
>   - **결과**  
>     $$
>     TV(P_{\theta},P_{\theta'})
     \;=\;
     \frac{2}{\sqrt{2\pi}}
     \int_{0}^{\Delta/(2\sigma)} e^{-t^{2}/2}\,dt.
>     $$

---

## p7. 총분산거리(TV): 예시(2/2)

$$
TV(P_{\theta}, P_{\theta'}) = \frac{2}{\sqrt{2\pi}} \int_{0}^{\Delta/(2\sigma)} e^{-t^{2}/2}\, dt
$$

$$
= \frac{2}{\sqrt{2\pi}} \sqrt{2} \int_{0}^{\Delta/(2\sqrt{2}\sigma)} e^{-u^{2}}\, du
$$

$$
= \frac{2}{\sqrt{\pi}} \int_{0}^{\Delta/(2\sqrt{2}\,\sigma)} e^{-u^{2}}\, du
$$

$$
= \operatorname{erf}\!\left(\frac{\Delta}{2\sqrt{2}\,\sigma}\right)
$$

---

$$
\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^{2}}\, dt
$$
$$
\operatorname{erfc}(x) = 1 - \operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{x}^{\infty} e^{-t^{2}}\, dt.
$$

<img src="/assets/img/probstat/3/image_3.png" alt="image" width="480px">

---

>**보충설명**
>
>1. **수식 전개 내역 (p7)**  
>
>   - **정의**  
>     p6 결과에서 시작한다.  
>     $$
>     TV(P_{\theta},P_{\theta'})=\frac{2}{\sqrt{2\pi}}\int_{0}^{\Delta/(2\sigma)} e^{-t^{2}/2}\,dt
>     $$
>     지수를 $e^{-u^{2}}$ 꼴로 만들기 위해 스케일 치환을 한다.  
>     $$
>     u=\frac{t}{\sqrt{2}},\quad t=\sqrt{2}\,u,\quad dt=\sqrt{2}\,du,\quad
>     $$
>     $$
>     t=0\Rightarrow u=0,\;\; t=\frac{\Delta}{2\sigma}\Rightarrow u=\frac{\Delta}{2\sqrt{2}\,\sigma}.
>     $$
>     전개:  
>     $$
>     \begin{aligned}
     TV
     &=\frac{2}{\sqrt{2\pi}}\int_{0}^{\Delta/(2\sigma)} e^{-t^{2}/2}\,dt \\
     &=\frac{2}{\sqrt{2\pi}}\int_{0}^{\Delta/(2\sqrt{2}\sigma)} e^{-(\sqrt{2}u)^{2}/2}\,(\sqrt{2}\,du) \\
     &=\frac{2}{\sqrt{2\pi}}\sqrt{2}\int_{0}^{\Delta/(2\sqrt{2}\sigma)} e^{-u^{2}}\,du \\
     &=\frac{2}{\sqrt{\pi}}\int_{0}^{\Delta/(2\sqrt{2}\sigma)} e^{-u^{2}}\,du.
     \end{aligned}
>     $$
>
>   - **예시**  
>     오류함수 정의를 대입하면  
>     $$
>     \operatorname{erf}(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x} e^{-t^{2}}\,dt
     \quad\Rightarrow\quad
     TV=\operatorname{erf}\!\Big(\frac{\Delta}{2\sqrt{2}\,\sigma}\Big).
>     $$
>
>   - **정리**  
>     $$
     TV(P_{\theta},P_{\theta'})=\operatorname{erf}\!\Big(\frac{\Delta}{2\sqrt{2}\,\sigma}\Big),
>     $$
>     즉 $TV$는 $\Delta/\sigma$만의 함수이며 단조 증가한다.
>
>---
>
>2. **$\operatorname{erf}$의 홀함수 성질**  
>
>   - **정의**  
>     $$
>     \operatorname{erf}(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x} e^{-t^{2}}\,dt.
>     $$
>     적분함수 $e^{-t^{2}}$는 양수·짝함수지만, 적분 한계가 $0\!\to\!x$이므로 전체 함수는 홀함수가 된다.
>
>   - **예시**  
>     $$
>     \begin{aligned}
     \operatorname{erf}(-x)
     &=\frac{2}{\sqrt{\pi}}\int_{0}^{-x} e^{-t^{2}}\,dt
      \quad(t=-u,\,dt=-du) \\
     &= -\frac{2}{\sqrt{\pi}}\int_{0}^{x} e^{-u^{2}}\,du
     = -\operatorname{erf}(x).
     \end{aligned}
>     $$  
>     따라서 $x<0\Rightarrow \operatorname{erf}(x)<0$, $\operatorname{erf}(0)=0$, $x>0\Rightarrow \operatorname{erf}(x)>0$.
>
>   - **정리**  
>     $\operatorname{erf}$는 **원점 대칭(홀함수)**이고, 도함수  
>     $$
>     \operatorname{erf}'(x)=\frac{2}{\sqrt{\pi}}e^{-x^{2}}>0
>     $$
>     로 **단조 증가**, 값의 범위는 $[-1,1]$이다. TV에서는 입력 $\frac{\Delta}{2\sqrt{2}\sigma}\ge 0$이므로 항상 $TV\ge 0$.
>
>---
>
>3. **“로그처럼 포화”되는 이유**  
>
>   - **정의**  
>     $x \to \pm\infty$에서 기울기(미분 값)가 $0$에 수렴하므로 그래프가 점점 평평해지고, 함수값은 유한한 극한에 가까워진다.  
>     $$
>     \lim_{x\to\infty}\operatorname{erf}(x)=1,\qquad
     \lim_{x\to-\infty}\operatorname{erf}(x)=-1
>     $$
>     $$
>     \operatorname{erf}'(x)=\frac{2}{\sqrt{\pi}}\,e^{-x^{2}}
     \xrightarrow[x\to\pm\infty]{} 0
>     $$
>
>   - **예시**  
>     $|x|$가 커질수록 $\operatorname{erf}'(x)$가 $0$에 가까워져 곡선이 점점 눕는다(변화량이 줄어든다). 그래서 $\operatorname{erf}(x)$는 위/아래에서 각각 일정한 값에 가까워지는 모습(포화)을 보인다.
>
>   - **정리**  
>     $\log x$는 계속 증가하여 $\lim_{x\to\infty}\log x=\infty$가 되지만, $\operatorname{erf}(x)$는 $-1$과 $1$에 수렴한다. 즉, $\operatorname{erf}$는 $[-1,1]$로 **포화**되고, $\log x$는 **비한정**으로 증가한다.

---

## p8. KL 발산

**쿨백–라이블러(Kullback–Leibler, KL) 발산**

확률측도 사이의 거리는 여러 가지가 있다. 총분산거리(total variation)를 대체할 수 있는 것들 중에서, 여기서는 다루기 더 편한 하나를 선택한다.

**정의**  
두 확률측도 $\mathbb{P}_\theta$와 $\mathbb{P}_{\theta'}$ 사이의 KL 발산은 다음과 같이 정의한다.

- $E$가 이산(discrete)인 경우  
  $$
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'}) \;=\;
  \sum_{x\in E} p_\theta(x)\,
  \log\!\left(\frac{p_\theta(x)}{p_{\theta'}(x)}\right)
  $$

- $E$가 연속(continuous)인 경우  
  $$
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'}) \;=\;
  \int_E f_\theta(x)\,
  \log\!\left(\frac{f_\theta(x)}{f_{\theta'}(x)}\right)\,dx
  $$

---

>**comment**  
> - $\mathbb{P}_\theta=\mathbb{P}_{\theta'}$이면  $\mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'})=0$ ($\log 1=0$이기 때문에).

---

## p9. KL 발산

**KL 발산의 성질 (Properties)**

- **비대칭성 (Asymmetry)**  
  $$
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'}) \neq \mathrm{KL}(\mathbb{P}_{\theta'},\mathbb{P}_\theta)
  \quad \text{(일반적으로)}
  $$

- **음이 아닌 값 (Non-negativity)**  
  $$
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'}) \ge 0
  $$

- **정확성/정부호성 (Definiteness)**  
  $$
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'}) = 0 \;\Rightarrow\; \mathbb{P}_\theta=\mathbb{P}_{\theta'}
  $$

- **삼각부등식 불성립 (No triangle inequality)**  
  $$
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta'}) \not\le
  \mathrm{KL}(\mathbb{P}_\theta,\mathbb{P}_{\theta''}) +
  \mathrm{KL}(\mathbb{P}_{\theta''},\mathbb{P}_{\theta'})
  \quad \text{(일반적으로)}
  $$
    
    
**그래서 거리가 아니라 발산이라고 불림  
비대칭성은 우리가 추정할 수 있는 능력의 핵심이다.**

---

>**보충설명**
>
>1. **비대칭성: 등호가 성립하지 않는 이유**  
>   - **핵심**  
>     $\mathrm{KL}(P\|Q)=\int p(x)\log\!\frac{p(x)}{q(x)}\,dx$,
>     $\ \mathrm{KL}(Q\|P)=\int q(x)\log\!\frac{q(x)}{p(x)}\,dx$.  
>     서로 **다른 분포로 가중(평균)** 을 취하므로 일반적으로 $\mathrm{KL}(P\|Q)\neq \mathrm{KL}(Q\|P)$ 이다.
>     등호가 성립하려면 보통 $p=q$ (a.e.) 같은 특수한 경우여야 한다.  
>   - **간단 예시(베르누이)**  
>     $P=\mathrm{Bern}(0.2)$, $Q=\mathrm{Bern}(0.5)$이면 $\mathrm{KL}(P\|Q)\approx 0.193$, $\mathrm{KL}(Q\|P)\approx 0.223$로 서로 다르다.
>
>---
>
>2. **비음수성(Non-negativity)**  
>   - **기브스 부등식 증명(볼록성 보강 포함)**  
>   
>     $$\phi(u)=u-1-\log u \quad (u>0)$$  
>
>     1차 미분: $$\phi'(u)=1-\tfrac{1}{u}$$,  
>     2차 미분: $$\phi''(u)=\tfrac{1}{u^2}>0$$.  
>
>     👉 **$\phi''(u)>0$이면 그래프는 ‘아래로 볼록(convex)’**이며, 이는 기울기인 $\phi'(u)$가 **계속 증가**함을 뜻한다.  
>     따라서 $$\phi'(u)=0$$이 되는 $$u=1$$에서 **최솟값**을 갖고, $$\phi(1)=0$$이므로 $$\phi(u)\ge 0$$ (등호는 $$u=1$$에서만).  
>
>     곧,  
>     $$\log u \le u-1 \quad (\text{등호는 } u=1 \text{에서만})$$  
>
>   - **비음수성 증명(부호 반전 단계 추가)**  
>   
>     위 부등식에 $$u=\tfrac{q(x)}{p(x)}$$를 대입하면  
>
>     $$
>     \log\frac{q(x)}{p(x)} \;\le\; \frac{q(x)}{p(x)} - 1
>     $$
>
>     **양변에 $-1$을 곱하면 부호가 바뀌어**  
>
>     $$
>     -\log\frac{q(x)}{p(x)} \;\ge\; 1 - \frac{q(x)}{p(x)}
     \quad\Longleftrightarrow\quad
     \log\frac{p(x)}{q(x)} \;\ge\; 1 - \frac{q(x)}{p(x)}
>     $$
>
>     이제 **양변에 $p(x)$를 곱해** 적분하면  
>
>     $$
>     \int p(x)\log\frac{p(x)}{q(x)}\,dx 
     \;\ge\; 
     \int \big(p(x)-q(x)\big)\,dx
>     $$
>
>     오른쪽은 확률밀도의 총질량이 1이므로  
>
>     $$
>     \int \big(p(x)-q(x)\big)\,dx
     =
     \int p(x)\,dx - \int q(x)\,dx
     = 1-1 = 0
>     $$
>
>     따라서  
>
>     $$
>     \mathrm{KL}(P\|Q)=\int p(x)\log\frac{p(x)}{q(x)}\,dx \;\ge\; 0,
>     $$
>
>     (등호는 거의 어디서나 $$p(x)=q(x)$$일 때만 성립).
>
>---
>
>3. **정확성/정부호성(Definiteness)**  
>   - **핵심**  
>     $\mathrm{KL}(P\|Q)=0 \Longleftrightarrow p(x)=q(x)$ (a.e.).  
>     위 기브스 부등식의 등호 조건이 $u\equiv 1$일 때뿐이므로  
>     $q/p\equiv 1 \Rightarrow p=q$ (거의 어디서나).
>
>---
>
>4. **삼각부등식 불성립(No triangle inequality)**  
>
>   - **핵심**  
>     KL은 한쪽 분포로 가중된 비대칭 발산이라 일반적으로 $\mathrm{KL}(P\|R)\le \mathrm{KL}(P\|Q)+\mathrm{KL}(Q\|R)$가 성립하지 않는다.     
>     
>   - **간단 반례(베르누이)**  
>     $P=\mathrm{Bern}(0.2)$, $Q=\mathrm{Bern}(0.5)$, $R=\mathrm{Bern}(0.8)$이면  
     $\mathrm{KL}(P\|R)\approx 0.832 > 0.193+0.223 \approx 0.416$로 삼각부등식이 깨진다.
>
>---
>
>5. **결론: 거리(distance)가 아니라 발산(divergence)**  
>   - **핵심**  
>     KL은 (i) 비음수, (ii) $=0\Rightarrow P=Q$는 만족하지만,  
>     (iii) **대칭이 아니고**,  
>     (iv) **삼각부등식도 불성립**한다.  
>     따라서 수학적 의미의 거리(metric)가 아니라 **발산(divergence)** 이다.
>
>---
>
>6. **왜 비대칭성이 추정할 수 있는 핵심인가?**  
>
>   - **정의**  
>     참분포의 pdf를 $f(x)$, 모델의 pdf를 $g_\theta(x)$ 라고 하자. > 
>     (이산인 경우에는 $\int$ 대신 $\sum$ 을 쓰면 동일한 내용이다.)
>
>   - **모델을 기준으로 한 거리 (뒤방향 KL)**  
>     $$
>     \mathrm{KL}\big(g_\theta \,\|\, f\big)
     \;=\;\int g_\theta(x)\,\log\!\frac{g_\theta(x)}{f(x)}\,dx
>     $$
>     **왜 어렵나?** 로그 안에 **모르는 참분포의 pdf** $f(x)$가 들어가므로, 보통 **데이터만으로는** 직접 계산/최적화하기 어렵다.   
>     
>     **추가 설명**: $\log f(x)$ 자체는 $\theta$와 무관하지만, 적분 $\int g_\theta(x)\,\log f(x)\,dx$는 **가중치** $g_\theta(x)$ 때문에 **$\theta$의 함수**가 된다. 따라서 앞방향과 달리 ‘상수항’으로 뺄 수 없고, 더구나 $f(x)$를 모르니 값을 구하기도 어렵다.
>
>   - **참분포를 기준으로 한 거리 (앞방향 KL)**  
>     $$
>     \mathrm{KL}\big(f \,\|\, g_\theta\big)
     \;=\;\int f(x)\,\log\!\frac{f(x)}{g_\theta(x)}\,dx
>     $$
>     $$
>     \;=\;\underbrace{\int f(x)\log f(x)\,dx}_{\theta\text{와 무관한 상수}}
     \;-\;\int f(x)\log g_\theta(x)\,dx
>     $$
>     **왜 쉬운가?** 첫 항은 모델 파라미터 $\theta$와 **무관한 상수**라 최적화에서 떨어져 나가고,  
>     두 번째 항은 **데이터 표본** $x_1,\dots,x_n\sim f$로
>     $$
>     \int f(x)\log g_\theta(x)\,dx
     \;\approx\; \frac{1}{n}\sum_{i=1}^n \log g_\theta(x_i)
>     $$
>     처럼 **표본 평균**으로 바로 근사할 수 있다.
>
>   - **정리**  
>     KL의 **비대칭성** 때문에, **앞방향** $\mathrm{KL}(f\|g_\theta)$는 **데이터만으로 쉽게 추정**되지만,  
     **뒤방향** $\mathrm{KL}(g_\theta\|f)$는 **모르는 $f(x)$** 및 가중치 $g_\theta(x)$ 때문에 일반적으로 **추정이 어렵다**.

---

## p10. KL 발산: 예시(1/2)  

**두 정규분포와 가정**  

$$
f_{\theta} = \mathcal{N}(\mu_{1}, \sigma^{2})
$$  

$$
f_{\theta'} = \mathcal{N}(\mu_{2}, \sigma^{2})
$$  

**평균 차이와 기준점**  

$$
\Delta = |\mu_{1} - \mu_{2}|
$$  

$$
m = \frac{\mu_{1} + \mu_{2}}{2}
$$  

---

**수식 전개 과정**  

$$
\mathrm{KL}(\mathbb{P}_{\theta}\,\|\,\mathbb{P}_{\theta'}) 
= \int_{\mathbb{R}} \log\!\left(\frac{d\mathbb{P}_{\theta}}{d\mathbb{P}_{\theta'}}(x)\right)\, d\mathbb{P}_{\theta}(x)
$$  

$$
= \int_{\mathbb{R}} f_{\theta}(x)\, \log\!\left(\frac{f_{\theta}(x)}{f_{\theta'}(x)}\right)\, dx
$$  

$$
= \int_{\mathbb{R}} f_{\theta}(x)\, \frac{(x-\mu_{2})^{2} - (x-\mu_{1})^{2}}{2\sigma^{2}}\, dx
$$  

$$
= \frac{1}{2\sigma^{2}} \int_{\mathbb{R}} f_{\theta}(x)\, \big[(x-\mu_{2})^{2} - (x-\mu_{1})^{2}\big]\, dx
$$  

---

>**보충설명**
>
>1. **두 분포의 가정**  
>
>   - **정의**  
>     같은 분산을 갖는 두 정규분포:
>     $$
>     f_{\theta}=\mathcal{N}(\mu_{1},\sigma^{2}),\qquad
     f_{\theta'}=\mathcal{N}(\mu_{2},\sigma^{2})
>     $$
>   - **표현식**  
>     $$
>     \Delta=\mu_{1}-\mu_{2},\qquad
     m=\frac{\mu_{1}+\mu_{2}}{2}
>     $$
>
>---
>
>2. **KL 정의 → 밀도형식으로 바꾸기**  
>
>   - **표현식**  
>     $$
>     \mathrm{KL}(\mathbb{P}_{\theta}\,\|\,\mathbb{P}_{\theta'})
     = \int \log\!\left(\frac{d\mathbb{P}_{\theta}}{d\mathbb{P}_{\theta'}}(x)\right)\, d\mathbb{P}_{\theta}(x)
>     $$
>     $$
>     = \int f_{\theta}(x)\,\log\!\frac{f_{\theta}(x)}{f_{\theta'}(x)}\,dx.
>     $$
>   - **설명**  
>     연속형에서 $d\mathbb{P}(x)=f(x)\,dx$로 쓸 수 있어 밀도비 형태로 정리된다.
>
>---
>
>3. **정규 pdf 대입 & 상수 소거**  
>
>   - **대입**  
>     $$
>     f_{\mu}(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\!\left(-\frac{(x-\mu)^{2}}{2\sigma^{2}}\right),
>     $$
>     $$
>     \log f_{\mu}(x)= -\frac{1}{2}\log(2\pi\sigma^{2})-\frac{(x-\mu)^{2}}{2\sigma^{2}}.
>     $$
>     같은 $\sigma$이므로 정규화상수는 소거되어
>     $$
>     \log\frac{f_{\mu_{1}}(x)}{f_{\mu_{2}}(x)}
     = \frac{(x-\mu_{2})^{2}-(x-\mu_{1})^{2}}{2\sigma^{2}}.
>     $$
>
>---
>
>4. **KL 전개 연결**  
>
>   - **표현식**  
>     $$
>     \mathrm{KL}(\mathbb{P}_{\theta}\,\|\,\mathbb{P}_{\theta'})
     = \int f_{\theta}(x)\,\log\!\frac{f_{\theta}(x)}{f_{\theta'}(x)}\,dx
>     $$
>     $$
>     = \int f_{\theta}(x)\,\frac{(x-\mu_{2})^{2}-(x-\mu_{1})^{2}}{2\sigma^{2}}\,dx
>     $$
>     $$
>     = \frac{1}{2\sigma^{2}}\!\int f_{\theta}(x)\,\big[(x-\mu_{2})^{2}-(x-\mu_{1})^{2}\big]\,dx.
>     $$

---

> **comment**  
>  
> - 자연 현상은 최대엔트로피 원리와 확산·열 등 미분방정식의 해 때문에 지수꼴(Exponential) 분포가 자주 나타난다.  
> - KL에서 로그를 사용하면 곱이 합으로 바뀌고 밀도비의 정규화상수가 소거되어 계산이 단순해진다.  
> - 두 가우시안의 KL에서는 지수항이 사라져 이차식 차이만 남고 평균 성질을 이용해 쉽게 적분된다.  
> - 동일 분산인 경우 KL은 평균 차이의 제곱에 비례하는 단순한 닫힌형식이 되어 실전 계산이 수월하다.

---

## p11. KL 발산: 예시(2/2)

$$
\mathrm{KL}(\mathbb{P}_{\theta}\,\|\,\mathbb{P}_{\theta'})
= \frac{1}{2\sigma^{2}} \int_{\mathbb{R}} f_{\theta}(x)\,\big[2(\mu_{1}-\mu_{2})x+\mu_{2}^{2}-\mu_{1}^{2}\big]\,dx
$$

$$
= \frac{1}{2\sigma^{2}}
\left[
2(\mu_{1}-\mu_{2})\int_{\mathbb{R}} x\,f_{\theta}(x)\,dx
\;+\;
(\mu_{2}^{2}-\mu_{1}^{2})\int_{\mathbb{R}} f_{\theta}(x)\,dx
\right]
$$

$$
= \frac{1}{2\sigma^{2}}\big[\,2(\mu_{1}-\mu_{2})\mu_{1}+(\mu_{2}^{2}-\mu_{1}^{2})\,\big]
$$

$$
= \frac{(\mu_{1}-\mu_{2})^{2}}{2\sigma^{2}}
= \frac{\Delta^{2}}{2\sigma^{2}}
$$

---

>**보충설명**
>
>1. **제곱 전개**  
>   - **출발식**  
>     $$
>     \log\frac{f_{\mu_1}(x)}{f_{\mu_2}(x)}
     = \frac{(x-\mu_2)^2-(x-\mu_1)^2}{2\sigma^2}.
>     $$
>   - **전개(직접 전개)**  
>     $$
>     (x-\mu_2)^2-(x-\mu_1)^2
>     $$
>     $$
>     = (x^2-2\mu_2 x+\mu_2^2)-(x^2-2\mu_1 x+\mu_1^2)
>     $$
>     $$
>     = 2(\mu_1-\mu_2)x+(\mu_2^2-\mu_1^2).
>     $$
>
>2. **KL에 대입**  
>   - **표현식**  
>     $$
>     \mathrm{KL}(\mathbb{P}_{\theta}\|\mathbb{P}_{\theta'})
     = \int_{\mathbb{R}} f_{\theta}(x)\,
       \log\frac{f_{\mu_1}(x)}{f_{\mu_2}(x)}\,dx
>     $$
>     $$
>     = \frac{1}{2\sigma^{2}} \int_{\mathbb{R}} f_{\theta}(x)\,
       \big[2(\mu_{1}-\mu_{2})x+\mu_{2}^{2}-\mu_{1}^{2}\big]\,dx.
>     $$
>
>3. **적분의 선형성(상수 인출, 항별 분리)**  
>   $$
>   = \frac{1}{2\sigma^{2}}
     \left\{
       2(\mu_{1}-\mu_{2})\!\int_{\mathbb{R}} x\,f_{\theta}(x)\,dx
       + (\mu_{2}^{2}-\mu_{1}^{2})\!\int_{\mathbb{R}} f_{\theta}(x)\,dx
     \right\}.
>   $$
>
>4. **평균과 전체질량 사용**  
>   - **사실** $f_{\theta}=\mathcal{N}(\mu_1,\sigma^2)$ 이므로 > 
>     $$
>     \int_{\mathbb{R}} f_{\theta}(x)\,dx = 1,\qquad
     \int_{\mathbb{R}} x\,f_{\theta}(x)\,dx = \mu_{1}.
>     $$
>   - **대입**  
>     $$
>     = \frac{1}{2\sigma^{2}}
       \Big[\,2(\mu_{1}-\mu_{2})\mu_{1}+(\mu_{2}^{2}-\mu_{1}^{2})\,\Big].
>     $$
>
>5. **대수 정리(단순화)**  
>   $$
>   2(\mu_{1}-\mu_{2})\mu_{1}+(\mu_{2}^{2}-\mu_{1}^{2})
>   $$
>   $$
>   = \mu_1^2-2\mu_1\mu_2+\mu_2^2
   = (\mu_1-\mu_2)^2.
>   $$
>
>6. **최종식**  
>   $$
>   \mathrm{KL}(\mathbb{P}_{\theta}\|\mathbb{P}_{\theta'})
   = \frac{(\mu_{1}-\mu_{2})^{2}}{2\sigma^{2}}
   = \frac{\Delta^{2}}{2\sigma^{2}},\qquad \Delta=|\mu_{1}-\mu_{2}|.
>   $$

---

## p12. MLE

**Maximum Likelihood Estimation**

$$
\mathrm{KL}(\mathbb{P}_{\theta^\ast}, \mathbb{P}_\theta)
= \mathbb{E}_{\theta^\ast}\!\left[\log \frac{p_{\theta^\ast}(X)}{p_\theta(X)}\right]
$$
$$
= \mathbb{E}_{\theta^\ast}[\log p_{\theta^\ast}(X)]
\;-\; \mathbb{E}_{\theta^\ast}[\log p_\theta(X)] .
$$

따라서 함수 $\theta \mapsto \mathrm{KL}(\mathbb{P}_{\theta^\ast}, \mathbb{P}_\theta)$는 다음 형태이다:
$$
\text{“constant”} \;-\; \mathbb{E}_{\theta^\ast}[\log p_\theta(X)] .
$$

대수의 법칙(LLN)에 의해 다음과 같이 추정할 수 있다.
$$
\mathbb{E}_{\theta^\ast}[h(X)] \;\sim\; \frac{1}{n}\sum_{i=1}^{n} h(X_i).
$$

$$
\widehat{\mathrm{KL}}(\mathbb{P}_{\theta^\ast}, \mathbb{P}_\theta)
= \text{“constant”} \;-\; \frac{1}{n}\sum_{i=1}^{n}\log p_\theta(X_i) .
$$

---

>**보충설명**
>
>1. **왜 $\mathbb{E}_{\theta^\ast}[\cdot]$ 인가? (KL의 가중)** > 
>
>   - **정의**  
>     KL은 **첫 번째 분포로 가중한 평균**이다:
>     $$
>     \mathrm{KL}(P\|Q)=\int \log\!\left(\frac{dP}{dQ}\right)\,dP.
>     $$
>     즉, 괄호 안 함수를 **$P$에 대해 평균**낸다는 뜻이다.
>
>   - **연속형 표현**  
>     밀도 $p_{\theta^\ast},\,p_{\theta}$가 있으면
>     $$
>     \mathrm{KL}(\mathbb{P}_{\theta^\ast}\,\|\,\mathbb{P}_{\theta})
     = \int p_{\theta^\ast}(x)\,\log\!\frac{p_{\theta^\ast}(x)}{p_{\theta}(x)}\,dx.
>     $$
>
>   - **기대값으로 쓰기**  
>     기대값 정의 $\mathbb{E}_{\theta^\ast}[g(X)] = \int g(x)\,p_{\theta^\ast}(x)\,dx$을
>     $$
>     g(x)=\log\!\frac{p_{\theta^\ast}(x)}{p_{\theta}(x)}
>     $$
>     에 적용하면
>     $$
>     \mathrm{KL}(\mathbb{P}_{\theta^\ast}\,\|\,\mathbb{P}_{\theta})
     = \mathbb{E}_{\theta^\ast}\!\left[\log\!\frac{p_{\theta^\ast}(X)}{p_{\theta}(X)}\right]
>     $$
>     $$
>     = \mathbb{E}_{\theta^\ast}[\log p_{\theta^\ast}(X)]-\mathbb{E}_{\theta^\ast}[\log p_{\theta}(X)].
>     $$
>
>   - **(참고: 이산형)**  
>     $$
>     \mathrm{KL}(\mathbb{P}_{\theta^\ast}\,\|\,\mathbb{P}_{\theta})
     = \sum_x p_{\theta^\ast}(x)\,\log\!\frac{p_{\theta^\ast}(x)}{p_{\theta}(x)}
>     $$
>     $$
>     = \mathbb{E}_{\theta^\ast}\!\left[\log\!\frac{p_{\theta^\ast}(X)}{p_{\theta}(X)}\right].
>     $$
>
>   - **정리**  
>     KL의 첫 번째 인자(여기서는 $\mathbb{P}_{\theta^\ast}$)가 **가중(표본을 제공하는 분포)** 이므로 자연스럽게 $\mathbb{E}_{\theta^\ast}[\cdot]$가 된다.
>
>---
>
>2. **왜 $\mathbb{E}_{\theta^\ast}[\log p_{\theta^\ast}(X)]$는 상수인가?**  
>
>- **정의**  
>  기대값 $\mathbb{E}_{\theta^\ast}[\cdot]$는 분포 $\mathbb{P}_{\theta^\ast}$에 대해 계산되고, 적분 함수 $\log p_{\theta^\ast}(X)$ 역시 $\theta^\ast$로만 정해진다.
>
>- **이유**  
>  우리가 최적화하는 변수는 $\theta$이며, 항 $\mathbb{E}_{\theta^\ast}[\log p_{\theta^\ast}(X)]$ 안에는 $\theta$가 전혀 등장하지 않는다. 따라서
>  $$
>  C:=\mathbb{E}_{\theta^\ast}[\log p_{\theta^\ast}(X)]
>  $$
>  는 $\theta$의 값과 무관한 **상수**이다.
>
>- **결론(분해식과 연결)**  
>  $$
>  \mathrm{KL}(\mathbb{P}_{\theta^\ast}\,\|\,\mathbb{P}_\theta)
  =\underbrace{\mathbb{E}_{\theta^\ast}[\log p_{\theta^\ast}(X)]}_{\text{const.}}
  -\mathbb{E}_{\theta^\ast}[\log p_\theta(X)]\,.
>  $$

---

> **comment**  
>  
> - $\widehat{\mathrm{KL}}$은 KL을 직접 구하기 어려울 때 데이터를 이용해 근사하는 **KL의 추정량**이다.

---

## p13. 함수의 최대화/최소화

**다음 동치가 성립한다.**
$$
\min_{\theta\in\Theta}\big(-h(\theta)\big)\;\Longleftrightarrow\;\max_{\theta\in\Theta} h(\theta).
$$

$$
\Downarrow
$$

**이 수업에서는 최대화에 초점을 맞춘다.**

$$
\arg\min_{\theta\in\Theta}\!\left(\,-\sum_{i=1}^{n}\log p_{\theta}(x_i)\right)
\;\Longleftrightarrow\;
\arg\max_{\theta\in\Theta}\sum_{i=1}^{n}\log p_{\theta}(x_i).
$$

---

> **comment**  
>  
> - 수학에서는 음의 부호가 붙은 최소화 문제를 동치인 최대화 문제로 바꾸어 다루는 편이 더 단순해 선호된다.  
> - 학습은 목적함수를 최대화하여 최적의 매개변수 $\theta$를 찾는 과정이다.

---

## p14. 단변수 함수의 최대화/최소화

**정의**  
두 번 미분 가능한 함수 $h:\Theta\subset\mathbb{R}\to\mathbb{R}$가 다음을 만족하면 **concave (오목)** 라고 한다:
$$
h''(\theta)\le 0,\quad \forall\,\theta\in\Theta.
$$
부등식이 엄격하면 **strictly concave (엄격히 오목)** 라고 한다:
$$
h''(\theta)<0.
$$
또한 $-h$가 (strictly) concave이면 $h$를 (strictly) **convex**라 하며, 이는 곧
$$
h''(\theta)\ge 0\ \big(h''(\theta)>0\big).
$$

**예시**  
- $\Theta=\mathbb{R},\quad h(\theta)=-\theta^{2}$
- $\Theta=(0,\infty),\quad h(\theta)=\sqrt{\theta}$
- $\Theta=(0,\infty),\quad h(\theta)=\log\theta$
- $\Theta=[0,\pi],\quad h(\theta)=\sin\theta$
- $\Theta=\mathbb{R},\quad h(\theta)=2\theta-3$

---

>**보충설명**
>
>1. **concave(오목)의 정의와 직관**  
>   - 두 번 미분 가능한 함수 $h:\Theta\to\mathbb{R}$가 $h''(\theta)\le 0$를 만족하면 **concave**라 한다.  
>   - $h''(\theta)<0$이면 **strictly concave**라 한다.  
>   - 직관적으로, 임의의 점에서의 **접선**은 그래프 **위쪽**에 있고, 두 점을 이은 **현**은 그래프 **아래**에 놓인다.
>
>2. **판별법(실무용)**  
>   - 정의역 $\Theta$에서 $h''(\theta)$를 계산하여 $\le 0$(또는 $<0$)인지 확인한다.  
>   - 선형함수는 $h''(\theta)=0$이므로 concave이면서 convex이기도 하다.
>
>3. **최적화와의 관계**  
>   - concave 함수에서 임계점 $h'(\theta)=0$은 전역 최댓값이 된다.  
>   - strictly concave이면 그 전역 최댓값은 유일하다.
>
>4. **슬라이드의 예시 점검**  
>   - $h(\theta)=-\theta^2$ \,(정의역 $\mathbb{R}$): $h''(\theta)=-2<0$이므로 **strictly concave**이다.  
>   - $h(\theta)=\sqrt{\theta}$ \,(정의역 $(0,\infty)$): $h''(\theta)=-\tfrac{1}{4}\theta^{-3/2}<0$이므로 **strictly concave**이다.  
>   - $h(\theta)=\log\theta$ \,(정의역 $(0,\infty)$): $h''(\theta)=-\theta^{-2}<0$이므로 **strictly concave**이다.  
>   - $h(\theta)=\sin\theta$ \,(정의역 $[0,\pi]$): $h''(\theta)=-\sin\theta\le 0$이므로 이 구간에서 **concave**이다(열린 구간에서는 strictly).  
>   - $h(\theta)=2\theta-3$ \,(정의역 $\mathbb{R}$): $h''(\theta)=0$이므로 **선형**이며 concave이면서 convex이다.
>
>5. **정의역 주의**  
>   - concavity는 **정의역에 따라 달라질 수 있다**. 예컨대 $\sin\theta$는 $[0,\pi]$에서는 concave이지만 다른 구간에서는 그렇지 않을 수 있다.

---

> **comment**  
>  
> - 목적함수가 **(strictly) convex**이면 모든 국소 최소점이 전역 최소점이며, **strictly convex**일 때 전역 최소해가 **유일**하다. 적절한 조건(학습률 등) 하에서 **gradient descent**는 그 전역 최소해로 수렴한다.  
> - $h''(\theta)<0$이면 함수는 **concave**(∩ 모양)이고, $h''(\theta)>0$이면 **convex**(∪ 모양)이다.  
> - 실제 문제에서는 $h(\theta)$의 **이차 미분**이 복잡하거나 존재하지 않을 수 있다. 이때는 1차 정보(기울기)만 쓰는 방법, 서브그래디언트, 또는 알려진 볼록/오목 성질을 활용하는 편이 실용적이다.

---

## p15. 다변수 함수의 최대화/최소화

**더 일반적으로 다변수 함수에 대해:**  
$h:\Theta\subset\mathbb{R}^{d}\to\mathbb{R}$, $d\ge 2$ 에 대하여 다음을 정의한다.

- **그래디언트 벡터 (gradient vector)**  
  $$
  \nabla h(\theta)=
  \begin{pmatrix}
  \dfrac{\partial h}{\partial \theta_{1}}(\theta)\\[2pt]
  \vdots\\[2pt]
  \dfrac{\partial h}{\partial \theta_{d}}(\theta)
  \end{pmatrix}
  \in \mathbb{R}^{d}
  $$

- **헤시안 행렬 (Hessian matrix)**  
  $$
  \nabla^{2}h(\theta)=
  \begin{pmatrix}
  \dfrac{\partial^{2}h}{\partial \theta_{1}\partial \theta_{1}}(\theta) & \cdots & \dfrac{\partial^{2}h}{\partial \theta_{1}\partial \theta_{d}}(\theta)\\
  \vdots & \ddots & \vdots\\
  \dfrac{\partial^{2}h}{\partial \theta_{d}\partial \theta_{1}}(\theta) & \cdots & \dfrac{\partial^{2}h}{\partial \theta_{d}\partial \theta_{d}}(\theta)
  \end{pmatrix}
  \in \mathbb{R}^{d\times d}
  $$

**concave/strictly concave의 조건**  
$$
h\ \text{is concave}\ \Longleftrightarrow\ x^{\top}\!\nabla^{2}h(\theta)\,x \le 0,\quad \forall x\in\mathbb{R}^{d},\ \theta\in\Theta.
$$
$$
h\ \text{is strictly concave}\ \Longleftrightarrow\ x^{\top}\!\nabla^{2}h(\theta)\,x < 0,\quad \forall x\in\mathbb{R}^{d},\ \theta\in\Theta.
$$

**예시**  
- $\Theta=\mathbb{R}^{2},\; h(\theta)=-\theta_{1}^{2}-2\theta_{2}^{2}$ 또는 $h(\theta)=-(\theta_{1}-\theta_{2})^{2}$  
- $\Theta=(0,\infty),\; h(\theta)=\log(\theta_{1}+\theta_{2})$

---

>**보충설명**
>
>1. **그래디언트·헤시안과 방향 도함수**  
>
>   0) 준비: 변수와 방향  
>   우리는 스칼라 값을 출력하는 다변수 함수 $h:\mathbb{R}^d \to \mathbb{R}$를 생각한다.  
>   입력은 $d$-차원 벡터 $\theta=(\theta_1,\theta_2,\dots,\theta_d)$이다.  
>   그리고 방향을 나타내는 또 다른 벡터 $x=(x_1,x_2,\dots,x_d)$를 잡는다.  
>   👉 “점 $\theta$에서 방향 $x$로 조금 움직여 보면 함수 값이 어떻게 변하는가?”를 알고자 한다.  
>
>   1) 방향 미분을 왜 하는가?  
>   다변수 함수는 모든 축과 모든 방향에서 달라지므로 한 번에 변화를 이해하기 어렵다.  
>   그래서 특정한 방향 $x$를 골라 그 방향으로만 함수를 잘라 1변수 함수처럼 보는 것이 편리하다.  
>   예: 산 위에서 “동쪽으로 걸어갈 때 경사가 얼마나 될까?”, “동북쪽 대각선으로 걸어가면 경사가 얼마나 될까?” → 이것이 방향 도함수이다.  
>
>   2) 방향 함수 정의  
>   방향 $x$로만 움직이는 보조 함수 $g(t)$를 정의한다:  
>   $$
>   g(t) = h(\theta + t x), \quad t \in \mathbb{R}.
>   $$  
>   $t=0$: 출발점 $\theta$  
>   $t$가 커짐: 방향 $x$로 이동한 점  
>   따라서 $g(t)$는 단순한 1변수 함수가 된다.  
>
>   3) 1차 미분: 방향 기울기  
>   $g(t)$를 $t$에 대해 미분하면  
>   $$
>   g'(t) = \frac{d}{dt}h(\theta+tx).
>   $$  
>   각 변수 편미분에 대해 체인룰을 적용하면  
>   $$
>   g'(t) = \sum_{i=1}^d 
   \frac{\partial h}{\partial \theta_i}(\theta+tx)\,
   \frac{d}{dt}(\theta_i+t x_i).
>   $$  
>   여기서 $\frac{d}{dt}(\theta_i+t x_i)=x_i$이므로  
>   $$
>   g'(t) = \sum_{i=1}^d \frac{\partial h}{\partial \theta_i}(\theta+tx)\, x_i.
>   $$  
>   이 식은 벡터 내적 꼴로  
>   $$
>   g'(t) = \nabla h(\theta+tx)\cdot x
>   $$  
>   로 정리된다.  
>
>   👉 그래디언트  
>   $$
>   \nabla h(\theta)=
   \begin{bmatrix}
   \frac{\partial h}{\partial \theta_1} \\
   \vdots \\
   \frac{\partial h}{\partial \theta_d}
   \end{bmatrix}
 >  $$  
 >  는 각 변수 축 방향 기울기를 모은 벡터이다.  
 >  따라서 내적 $\nabla h \cdot x$는 “방향 $x$로 움직일 때 함수가 얼마나 변하는지”를 뜻한다.  
>
>   4) 2차 미분: 방향 곡률  
>   다시 미분하면  
>   $$
>   g''(t) = \frac{d}{dt}\big(\nabla h(\theta+tx)\cdot x\big).
>   $$  
>   성분별로 전개하면  
>   $$
>   g''(t) = \sum_{i=1}^d 
   \left(\frac{d}{dt}\Big(\frac{\partial h}{\partial \theta_i}(\theta+tx)\Big)\right) x_i.
>   $$  
>
>   5) 각 변수 편미분에 체인룰 적용  
>   여기서$\frac{\partial h}{\partial \theta_i}(\theta+tx)$는 여전히 $d$-변수 함수이므로, 다시 체인룰을 적용한다:  
>   $$
>   \frac{d}{dt}\left(\frac{\partial h}{\partial \theta_i}(\theta+tx)\right)
   = \sum_{j=1}^d 
   \frac{\partial}{\partial \theta_j}\left(\frac{\partial h}{\partial \theta_i}\right)(\theta+tx)\,
   \frac{d}{dt}(\theta_j+tx_j).
>   $$  
>
>   여기서  
>   $$\frac{\partial}{\partial \theta_j}\left(\frac{\partial h}{\partial \theta_i}\right) 
      = \frac{\partial^2 h}{\partial \theta_j \partial \theta_i}, \frac{d}{dt}(\theta_j+tx_j)=x_j$$  
>
>   따라서  
>   $$
>   \frac{d}{dt}\left(\frac{\partial h}{\partial \theta_i}(\theta+tx)\right)
   = \sum_{j=1}^d 
   \frac{\partial^2 h}{\partial \theta_j \partial \theta_i}(\theta+tx)\, x_j.
>   $$  
>
>   6) 다시 대입  
>   이를 $g''(t)$에 넣으면:  
>   $$
>   g''(t) = \sum_{i=1}^d 
   \left(\sum_{j=1}^d 
   \frac{\partial^2 h}{\partial \theta_j \partial \theta_i}(\theta+tx)\, x_j
   \right) x_i.
>   $$  
>   정리하면  
>   $$
>   g''(t) = \sum_{i=1}^d \sum_{j=1}^d 
   \frac{\partial^2 h}{\partial \theta_j \partial \theta_i}(\theta+tx)\, x_i x_j.
>   $$  
>
>   7) 행렬 꼴: 헤시안  
>   위 식에 등장한 2차 편미분들을 행렬로 모으면 헤시안 행렬이다:  
>   $$
>   \nabla^2 h(\theta) =
   \begin{bmatrix}
   \frac{\partial^2 h}{\partial \theta_1^2} & \cdots & \frac{\partial^2 h}{\partial \theta_1 \partial \theta_d} \\
   \vdots & \ddots & \vdots \\
   \frac{\partial^2 h}{\partial \theta_d \partial \theta_1} & \cdots & \frac{\partial^2 h}{\partial \theta_d^2}
   \end{bmatrix}.
>   $$  
>   따라서  
>   $$
>   g''(t) = x^\top \nabla^2 h(\theta+tx)\, x.
>   $$  
>   특히 $t=0$일 때  
>   $$
>   g''(0) = x^\top \nabla^2 h(\theta)\, x.
>   $$  
>
>   8) 요약과 직관  
>   - $\nabla h(\theta)$: 모든 축 방향의 기울기를 모은 벡터  
>   - $\nabla h(\theta)\cdot x$: 방향 $x$로 본 순간 기울기  
>   - $\nabla^2 h(\theta)$: 모든 축·쌍방향의 곡률을 모은 행렬  
>   - $x^\top \nabla^2 h(\theta)x$: 방향 $x$로 본 순간 곡률  
>
>   👉 결국 방향 미분은 “다변수 함수 그래프를 1차원 단면 곡선으로 잘라보는 방법”이며, 그 결과는 그래디언트와 헤시안이라는 벡터/행렬 연산으로 깔끔히 표현된다.  
>
>---
>
>2. **concave / strictly concave와 방향 2차 도함수의 관계**  
>
>   - **정의**  
>     다변수 함수 $h:\Theta \subset \mathbb{R}^d \to \mathbb{R}$가 **concave**라는 것은 모든 $\theta \in \Theta$와 모든 방향 $x \in \mathbb{R}^d$에 대해  
>     $$
>     x^\top \nabla^2 h(\theta)\, x \leq 0
>     $$  
>     가 성립하는 것을 의미한다.  
>     만약 부등식이 항상 엄격히 성립한다면  
>     $$
>     x^\top \nabla^2 h(\theta)\, x < 0
>     $$  
>     이고, 이 경우 **strictly concave**라 한다.  
>
>   - **의미**  
>     $x^\top \nabla^2 h(\theta) x$는 $\theta$에서 방향 $x$로 잘라본 2차 도함수(방향 곡률)이다.  
>     따라서 concave 조건은 “모든 방향에서 함수의 곡률이 0 이하”임을 뜻하고, strictly concave 조건은 “항상 음의 곡률을 가진다”는 뜻이다.  
>
>   - **정리**  
>     즉, concave 함수는 모든 방향으로 볼 때 그래프가 위로 볼록하게 휘어져 있고(flat하거나 휘어짐), strictly concave 함수는 항상 위로 볼록하게 휘어져 있어서 극댓값이 유일하게 존재한다.  
>
>3. **예시 해석**  
>
>   - **예시 1:**  
>     $$
>     h(\theta) = -\theta_1^2 - 2\theta_2^2, \quad \Theta = \mathbb{R}^2
>     $$  
>     이 함수의 헤시안은  
>     $$
>     \nabla^2 h(\theta) =
     \begin{bmatrix}
     -2 & 0 \\
     0 & -4
     \end{bmatrix}.
>     $$  
>     임의의 $x=(x_1,x_2)$에 대해  
>     $$
>     x^\top \nabla^2 h(\theta)x = -2x_1^2 - 4x_2^2 < 0
>     $$  
>     이므로 $h$는 **strictly concave**이다.  
>
>   - **예시 2:**  
>     $$
>     h(\theta) = -(\theta_1 - \theta_2)^2, \quad \Theta = \mathbb{R}^2
>     $$  
>     이 함수의 헤시안은  
>     $$
>     \nabla^2 h(\theta) =
     \begin{bmatrix}
     -2 & 2 \\
     2 & -2
     \end{bmatrix}.
 >    $$  
 >    방향 도함수로 확인하면, 임의의 $x=(x_1,x_2)$에 대해  
 >    $$
 >    x^\top \nabla^2 h(\theta)x = -2x_1^2 + 4x_1x_2 - 2x_2^2
     = -2(x_1 - x_2)^2 \leq 0.
 >    $$  
 >    특히 $x_1=x_2$인 방향에서는 $x^\top \nabla^2 h(\theta)x=0$이 된다.  
 >    따라서 이 함수는 **concave**이지만 **strictly concave**는 아니다.  
>
>   - **예시 3:**  
>     $$
>     h(\theta) = \log(\theta_1+\theta_2), \quad \Theta=(0,\infty)^2
>     $$  
>     이 함수의 헤시안은  
>     $$
>     \nabla^2 h(\theta) =
     -\frac{1}{(\theta_1+\theta_2)^2}
     \begin{bmatrix}
     1 & 1 \\
     1 & 1
     \end{bmatrix}.
>     $$  
>     임의의 $x$에 대해  
>     $$
>     x^\top \nabla^2 h(\theta)x = -\frac{(x_1+x_2)^2}{(\theta_1+\theta_2)^2} \leq 0,
>     $$  
>     이므로 concave 함수임을 알 수 있다. 또한 특정 방향($x_1=-x_2$)에서는 $0$이 되므로 strictly concave는 아니다.  
>
>   - **정리**  
>     위의 예시들은 concavity 조건을 방향 2차 도함수 $x^\top \nabla^2 h(\theta)x$로 직접 확인할 수 있음을 보여준다.  
>
>---
>
>4. **왜 $t=0$에서의 방향 2차 도함수로 concavity를 판단하는가?**  
>
>- **기본 아이디어**  
>  방향 함수 $g(t) = h(\theta + tx)$를 정의하면,  
>  $$
>  g''(0) = x^\top \nabla^2 h(\theta)\, x
>  $$  
>  가 성립한다. 즉, $\theta$라는 점에서 방향 $x$로 잘라본 단면 곡선의 곡>률을 나타낸다.  
>
>- **왜 $t=0$인가?**  
>  $t=0$은 단면 곡선을 $\theta$에서 출발할 때의 위치이다.  
>  concavity 여부는 “모든 점 $\theta$에서, 모든 방향 $x$에 대해 그래프가 위로 볼록한가?”를 묻는 것이므로,  
>  출발점 $\theta$에서의 곡률만 보면 충분하다.  
>  $t \neq 0$을 넣으면 이미 $\theta$에서 벗어난 다른 점 $\theta'=\theta+tx$에서의 곡률을 보는 것이고,  
>  그 점에서의 concavity는 다시 $\theta'$를 기준으로 같은 조건을 확인해야 한다.  
>
>- **직관**  
>  1변수 함수에서는  
>  $$
>  \text{concave} \;\;\Longleftrightarrow\;\; f''(x) \leq 0 \quad (\text{모든 } x \text{에 대해})
>  $$  
>  라고 한다.  
>
>  다변수 함수도 마찬가지로, 어떤 점 $\theta$에서 concavity를 보려면  
  그 점을 통과하는 모든 방향 $x$의 곡률이 0 이하임을 확인하면 된다.  
>
>  따라서 $g(t)=h(\theta+tx)$를 잡아  
>  $$
>  g''(0) \leq 0
>  $$  
>  인지 확인하는 것이다.  
>
>- **정리**  
>  $$
>  g''(0) = x^\top \nabla^2 h(\theta)x
>  $$  
>  는 “점 $\theta$에서 방향 $x$로 본 국소 곡률”이다.  
>  이 값이 모든 $x$에 대해 $\leq 0$이면, $\theta$에서 함수는 concave하다.  

---

## p16. Convex / Concave 함수 예시  

왼쪽 그림은 Convex 함수의 예시로 $z = x^{2} + y^{2}$,  
오른쪽 그림은 Concave 함수의 예시로 $z = -x^{2} - y^{2} + 1$을 나타낸다.  

<img src="/assets/img/probstat/3/image_4.png" alt="image" width="600px">

---

>**보충설명**
>
>- **Convex function (볼록 함수)**  
>  그래프가 위로 열린 그릇 모양으로, 어떤 두 점을 잡아도 그 사이를 잇는 직선이 함수 위에 놓인다.  
>  헤시안 행렬은 양의 정부호(positive definite)로, 모든 방향 2차 도함수 $x^\top \nabla^2 h(\theta)x \geq 0$ 이다.  
>  따라서 최소점을 가지며, 그림에서 바닥의 검은 점이 극솟값을 나타낸다.  
>
>- **Concave function (오목 함수)**  
>  그래프가 뒤집힌 그릇 모양으로, 어떤 두 점을 잡아도 그 사이를 잇는 직선이 함수 아래에 놓인다.  
>  헤시안 행렬은 음의 정부호(negative definite)로, 모든 방향 2차 도함수 $x^\top \nabla^2 h(\theta)x \leq 0$ 이다.  
>  따라서 최대점을 가지며, 그림에서 꼭대기의 검은 점이 극댓값을 나타낸다.  
>
>- **정리**  
>  Convex 함수는 최적화 문제에서 최소화 성질을,  
>  Concave 함수는 최대화 성질을 설명할 때 중요한 예시가 된다.  

---

## p17. 함수의 최대화/최소화  

strictly concave 함수는 최대화하기 쉽다. **최대값이 존재한다면 그것은 유일(unique)하다.**  
이는 다음 조건의 **유일한 해**로 주어진다.  

- 1차원 함수의 경우:  
$$
h'(\theta) = 0
$$  

- 다변수 함수의 경우:  
$$
\nabla h(\theta) = 0 \;\;\in \mathbb{R}^d
$$  

수치적으로 해를 찾기 위한 알고리즘이 많이 존재하며, 이는 **convex optimization** 이론에 속한다.  
이번 수업에서는 최대값이 닫힌 형태(closed form formula)로 표현되는 경우가 자주 등장한다.  

---

>**보충설명**  
>  
>위 조건은 그래디언트가 0인 점(= stationary point)을 찾는 것이고, 이때 헤시안의 부호가 그 점이 최대값인지 최소값인지를 판별한다.  
>- 헤시안이 음의 정부호(negative definite) → 해당 점은 최대값.  
>- 헤시안이 양의 정부호(positive definite) → 해당 점은 최소값.  
>따라서 strictly concave 함수에서는 stationary point가 존재하면 그것이 곧 유일한 최대값이 된다.  
  
---
  
## p18. 통계모델의 우도  
  
  
$(E, (\mathbb{P}_\theta)_{\theta \in \Theta})$를 i.i.d.인 확률변수 $X_{1}, \dots, X_{n}$의 표본과 연관된 통계모델이라고 하자.  
$E$는 이산(discrete) 집합(유한 혹은 가산)이라고 가정한다.  

**정의**  

모델의 우도(likelihood)는 다음과 같이 정의된 사상(map) $L_{n}$ (또는 간단히 $L$) 이다.  

$$
\begin{array}{rcl}
L_{n} & : & \;\;\;\;\;\;\;\;\; E^{n} \times \Theta \;\to\; \mathbb{R} \\
      &   & (x_{1}, \dots, x_{n}, \theta) \;\mapsto\; \mathbb{P}_{\theta}[X_{1} = x_{1}, \dots, X_{n} = x_{n}]
\end{array}
$$

---

>**보충설명**  
>
>- 위 식은 i.i.d. 표본 $(X_{1}, \dots, X_{n})$이 실제로 특정 값 $(x_{1}, \dots, x_{n})$을 관측했을 때,  
>  그 사건이 모수 $\theta$ 하에서 일어날 확률을 함수로 나타낸 것이다.  
>
>- 즉, $L_{n}$은 **입력**으로 표본 데이터 $(x_{1}, \dots, x_{n})$와 모수 $\theta$를 받고,  
>  **출력**으로 해당 표본이 $\theta$ 하에서 관측될 확률 $\mathbb{P}_{\theta}[X_{1}=x_{1}, \dots, X_{n}=x_{n}]$을 돌려준다.  
>
>- 확률분포의 관점에서 보면 $L_{n}$은 $\theta$의 함수가 아니라 데이터 $(x_{1}, \dots, x_{n})$의 함수처럼 보이지만,  
>  **통계학에서는 표본을 고정된 값으로 보고 $\theta$를 변수로 취급**한다. > 
>  이때 $L_{n}(\theta)$를 **우도(likelihood)**라고 부른다.  
>
>- 따라서 우도함수는 “어떤 모수 $\theta$가 주어졌을 때, 실제 관측된 데이터가 나올 가능성이 얼마나 높은가”를 정량화한 함수이다.  

---

## p19. 가우시안 모델의 우도  

예제 1 (가우시안 모델):  
만약 $X_{1}, \dots, X_{n} \overset{iid}{\sim} \mathcal{N}(\mu, \sigma^{2})$, some $\mu \in \mathbb{R}, \ \sigma^{2} > 0$라 하자.  

- $E = \mathbb{R}$  
- $\Theta = \mathbb{R} \times (0, \infty)$  
- $\forall (x_{1}, \dots, x_{n}) \in \mathbb{R}^{n}, \ \forall (\mu, \sigma^{2}) \in \mathbb{R} \times (0, \infty)$,  
  $$
  L(x_{1}, \dots, x_{n}, \mu, \sigma^{2}) 
  = \frac{1}{(\sigma \sqrt{2\pi})^{n}} 
  \exp \left( -\frac{1}{2\sigma^{2}} \sum_{i=1}^{n} (x_{i} - \mu)^{2} \right).
  $$

---

>**보충설명**
>
>- $X_{1}, \dots, X_{n} \overset{iid}{\sim} \mathcal{N}(\mu, \sigma^{2})$라는 것은 각 표본 $X_{i}$가 평균 $\mu$, 분산 $\sigma^{2}$인 정규분포를 따르며, 서로 독립이고 동일한 분포(i.i.d.)라는 의미이다.  
>
>- 확률 공간은 $E = \mathbb{R}$, 모수 공간은 $\Theta = \mathbb{R} \times (0,\infty)$이다.  
  여기서 $\mu \in \mathbb{R}$, $\sigma^{2} \in (0,\infty)$로 주어진다.  
>
>- 정규분포의 확률밀도함수(pdf)는  
>  $$
>  f(x \mid \mu, \sigma^{2}) = \frac{1}{\sigma \sqrt{2\pi}} 
  \exp\left( -\frac{(x - \mu)^{2}}{2\sigma^{2}} \right).
>  $$  
>
>- 독립성을 가정하면 $n$개의 관측치에 대한 결합확률은 곱으로 표현된다:  
>  $$
>  L(x_{1}, \dots, x_{n}, \mu, \sigma^{2}) 
  = \prod_{i=1}^{n} f(x_{i} \mid \mu, \sigma^{2}).
>  $$  
>
>- 지수함수의 성질에 의해 곱이 합으로 바뀌어, 최종적으로  
>  $$
>  L(x_{1}, \dots, x_{n}, \mu, \sigma^{2}) 
  = \frac{1}{(\sigma \sqrt{2\pi})^{n}} 
  \exp\left( -\frac{1}{2\sigma^{2}} \sum_{i=1}^{n} (x_{i} - \mu)^{2} \right)
>  $$  
>  와 같이 정리된다.  

---

## p20. 포아송 모델의 우도  

예제 2 (포아송 모델):  
만약 $X_{1}, \dots, X_{n} \overset{iid}{\sim} \text{Poiss}(\lambda)$ for some $\lambda > 0$라 하자.  

- $E = \mathbb{N}$  
- $\Theta = (0, \infty)$  
- $\forall (x_{1}, \dots, x_{n}) \in \mathbb{N}^{n}, \ \forall \lambda > 0$,  
  $$
  \begin{aligned}
  L(x_{1}, \dots, x_{n}, \lambda) 
  &= \prod_{i=1}^{n} \mathbb{P}_{\lambda}[X_{i} = x_{i}] \\
  &= \prod_{i=1}^{n} \frac{e^{-\lambda} \lambda^{x_{i}}}{x_{i}!} \\
  &= e^{-n\lambda} \frac{\lambda^{\sum_{i=1}^{n} x_{i}}}{x_{1}!\cdots x_{n}!}.
  \end{aligned}
  $$

<img src="/assets/img/probstat/3/image_5.png" alt="image" width="600px">

---

>**보충설명**
>
>- $X_{1}, \dots, X_{n} \overset{iid}{\sim} \text{Poiss}(\lambda)$라는 것은 각 표본 $X_{i}$가 모수 $\lambda > 0$인 포아송 분포를 따르며, 서로 독립이고 동일한 분포라는 의미이다.  
>
>- 확률 공간은 $E = \mathbb{N}$ (자연수 집합), 모수 공간은 $\Theta = (0,\infty)$이다.  
>
>- 포아송 분포의 확률질량함수(pmf)는  
>  $$
>  f(x \mid \lambda) = \mathbb{P}_{\lambda}[X = x] 
  = \frac{e^{-\lambda} \lambda^{x}}{x!}, \quad x \in \mathbb{N}.
>  $$  
>
>- $n$개의 관측치에 대한 결합확률은 독립성 때문에 곱으로 표현된다:  
>  $$
>  L(x_{1}, \dots, x_{n}, \lambda) 
  = \prod_{i=1}^{n} \frac{e^{-\lambda} \lambda^{x_{i}}}{x_{i}!}.
>  $$  
>
>- 지수항 $e^{-\lambda}$는 곱해질 때 $e^{-n\lambda}$로 정리되고, 지수 $\lambda^{x_{i}}$는 합으로 묶여  
>  $$
>  L(x_{1}, \dots, x_{n}, \lambda) 
  = e^{-n\lambda} \frac{\lambda^{\sum_{i=1}^{n} x_{i}}}{x_{1}!\cdots x_{n}!}
>  $$  
>  와 같이 단순화된다.  
>
>- 따라서 우도 함수는 표본의 합 $\sum_{i=1}^{n} x_{i}$와 표본 각각의 팩토리얼에 의해 결정된다.  

---

## p21. 최대우도추정량

**Maximum Likelihood Estimator**

$X_{1}, \dots, X_{n}$는 통계모델 $(E, (P_{\theta})_{\theta \in \Theta})$와 연관된 i.i.d. 표본이라 하고, 이에 대응하는 우도를 $L$이라 하자.  

**정의**  
$\theta$의 최대우도추정량(MLE)은 다음과 같이 정의된다:  
$$
\hat{\theta}_{n}^{MLE} 
= \arg\max_{\theta \in \Theta} L(X_{1}, \dots, X_{n}, \theta),
$$
단, 존재한다고 가정한다.  

**비고 (로그우도추정량)**  
실제 계산에서는 로그우도를 사용한다:  
$$
\hat{\theta}_{n}^{MLE} 
= \arg\max_{\theta \in \Theta} \log L(X_{1}, \dots, X_{n}, \theta).
$$

---

>**보충설명**
>
>- **MLE의 직관**  
>  최대우도추정량(Maximum Likelihood Estimator, MLE)은 주어진 표본이 실제로 관측될 가능성을 가장 크게 만드는 모수값을 선택하는 방법이다.  
>  즉, 우도함수 $L(X_{1}, \dots, X_{n}, \theta)$를 최대로 만드는 $\theta$를 추정치로 삼는다.  
>
>- **로그우도의 사용 이유**  
>  곱으로 이루어진 우도함수는 $n$이 커질수록 수치적으로 계산하기 어렵다.  
>  로그를 취하면 곱이 합으로 변하여 계산이 단순해지고, 미분을 통한 최적화 과정도 쉬워진다.  
>  (예: $\log \prod_{i=1}^{n} f(x_{i} \mid \theta) = \sum_{i=1}^{n} \log f(x_{i} \mid \theta)$)  
>
>- **추정량의 성질**  
>  적절한 정규성 조건하에서 MLE는 일치성(consistency), 점근적 정규성(asymptotic normality), 효율성(efficiency) 등을 가진다.  
>  따라서 통계학과 머신러닝에서 널리 사용되는 추정 방법이다.  

## p22. 피셔 정보  

**정의: 피셔 정보(Fisher information)**  

한 관측치에 대한 로그우도를 다음과 같이 정의한다:  
$$
\ell(\theta) = \log L_{1}(X, \theta), \quad \theta \in \Theta \subset \mathbb{R}^{d}
$$  

$\ell$이 거의 모든 경우(a.s.)에서 두 번 미분 가능하다고 가정하자.  
일정한 정규성 조건하에서 (Under some regularity conditions), 통계모델의 피셔 정보는 다음과 같이 정의된다:  
$$
I(\theta) 
$$
$$
= \mathbb{E}\!\big[\nabla \ell(\theta)\nabla \ell(\theta)^{\top}\big] 
- \mathbb{E}[\nabla \ell(\theta)]\mathbb{E}[\nabla \ell(\theta)]^{\top} 
$$
$$
= -\mathbb{E}\!\big[\nabla^{2}\ell(\theta)\big].
$$  

만약 $\Theta \subset \mathbb{R}$이면,  
$$
I(\theta) = \mathrm{var}\!\big[\ell'(\theta)\big] = -\mathbb{E}[\ell''(\theta)].
$$  

---

>**보충설명**
>
>1. **왜 a.s.라는 표현이 붙는가?**  
>   로그우도 함수 $\ell(\theta)$가 모든 경우에 항상 두 번 미분 가능하다고 단정할 수는 없다.  
>   예외적으로 미분이 불가능한 표본이 있을 수 있지만, 그런 경우는 확률적으로 0에 해당한다.  
>   그래서 “거의 확실히(almost surely, a.s.) 두 번 미분 가능하다”라는 표현을 써서,  
>   확률 1의 집합 위에서는 문제없이 미분할 수 있음을 강조한다.  
>
>2. **일정한 정규성 조건의 의미**  
>   수식 전개 과정에서는 미분과 기댓값을 교환하는 과정이 필요하다.  
>   예를 들어  
>   $$
>   \mathbb{E}\!\left[\frac{\partial}{\partial \theta}\ell(\theta)\right]
   = \frac{\partial}{\partial \theta}\mathbb{E}[\ell(\theta)]
>   $$
>   와 같은 식이 자연스럽게 성립해야 한다.  
>   이를 보장하는 가정을 “정규성 조건”이라고 부른다.  
>   즉, 수학적으로 까다로운 예외 상황을 배제하고, 우리가 원하는 성질이 성립하도록 하는 기술적 조건이다.  
>
>---
>
>3. **수식 전개 과정**  
>
>- **스칼라에서의 분산**  
>  스칼라 확률변수 $X$의 분산 정의는  
>  $$
>  \mathrm{Var}(X) = \mathbb{E}\big[(X - \mathbb{E}[X])^{2}\big].
>  $$  
>  즉, 편차의 제곱의 평균을 의미한다.  
>
>- **벡터에서의 분산 → 공분산 행렬**  
>  벡터 $U = (U_{1}, U_{2}, \dots, U_{d})^{\top}$에 대해서는 각 성분쌍의 공분산을 모두 담아야 하므로  
>  분산을 공분산 **행렬**로 정의한다:  
>  $$
>  \mathrm{Var}(U) = \mathbb{E}\!\left[(U - \mathbb{E}[U])\,(U - \mathbb{E}[U])^{\top}\right].
>  $$  
>
>- **왜 외적(outer product)인가?**  
>  $(U-\mathbb{E}[U])$는 $d\times 1$ 열벡터, $(U-\mathbb{E}[U])^{\top}$는 $1\times d$ 행벡터이므로  
  곱은 $d\times d$ 행렬이 된다. 그 행렬의 $(i,j)$ 성분은  
>  $$
>  \big(\mathrm{Var}(U)\big)_{ij}
  = \mathbb{E}\!\big[(U_{i}-\mathbb{E}[U_{i}])\,(U_{j}-\mathbb{E}[U_{j}])\big],
>  $$  
>  즉 $U_i$와 $U_j$의 공분산이 된다.  
>
>- **점수 함수와 피셔 정보**  
>  점수 함수(score function)는  
>  $$
>  U(\theta)=\nabla \ell(\theta)=\frac{\partial}{\partial \theta}\log L_{1}(X,\theta)
>  $$  
>  로 두고, 피셔 정보는 점수 함수의 분산으로 정의한다:  
>  $$
>  I(\theta)=\mathrm{Var}\big[U(\theta)\big].
>  $$  
>
>- **분산 전개 (행렬/벡터 연산을 모두 풀어 씀)**  
>  편의상 $m:=\mathbb{E}[U(\theta)]$로 둔다. 그러면
>  $$
>  \mathrm{Var}\big[U(\theta)\big]
  = \mathbb{E}\!\left[(U(\theta)-m)\,(U(\theta)-m)^{\top}\right].
>  $$  
>
>  1) **곱(외적) 전개**  
>  $$
>  (U-m)(U-m)^{\top}
  \;=\; U U^{\top} \;-\; U m^{\top} \;-\; m U^{\top} \;+\; m m^{\top}.
>  $$  
>
>  2) **기대값의 선형성 적용**  
>  $$
>  \begin{aligned}
  \mathrm{Var}[U]
  &= \mathbb{E}[U U^{\top}]
   \;-\; \mathbb{E}[U m^{\top}]
   \;-\; \mathbb{E}[m U^{\top}]
   \;+\; \mathbb{E}[m m^{\top}] \\
  &= \mathbb{E}[U U^{\top}]
   \;-\; \mathbb{E}[U]\, m^{\top}
   \;-\; m\, \mathbb{E}[U]^{\top}
   \;+\; m m^{\top}.
  \end{aligned}
 > $$  
 > 여기서 $m=\mathbb{E}[U]$는 상수 벡터이므로 기대값 바깥으로 뺄 수 있고,  
>  $\mathbb{E}[U]=m$, $\mathbb{E}[U]^{\top}=m^{\top}$를 대입하면  
>  $$
>  \mathrm{Var}[U]
  = \mathbb{E}[U U^{\top}] \;-\; m m^{\top} \;-\; m m^{\top} \;+\; m m^{\top}
>  $$
>  $$
>  = \mathbb{E}[U U^{\top}] \;-\; m m^{\top}.
>  $$
>
>  따라서
>  $$
>  \boxed{\,\mathrm{Var}[U(\theta)]
  = \mathbb{E}\!\big[U(\theta)U(\theta)^{\top}\big]
  - \mathbb{E}[U(\theta)]\,\mathbb{E}[U(\theta)]^{\top}\, }.
>  $$
>
>- **정규성 조건 적용**  
>  정규성 조건하에서는 $\mathbb{E}[U(\theta)]=0$임을 보일 수 있다.  
>
>  실제로,
>  $$
>  U(\theta) = \frac{\partial}{\partial \theta} \log p_\theta(X)
  = \frac{1}{p_\theta(X)} \frac{\partial}{\partial \theta} p_\theta(X),
>  $$
>  이므로
>  $$
>  \mathbb{E}[U(\theta)]
  = \int U(\theta) p_\theta(x)\,dx
>  $$
>  $$
>  = \int \frac{1}{p_\theta(x)} \frac{\partial}{\partial \theta} p_\theta(x)\, p_\theta(x)\,dx
  = \int \frac{\partial}{\partial \theta} p_\theta(x)\, dx.
>  $$  
>  정규성 조건(미분과 적분 교환 가능) 하에서는  
>  $$
>  \mathbb{E}[U(\theta)]
  = \frac{\partial}{\partial \theta} \int p_\theta(x)\, dx
  = \frac{\partial}{\partial \theta} (1) = 0.
>  $$  
>
>  따라서  
>  $$
  I(\theta)=\mathrm{Var}[U(\theta)]
  = \mathbb{E}\!\big[U(\theta)U(\theta)^{\top}\big].
>  $$  
>
>--- 
>
>4. **피셔 정보의 두 표현이 같아지는 이유 (수식 전개 과정 (2))**  
>
>- **로그우도 함수의 정의**  
>  확률밀도(또는 질량) 함수 $p_\theta(x)$에 대해  
>  $$
>  \ell(\theta) = \log p_\theta(X).
>  $$  
>
>- **점수 함수(score function)**  
>  점수 함수는 로그우도의 기울기이므로  
>  $$
>  U(\theta) = \nabla_\theta \ell(\theta) 
  = \nabla_\theta \log p_\theta(X).
>  $$  
>  로그 미분 성질에 의해  
>  $$
>  U(\theta) = \frac{\nabla_\theta p_\theta(X)}{p_\theta(X)}.
>  $$  
>
>- **피셔 정보의 정의**  
>  피셔 정보는 점수 함수의 분산으로 정의된다. 정규성 조건 때문에 $\mathbb{E}[U(\theta)]=0$이므로  
>  $$
>  I(\theta) = \mathbb{E}[U(\theta)U(\theta)^{\top}].
>  $$  
>
>- **로그우도의 2차 도함수 전개 (단계별)**  
>  $\ell(\theta) = \log p_\theta(X)$를 두 번 미분하면 다음과 같이 된다.  
>
>  1) **1차 미분**  
>  $$
>  \frac{\partial}{\partial \theta_i}\ell(\theta)
  = \frac{1}{p_\theta(X)} \frac{\partial}{\partial \theta_i} p_\theta(X).
>  $$  
>
>  2) **2차 미분 준비**  
>  $$
>  \frac{\partial^2}{\partial \theta_i \partial \theta_j}\ell(\theta)
  = \frac{\partial}{\partial \theta_j}\left(\frac{1}{p_\theta(X)} \frac{\partial}{\partial \theta_i} p_\theta(X)\right).
>  $$  
>
>  3) **곱의 미분 적용**  
>  $$
>  = \frac{\partial}{\partial \theta_j}\!\left(\frac{1}{p_\theta(X)}\right)\cdot \frac{\partial}{\partial \theta_i}p_\theta(X)
  + \frac{1}{p_\theta(X)} \cdot \frac{\partial^2}{\partial \theta_i \partial \theta_j}p_\theta(X).
>  $$  
>
>  4) **각 항 계산**  
>  $$
>  \frac{\partial}{\partial \theta_j}\!\left(\frac{1}{p_\theta(X)}\right)
  = -\frac{1}{p_\theta(X)^2}\frac{\partial}{\partial \theta_j}p_\theta(X).
>  $$  
>
>  따라서  
>  $$
>  \frac{\partial^2}{\partial \theta_i \partial \theta_j}\ell(\theta)
>  $$
>  $$
>  = \frac{1}{p_\theta(X)} \frac{\partial^2}{\partial \theta_i \partial \theta_j}p_\theta(X)
  - \frac{1}{p_\theta(X)^2}\frac{\partial}{\partial \theta_i}p_\theta(X)\frac{\partial}{\partial \theta_j}p_\theta(X).
>  $$  
>
>- **기댓값 취하기**  
>  양변에 $-1$을 곱하고 기댓값을 취하면  
>  $$
>  -\,\mathbb{E}\!\left[\frac{\partial^2}{\partial \theta_i \partial \theta_j}\ell(\theta)\right]
>  $$
>  $$
>  = -\int \left[\frac{1}{p_\theta(x)} \frac{\partial^2}{\partial \theta_i \partial \theta_j}p_\theta(x)
  - \frac{1}{p_\theta(x)^2}\frac{\partial}{\partial \theta_i}p_\theta(x)\frac{\partial}{\partial \theta_j}p_\theta(x)\right] p_\theta(x)\, dx.
>  $$  
>
>  전개하면  
>  $$
>  = -\int \frac{\partial^2}{\partial \theta_i \partial \theta_j}p_\theta(x)\, dx
  + \int \frac{1}{p_\theta(x)}\frac{\partial}{\partial \theta_i}p_\theta(x)\frac{\partial}{\partial \theta_j}p_\theta(x)\, dx.
>  $$  
>
>- **첫 번째 항 소거**  
>  $$
>  \int \frac{\partial^2}{\partial \theta_i \partial \theta_j}p_\theta(x)\, dx
  = \frac{\partial^2}{\partial \theta_i \partial \theta_j}\int p_\theta(x)\,dx
  = \frac{\partial^2}{\partial \theta_i \partial \theta_j}(1)=0.
>  $$  
>
>  따라서 남는 것은  
>  $$
>  -\,\mathbb{E}\!\left[\frac{\partial^2}{\partial \theta_i \partial \theta_j}\ell(\theta)\right]
  = \int \frac{1}{p_\theta(x)}\frac{\partial}{\partial \theta_i}p_\theta(x)\frac{\partial}{\partial \theta_j}p_\theta(x)\, dx.
>  $$  
>
>- **점수 함수와 연결**  
>  점수 함수의 성분은  
>  $$
>  U_i(\theta) = \frac{1}{p_\theta(X)} \frac{\partial}{\partial \theta_i}p_\theta(X).
>  $$  
>  따라서  
>  $$
>  U_i(\theta)U_j(\theta) 
  = \frac{1}{p_\theta(X)^2}\frac{\partial}{\partial \theta_i}p_\theta(X)\frac{\partial}{\partial \theta_j}p_\theta(X).
>  $$  
>
>  기댓값을 취할 때는 분포 $p_\theta(x)$에 대해 적분하므로 분모의 $p_\theta(x)^2$ 중 하나가 분자의 $p_\theta(x)$와 소거된다:  
>  $$
>  \mathbb{E}[U_i(\theta)U_j(\theta)] 
  = \int \frac{1}{p_\theta(x)^2}\frac{\partial}{\partial \theta_i}p_\theta(x)\frac{\partial}{\partial \theta_j}p_\theta(x)\, p_\theta(x)\, dx,
>  $$  
>  $$
>  = \int \frac{1}{p_\theta(x)}\frac{\partial}{\partial \theta_i}p_\theta(x)\frac{\partial}{\partial \theta_j}p_\theta(x)\, dx.
>  $$  
>
>- **결론**  
>  따라서  
>  $$
>  \mathbb{E}[U_i(\theta)U_j(\theta)]
  = -\,\mathbb{E}\!\left[\frac{\partial^2}{\partial \theta_i \partial \theta_j}\ell(\theta)\right].
>  $$  
>
>  행렬 형태로 쓰면  
>  $$
>  \boxed{\,I(\theta) = \mathbb{E}[U(\theta)U(\theta)^{\top}] 
  = -\,\mathbb{E}[\nabla^{2}\ell(\theta)]\, }.
>  $$
>
>---
>
>5. **스칼라 모수의 경우**  
>
>- 만약 모수 공간이 $\Theta \subset \mathbb{R}$인 경우, 즉 $\theta$가 스칼라(한 개의 값)라면 피셔 정보는 다음과 같이 단순화된다.  
>
>- 점수 함수는  
>  $$
>  U(\theta) = \ell'(\theta),
>  $$  
>  이고, 따라서 피셔 정보는 점수 함수의 분산이다:  
>  $$
>  I(\theta) = \mathrm{Var}[\ell'(\theta)].
>  $$  
>
>- 한편, 로그우도의 2차 도함수를 이용하면  
>  $$
>  I(\theta) = -\,\mathbb{E}[\ell''(\theta)].
>  $$  
>
>- 즉, 스칼라 모수의 경우에는 벡터/행렬 형태가 아니라 단일 값으로 표현되며, 점수 함수의 분산과 로그우도의 음의 기댓값이 서로 같은 피셔 정보의 두 가지 표현을 이룬다.

---

## p23. 최대우도추정량(MLE)의 성질  

**정리 (Theorem)**  

$\theta^{\ast} \in \Theta$ (참 모수, true parameter)라 하자. 다음을 가정한다:  

1. 모델이 식별 가능하다 (The model is identified).  
2. 모든 $\theta \in \Theta$에 대해, 분포 $P_\theta$의 지지집합(support)은 $\theta$에 의존하지 않는다.  
3. $\theta^{\ast}$는 $\Theta$의 경계(boundary)에 있지 않다.  
4. $I(\theta)$는 $\theta^{\ast}$ 근방에서 가역적(invertible)이다.  
5. 그 외 몇 가지 기술적인 조건들이 성립한다.  

---

**따라서 $\hat{\theta}_n^{MLE}$는 다음을 만족한다:**  

- 일치성(Consistency):  
  $$
  \hat{\theta}_n^{MLE} \;\;\xrightarrow{P}\;\; \theta^{\ast}, 
  \quad n \to \infty, 
  \quad \text{w.r.t. } \mathbb{P}_{\theta^{\ast}}.
  $$  

- 점근정규성(Asymptotic Normality):  
  $$
  \sqrt{n}\,(\hat{\theta}_n^{MLE} - \theta^{\ast})
  \;\;\xrightarrow{d}\;\;
  \mathcal{N}\!\big(0,\, I(\theta^{\ast})^{-1}\big),
  \quad n \to \infty,
  \quad \text{w.r.t. } \mathbb{P}_{\theta^{\ast}}.
  $$

---

>**보충설명**
>
>1. **모델이 식별 가능하다는 의미**  
>   서로 다른 모수 $\theta_1 \neq \theta_2$가 항상 서로 다른 분포 $P_{\theta_1} \neq P_{\theta_2}$를 유도한다는 뜻이다.  
>   즉, 데이터를 통해 모수를 유일하게 식별할 수 있어야 한다.  
>   만약 서로 다른 $\theta$가 같은 분포를 만들면, 추정량이 어떤 값을 수렴해야 하는지 정의되지 않는다.  
>
>2. **지지집합(support)과 $\theta$에 의존하지 않는다는 의미**  
>   확률분포 $P_\theta$의 지지집합이란, 확률밀도(또는 질량) $p_\theta(x) > 0$인 $x$의 집합이다.  
>   “$\theta$에 의존하지 않는다”는 것은, 모수 값이 달라져도 확률변수가 가질 수 있는 값의 범위는 변하지 않는다는 뜻이다.  
>   예를 들어 정규분포 $N(\mu,\sigma^2)$의 경우 지지집합은 항상 $\mathbb{R}$이므로 $\mu, \sigma$에 의존하지 않는다.  
>
>3. **$\theta^{\ast}$가 경계(boundary)에 있지 않다는 의미**  
>   참 모수 $\theta^{\ast}$는 모수공간 $\Theta$의 내부에 존재해야 한다는 조건이다.  
>   만약 경계에 있으면, 예를 들어 분산이 0에 가까운 경우처럼, 미분 가능성이 깨지거나 점근정규성이 무너지기 쉽다.  
>
>4. **$I(\theta)$가 가역적(invertible)이라는 의미**  
피셔 정보행렬 $I(\theta)$가 **양의 정부호(positive definite)**라는 것은, 행렬이 항상 양수 방향으로만 값을 가지는 안정적인 성질을 갖는다는 뜻이다.
>이 성질 덕분에 역행렬을 구할 수 있다.
>  
>  만약 $I(\theta)$의 역행렬이 존재하지 않는다면, 추정량의 분산을 계산할 수 없게 된다.
>그 결과 MLE의 점근적 분포가 정상적인 정규분포 형태를 띠지 못하고 **특이(singular)**한 모양이 되어,
>신뢰구간을 구하거나 가설검정을 하는 등의 통계적 해석이 불가능해진다.
>
>5. **그 외 기술적인 조건들**  
>   - 로그우도의 적분과 미분을 교환할 수 있도록 보장하는 정규성 조건  
>   - 모수 공간의 적당한 연속성, 매끄러움(smoothness)  
>   - 확률적 수렴에 필요한 제한 조건(예: 균등적분 가능성)  
>   이들은 주로 미분과 기댓값의 교환, 중심극한정리 적용 등을 정당화하기 위해 필요하다.  
>
>6. **결론 (첫 번째 항목: 일치성)**  
>   $$
>   \hat{\theta}_n^{MLE} \;\xrightarrow{P}\; \theta^{\ast}
>   $$  
>   이 조건은 표본의 크기가 무한히 커지면, 최대우도추정량이 참 모수에 확률적으로 수렴한다는 뜻이다.  
>   즉, MLE는 “일치추정량(consistent estimator)”이다.  
>
>7. **결론 (두 번째 항목: 점근정규성)**  
>   $$
>   \sqrt{n}\,(\hat{\theta}_n^{MLE} - \theta^{\ast})
   \;\xrightarrow{d}\; \mathcal{N}\!\big(0, I(\theta^{\ast})^{-1}\big)
>   $$  
>   이는 MLE가 대수적으로는 참 모수에 가까워질 뿐 아니라, 그 주변에서 정규분포를 따른다는 사실이다.  
>   따라서 $n$이 클수록 추정량의 분포가 평균 $\theta^{\ast}$, 공분산 $I(\theta^{\ast})^{-1}$인 정규분포로 근사된다.  
>   이 성질을 활용해 신뢰구간을 만들고, 가설검정을 수행할 수 있다.  
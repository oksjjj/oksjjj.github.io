---
layout: post
title: "[확률과 통계] 4주차"
date: 2025-09-28 14:01:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. 신경망을 학습시키는 방법?  

- **경사하강법(gradient descent), 확률적 경사하강법(SGD) 복습**  
- **계산 그래프(computation graphs)**  
- **사슬 구조에서의 역전파(backprop through chains)**  
- **다층 퍼셉트론(MLPs)에서의 역전파(backprop through MLPs)**  
- **유향 비순환 그래프(DAGs)에서의 역전파(backprop through DAGs)**  
- **미분 가능한 프로그래밍(differentiable programming)**  

---

## p3. 기본 원리? (Basic rationale?)

<img src="/assets/img/probstat/4/image_1.png" alt="image" width="720px">

---

### 보충 설명  

#### 1. **기본 원리(Basic rationale)**  
- 딥러닝의 목적은 데이터 인스턴스 $x^{(i)}$ 를 입력받아 올바른 분류 레이블 $y^{(i)}$ 를 출력하도록 모델 $f_\theta$ 를 학습하는 것이다.  
- 이를 위해 **손실 함수(loss)** $\mathcal{L}(f_\theta(x^{(i)}), y^{(i)})$ 를 정의하여, 예측과 실제 정답 사이의 차이를 수치로 측정한다.  
- 손실 함수는 보통 **거리 기반 함수**로 정의되며, “어떻게 정의하느냐”가 모델 학습 성능에 큰 영향을 준다.  

#### 2. **모델 파라미터와 학습 과정**  
- 각 레이어는 $\theta_1, \theta_2, \dots, \theta_6$ 등 **파라미터 집합**을 가진다.  
- 학습의 목표는 모든 데이터 인스턴스에 대해 손실의 합을 최소화하는 파라미터 $\theta^\ast$ 를 찾는 것이다.  

  $$
  \theta^\ast = \arg\min_{\theta} \sum_{i=1}^N \mathcal{L}\big(f_\theta(x^{(i)}), y^{(i)}\big)
  $$  

- 이 과정을 통해 모델은 데이터에 **가장 잘 맞는 매개변수**를 학습한다.  

#### 3. **Loss function과 Objective function의 관계**  
- **Loss function (손실 함수)**: 개별 데이터 인스턴스 $(x^{(i)}, y^{(i)})$ 에 대한 오차를 측정한다.  
  $$
  \mathcal{L}(f_\theta(x^{(i)}), y^{(i)})
  $$  
- **Objective function (목적 함수)**: 전체 데이터셋에 대해 손실을 합산/평균한 값으로, 실제로 최소화해야 하는 대상이다.  
  $$
  J(\theta) = \frac{1}{N}\sum_{i=1}^N \mathcal{L}(f_\theta(x^{(i)}), y^{(i)})
  $$  
- 따라서, 학습은 결국 **Objective function $J(\theta)$ 를 최소화하는 최적화 문제**로 귀결된다.  
- 손실 함수는 그 목적 함수를 구성하는 **기본 단위**라고 볼 수 있다.  

---

## p4. 최적화 (Optimization)  

<img src="/assets/img/probstat/4/image_2.png" alt="image" width="360px">

$$
\theta^\ast = \arg\min_{\theta} J(\theta)
$$  

**우리가 $J$에 대해 알고 있는 지식은 무엇인가?**  
- 우리는 $J(\theta)$ 를 계산할 수 있다.  
  → Black box optimization 
- 우리는 $J(\theta)$ 와 $\nabla_\theta J(\theta)$ 를 계산할 수 있다. ($\nabla_\theta$는 Gradient)  
  → First order optimization  
- 우리는 $J(\theta)$, $\nabla_\theta J(\theta)$, 그리고 $H_\theta(J(\theta))$ 를 계산할 수 있다. ($H_\theta$는 Hessian)  
  → Second order optimization  

---

### 보충 설명  

1. **블랙박스 최적화**  
- 내부 구조를 알지 못한 채 단순히 함수값 $J(\theta)$ 만을 이용하여 최소화를 시도하는 방식이다.  
- 신경망을 처음 보면 내부 계산 과정을 명확히 알 수 없다는 점에서 **black box optimization** 으로 이해할 수 있다.  

2. **1차 최적화 (First-order optimization)**  
- 함수값과 함께 **기울기(gradient)** $\nabla_\theta J(\theta)$ 를 사용할 수 있다.  
- 대표적으로 **경사하강법(gradient descent), 확률적 경사하강법(SGD)** 등이 이 범주에 속한다.  

3. **2차 최적화 (Second-order optimization)**  
- 함수값과 기울기뿐 아니라, **헤시안(Hessian)** $H_\theta(J(\theta))$ 까지 활용한다.  
- 곡률 정보를 이용해 더 정밀한 최적화가 가능하지만, 계산량이 매우 크다는 단점이 있다.  

---

## p5. 경사하강법 (Gradient Descent)  

<img src="/assets/img/probstat/4/image_3.png" alt="image" width="600px">

---

### 보충 설명  

#### 1. **경사하강법(Gradient Descent)의 기본 개념**  
- 목적 함수 $J(\theta)$ 를 최소화하기 위해 파라미터 $\theta$ 를 반복적으로 갱신하는 방법이다.  
- 현재 위치에서 기울기(gradient)의 반대 방향으로 이동하여 $J(\theta)$ 값을 줄인다.  

#### 2. **지역 최소값(Local minima)과 전역 최소값(Global minimum)**  
- 최적화 곡면은 여러 개의 골짜기를 가질 수 있다.  
- 이 중 일부는 **지역 최소값(local minima)** 으로, 더 낮은 값이 존재하더라도 그 안에 머무를 수 있다.  
- 반면 가장 낮은 지점은 **전역 최소값(global minimum)** 으로, 이론적으로는 도달해야 하는 목표점이다.  
- 실제로는 지역 최소값에 도달하는 경우가 대부분이며, 흔히 “local minima에 빠지는 게 99.9% 이상”이라고 말할 정도로 전역 최소값 도달은 드물다.  

#### 3. **파라미터 공간과 양자화(Quantization)**  
- 실제 학습에서 사용하는 파라미터 공간은 전체 범위를 다 활용하지 못하고, 비효율적으로 사용되는 경우가 많다.  
- 이런 상황에서 **양자화(quantization)** 기법을 적용하면 파라미터를 압축해 표현할 수 있으며, 계산 및 저장 효율을 크게 높일 수 있다.  

---

## p6. 확률적 경사하강법 (Stochastic Gradient Descent, SGD)  

- 전체 손실 함수 $J$ (각 샘플별 개별 손실의 합)를 최소화하고자 한다.  

- 확률적 경사하강법에서는 데이터의 부분집합(batch)에 대해 그래디언트를 계산한다.  
  - 배치 크기(batchsize)=1인 경우, 각 샘플마다 $\theta$ 가 갱신된다.  
  - 배치 크기(batchsize)=N (전체 집합)인 경우, 이는 표준 경사하강법(standard gradient descent)이 된다.  

- 그래디언트 방향은 모든 샘플에 대해 평균을 취한 경우(표준 경사하강법)에 비해 **노이즈가 많다(noisy)**.  

- **장점**  
  - 더 빠르다: 작은 샘플로 전체 그래디언트를 근사한다.  
  - 암묵적인 정규화 효과(implicit regularizer)가 있다.  

- **단점**  
  - 분산이 크고(high variance), 갱신이 불안정하다(unstable updates).  

---

### 보충 설명  

#### 1. **확률적(Stochastic)이라는 명칭의 이유**  
- 확률적 경사하강법(SGD)은 전체 데이터를 한 번에 학습하는 대신, **데이터를 작은 덩어리(chunk, mini-batch)** 로 나누어 학습한다.  
- 이때 어떤 chunk(샘플 집합)를 사용할지는 **확률적으로(random)** 선택된다.  
- 따라서 학습 과정에서 매번 다른 부분 집합을 기반으로 파라미터가 갱신되며, 이러한 무작위성이 반영되어 “Stochastic”이라는 이름이 붙는다.  

#### 2. **암묵적인 정규화 효과(Implicit Regularization)**  
- SGD는 전체 데이터에 대해 정확한 그래디언트를 계산하지 않고, 무작위로 선택된 작은 샘플 집합으로 근사한다.  
- 이 과정에서 갱신 방향에 노이즈가 섞이게 되는데, 이런 노이즈가 모델이 **특정 데이터에 과적합(overfitting) 되는 것을 방지하는 역할**을 한다.  
- 즉, 명시적으로 정규화 항(regularization term)을 추가하지 않아도, 확률적 샘플링으로 인한 변동성이 일종의 **규제(regularization)** 로 작용하여 일반화 성능을 높여준다.  

---

## p7. 모멘텀 (Momentum)  

- 언덕을 굴러 내려가는 무거운 공이 속도를 얻는 것과 같다.  
- 그래디언트 스텝은 이전 업데이트 방향을 계속 따르는 쪽으로 편향된다.  

$$
\theta^{t+1} \leftarrow \theta^t - \eta \nabla f(\theta^t) + \alpha \cdot m^t
$$  

- 도움을 줄 수도 있고, 방해가 될 수도 있다.  
- 모멘텀의 강도(strength of momentum)는 **하이퍼파라미터(hyperparameter)** 이다.  

<img src="/assets/img/probstat/4/image_4.png" alt="image" width="720px">  

---

### 보충 설명  

1. **모멘텀에 대한 직관적인 설명**  
- 단순한 경사하강법은 현재 기울기에만 의존해 파라미터를 이동시킨다.  
- 모멘텀을 적용하면 이전 단계의 이동 방향이 누적되어, 마치 공이 굴러가며 가속도를 얻는 것처럼 파라미터 갱신에 관성이 붙는다.  
- 이로 인해 **지역 최소값(local minima)** 에 갇히지 않고 벗어날 수 있는 가능성이 커진다.  

2. **수식 해석**  
- $\eta$ : 학습률(learning rate), 업데이트 크기를 조절한다.  
- $\nabla f(\theta^t)$ : 현재 시점에서의 그래디언트.  
- $\alpha \cdot m^t$ : 이전 업데이트에서 온 관성(모멘텀 항), $\alpha$ 가 클수록 더 큰 영향을 준다.  
- 결과적으로 이동 방향은 "현재 그래디언트"와 "과거의 업데이트"가 결합된 형태가 된다.  

3. **모멘텀의 효과**  
- **장점**: 진동(oscillation)을 줄이고, 평평한 지역을 빠르게 통과하며, 지역 최소값에서 빠져나오는 데 도움을 준다.  
- **단점**: 하이퍼파라미터 $\eta$ 와 $\alpha$ 를 적절히 조정하지 않으면 오히려 발산하거나 최적점 근처에서 크게 진동할 수 있다.  

4. **하이퍼파라미터로서의 $\alpha$의 의미**  
- 모멘텀의 강도 $\alpha$ 는 문제와 데이터셋에 따라 달라지는 값이며, 반드시 실험적으로 조정해야 한다.  
- $\alpha$는 학습률 $\eta$ 와 함께 모델의 수렴 속도와 안정성을 좌우하는 핵심 요소다.  

---

## p8. 예시: SGD의 동작  

<img src="/assets/img/probstat/4/image_5.png" alt="image" width="720px">  

- 스텝 크기 $\alpha = 0.02$  
- 모멘텀 $\beta = 0.99$  

모멘텀은 보통 진동을 억제하고 반복(iteration)의 속도를 높여 더 빠른 수렴을 가능하게 하는 수단으로 이해된다.  
하지만 모멘텀은 또 다른 흥미로운 동작을 보인다.  
더 넓은 범위의 스텝 크기를 사용할 수 있게 하고, 동시에 자체적인 진동을 만들어내기도 한다.  
그렇다면 어떤 일이 일어나고 있는 것일까?  

[참고 링크: <a href="https://distill.pub/2017/momentum/" target="_blank">https://distill.pub/2017/momentum/</a>]  

---

### 보충 설명  

1. **SGD의 이동 경로**  
- 그림에서 주황색 궤적은 확률적 경사하강법(SGD)이 출발점에서 해(solution)로 이동하는 과정을 나타낸다.  
- 단순 경사하강법은 불안정하거나 수렴이 느릴 수 있는데, 모멘텀을 적용하면 궤적이 달라진다.  

2. **모멘텀의 영향**  
- 모멘텀은 진동을 줄이고 더 빠른 방향으로 이동하게 만든다.  
- 그러나 동시에, 스텝 크기와 결합될 때 새로운 진동을 만들어낼 수도 있다.  
- 따라서 모멘텀은 단순히 학습 속도를 높이는 요소를 넘어서, **최적화 경로 자체를 바꾸는 요인**이 된다.  

3. **스텝 크기와 모멘텀의 조합**  
- 학습률(스텝 크기, $\alpha$)과 모멘텀($\beta$)은 서로 긴밀히 상호작용한다.  
- $\alpha$가 지나치게 크면 발산할 수 있고, $\beta$가 너무 크면 진동이 심해진다.  
- 적절한 조합을 선택하면 빠른 수렴과 안정성을 동시에 얻을 수 있다.  

---

## p9. 목적 함수의 예시 (손실 함수)  

<img src="/assets/img/probstat/4/image_6.png" alt="image" width="720px">  

---

### 보충 설명  

#### 1. (상단의 첫 번째 그림)  
- 목적 함수 $J(\theta)$ 가 매끄럽고 단일한 곡선 형태를 보이는 경우이다.  
- 전역 최소값(global minimum)을 안정적으로 찾을 수 있으며, 학습이 빠르고 안정적으로 수렴한다.  

#### 2. (상단의 두 번째 그림) Local minima  
- 여러 개의 골짜기를 가지는 경우, 전역 최소값이 아닌 지역 최소값(local minima)에 머무를 수 있다.  
- 이런 경우 더 좋은 해를 찾지 못하고 학습 성능이 제한될 수 있다.  

#### 3. (상단의 세 번째 그림) Vanishing gradient  
- 그래프가 상수 함수 형태를 보인다.  
- 상수 함수 $J(\theta) = c$ 를 미분하면  
  $$
  \nabla_\theta J(\theta) = 0
  $$  
  이므로 파라미터 업데이트가 전혀 일어나지 않는다.  
- 이로 인해 학습이 멈추게 된다.  

#### 4. (하단의 첫 번째 그림) Vanishing gradient (단계적)  
- 계단 함수 형태의 그래프에서는 특정 구간에서 기울기가 0이 된다.  
- 이런 경우에도 $\nabla_\theta J(\theta) = 0$ 이 되어 학습이 정체된다.  

#### 5. (하단의 두 번째 그림) Exploding gradient  
- 그래프 모양은 두 곡선이 아래쪽에서 만나면서 원점 근처에서 값이 급격히 커지는 형태이다.  
- 예를 들어 다음과 같은 함수가 있다:  
  $$
  J(\theta) = \frac{1}{|\theta|}
  $$  
- 이때 그래디언트는  
  $$
  \nabla_\theta J(\theta) 
  = \frac{d}{d\theta}\left(\frac{1}{|\theta|}\right) 
  = -\frac{\text{sgn}(\theta)}{\theta^2}
  $$  
  로 계산된다.  
- $\theta \to 0$ 으로 다가가면 분모 $\theta^2$ 가 0에 수렴하므로 그래디언트가 폭발적으로 커진다.  
- 이로 인해 파라미터 업데이트가 매우 불안정해지고, 학습이 발산하거나 최적점을 지나칠 수 있다.  

#### 6. (하단의 세 번째 그림)  
- 불연속적이거나 급격한 변화가 있는 그래프의 경우, 그래디언트 방향이 일관성을 가지지 못한다.  
- 이런 상황에서는 최적화가 불안정해지고, 수렴하기 어려워진다. 

---

## p10. 볼록 함수 (Convex function)  

<img src="/assets/img/probstat/4/image_7.png" alt="image" width="480px">   

단순한 경우:  
- 볼록(convex)  
- 단일 최소값(single minimum)  
- 모든 지점에서 그래디언트는 최소값을 향한다  
- 최소값에 가까워질수록 그래디언트가 점진적으로 0에 수렴한다  

---

### 보충 설명  

1. **볼록 함수의 특징**  
- 볼록 함수는 전체 영역에서 오직 하나의 최소값만 존재한다.  
- 따라서 최적화 과정에서 여러 지역 최소값(local minima)에 갇히는 문제가 발생하지 않는다.  

2. **그래디언트의 방향성**  
- 함수의 어느 지점에서나 그래디언트는 항상 최소값 쪽을 가리킨다.  
- 이 성질 덕분에 경사하강법은 단순하면서도 안정적으로 전역 최소값에 도달할 수 있다.  

3. **그래디언트의 크기 변화**  
- 최소값 근처에 접근할수록 그래디언트의 크기가 점차 줄어든다.  
- 이는 학습이 급격하게 요동치지 않고, 점진적으로 수렴하게 만드는 중요한 성질이다.  

---

## p11. 선형 불연속 함수 (구간별 선형 함수, Piecewise linear function)  

<img src="/assets/img/probstat/4/image_8.png" alt="image" width="480px"> 

불연속적(discontinuous):  
- 하지만 한쪽에서 정의된 편도 도함수(one-sided derivatives)가 존재한다.  
- PyTorch에서는 문제가 되지 않는다.  

---

### 보충 설명  

1. **구간별 선형 함수의 특징**  
- 함수가 여러 구간에서 서로 다른 직선으로 정의되어 있어, 특정 지점에서 불연속적일 수 있다.  
- 예를 들어 ReLU 계열 함수처럼 구간에 따라 기울기(그래디언트)가 달라지는 구조를 가질 수 있다.  

2. **편도 도함수의 정의 가능성**  
- 불연속 지점에서도 왼쪽과 오른쪽에서 접근하는 **편도 도함수(one-sided derivative)** 는 잘 정의된다.  
- 따라서 최적화 과정에서 해당 지점을 지나더라도 업데이트 방향을 정할 수 있다.  

3. **PyTorch와 같은 자동 미분 프레임워크의 처리 방식**  
- PyTorch는 구간별로 정의된 함수에 대해 편도 도함수를 활용해 자동으로 그래디언트를 계산한다.  
- 따라서 불연속적인 형태의 함수라도 실제 학습 과정에서는 문제가 되지 않는다.  

---

## p12. 그래디언트 폭발 (Exploding Gradient)  

<img src="/assets/img/probstat/4/image_9.png" alt="image" width="480px">  

Exploding gradient:  
- 최소점(minimizer)에 가까워질수록 그래디언트가 무한대로 발산한다.  
- 불안정한 업데이트와 overshoot(최적점을 지나쳐 버림)이 발생한다.  

**함수 $1/x$ 의 원점에서의 도함수는 무엇인가?**  

---

### 보충 설명  

1. **그래프의 형태**  
- $J(\theta)$ 가 두 곡선이 아래에서 만나면서 $\theta=0$ 근처에서 매우 가파르게 꺾인다.  
- 이 지점에서 그래디언트가 급격히 커지며 발산하는 것이 특징이다.  

2. **수학적 해석**  
- 예를 들어 $J(\theta) = \frac{1}{\theta}$ 라고 하면,  
  $$
  \nabla_\theta J(\theta) = -\frac{1}{\theta^2}
  $$  
- $\theta \to 0$ 에 가까워지면 분모가 0에 수렴하므로 그래디언트가 무한대로 커진다.  
- 이로 인해 학습 과정에서 파라미터가 큰 폭으로 갱신되면서 발산하거나 최적점을 지나쳐 버리는 문제가 생긴다.  

3. **학습 과정에서의 영향**  
- 그래디언트 폭발은 특히 심층 신경망에서 층(layer)의 곱이 누적되면서 발생할 수 있다.  
- 파라미터 업데이트가 지나치게 커져 네트워크가 안정적으로 학습하지 못하게 된다.  
- 이를 막기 위해 gradient clipping, 정규화, 적절한 가중치 초기화와 같은 기법이 사용된다.  

---

## p13. 손실 함수(loss function)에 중요한 것은 무엇인가?  

- **어디에서나 연속적(continuous)** 일 것  
- **어디에서나 미분 가능(differentiable)** 할 것  
- **어디에서나 매끄럽(smooth)** 게 변할 것  

---

이러한 성질들을 가진 **“가능한 최선의” 비선형성**을 우리는 어떻게 모델링할 수 있을까?  

---

## p14. 손실 함수(loss function)에 중요한 것은 무엇인가?   

- **어디에서나 연속적(continuous)** ✔️  
- **어디에서나 미분 가능(differentiable)** ✔️  
- **어디에서나 매끄럽다(smooth)** ✔️  

<img src="/assets/img/probstat/4/image_10.png" alt="image" width="240px">  

- $\Phi$ 는 임의의 매끄러운 함수(smoothing function)이다.  

---

### 보충 설명  

1. **GeLU의 정의**  
- GeLU(Gaussian Error Linear Unit)는 활성화 함수로, 입력 $z$ 에 대해 확률적 매끄러움(smoothing)을 적용한 형태이다.  
- 수식에서 $\Phi(z)$ 는 정규분포의 누적분포함수(CDF)로 주어지는 경우가 많다.  

2. **연속성, 미분 가능성, 매끄러움의 충족**  
- GeLU는 모든 구간에서 연속적이고 미분 가능하다.  
- 또한 곡선이 부드럽게 연결되어 있어 매끄러운(smooth) 성질을 만족한다.  

3. **반복 적용 시의 안정성**  
- 이러한 세 가지 성질(연속성, 미분 가능성, 매끄러움)을 동시에 만족하는 함수는, 여러 층(layer)에 반복 적용되더라도 해당 성질이 유지된다.  
- 따라서 GeLU는 딥러닝에서 안정적인 학습을 가능하게 하는 활성화 함수로 널리 활용된다.  

---

## p15. 계산 그래프 (Computation Graphs)  

<img src="/assets/img/probstat/4/image_11.png" alt="image" width="240px">  

- 함수적 변환들의 그래프, 즉 노드(□)로 이루어져 있으며, 이들이 연결되면 어떤 유용한 계산을 수행한다.  
- 딥러닝은 주로 **유향 비순환 그래프(directed acyclic graphs, DAGs)** 형태의 계산 그래프를 다루며, 각 노드는 미분 가능하다.  

---

### 보충 설명  

1. **계산 그래프의 개념**  
- 계산 그래프는 입력 데이터(예: 텐서)가 여러 연산을 거쳐 출력으로 변환되는 과정을 구조적으로 표현한 것이다.  
- 각 노드는 덧셈, 곱셈, 활성화 함수 등 특정 연산을 나타낸다.  

2. **DAG 구조의 특징**  
- 사이클이 없는 방향 그래프이므로 연산의 흐름이 입력에서 출력으로 일방향으로 진행된다.  
- 이 구조 덕분에 순전파(forward pass)와 역전파(backpropagation)를 체계적으로 수행할 수 있다.  

3. **프레임워크에서의 활용**  
- PyTorch, TensorFlow 같은 딥러닝 프레임워크는 모델을 정의하면 내부적으로 자동으로 계산 그래프를 생성한다.  
- 이를 통해 복잡한 미분 과정을 자동 미분(autograd)으로 처리할 수 있으며, 사용자는 직접 도함수를 계산할 필요가 없다.  

---

## p16. 계산 그래프 (Computation Graph)  

<img src="/assets/img/probstat/4/image_12.png" alt="image" width="720px">  

- 입력 $x$ 가 가중치 $W_1$ 과 결합되어 선형 변환을 거친 후 $z$ 가 된다.  
- $z$ 는 활성화 함수(ReLU)를 거쳐 은닉 표현 $h$ 가 된다.  
- $h$ 는 다시 가중치 $W_2$ 와 결합된 선형 변환을 거쳐 출력 $y$ 로 이어진다.  

---

### 보충 설명  

1. **중간 노드(Intermediate node) $z$**  
- $z$ 는 입력 $x$ 와 가중치 $W_1$ 를 곱하고 편향을 더한 뒤 얻어지는 중간 결과물이다.  
- 계산 그래프에서는 이러한 중간 노드가 이후 연산의 입력이 되며, 역전파 시 그래디언트 전파에도 중요한 역할을 한다.  

2. **계산 흐름의 구조**  
- 선형 변환(linear)과 비선형 활성화 함수(relu)가 번갈아 적용되면서 표현력이 강화된다.  
- 계산 그래프는 이를 순차적으로 보여주어, 입력에서 출력으로 이어지는 과정을 직관적으로 이해할 수 있게 한다.  

3. **계산 그래프의 해석**  
- 신경망(neural network)의 복잡한 연산 과정을 단순한 노드와 엣지의 조합으로 분해할 수 있다.  
- 이는 모델 구조를 분석하거나, 자동 미분으로 역전파를 수행할 때 핵심적인 틀이 된다.  

---

## p17. 순전파 (Forward pass)  

<img src="/assets/img/probstat/4/image_13.png" alt="image" width="360px"> 

---

### 보충 설명  

1. **순전파의 정의**  
- 순전파(forward pass)는 입력 데이터 $x_{\text{in}}$ 과 모델의 매개변수 $\theta$ 를 함수 $f$ 에 적용하여 출력 $x_{\text{out}}$ 을 얻는 과정이다.  
- 이는 신경망에서 예측을 생성하는 단계에 해당한다.  

2. **함수 $f$ 의 역할**  
- $f$ 는 선형 변환, 비선형 활성화 함수, 합성곱(convolution) 연산 등 다양한 연산으로 구성될 수 있다.  
- 계산 그래프 상에서는 일련의 노드와 연산으로 표현된다.  

3. **학습과의 연계성**  
- 순전파에서 얻은 $x_{\text{out}}$ 은 손실 함수(loss function)에 입력되어 모델의 성능을 측정한다.  
- 이후 역전파(backpropagation)를 통해 $\theta$ 에 대한 그래디언트가 계산되고, 파라미터 업데이트로 이어진다.  

---

## p18. 순전파: 다층 구조 (Forward Path : Multiple Layers)  

<img src="/assets/img/probstat/4/image_14.png" alt="image" width="720px">  

- 예를 들어, 이 계산 그래프(computation graph)는 다층 퍼셉트론(Multi-Layer Perceptron, MLP)을 나타낼 수 있다.   
 
주어진 계산 그래프 MLP는 “통계적 모델(statistical model)”의 좋은 예시이다.  

---

### 보충설명  

1. **순전파의 다층 구조**  
- 입력 $x_0$ 가 첫 번째 함수 $f_1$ 과 매개변수 $\theta_1$ 에 의해 변환되어 $x_1$ 이 된다.  
- 이후 $x_1$ 은 $f_2$ 와 $\theta_2$ 를 거쳐 $x_2$ 로 변환되고, 이런 과정이 $L$ 개의 층(layer)을 따라 반복된다.  
- 마지막 층의 출력 $x_L$ 은 손실 함수 $\mathcal{L}$ 에 입력되어 최종적인 목적 함수 $J$ 가 계산된다.  

2. **계산 그래프의 해석**  
- 각 함수 $f_i$ 는 선형 변환이나 비선형 활성화 함수를 포함할 수 있으며, $\theta_i$ 는 해당 층의 학습 가능한 매개변수이다.  
- 이 구조를 통해 입력에서 출력, 그리고 손실 함수에 이르는 전체 모델의 흐름이 명확히 드러난다.  

3. **MLP와 통계적 모델**  
- 다층 퍼셉트론(MLP)은 계산 그래프 구조를 가장 대표적으로 보여주는 신경망 모델이다.  
- 여러 층을 통해 특징을 변환하고, 확률적 또는 통계적 관점에서 해석 가능한 모델로 이어진다.  

---

## p19. 다층 신경망 학습 (Training Multi-layer Neural Networks)  

<img src="/assets/img/probstat/4/image_15.png" alt="image" width="720px">   

- 우리는 비용 함수 $J$ 의 그래디언트를 **모델 매개변수(model parameters)** 에 대해 계산해야 한다.  
- 설계상, 각 층은 자신의 입력(데이터와 매개변수)에 대해 미분 가능하도록 구성된다.  

---

### 보충 설명  

1. **그래디언트의 전파**  
- 최종 출력 $J$ (비용 함수)에서 그래디언트가 계산되고, 연쇄법칙(chain rule)에 의해 역전파된다.  
- 이 과정에서 각 층 $f_1, f_2, \dots, f_L$ 에 대응하는 매개변수 $\theta_1, \theta_2, \dots, \theta_L$ 에 대한 그래디언트가 계산된다.  

2. **비용 함수 표면에서의 최적화**  
- 오른쪽 그림은 비용 함수 $J(\theta)$ 의 표면을 나타내며, 매개변수 $\theta$ 가 반복(iteration)을 거치며 업데이트되는 과정을 보여준다.  
- 그래디언트는 현재 지점에서의 기울기를 바탕으로 파라미터가 이동할 방향과 크기를 결정한다.  

---

## p20. 벡터(행렬) 미적분학 요약  

- **x**: 크기가 $[n \times 1]$인 열 벡터(column vector)  

$$
\mathbf{x} =
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}
$$

- 벡터 **x**에 대한 함수를 정의한다:  

$$
\mathbf{y} = f(\mathbf{x})
$$

- **$y$가 스칼라인 경우**  

$$
\frac{\partial y}{\partial \mathbf{x}}
=
\left(
\frac{\partial y}{\partial x_1},
\frac{\partial y}{\partial x_2},
\dots,
\frac{\partial y}{\partial x_n}
\right)
$$  

- → 이때 도함수는 크기가 $[1 \times n]$인 **행 벡터(row vector)** 가 된다.  

- **$\mathbf{y}$가 $[m \times 1]$ 벡터인 경우 (야코비안, Jacobian 표현식)**  

$$
\frac{\partial \mathbf{y}}{\partial \mathbf{x}}
=
\begin{pmatrix}
\frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} & \cdots & \frac{\partial y_1}{\partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial y_m}{\partial x_1} & \frac{\partial y_m}{\partial x_2} & \cdots & \frac{\partial y_m}{\partial x_n}
\end{pmatrix}
$$  

- → 이때 도함수는 크기가 $[m \times n]$인 **행렬(matrix)** 이 된다.  
(행의 개수는 $m$, 열의 개수는 $n$)  

---

## p21. 벡터(행렬) 미적분학 요약  

- $y$가 스칼라(scalar)이고, **X**가 크기 $[n \times m]$인 행렬(matrix)이라면  

$$
\frac{\partial y}{\partial \mathbf{X}}
=
\begin{pmatrix}
\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{21}} & \cdots & \frac{\partial y}{\partial x_{n1}} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial y}{\partial x_{1m}} & \frac{\partial y}{\partial x_{2m}} & \cdots & \frac{\partial y}{\partial x_{nm}}
\end{pmatrix}
$$  

- 결과는 크기가 $[m \times n]$인 행렬(matrix)이다.  

---

## p22. 벡터(행렬) 미적분학 요약  

- 연쇄 법칙(Chain rule):  

  함수 $h(\mathbf{x}) = f(g(\mathbf{x}))$ 에 대하여,  
  그 도함수는 다음과 같다:  

  $$
  h'(\mathbf{x}) = f'(g(\mathbf{x})) g'(\mathbf{x})
  $$  

- $\mathbf{z} = f(\mathbf{u}), \ \mathbf{u} = g(\mathbf{x})$ 로 두면:  

  $$
  \left.\frac{\partial \mathbf{z}}{\partial \mathbf{x}}\right|_{\mathbf{x}=a}
  =
  \left.\frac{\partial \mathbf{z}}{\partial \mathbf{u}}\right|_{\mathbf{u}=g(a)}
  \cdot
  \left.\frac{\partial \mathbf{u}}{\partial \mathbf{x}}\right|_{\mathbf{x}=a}
  $$  

  - $\frac{\partial \mathbf{z}}{\partial \mathbf{x}} \in \mathbb{R}^{m \times n}$  
  - $\frac{\partial \mathbf{z}}{\partial \mathbf{u}} \in \mathbb{R}^{m \times p}$  
  - $\frac{\partial \mathbf{u}}{\partial \mathbf{x}} \in \mathbb{R}^{p \times n}$  

- 여기서 $p =$ 벡터 $\mathbf{u}$의 길이($\mid \mathbf{u} \mid$),  
  $m = \mid \mathbf{z} \mid$, $n = \mid \mathbf{x} \mid$.  

- 예시:  
  $\mid \mathbf{z} \mid = 1$, $\mid \mathbf{u} \mid = 2$, $\mid \mathbf{x} \mid = 4$ 라면  

<img src="/assets/img/probstat/4/image_16.png" alt="image" width="360px"> 

---

## p23. 연쇄 법칙(Chain Rule)에 의한 동적 프로그래밍  

<img src="/assets/img/probstat/4/image_17.png" alt="image" width="720px">  

<img src="/assets/img/probstat/4/image_18.png" alt="image" width="300px">  

- 우리는 연쇄 법칙을 사용하여 모든 도함수를 개별적으로 계산할 수 있다.  
- 그러나 회색 박스 안의 항들은 **공유**된다. 따라서 이 값은 한 번만 계산하면 된다.  
- **역전파(Backpropagation)** 는 계산 그래프 전체에서 공유되는 항들을 전파(propagating)하는 알고리즘이다.  

---

## p24. 정보의 순방향 / 역방향 (Forward / Backward direction of information)  

**Forward pass**  

네트워크를 통해 데이터를 순방향으로 전달하며, 출력을 계산하고 손실(loss)을 계산한다.  

<img src="/assets/img/probstat/4/image_19.png" alt="image" width="680px"> 

---

**Backward pass**  

출력과 손실로부터의 오차 신호(그래디언트)를 네트워크를 통해 역방향으로 전달하여, 입력과 매개변수로 되돌려 준다.  

<img src="/assets/img/probstat/4/image_20.png" alt="image" width="720px">  

---

## p25. 일반적인 층(Generic Layer)의 역전파  

<img src="/assets/img/probstat/4/image_21.png" alt="image" width="480px">  

---

- 우리는 두 종류의 편도함수 배열을 추적할 것이다:  
  - **L** : 층의 출력에 대한 층의 입력의 그래디언트 (행렬)  
  - **g** : 활성화(activation)에 대한 비용 함수의 그래디언트 (행 벡터)  

<img src="/assets/img/probstat/4/image_22.png" alt="image" width="360px"> 

---

## p26. 일반적인 층(Generic Layer)의 역전파 (계속)  

<img src="/assets/img/probstat/4/image_23.png" alt="image" width="480px"> 

---

- 한 층에 대해 **L** 과 **g** 를 알고 있다면, **매개변수 업데이트(parameter update)** 는 간단하다.  

<img src="/assets/img/probstat/4/image_24.png" alt="image" width="300px">

---

## p27. 일반적인 층(Generic Layer)의 역전파 (계속)  

<img src="/assets/img/probstat/4/image_25.png" alt="image" width="480px">  

---

- 그런데, 각 층에 대해 $L$ 과 $g$ 는 어떻게 구할 수 있을까?  

- **L** 은 해당 층의 도함수 함수 $f'$ 로부터 얻어진다 (주어진다고 가정함):  

<img src="/assets/img/probstat/4/image_26.png" alt="image" width="150px">

- **g** 는 다음의 점화식을 통해 반복적으로 계산될 수 있다:  

<img src="/assets/img/probstat/4/image_27.png" alt="image" width="150px"> 

---

- 오차 신호의 역전파(backpropagation of error signals)를 통해 그래디언트가 전달된다.  

---

## p28. 일반적인 층(Generic Layer)의 역전파  

<img src="/assets/img/probstat/4/image_28.png" alt="image" width="480px">   

---

- 이 모든 과정은 **매개변수 갱신 방향(parameter update directions)** 을 계산하기 위한 것이다.  

---

## p29. 모든 것을 종합하기 (Putting it all together)
  
**Forward**  
  
데이터를 네트워크를 따라 순방향으로 전달하여 출력과 손실(loss)을 계산한다.  

<img src="/assets/img/probstat/4/image_29.png" alt="image" width="680px">  

---

**Backward**  
  
출력과 손실로부터 발생한 **오차 신호(그래디언트)** 를 네트워크를 통해 역방향으로 전달한다.  

<img src="/assets/img/probstat/4/image_30.png" alt="image" width="720px">  

---

### Update:
- 매개변수 갱신  

<img src="/assets/img/probstat/4/image_31.png" alt="image" width="240px">  


그리고 이 과정을 반복한다.  

---

## p30. 일반적인 층(Generic Layer)에 대한 역전파  

<img src="/assets/img/probstat/4/image_32.png" alt="image" width="360px">  

- 학습하는 도중 층(layer) $l$은 세 개의 입력을 가진다:

<img src="/assets/img/probstat/4/image_33.png" alt="image" width="150px">  

---

- 그리고 세 개의 출력을 가진다:

<img src="/assets/img/probstat/4/image_34.png" alt="image" width="360px">  

---

- 주어진 입력이 있을 때, 우리는 다음을 계산하면 된다:  

<img src="/assets/img/probstat/4/image_35.png" alt="image" width="240px">  

---

## p31. 요약 (Summary)

<img src="/assets/img/probstat/4/image_36.png" alt="image" width="400px">  

---

1. **Forward pass**: 각 학습 예제에 대해, 모든 층의 출력을 계산한다.  

$$
x_l = f_l(x_{l-1}, \theta_l)
$$  

---

2. **Backward pass**: 위에서부터 아래로 순차적으로 손실 함수의 도함수를 계산한다.  

$$
\frac{\partial J}{\partial x_{l-1}} 
= \frac{\partial J}{\partial x_l} \cdot \frac{\partial f_l}{\partial x_{l-1}}
$$  

---

3. **Parameter update**: 가중치에 대한 그래디언트를 계산하고, 가중치를 갱신한다.  

$$
\frac{\partial J}{\partial \theta_l} 
= \frac{\partial J}{\partial x_l} \cdot \frac{\partial f_l}{\partial \theta_l}
$$  

---

## p32. 다층 퍼셉트론(MLP)? 장점과 단점

<img src="/assets/img/probstat/4/image_37.png" alt="image" width="500px">  

---

**장점**  
- **보편성 (Universal)**  
- **단순함, 우아한 이론 (Simple, elegant theory)**  
- **병렬화가 매우 쉬움 (Embarrassingly parallel)**  

---

**단점**  
- **약한 귀납적 편향 (Weak inductive biases)**  
- **샘플 비효율적, 데이터 많이 필요 (Sample inefficient / data hungry)**  
- **밀집된(fully-connected) 선형 계층**은 **많은 계산 자원**을 소모함  

---

## p33. 왜 다른 아키텍처(architecture)를 사용해야 하는가?  

<img src="/assets/img/probstat/4/image_38.png" alt="image" width="600px">  

---

### 보충 설명  

- **전체 회색 사각형의 의미**  
  입력 공간 $\mathcal{X}$ 에서 출력 공간 $\mathcal{Y}$ 로 가는 **모든 가능한 함수들의 집합**을 의미한다. 즉, 이 안에는 우리가 상상할 수 있는 모든 입력-출력 매핑이 포함되어 있다.  

- **초록색 타원의 의미**  
  주어진 **데이터를 설명할 수 있는 함수들의 집합**을 나타낸다. 이 영역 안의 함수들은 최소한 관찰된 데이터에는 들어맞는다.  

- **위 그림의 종합적인 의미**  
  실제로는 우리가 모든 가능한 함수(회색 영역)를 다 고려하는 것이 아니라, 데이터에 맞는 함수(초록색 영역) 중에서 학습 알고리즘이 하나의 해답(파란색 X)을 선택한다는 것을 보여준다. 하지만 선택된 해답이 참 해답(초록색 원)과 항상 일치하는 것은 아니다.  

---

## p34. 왜 다른 아키텍처(architecture)를 사용해야 하는가?  

<img src="/assets/img/probstat/4/image_39.png" alt="image" width="600px">  

---

### 보충 설명  

- **데이터의 역할**  
  학습에 사용되는 데이터가 많아질수록, 주어진 데이터와 잘 맞는 해답의 범위가 점점 좁아진다.  

- **그림의 의미**  
  33페이지에서 보여준 초록색 영역(Fits the data)이 더 작은 타원으로 표현되며,  
  이는 모델이 찾을 수 있는 해답의 불확실성이 줄어드는 과정을 나타낸다.  

---

## p35. 왜 다른 아키텍처(architecture)를 사용해야 하는가?  

<img src="/assets/img/probstat/4/image_40.png" alt="image" width="600px">  

---

데이터가 적을수록, 더 나은 아키텍처가 필요하다.  

우리는 참 해답에 더 가까워질 수 있다.  
- 방법 1: 더 많은 데이터를 추가하는 것  
- 방법 2: 더 제한적인 아키텍처를 사용하는 것  

---

### 보충 설명  

- **가설 공간(hypothesis space)** 은 모델이 만들 수 있는 함수들의 전체 집합을 뜻한다.  
- 초록색 타원은 **데이터와 일치하는 함수들**이고, 흰색 원 $\mathcal{F}$ 는 **현재 모델 구조(architecture)로 표현 가능한 함수들의 범위**다.  
- 두 영역이 겹친다는 것은: 데이터와 맞는 함수들 중에서 모델이 실제로 표현할 수 있는 후보가 존재한다는 뜻이다.  
- **더 제한적인 아키텍처**란, 모델이 표현할 수 있는 함수의 범위를 인위적으로 줄이는 것을 의미한다.  
  - 예: 모든 가능한 복잡한 함수 대신, **특정 구조(예: CNN의 합성곱 구조, RNN의 순차 구조)** 를 강제로 적용하는 것.  
- 이렇게 하면 학습된 해답(파란 X)이 불필요하게 넓은 공간에 퍼지지 않고, 참 해답(초록 O)에 더 가까운 위치로 제한될 수 있다.  

---

## p36. 일반화(Generalization)와 아키텍처(Architectures)  

<img src="/assets/img/probstat/4/image_41.png" alt="image" width="720px">  

- — <span style="color:green">**참 해답 (True solution)**</span>  
- — <span style="color:blue">**학습된 해답 (Learned solution)**</span>  
- ● **훈련 데이터 (Training data)**  

---

### 보충 설명  

#### 1. **일반화의 의미**  
- **일반화(generalization)** 는 학습 데이터(●)에만 잘 맞추는 것이 아니라, 보지 않은 새로운 데이터에도 잘 동작하는 능력을 말한다.  
- 그림에서 초록색 선은 **참 해답(True solution)**, 파란색 선은 **학습된 해답(Learned solution)**, 검은 점은 **훈련 데이터(Training data)** 를 나타낸다.  

#### 2. **데이터 양과 모델의 대응**  
- 훈련 데이터가 적으면(왼쪽) 모델은 참 해답의 복잡한 패턴을 반영하지 못하고 단순한 곡선을 학습한다.  
- 데이터가 늘어나면(가운데, 오른쪽) 점차 참 해답의 패턴을 더 많이 반영할 수 있다.  

#### 3. **아키텍처의 역할**  
- 같은 5층 ReLU 네트워크라도, 데이터가 얼마나 주어지느냐에 따라 학습된 해답의 모양이 달라진다.  
- 따라서 **데이터 양과 아키텍처 설계** 모두가 일반화 성능에 큰 영향을 준다.  

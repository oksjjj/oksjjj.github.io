---
layout: post
title: "[확률과 통계] 9주차"
date: 2025-10-28 23:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. 생성 모델의 일반 개념 (General Concept of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_1.png" alt="image" width="600px">

> **강의 내용**  
>
> 생성 모델이 무엇이냐 이런 거를 먼저 좀 생각해 보면 좋을 것 같아요.  
>
> 예를 들어서  
> 텍스트가 주어지고 거기에 대해서 어떤 shape이나 이미지를 생성하는  
> AI 모델을 생각을 해보면,  
> 제네리티브 모델, 생성하는 모델이기 때문에  
> 생성하는 생성자가 있어야 되잖아요.  
>
> 그래서 그 생성자를 제너레이터라고 부릅니다.  
> 제네리티브 모델이기 때문에.  
>
> 제네레이터에는 크게 두 가지 인풋이 있는데요.  
>
> 하나는 이제 컨디션 인풋.  
> 우리가 텍스트 이미지 생성이라고 한다면  
> 텍스트 청크들, 토큰의 시리즈,  
> 혹은 이렇게 원핫 벡터로 표현되어 있는  
> 어떤 컨셉들, 그런 것들이  
> 첫 번째 인풋으로 들어가고.  
>
> 두 번째 인풋은 랜덤성입니다. 랜덤성.  
>
> 제네리티브 모델이 Probability나 Statistics에서  
> 굉장히 잘 정의된 학문인데,  
> 가장 중요한 건  
> 인풋으로 random variable이 들어가야 된다는 겁니다.  
>
> 그래서 이 랜덤성이 뭘 표현하느냐 하면  
> 
> random variable, 주사위로 표현된 랜덤성이 들어갔을 때  
> output distribution, 이미지 distribution의 여러 가지 이미지 surface를  
> 표현할 수 있게 해주는 거예요.  
>
> 인풋이 Bird라고 했을 때  
> 항상 똑같은 이미지만 만들면 안 되잖아요.  
> 
> Bird에 대한 여러 가지 variation이 나와야 하고,  
> 그 랜덤성을 표현하기 위해 랜덤 배리어블이 들어갑니다.  
>
> 보통 현대 생성 모델은 다 이런 파이프라인을 갖습니다.  
> 
> 굉장히 컨셉추얼하고 간소화된 구조지만  
> 크게 보면 이런 거라고 보면 될 것 같아요.      

---

## p3. 생성 모델의 확률적 표현 (Probabilistic Representation of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_2.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 그러면 이런 걸 생각을 해볼게요.  
> 
> Bird인데, Bird의 어떤 latent information을 통해서  
> 새의 각각의 모양들을 표현할 수 있을 것인가?  
> 
> 이런 것들이 핵심인데요.  
>
> 주사위가 여러 개가 있는 게 어떤 걸 표현을 하는 거냐면  
> 
> 랜덤성의 하나하나의 feature들이  
> 생성되는 이미지의 어떠한 것들을  
> 결정을 할 것이냐 라고 생각해 볼 수 있을 것 같아요.  
>
> 첫 번째 주사위는 색에 대한 것.  
> 두 번째 주사위는 각각의 컴포넌트들이 어떻게 결합되는지? 각도에 대한 것.  
> 그리고 새 사이즈에 대한 것.  
> 
> 이런 주사위, 랜덤 배리어블이  
> 여러 가지들을 statistical하게 결정하는 거겠죠.  
>
> 그리고 이게 뭘 표현하려고 하는 거냐면  
> 
> high dimensional한 랜덤 배리어블이 들어간다는 거예요.  
> 우리 앞에서 배웠던 보통 multivariate gaussian 랜덤 배리어블이  
> 랜덤성으로 들어갑니다.  
>
> 굉장히 좀 신기한 건데  
> multivariate gaussian distribution에는 semantic이 없어요.  
> 
> 그냥 뭔가 각각의 축들이  
> 어떤 컬러나 앵글을 표현하라고 설정하지 않았습니다.  
>
> 그런데 생성 모델에서 학습을 하다 보면  
> 명확하게 첫 번째 feature는 무조건 컬러다 이건 아니지만  
> semantic하게 나눠지게 되거든요.  
> 
> 나중에 이제 실습할 때 보시겠지만.  
>
> 그래서 그런 점들이 generative 모델의 가장 큰 특성 중 하나다.  
> 우리가 뭔가 feature를 부여하지 않더라도  
> 학습 이후에 그런 feature들이  
> high dimensional한 space,  
> high dimensional 랜덤 배리어블에 association이 된다.  
>
> 그런 것들이 재밌는 점이고  
> 실습을 통해 더 알아보도록 하겠습니다.     

---

## p4. 데이터 생성기의 분류 (Categorization of Data Generators)  

두 가지 접근 방식이 있다.  

1. **직접 접근(Direct approach)**: 데이터를 직접 생성하는 함수를 학습한다.  
(혼동스럽게도, 때때로 “암묵적 생성 모델(implicit generative model)”이라고도 불린다.)

   $$
   G : \mathcal{Z} \rightarrow \mathcal{X}
   $$

2. **간접 접근(Indirect approach)**: 데이터를 평가(score)하는 함수를 학습하고,  
   이 함수 아래에서 점수가 높은 지점을 찾아 데이터를 생성한다.  

   $$
   E : \mathcal{X} \rightarrow \mathbb{R}
   $$

> **강의 내용**  
> 
> Data Generator에는 크게 두 가지 방법이 있을 수가 있습니다.  
> 
> 먼저 Direct Approach라는 게 있습니다.  
> 
> 앞에서 말했었던 GAN은  
> Direct Approach를 사용하는 중요한 모델 중의 하나인데.  
>
> 어떤 뜻이냐면  
> random variable input을 가지고  
> output에 대한 데이터를 직접적으로 생성해주는  
> 모델들을 Direct Approach 모델들이라고 하고.  
>
> Indirect Approach 같은 경우는  
> 
> 전형적으로 Diffusion 같은 모델들이  
> Indirect Approach인데.  
> 
> neural network input에 random variable을 넣어서  
> 뭔가 나오는 게 아니라  
> 
> 추가적인 파이프라인이 또 있습니다.  
>
> 그 파이프라인의 하나의 component로써  
> neural network가 작동을 하고.  
> 
> 보통 energy function 혹은 score function 이런 걸로 표현을 하는데.  
> 
> 그런 score 혹은 energy로  
> 얼마나 데이터가 잘 생성됐느냐 안 됐느냐에 대해서 판단을 하는  
> 
> 그런 함수들을 neural network로 모델링을 해가지고  
> 데이터를 생성하는 그런 모델들이 있는데.  
>
> 아까 말씀드렸었던 것처럼  
> 그런 Diffusion 모델, Normalizing Flows 모델들이  
> 여기에 속하게 됩니다.  
>
> 오늘 배울 VAE는  
> 첫 번째와 두 번째 중간 정도에 있는 것 같아요.  
> 첫 번째가 더 가깝다고 봐야 될 것 같고.      

---

## p5. 직접 접근(Direct Approach)의 학습과 샘플링 과정  

<img src="/assets/img/lecture/probstat/9/image_3.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 이제 데이터 생성을 하는 파이프라인을,  
> 이렇게 한번 봐보면 될 것 같아요.  
>
> 만약에 사람 얼굴을 생성을 한다면  
> 
> 왼쪽과 같은 사람 얼굴들을 많이 모아놓은 이런 데이터셋에  
> learner가 존재를 해서 옵티멀한 파라미터를 찾게 되고  
> 그 파라미터가 neural network,  
> generator의 파라미터로써 작용을 하고.  
>
> 이건 트레이닝 과정에 대한 거고  
> 
> 샘플링 할 때는, inference time, test time이라고도 얘기하는데  
>
> 샘플링 할 때는  
> Gaussian Random Variable을 generator에 주입을 했을 때  
> 우리가 원하는 이미지가 나오기를 원하는 거.  
>
> 그래서 많은 생성 모델들이  
> training time이랑 test time이 이렇게 나와요.  
>
> 근데 우리가 앞에서 살짝 봤었던  
> classification 모델 같은 경우는 이런 scheme은 아니거든요.  
> 
> input과 output이 똑같고 데이터의 모양만 다른 게  
> 트레이닝과 샘플링 했을 때의 차이인 건데.  
>
> 생성 모델들은  
> 트레이닝 하는 과정과 샘플링 하는 과정이,  
> 파이프라인이 이렇게 쪼개져 있어요.  
>
> 그래서 이 두 개가  
> 기존에 잘 알려져 있는  
> 딥러닝 neural network를 활용하는 문제들의 파이프라인과  
> 다르다는 것을 아셔야 될 것 같습니다.      

---

## p6. 간접 접근 (Indirect Approach)  

<img src="/assets/img/lecture/probstat/9/image_4.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 이제 Indirect Approach를 잠깐 살펴보자면  
> 
> 데이터가 존재 하고 러너가 존재해서  
>
> 아까 score function를 말씀드렸습니다.  
> energy, likelihood와 같은 개념들을 스코어링 해준다.  
>
> 트레이닝 methodology가 존재해서  
> score function의 값을 높이거나 혹은 낮추는 형식으로  
> 간접적으로 스코어링을 하게 되고  
>
> 그리고 이렇게 스코어링 된,  
> 스코어링이 최적으로 된 데이터의 위치들이  
> 샘플링을 했을 때 생성되는 데이터라고 보면 될 것 같아요.  
>
> 여기 트레이닝이랑 샘플링이 나눠져 있죠.  
>
> 트레이닝은 score function을,  
> score를 높이거나 낮추는 거죠.  
>
> 그리고 샘플링은  
> 그렇게 만들어진 어떤 러너의 파라미터를 가지고 샘플링,  
> MCMC 등의 알고리즘을 통해서 샘플링하는 거.  
>
> 사실 지금 이 파이프라인을 보면  
> 이해가 잘 안 되실 것 같은데요.  
> 
> 뒤에 normalizing flow랑 diffusion model 등을 배우면  
> 이게 어떤 뜻인지 완벽하게 이해를 하실 수 있을 것 같습니다.  
>
> 오늘 강의는 사실 여기에 초점을 맞추진 않았습니다.  
> 강의를 계속 진행하다 보면 나올 것 같습니다.      

---

## p7. 생성 모델 (Generative Models)  

목표는 학습 데이터를 그대로 복제하는 것이 아니라,  
**새로운(new)** 데이터를 만드는 것이다.  
그 데이터는 **현실적인(realistic)** 데이터여야 하며,  
실제 데이터의 **본질적인 속성(essential properties)**을 포착해야 한다.  

이것을 정량화하는 한 가지 방법은  
모델 하에서의 **테스트 데이터의 가능도(likelihood)**를 이용하는 것이다.  
(학습 데이터를 기억하는 모델은,  
분류기(classifier)가 과적합(overfit)되는 것과  
정확히 같은 의미에서 과적합된 것이다.)  

$$
\{x_{\text{test}}^{(i)}\}_{i=1}^{N}, \quad x_{\text{test}}^{(i)} \sim p_{\text{data}}
$$  

$$
\text{generalization error} = \sum_i \log p_\theta (x_{\text{test}}^{(i)})
$$  

> **강의 내용**  
> 
> 생성 모델의 목표는 무엇이냐 라고 한다면  
> 
> 여러분들이 헷갈릴 수도 있을 것 같은데  
> 명확하게 해야 될 것 같아요.  
>
> 우리는 트레이닝 데이터를 가지고  
> 트레이닝 데이터를 완벽하게 똑같이 만드는 게 목표가 아닙니다.  
>
> 특정 트레이닝 데이터에 어떤 distribution이 생겼다고 했을 때  
> 그 distribution과 굉장히 닮은 애를 만들어야 해요.  
> 그게 목적입니다.  
>
> 만약에 트레이닝 데이터와 완벽하게 똑같은 애를 만든다고 가정을 하면  
> 
> GPT 같은 것도 어떻게 보면  
> generative AI 기술의 하나라고 볼 수 있는데  
> 생성할 때마다 데이터셋과 완벽하게 align된 데이터들이 생성이 되겠죠  
> 완전히 똑같은 트레이닝 데이터를 복원을 하는 게 목적이라고 한다면  
> 
> 그런데 아시다시피 새로운 가치를 extrapolation이 되는 게  
> 현대 generative AI 모델들의 큰 특징점이거든요.  
>
> 새로운 정보가 창출돼요.  
> (뭐 많이 잘 창출되지는 않는데)  
> 
> 그런데 창출된 지식이 현실의 physical knowledge에  
> 위반이 됐을 때 그것을 hallucination이라고 하죠.  
>
> 그 두 가지의 줄다리기가 있는데  
> 
> 어쨌든 extrapolation을 하기 위해서는  
> 트레이닝 데이터에 완벽하게 매칭을 하는 게 아니라  
> realistic하고 world knowledge를 잘 반영할 수 있는  
> 그런 새로운 데이터를 만드는 거.  
> 그런 것들이 생성 모델의 목표라고 보시면 될 것 같아요.  
>
> 그러면 이것을 어떻게 quantification을 하느냐.  
> 
> language 모델 같은 경우는  
> 어떻게 evaluation 하느냐, 어떻게 평가를 하느냐  
> 이런 거랑 되게 비슷한 느낌인데  
> 
> 사실 똑같은 어떤 철학적인 목적,  
> 철학적인 배경이 있다고 생각하면 될 것 같아요.  
>
> 이제 test data에 대해서 생각을 하는 거죠.  
> 
> 저기 보면 $\log p_\theta$라고 얘기하는데  
> 이게 앞에서 배웠었던 log-likelihood의 개념에서 나왔었던 notation이죠.  
>
> $\log p_\theta$가,  
> $p_\theta$는 여기서 statistical model이 되는 거고.  
>
> 그래서 트레이닝한 다음에, test data에다가  
> 우리가 만들어 놓은 statistical model에 대한  
> likelihood estimation을 했을 때  
> 얼마나 많은 에러가 생기냐.  
>
> 이게 generalization 에러가 얼마나 생기냐인데  
> 이게 이제 크면 클수록  
> 아까 말씀드렸었던 extrapolation과 hallucination의 사이에 있는 것,  
> 그런 것들을 표현하는 거다  
> 라고 생각하시면 될 것 같고요.  
>
> 그러니까 generalization 에러가 크다고  
> 무조건 나쁜 것도 아니고  
> 
> generalization 에러가 0이면  
> 트레이닝 데이터와 똑같은 거거든요, test data가.  
>
> 또 그게 또 좋은 것도 아니고  
> 요즘엔 갑론을박이 있는 것 같습니다.  
>
> extrapolation에 대한 철학적 정의가 어떻게 돼야 되는 것인가,  
> 새로운 정보를 창출이 어떻게 정의가 되어야 되는지  
> 아직도 말이 많은 것 같습니다.  
>
> 그래서 language model을 평가를 하기 위한 최적의 매트릭이 무엇이냐  
> 
> 이런 것도 다 그런 생각에서 오는 것 같고요.     

---

## p8. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_5.png" alt="image" width="600px">

> **강의 내용**  
> 
> 이제 density based model에 대해 생각을 해보자면.  
> 
> 트레이닝 데이터 $N$개가 주어진다고 했을 때,  
> probability density의 특징이,  
> sum 했을 때 $1$이라고 했었죠.  
> 
> normalization equation에 따라서.       

---

## p9. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_6.png" alt="image" width="600px">

> **강의 내용**  
> 
> 트레이닝 데이터가 있을 때  
> discrete한 케이스라서 이렇게 봉들이 생길 텐데  
> 
> 트레이닝 데이터의 $y$축에 해당하는 것들,  
> 그것을 다 summation 했을 때 $1$이 돼야 되는  
> 그런 조건을 생각해볼 수 있을 것 같아요.     

---

## p10. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_6_1.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 데이터가 있는 곳에서는  
> mass가 표현되어야 되니까,  
> 
> 데이터가 있는 곳에서는 높이가 높게 평가가 될 것이고  
> 데이터가 없는 곳에서는 높이가 낮게 평가가 되어야겠죠.  
>
> 그래서 density based model들,  
> energy model, diffusion model 같은 경우는  
> 학습을 한 다음에 실제로 density estimation을 해보면  
> 이런 모양이 많이 나옵니다.  
>
> 이런 모양이 잘 나오면  
> 전문가가 봤을 때 트레이닝이 잘 되었다고  
> 판단하는 경우도 많습니다.  

---

## p11. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_7.png" alt="image" width="800px">

$$
\begin{aligned}
p_\theta^* 
&= \arg \min_{p_\theta} \text{KL}(p_{\text{data}}, p_\theta) \\
&= \arg \min_{p_\theta} \mathbb{E}_{x \sim p_{\text{data}}} 
   \left[- \log \frac{p_\theta(x)}{p_{\text{data}}(x)} \right] \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ] 
   - \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_{\text{data}}(x) ]  
   \quad\quad\quad \text{(max likelihood)} \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ]
   \quad\quad\quad \text{(두 번째 항은 } p_\theta \text{에 의존하지 않기 때문에 생략)} \\
&\approx \arg \max_{p_\theta} 
   \frac{1}{N} \sum_{i=1}^{N} \log p_\theta(x^{(i)})
\end{aligned}
$$  

> **강의 내용**  
> 
> 이 내용을 보시고 처음 보시는 내용처럼 생각하시면 안 돼요.  
> 시험에도 나왔었고, 앞에서 많이 다뤘었습니다.  
>
> 그래서 maximum likelihood estimation,  
> $p_\theta^\*$  
> 
> 최적의 probability distribution은  
> KL divergence를 줄이는 거였었고.  
>
> 그래서 계산을 쭉 따라서 해보면  
> constant 항이 나오고,  
> 
> 그리고 그 $p_{\text{data}}$와 $p_\theta$의 관계들,  
> $log$ 함수를 통한 decompose 등을 하다 보면  
> 맨 마지막에  
> $\arg\max \log p_\theta$를 하는 것이고,  
>
> 물리적으로 봤을 때  
> 위에서 그림으로 표현하는 것처럼  
> 데이터가 있는 데는 확률을 높이고  
> 데이터가 없는 데는 확률을 낮추는 형식으로  
> 표현된다고 보시면 될 것 같아요.  
>
> 그래서 우리가 앞에서 수학적으로만 배웠는데  
> 
> 이런 물리적인 성질을 가지고  
> maximum likelihood를 정의를 했었던,  
> 
> 그러니까 이런 물리적인 특징을 사용하는 게  
> 생성 모델의 학습 방법입니다.  
> 이렇게 생각하시면 될 것 같습니다.  
>
> (질문)  
> 
> 회색의 실선이 $p_\theta$고  
> 점들이 $p_{\text{data}}$라고 보면 될까요?  
> 점에 이렇게 녹색 화살표가 있는 게 $p_{\text{data}}$고.  
>
> (답변)  
> 
> 아 왼쪽 그림 말씀하시는 거죠?  
> 
> 그러니까 알고리즘을 통해서 maximization을 하다 보면  
>
> 예를 들어서 왼쪽에 어떤 회색의 영역이 있었는데  
> maximization을 취하다 보면  
> 
> 이게 optimization이라는 것이  
> 한 번에 딱 되는 게 아니라  
> 시간을 걸쳐서 iterative하게 되는 거거든요.  
>
> 그래서 점진적으로  
> mass가 존재하는 데는 초록색으로 표현되어 확률이 높아지고  
> mass가 없는 데는 빨간색으로 표현되어 확률이 낮아지고  
> 이렇게 된다는 거죠.  
>
> (질문)  
> 
> 아 그럼 오른쪽 그림에서  
> 회색이 $p_\theta$고  
> 이제 녹색과 빨간색이 있는 그 영역이  
> $p_{\text{data}}$라고 보면 될까요?  
>
> (답변)  
> 
> 그게 이제 업데이트된 영역이에요.  
> $p_{\text{data}}$는 x축에 있고요.  
> 그래서 그렇게 생각하시면 될 것 같아요.         

---

## p12. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

<img src="/assets/img/lecture/probstat/9/image_8.png" alt="image" width="480px">

> **강의 내용**  
> 
> 여기까지가 개요구요.  
> 
> 오늘의 교육은,  
> 강의 길이가 꽤 길어서,  
> 아마 다음 주까지 연결해서 할 수도 있을 것 같습니다.  
> 코드 실습하면서.  
>
> 그래서 이제 variational auto encoder에 대해서  
> 살펴보도록 하겠습니다.  
>
> 앞에서 제가 VAE가  
> direct approach에 가깝다고 얘기를 했는데,  
>
> 먼저 이런 걸 한 번 생각을 해 볼게요.  
> 
> 그림에서.  
>
> $z$라는 latent variable,  
> 그러니까 Gaussian Random Variable이라고 얘기를 했었고,  
> 
> 아까 말씀드렸던 것처럼  
> size, color, breed 여러 가지 feature에 대해서  
> 
> 인간이 정의하지는 않았지만  
> 훈련을 하다 보면 mapping이 되는  
> 어떤 그런 정보를 담기 위해서 하는 거라고 보면 될 것 같고  
> 
> generator라는 것을 통해서  
> 이 $z$를 mapping해서 생성을 하는 거죠.  
>
> 그래서 여기서, notation을,  
> terminology를 만들어 봅시다.  
> 
> $z$는 명확하게 latent variable이라고 부를 것이고  
> 
> $x$는 observed variable,  
> 데이터셋 안에 존재하는 데이터라고 보면 될 것 같아요.  
>
> 그래서 여기 그림에서, 텍스트에서 보이는 것처럼  
> world model, physical model, renderer, image, videos, audio  
> 
> 사실 이 프레임을 가지고 데이터를 생성하는  
> 현대 모든 생성 모델들은  
> 이런 구조로써 다 표현이 가능해집니다.  
>
> 예를 들어서 얀 르쿤이 말했던 world model 이런 것들,  
> 
> 요즘에 3D 비디오 하면서 인터랙티브하게 움직이게 하는 것들,  
> 다 이런 구조를 가지고 있습니다.  
>
> pipeline을 뜯어보고, 모델 아키텍처들을 뜯어보면  
> 결국엔 이렇게 하는 것입니다  
>
> 이렇게 개념적으로 파악을 하셔야 될 것 같습니다          

---

> world model이라 함은, 인공지능이 외부 세계의 구조를 스스로 학습하여  
> 환경의 규칙과 변화를 내부적으로 표현하려는 개념이라 한다.  
>
> 여기에서는 에이전트가 모든 정보를 직접 관찰하지 못하더라도  
> 세계가 어떻게 움직이는지 예측할 수 있는 능력을 갖추는 것을 목표로 한다.  
>
> 다시 말해, world model은 단순한 입력–출력 함수가 아니라  
> 환경의 인과관계와 시간적 동역학을 내재적으로 담아내는  
> 일종의 내부 시뮬레이터라 할 수 있다.  
>
> 이러한 모델이 구성되면,  
> “어떤 행동을 취하면 세계가 어떻게 변할 것인가”를  
> 에이전트가 스스로 추론할 수 있게 되며,  
> 이는 보다 고차원적인 reasoning과 지능을 구현하는 데  
> 핵심적 역할을 수행한다.

---

## p13. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

잠재 변수는 사전 분포(prior distribution)로부터 샘플링된다.  

$$
z \sim p(z)
$$  

그리고 생성기(generator)는 잠재 변수 $z$를 입력으로 받아  
관측 변수 $x$의 분포(distribution)를 생성한다.  

<img src="/assets/img/lecture/probstat/9/image_9.png" alt="image" width="720px">

> **강의 내용**  
> 
> 이제 좀 distributional한 센스로 얘기를 해보면.  
> 
> latent variable을 샘플링합니다.  
> $p(z)$라는 probability density로부터  
> 
> $z$라는 random sample, latent variable이 있고  
> 
> 지금 그림에서 보면 distribution에서 distribution으로 가는 걸로  
> 우리의 이야기가 격상이 됐죠.  
>
> 그래서 파란색 distribution으로부터,  
> 
> 파란색 distribution은 굉장히 간단합니다.  
> 정보가 없어요.  
>
> 아까 그림에서 봤던 것들.  
>
> 이것은 1-dimensional한 데이터를 고려하는 건데  
> 실제 데이터는 high-dimensional하잖아요.  
> density를 이렇게 $z$축으로, 봉우리로 표현하기도 어려운데.  
>
> 이런 식으로 오른쪽과 같이  
> multi-modal한 density의,  
> 로컬 미니멈, 로컬 맥시멈들이 많은 형태의  
> 복잡한 곳으로  
> mapping을 해주는 게 제네레이터다.  
> 
> 이렇게 생각하시면 될 것 같아요.  
>
> 그래서 앞에서 단순하게 verbal하게 정의를 했었던  
> pose, size 이런 것들이 사실 알고 보면  
> 
> 우리가 수학적으로 생각을 했을 때는  
> 쉬운 distribution에서 어려운 distribution으로 보내는 게  
> 제네레이터 모델이다.  
> 라고 생각하시면 될 것 같습니다.  
>
> 이게 사실 굉장히 심오한 이론들로 연결이 되는데  
> 그런 것들은 뒤에서 차분히 얘기하도록 하겠습니다.          

---

## p14. 변분 오토인코더 (Variational Autoencoder)  

신경망(neural network)을 이용하여 확률 분포(distribution)를 표현한다.  

- $ \theta $ : 학습 가능한 파라미터(learnable parameters)  
- 표현되는 함수:  

  $$
  p_\theta(x \mid z)
  $$  

<img src="/assets/img/lecture/probstat/9/image_10.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 제네레이터가 무엇이냐?  
> 수학적으로 조금 더 생각을 해보면  
> 
> $p(z)$는 latent variable에 대한 distribution이라 하고  
> 
> $p_\theta(x)$는 ...  
>
> 우리가 제네레이터를  
> $\theta$라는 파라미터로 parameterization 했기 때문에  
> 그 파라미터를 지나서, 그 결과물에 대한 distribution이기 때문에  
> $p_\theta(x)$로 표현했습니다.  
>
> 그럼 이제 제네레이터는,  
> conditional한 probability로    
> 확률적으로 생각을 할 수 있어요.  
>
> 우리가 conditioning, marginalization 이런 부분을 했잖아요.  
> 
> 그래서 $z$라는 어떤 랜덤 배리어블이  
> 컨디션이 걸렸을 때 나오는 $x$ 데이터의 모양이 어떠하냐.  
>
> 그러니까 제네레이터는    
> $p_\theta(x \mid z)$라는 이런 수학적 객체로  
> 표현할 수 있다는 겁니다.  
>
> 그래서 이제 여기서부터 확률이,  
> 우리가 앞에서 배웠었던 재미없었던 도구들이  
> 이것을 다루기 위한 중요한 도구들로 탈바꿈을 합니다.  
>
> marginalization 같은 경우는  
> 이것의 평균치를 어떻게 움직이느냐  
> 라는 것이 되는 거고  
> 
> 그리고 latent variable이 하나인데,  
> latent variable이 여러 개 있을 때  
> 정보량들이 서로 어떻게 연결되고 하는 것들을  
> 다 공부를 했었습니다.  
> 앞에 수식 같은 걸로.  
>
> 그런 것들이 이제 뒤에서  
> 생성 모델을 학습하기 위한  
> 수학적 백그라운드가 되거든요.  
>
> 그래서 이제 앞에 내용을 계속 살펴보시면서  
> 이 내용들이 어떻게 연결되는지  
> 보시면 될 것 같아요.          

---

## p15. 최대우도추정 (Maximum Likelihood Estimation)  

**Kullback–Leibler (KL) 발산 최소화:**  

$$
\min_{\theta} \, D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
$$  

> KL발산 외에 고려할 수 있는 다른 기준은?

**즉, 우도 최대화(Maximize likelihood):**  

$$
\max_{\theta} \, \mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
$$  

<img src="/assets/img/lecture/probstat/9/image_11.png" alt="image" width="480px">

전개 과정:  

$$
\begin{aligned}
\arg \min_{\theta} D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
&= \arg \min_{\theta} \sum_{x} p_{\text{data}}(x) 
\log \frac{p_{\text{data}}(x)}{p_{\theta}(x)} \\
&= \arg \min_{\theta} 
\left[- \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) + \text{const}\right] \\
&= \arg \max_{\theta} \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) \\
&= \arg \max_{\theta} 
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
\end{aligned}
$$  

> **강의 내용**  
> 
> 우리가 KL Divergence이라는 것을 공부를 했고,  
> Total variance도 공부를 했는데  
> 
> KL Divergence를 메인으로 많이 쓴다고 했잖아요.  
>
> 제가 그때 당시에 얘기를 했던 게  
> 거의 모든 생성 모델은 KL Divergence와 커플링 되어 있다라고 얘기를 했었고.  
>
> 그래서 여기서 나왔습니다.  
> 그 KL Divergence를 줄이는 것이 우리의 목표인 거예요.  
>
> 근데 여기 줄이는 관점에서  
>
> 데이터가 굉장히 크면  
> $\theta$가 아무리 크더라도  
> 이 KL Divergence를 일정 이하로만 줄이는 것만 가능하지  
> 0으로 만들 수는 없거든요.  
>
> 데이터가 너무나 크고  
> 그걸 표현하기 위한 우리의 파라미터는 정해져 있기 때문에.  
>
> 그래서 KL Divergence를 계산을 하지만,  
> 그러니까 minimization을 하지만  
> 
> 이것은 로컬 미니멈적인 minimization이고  
> 글로벌 minimization은 불가능하다고.  
> 뉴럴 네트워크, 논리니어한 머신을 다루고 있기 때문에.  
>
> 그러면 이제 KL Divergence가 어떤 의미였는지 잘 생각을 해보면  
>
> 그것은 두 분포 간의 다름을 정의하는 functional이었잖아요.  
>
> 그래서 데이터에 대한 distribution이 있고  
> 모델이 만들어낸 생성된 데이터들에 대한 distribution $p_\theta(x)$가 있을 때,  
> 이 두 개를 최대한 같게,  
> 이 두 개의 다름을 최대한 줄이는 것을  
> 목적으로 하는 겁니다.  
>
> 만약 이 KL Divergence가 정말 작은 값이라고 한다면  
> 어떤 걸 기대할 수 있냐면  
> 
> 우리가 만들어낸,  
> $x$에 대한 probability distribution $p_\theta(x)$가  
> $p_{\text{data}}$와 닮았으니까  
> 생성된 데이터 이미지가, 즉 샘플링된 이미지가,  
> 데이터에 있는 이미지와 닮을 것이라는  
> 희망을 가지는 거예요.  
>
> 이것이 input과 output에 대한 철학이라고 한다면  
>
> 이제는 훈련 방법론에 대한 철학입니다.  
>
> classification은 어땠었죠?  
> 
> classification은  
> 하나의 이미지가 있고, 거기에 해당하는 레이블이 존재하는   
> one to one을 매칭을 하는  
> one to one dependent한 objective function을 가지게 되는데  
> 여기서는 그렇지가 않습니다.  
>
> 여기서는 probability distribution을 매칭하는 것이기 때문에  
> 다대다 매칭이에요.  
> 
> 왜냐하면 $p_{\text{data}}$에는 얼마나 많은 데이터가 있고  
> $p_\theta$를 만들 수 있는 데이터가 얼마나 많겠습니까?  
>
> 그것들에 대한 pairing이 없어요.  
> distribution으로 매칭을 하는 거에요.  
>
> 이것이 철학적 다름입니다.  
> 그래서 KL Divergence 같은 걸 공부를 하는 거예요.  
> 다대다 매칭을 하기 위해서.  
>
> 그러니까 다대다 매칭을 한다는 것이 어떤 의미냐면  
>
> 다시 돌아가 보죠.  
>
> 첫 번째 이 슬라이드를 봤을 때  
> 이 랜덤 베리어블을 뽑을 때마다  
> 다른 데이터가 나오게끔 하는 파이프라인을  
> 그 학습 방법론으로부터 끌고 왔다는 거죠.  
>
> 랜덤 베리어블이 계속 달라지는데  
> 같은 값만 나오게 된다면 그건 말이 안 되는 거죠.  
>
> 랜덤 베리어블을 샘플링하면,  
> 같은 값을 주더라도 생성을 하면 다른 이미지가 나와요.  
> 굉장히 재밌는 현상인데,  
> 그런 어떤 철학이 있다는 거.  
>
> 그렇습니다.  
>
> 그래서 우리는 KL Divergence와  
> maximum likelihood의 estimation과 연결을 했었고  
>
> 다시 KL Divergence를 주고  
> maximum likelihood가 변경이 됐었고  
> 생성 모델을 푸는 게 그렇다.  
>
> 그래서 이런 도구들을 배웠었습니다.          

---

## p16. 최대우도추정 (Maximum Likelihood Estimation)

우리는 다음 식을 최대화하고자 한다.

$$
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_\theta(x)]
$$  

여기서 $p_\theta(x)$는 다음과 같이 표현된다.

$$
p_\theta(x) = \int_z p_\theta(x \mid z) \, p(z) \, dz
$$  

<img src="/assets/img/lecture/probstat/9/image_12.png" alt="image" width="480px">

이때 두 가지 미지항(unknowns)이 존재한다.

1. **최적화 대상:** $\theta$ — 학습 가능한 파라미터  
2. **제어 불가능한 요소:** “진짜” 사전 분포 $p(z)$  

따라서 다음과 같은 아이디어가 제시된다.  
→ **“제어 가능한(controllable)” 분포 $q(z)$**를 도입한다.

> **강의 내용**  
> 
> 조금 더 디테일하게 가봅시다.  
>
> $\log p_\theta$가  
> 생성된 데이터에 대한 distribution이라고  
> 얘기를 했었잖아요.  
>
> $\theta$는 뉴럴 네트워크의 파라미터였고.  
>
> 그래서 이제 $p_\theta(x)$를  
> marginalization, conditioning하는 룰을 통해서,  
> (앞에서 배웠었던 룰을 통해서)  
> 중간에 이 적분 형식으로 쪼개 본다고 해봅시다.  
>
> 이게 정확하게 equal이 성립을 하거든요.  
> conditional probability의 정의에 따라서.  
>
> 여기서 $p(z)$는 Gaussian Random Variable이고,  
> $p_\theta(x \mid z)$는 제네레이터였죠.  
>
> 그렇게 했을 때  
> $p_\theta(x)$,  
> 데이터의 생성에 대한 데이터 distribution이 연결되는 겁니다.  
>
> 우리가 앞에서 그린 파이프라인에서는  
>
> 모델에다 데이터를 넣었다,  
> 랜덤 배리어블을 넣었다,  
> latent variable을 넣었다,  
> 이렇게 뭐를 넣었다 뺐다 이런 얘기를 했는데  
> 수학적으로 이제 명확하게 정의를 한 겁니다.  
>
> informal한 거를 formal한 단계로 바꾼 거예요.  
>
> 그래서 이 적분의 형태로 표현하는 것이,  
> 제네레이터를 표현할 수 있는 방법 중 하나다.  
>
> 근데 여기서 문제가 뭐냐면,  
> $\theta$를,  
> conditional한 이런 입장에서  
> 어떻게 optimization을 하느냐.  
>
> 그것이 문제가 되겠죠.     

---

> - 최대우도추정(MLE)은 실제 데이터 분포 $p_{\text{data}}$에 대해  
>   모델 분포 $p_\theta(x)$의 로그 가능도 $\log p_\theta(x)$를 최대화하는 것을 목표로 한다.  
>
> - 그런데 $p_\theta(x)$는 단순한 형태가 아니라  
>   **잠재 변수 $z$에 대한 적분 형태**로 표현된다. 조건부 확률의 정의를 이용하면 다음과 같다.  
>
>   $$
>   p_\theta(x) = \int_z p_\theta(x \mid z)\, p(z)\, dz
>   $$
>
> - 여기서  
>   - $p(z)$는 **잠재 변수의 사전 분포(prior distribution)**이며 보통 가우시안으로 가정한다.  
>   - $p_\theta(x \mid z)$는 **생성기(generator)**로, “$z$가 주어졌을 때 $x$가 생성될 확률”을 나타낸다.  
>
> - 이 적분식은 우리가 앞서 직관적으로 이해했던  
>   “잠재 변수 $z$를 입력받아 데이터를 생성한다”는 개념을  
>   **수학적으로 공식화한 표현**이다.  
>
> - 하지만 이 식을 직접 최적화하는 것은 매우 어렵다. 그 이유는 다음과 같다.  
>   1) $p_\theta(x)$는 $z$에 대한 적분이므로 **폐형식(closed form)**으로 계산이 불가능하다.  
>   2) $p(z)$는 우리가 직접 제어할 수 없는 **고정된 분포**이다.  
>
> - 따라서 실제 학습에서는  
>   직접적인 사전 분포 $p(z)$ 대신  
>   **제어 가능한(controllable) 근사 분포 $q(z)$**를 도입하여  
>   계산과 최적화를 가능하게 만든다.  
>
> - 이 발상이 바로 **변분 오토인코더(VAE)**의 핵심 동기이다.  
>   - 즉, $p_\theta(x)$를 직접 계산하는 대신  
>   - 잠재 공간의 “근사 posterior”인 $q(z)$를 활용하여  
>     효율적으로 로그 가능도를 최대화할 수 있는 구조를 만든다.  
>
> - 다시 말해, VAE는  
>   **잠재 변수 적분 때문에 계산 불가능한 MLE 문제를  
>   변분 근사(variational approximation)를 이용해 해결하려는 방법**이다.  

---

## p17. 잠재 변수 모델 (Latent Variable Model)

<img src="/assets/img/lecture/probstat/9/image_13.png" alt="image" width="600px">

> **강의 내용**  
> 
> 제가 정말 하고 싶었던 것은 이 페이지입니다.  
> 
> 이것이 오늘 배우는 VAE라는   
> 스트럭처의 모든 것을 다 표현한다고 생각하시면 될 것 같아요.  
>
> 이게 어떻게 보면 어려울 수도 있는데,  
> 또 어떻게 보면 어렵진 않거든요.  
> 
> 그래서 이것을 완벽하게 수학적으로 이해를 하면,  
> VAE가 수학적으로 모델링해서  
> 이런 의미가 되는거구나 라고 바로 깨달을 수가 있습니다.  
>
> 그래서 이런 식의 수식을 묘사를 하는 것을,  
> Latent Variable Model이라고 합니다.  
> 
> Probability applied statistics에서  
> 굉장히 많이 쓰이는 모델이고,  
> 
> 통계학으로 뭔가를 하시는 분들은 이런 것을 많이 하십니다.  
> 베이지안 통계 이런 거 하시는 분들.  
>
> 그래서 $\log p_\theta(x)$를,  
> 어떻게 여러 개의 term으로,  
> 이해할 수 있는 term으로 쪼개느냐,  
> 이것에 대한 이야기인데,  
> 하나씩 살펴봅시다.  
>
> 그래서 첫 번째  
> $\log p_\theta(x)$을 maximization 하는 것이  
> 우리의 목표였었죠.  
>
> 다음 줄을 보면  
> $\int q(z)\,\log p_\theta(x)\,dz$라는 것으로 표현을 합니다.  
> 
> 적분을 했을 때, equality가 성립하는 이유가 뭐냐면  
>
> $\log p_\theta(x)$는 $z$와 관련이 없잖아요.  
> 그래서 $\log p_\theta(x)$가 밖으로 나오면  
> $q(z)$를 적분하는 겁니다.  
> 
> 그런데 모든 probability distribution을 적분하면 뭐가 됐었죠?  
> 1이거든요.  
>
> 그러니까 이것이 성립 하는 거죠.  
> $\log p_\theta(x)$가 안으로 들어오게 되면서.  
>
> 그리고 이제 condition이 갑자기 나오는데  
> 
> $p_\theta(x)$에서,  
> 그것을 conditioning하는 무언가로 뽑아내기 위해서  
> Bayes rule이라는 것을 사용합니다.  
>  
> 이 강의에서 더 디테일하게 다루진 않겠지만,  
> 굉장히 중요한 철학이라  
> 직접 찾아보시면 좋을 것 같아요.  
>
> 그래서 $p_\theta(x)$는 이렇게 쪼개질 수 있는데요.  
> $p_\theta(x \mid z) \cdot p_\theta(z)$  
> 그거를 $p_\theta(z \mid x)$로 나누는 거.  
>
> 지금 보면 condition이 뒤집혀졌죠.  
> 그렇게 되고  
> 
> 이제 $q(z) / q(z)$를 동시에 곱해줍니다.  
>
> 그런데 이것을 곱하는 게 가능한 이유는  
> 약분을 하면 1이니까  
>   
> 이제 log 함수의 특징에 따라서 나눠질 수 있어요.  
> $\log ab$는 $\log a$ 더하기 $\log b$로 나눠지거든요.  
> 고등학교 수학 시간 때 생각을 해보면.  
>
> 그래서 이것을 이제 잘 조립을 해서 표현을 하면 최종 식이 나옵니다.  
>
> 총 3개가 있는데  
> 이 3개를 neural network로 잘 표현한 것이  
> VAE라고 보면 될 것 같아요.  
>
> 이제 하나씩 알아 봅시다.  
>
> intractable  
> $p_\theta(x)$라는 것을  
> 수학적으로 직접 표현하는 것은 불가능해요.  
>
> 왜냐하면 굴곡이 많이 있고...  
> 특수한 경우가 아닌 이상에야  
> 표현할 수 없습니다.  
> 아예 불가능합니다.  
>
> 왜냐하면 $x$가 모델링하는 것은  
> 이미지, 음성, language 등의  
> 복잡하고 high-dimensional한  
> 스페이스를 고려하기 때문입니다.  
>
> 그래서 이렇게 바꿔서 하는 겁니다.      

---

> - 목표는 $\log p_\theta(x)$를 **최대화**하는 것이다.  
> - 이를 다루기 위해, 임의의 보조 분포 $q(z)$를 곱해 적분 형태로 변환하면  
>   $z$에 무관한 상수항인 $\log p_\theta(x)$를 적분 내부로 옮길 수 있다.  
>
> - 베이즈 규칙  
>
>   $$
>   p_\theta(z \mid x)=\frac{p_\theta(x\mid z)\,p_\theta(z)}{p_\theta(x)}
>   $$  
>
>   을 대입하고,  
>   $q(z)$를 곱하고 나누어(즉, 1을 곱한 것과 동일)  
>   로그의 성질 $\log a - \log b$를 사용해 각 항을 분리한다.  

---

## p18. 계산 불가능한 식에서 계산 가능한 형태로 (From Intractable to Tractable Formulation)

<img src="/assets/img/lecture/probstat/9/image_14.png" alt="image" width="720px">

> **강의 내용**  
> 
> 우리가 $\log p_\theta(x)$ 수식을 유도해서  
> 맨 마지막 항을 남겨놨는데.  
>
> 여기서 tractable 하다는 것은  
> 우리가 뭔가 계산할 수 있다는 것이고  
> 
> intractable 하다는 것은  
> 계산할 수 없다는 겁니다.  
>
> 그러면 계산을 할 수 없는데  
> 왜 이런 모델이 왜 필요하냐고 하면은,  
>
> 컴퓨터 공학 하시는 분들은  
> (저는 수학을 깊게 공부한 입장이라 참을 수가 없긴 한데)  
> intractable한 것을 무시합니다.  
>
> 어떠한 KL divergence를 계산하면  
> 항상 양수 혹은 어떤 constrained된 값을 갖게 되거든요.  
>
> 그래서 세 번째 term을 control을 하지 않고  
> 가만히 발산하게 놔두더라도  
> 
> 앞에 두 개를 control해서  
> 최종적으로 $\log p_\theta(x)$를  
> control할 수 있다.  
> 
> 이런 철학이 있습니다.  
>
> 그래서 intractable한  
> 맨 마지막 term을 그냥 무시하시면 된다.  
>
> 그런데 이것까지 control을 잘 할 수 있는  
> 어떤 새로운 방법이 나오면  
> $\log p_\theta(x)$를 더 잘 묘사할 수 있겠죠.  
>
> 그런데 현실에서는  
> 그렇게 안 해도 생각보다 잘 됩니다.   

---

> - 우리가 다루는 $\log p_\theta(x)$는 **직접 계산이 불가능(intractable)** 하다.  
>   그 이유는 잠재변수 $z$에 대해  
>   $$p_\theta(x)=\int p_\theta(x\mid z)p_\theta(z)\,dz$$  
>   와 같은 **고차원 적분**을 닫힌 형태(closed-form)로 계산하기 어렵기 때문이다.  
>
> - 이를 우회하기 위해, $\log p_\theta(x)$를  
>   $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]  
>   \;-\; D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))  
>   \;+\; D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$$  
>   와 같이 세 항으로 분해한다.  
>
> - **초록색의 두 항(앞의 두 항)은 ‘원래는’ 계산이 불가능(intractable)** 하지만,  
>   아래 두 가지 이유로 실제 학습 과정에서는 **계산 가능(tractable)** 하다:  
>
>   > ① 첫 번째 항 $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]$$는  
>   >     **몬테카를로 샘플링(Monte-Carlo estimation)** 을 이용하면  
>   >     충분히 정확하게 추정할 수 있기 때문이다.  
>   >     즉, $z\sim q(z)$ 를 샘플링한 후  
>   >     $\log p_\theta(x\mid z)$ 값을 평균 내면 된다.  
>
>   > ② 두 번째 항 $D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))$는  
>   >     **q(z)와 p(z)가 모두 가우시안인 경우(표준 VAE의 기본 설정)**  
>   >     **해석적(analytic) 닫힌형 해(closed-form solution)** 이 존재한다.  
>   >     따라서 이 항은 직접 계산이 가능해진다.  
>
> - 반면 마지막 항  
>   $$D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$$  
>   은 **여전히 계산 불가능(intractable)** 하다.  
>   이유는 $p_\theta(z\mid x)$ 를 구하려면  
>
>   $$p_\theta(z\mid x)=\frac{p_\theta(x\mid z)p_\theta(z)}{p_\theta(x)}$$  
>
>   이 되는데, 여기서 또다시 **계산 불가능한 $\log p_\theta(x)$가 등장하기 때문**이다.  
>
> - 하지만 이 항은 항상 **0 이상**이며,  
>   우리는 이를 직접 계산하지 않아도  
>   앞의 두 항(ELBO)의 합을 최대화하는 것만으로  
>   원래 목적 함수 $\log p_\theta(x)$를 **간접적으로 최대화**할 수 있다.  
>
> - 이것이 바로 변분추론(VI)의 핵심 아이디어이다.  
>   **계산 불가능한 목적을 직접 최적화하지 않고**,  
>   **계산 가능한 하한(ELBO)** 을 최대화함으로써  
>   $\log p_\theta(x)$에 최대한 가까운 값을 찾는다.  

---

## p19. 증거 하한 (Evidence Lower Bound, ELBO)

<img src="/assets/img/lecture/probstat/9/image_15.png" alt="image" width="600px">

- 이것을 **Evidence Lower Bound (ELBO)** 라고 부른다.  
- 이는 $\log p_\theta(x)$의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.

> **강의 내용**  
> 
> 이제 좌변 우변으로 정리했습니다.  
>
> intractable항 두 개를 왼쪽에 넣고.  
> tractable항 두 개를 오른쪽에 넣고.  
>
> 그래서 이렇게 조합을 했을 때  
> evidence lower bound라는  
> 굉장히 중요한 개념이 나오게 됩니다.  
>
> lower bound나 upper bound에 대해  
> 들어보신 적 있나요?  
>
> $f(x) = - x^2 + c$라는 함수가 있다고 하면,  
> upper bound는 $c$에요.  
>
> 어떤 뭔가가 변화할 때  
> 최대로 될 수 있는 threshold를  
> upper bound라고 합니다.  
>
> lower bound는 upper bound와 반대겠죠?  
>
> upper bound, lower bound는 그런 개념인데  
>
> intractable한 것을 무시하고 왼쪽으로 넘긴 다음  
> 어떤 무언가의 양수값으로 계산을 하고  
> equality를 inequality로 바꾸면  
>
> 그럼 이제 lower bound가  
> 명확하게 표현되는 것이기 때문에  
> 이것을 evidence lower bound라고 합니다  
>
> evidence라고 얘기하는 것은 뭐냐면  
> 우리가 tractable한 것 가지고  
> 결정을 하기 때입니다  
>
>
> (질문)
>   
> 가장 오른쪽에 있는 항목이 intractable한 이유가  
> given $x$인데  
> $x$가 intractable하니까  
> 마지막 항도 intractable한 것 아닌가요?  
>
> (답변)  
>
> 그것은 $z \mid x$를 알 수가 없기 때문입니다.  
> 이 slide 맨 마지막 말씀하신 거죠?  
>
> (질문)  
>
> 네.  
> 그럼 첫 번째 $x \mid z$는?  
>
> (답변)  
>
> 그거는 generator이기 때문에  
>
> $z$를 넣었을 때  
> 어떻게 작동하는지에 대해  
> 모델링을 해야 하는 건데  
> 이게 정보량의 차이가 있습니다.  
>
> $z$는 우리가 모델링한  
> 이미 알고 있는 것이기 때문에  
> 이렇게 conditional expectation을  
> 구할 수 있는 건데  
>
> $z \mid x$는  
> input이 data이거든요.  
>
> 그러니까 정보가 있는 것에서  
> 정보가 없는 것을 모델링해야 합니다.  
>
> $x$가 input이고, $z$가 output인데  
> $x$는 정보가 굉장히 많은 것,  
> $z$는 latent variable로 정보가 없는 것.  
>
> 그런데 정보가 있는 것을 input으로 넣어서  
> 정보가 없는 것으로 만드는 그런 모델은 없습니다.  
>
> 그래서 intractable한 거예요.  
> 
> 의미론적으로 봤을 때  
> 이게 다 bayes rule에서 나온 것인데  
> 사전 확률, 차후 확률  
> 같은 것을 하셨으면  
> 이 의미가 뭔지  
> 조금 더 이해를 하실 것 같습니다.  
>
> 그런데 지금 단계에서  
> bayes의 철학까지  
> 다 다룰 수는 없기 때문에  
> 그냥 방금 전에 제가 말씀드린 설명으로  
> 이해해 주시면 좋을 것 같고  
>
> 하여튼 이게 intractable하다.  
> 모델링이 불가능까지는 아니지만  
> 굉장히 까다롭습니다.  
>
> 그래서 $q$라는  
> 어떤 새로운 distribution을  
> 가정을 했을 때 이렇게 표현이 됩니다.  
>
> 이제 $q(z)$라는 게 제일 중요한 건데  
> 이것은 뒤에서 설명하겠습니다.    

---

## p20. 매개변수화(Parameterization)

<img src="/assets/img/lecture/probstat/9/image_16.png" alt="image" width="500px">

- 이것은 **Evidence Lower Bound (ELBO)** 라고 불린다.  
- 이는 $\log p_\theta(x)$ 의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.  
- 이제 $q(z)$를 직접 다루기 어려우므로,  
  이를 **매개변수화(parameterize)** 하여  
  **$q_\phi(z \mid x)$** 로 표현한다.  
- 여기서 $\phi$ 는 **추론 네트워크(inference network)** 의  
  학습 가능한 파라미터이다.  
- 반면, **$p_\theta(z)$** 는 단순하고 알려진 **사전분포(prior)** 로 둔다.

> **강의 내용**  
> 
> $q(z)$라는 걸 다루기 힘들기 때문에  
> 이제 $q$를 $\phi$라는 파라미터를 가지고  
> 파라미터라이징을 하게 됩니다.  
>
> 그러니까 뉴럴 네트워크 스트럭처를  
> 고려하겠다는 거예요.  
>
> 그래서 $q(z)$를  
> $q_{\phi}(z \mid x)$로 바꾸고,  
>
> $p_{\theta}(z)$를  
> prior knowledge가 가미된,  
> 이미 알고 있는 어떤  
> $p(z)$로 바꿀 수 있습니다.  
>
> 이것은 그냥 테크닉이라고 생각하시면 될 것 같습니다.

---

> - 실제로 $q(z)$는 임의의 형태를 가질 수 있지만,  
>   그 분포를 명시하거나 직접 계산하는 것은 불가능하다.  
>   따라서 이를 **신경망으로 근사(parameterize)** 하여  
>   $q_\phi(z \mid x)$ 형태로 표현한다.  
>   이때 $\phi$는 인코더(추론 네트워크)의 학습 가능한 파라미터이다.  
>
> - 인코더 $q_\phi(z \mid x)$는 **입력 데이터 $x$로부터 잠재변수 $z$를 추정**하고,  
>   디코더 $p_\theta(x \mid z)$는 **잠재변수 $z$로부터 데이터를 복원 또는 생성**한다.  
>   이렇게 두 확률 모델이 짝을 이루어 작동한다.  
>
> - 사전분포 $p_\theta(z)$는 보통 **표준정규분포 $\mathcal{N}(0, I)$** 로 설정한다.  
>   이는 계산을 단순하게 하고, 잠재공간의 구조를 일정하게 유지시킨다.  
>
> - 결국 인코더와 디코더의 파라미터 $\phi, \theta$를 조정하여  
>   **ELBO를 최대화**하는 것이 VAE의 학습 과정이다.  
>   이는 곧 **잠재변수 분포 추정**과 **데이터 생성 과정 학습**을  
>   동시에 수행하는 절차이다.  

---

## p21. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_17.png" alt="image" width="800px">

> **강의 내용**  
> 
> 그래서 이렇게 잘 가공해서 테크닉을 써서 바꾸게 되면  
> ELBO가 변형된 동치꼴의 무언가가 나오는데,  
> 
> 이걸 해석하기 위해서 아래의 파이프라인을 보셔야 할 것 같아요.  
> 이것이 VAE의 파이프라인이라고 생각하시면 될 것 같습니다.  
>
> 그리고 뒷부분에 $z$와 디코더, $x'$이 표현되어 있는데  
> 이것은 우리가 아까 앞에서 봤었던 파이프라인에서  
> 제네레이터로 표현되어 있는 파이프라인입니다  
> 
> 이것은 반쪽이고  
> VAE에서는 앞에 반쪽이 더 있습니다.  
> 
> 되게 독특하게 생겼습니다.  
>
> 그래서 이것이 어떻게 동작하는지  
> 먼저 수학적인 것은 조금 뒤로 미루고  
> 동작하는 원리에 대해서 한번 얘기를 해볼게요.  
>
> VAE는 훈련을 시키기 위해서  
> $x$를,  
> 인코더라는 스트럭처를 통해서  
> (중간에 $q_{\phi}(z \mid x)$라고 표현되어 있잖아요)  
> distribution으로 매칭을 시켜 놓습니다.  
>
> 이것을 인코딩이라고 하고,  
> 
> 여러분,  
> 인코딩, 디코딩이라고 들어보셨잖아요.  
> 인코딩하는 것은 정보를 줄이는 것이고  
> 디코딩하는 것은 줄여진 정보를 다시 복원하는 것입니다.  
>
> 인코더, 디코더와 같은 것들은  
> 통신 이론에서 굉장히 중요한 파운데이션인데  
> 거기에서의 인코더, 디코더와 똑같습니다.  
> (정보가 조금 왔을 때)  
> 거기에서도 ELBO를 논하니까.  
>
> 그래서 $x$라는 원래 오리지널 이미지를  
> 인코더를 통해서,  
> 중간에 $q_{\phi}$라는 우리가 미리 정해놓은,  
> 파라메터라이징 할 수 있는 뉴럴 네트워크를 통해  
> distribution으로 매핑을 하고  
>
> 뒤에서 보겠지만 이것은 가우시안 distribution이 될 겁니다.  
>
> 그래서 거기에서 샘플링을 합니다.  
> $z$라는 랜덤 배리어블을 샘플링을 합니다.  
>
> 이 $z$가,  
> 우리가 앞에서, 파인프라인에서 봤었던  
> 제네레이터의 그 $z$가 되는 거죠.  
>
> 여기서 $p_{\theta}$를 $p$로 바꾼다는 게 그런 의미인 거고  
>
> $z$라는 것을 디코더를 통해서  
> $x'$이라는 것으로 변환을 하죠.  
>
> 그러면 이제 $x$라는 원본 이미지가, 원본 데이터가  
> 인코더랑 디코더를 거치면서  
> 이런 arbitrary한 모양으로 바뀌게 되거든요.  
>
> 그래서 그 다름을 줄이기 위해서,  
> $x$랑 $x'$이 모양이 같도록 하는  
> reconstruction loss를 정의하게 됩니다.  
>
> 이것은 VAE의 중요한 파트로서  
> reconstruction loss,  
> 
> $x$가 인코더를 거치고 디코더를 거쳐서 다시 reconstruct 됐을 때  
> 구조적 모양을 완벽하게 똑같이 따라야 된다.  
>
> 이게 reconstruction loss로 정의가 됩니다.  
>
> 그래서 이 첫 번째.  
> 이 초록색으로 박스로 되어 있는 게 그런 rationale을 표현하는 것이고,  
> 이게 reconstruction loss에 대한 것입니다.  
>
> 수식을 잘 보면  
> $x$가 들어가서,  
> $q_{\phi}$를 보면,  
> $x$가 인풋이고 $z$가 아웃풋이잖아요.  
>
> 이게 인코더에 대한 부분이었고  
>
> 그렇게 표현된 $z$가 다시  
> $\log p_{\theta}$에 인풋 $z$로 들어간 다음에  
> $x$로 다시 나왔잖아요.  
>
> 이 파이프라인은 이런 수학적 구조를 설명하고 있는 거죠.    

---

> - 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를 받아  
>   잠재변수 $z$의 분포를 추정하는 역할을 한다.  
>   일반적으로 이 분포는 가우시안(정규분포) 형태로 가정된다.  
>
> - 디코더 $p_\theta(x \mid z)$는 샘플링된 $z$로부터  
>   원래의 입력 $x$를 재구성하도록 학습된다.  
>   즉, 인코더가 정보를 요약하고,  
>   디코더가 그 정보를 바탕으로 데이터를 복원하는 구조이다.  
>
> - 전체 손실 함수는 두 부분으로 구성된다.  
>
>   (1) $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$  
>       재구성 손실로서, 입력 $x$와 복원된 $x'$의 차이를 최소화한다.  
>
>   (2) $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p_\theta(z))$  
>       정칙화 항으로서, 인코더가 추정한 분포가  
>       사전분포 $p_\theta(z)$(보통 $\mathcal{N}(0, I)$)와  
>       유사하도록 만드는 역할을 한다.  
>
> - 이 두 항의 균형을 조정함으로써  
>   VAE는 잠재공간을 구조적으로 유지하면서  
>   새로운 데이터를 생성할 수 있는 능력을 갖추게 된다.  
>
> - 이러한 구조는 생성 모델로서뿐 아니라  
>   이상치 탐지(Anomaly Detection)와 같은 응용에서도 널리 활용된다.  
>   학습된 모델은 정상 데이터의 잠재공간을 학습하므로,  
>   재구성 오차가 큰 데이터는 이상치로 판별된다.

---

## p22. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_18.png" alt="image" width="800px">

> **강의 내용**  
> 
> 이제 두 번째 term은 regularization loss입니다.  
> 그러면 $q_{\phi}$를 우리가 모델링 했는데 Neural Network 혹은 파라미터로 모델링 하겠다고 했는데  
> 이 모양이 컨트롤되지 않으면 우리가 $z$를 샘플링 할 수가 없거든요.  
>
> 그래서 $z$를 샘플링을 해야만 인코더, 디코더 스트럭처를 표현할 수 있기 때문에  
> 그래서 이제 $p(z)$는 Gaussian Distribution이나 우리가 알 수 있는 Distribution을 고려하고  
> $q_{\phi}$랑 $p$랑 거리를 줄여서 KL divergence를 통해서  
>
> 그래서 최종적으로 이게 만약에 0이 되면  
> 이제 $q_{\phi}$가 Gaussian Random Variable이나 똑같은 거니까  
> 거기서 그냥 Gaussian Random Variable 샘플에서 쓰면 되잖아요.  
>
> 그래서 그렇게 해서 모양적으로 컨트롤하는 regularization loss, 두 번째 loss가 있습니다.  
>
> 그래서 첫 번째 loss와 두 번째 loss가 포괄적으로 표현되어 가지고 학습을 하는 거  
> 그게 이제 VAE의 전체적인 학습 파이프라인이라고 보시면 될 것 같아요.  
>
> 그래서 이게 결국에는 전부 다 여기서 온 거거든요.  
> Latent Variable에서.  
> VAE는 이거 보면 이제 조금은 이해가 가실 것 같아요.  
> 좀 간접적인 레벨에서라도.  
>
> $\log p_{\theta}(x)$를 계산하기 위해서 막 이상한 걸 많이 했는데  
> 이런 구조를 통해 가지고 이제 그걸 풀겠다는 게 VAE의 철학이라고 보시면 될 것 같아요.  
>
> Diffusion Model, Latent Variable Model, Diffusion Model, Normalizing Flow Model  
> 다 똑같은 얘기를 하는데 완전히 다른 접근 방식을 갖고 갑니다.  
>
> 그래서 이 큰 파이프라인은 완벽하게 이해를 하셔야 될 것 같아요.  
> 수학적인 디테일은 모를 수 있지만  
> 지금 보면 $x$가 인코더로 들어가서 디코더로 표현되어 가지고 복원이 되고  
> 이런 구조를 알아야 코드를 딱 봤을 때  
> 아 이게 이 파트였구나 이렇게 바로 이제 이해를 하실 것 같아요.  
>
> 그런 것 같고  
> 그래서 이거는 앞으로 코딩을 직접 진행을 하시면  
> 이해를 하실 수 있는 부분들이라고 생각을 합니다.  

---

> - 위 식은 ELBO를 최대화하는 대신, 동등하게 손실을 최소화하는 형태로 표현된 것이다.  
>   왼쪽 항은 재구성 손실(reconstruction loss),  
>   오른쪽 항은 정칙화 손실(regularization loss)에 대응한다.  
>
> - 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를  
>   잠재공간(latent space) 상의 확률분포로 압축하여 표현한다.  
>   여기서 $\phi$는 인코더의 학습 파라미터이며,  
>   인코더는 $q_\phi(z \mid x)$가 사전분포(prior) $p(z)$에  
>   가깝도록 학습된다.  
>
> - 사전분포 $p(z)$는 일반적으로  
>   가우시안 분포 $\mathcal{N}(0, I)$로 설정된다.  
>   이렇게 단순한 분포를 prior로 두는 이유는  
>   잠재공간이 구조적으로 안정적이고,  
>   샘플링이 쉬운 공간이 되도록 만들기 위함이다.  
>
> - 정칙화 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$은  
>   인코더가 만든 분포 $q_\phi(z \mid x)$가  
>   $\mathcal{N}(0, I)$와 멀어지지 않도록 제한하는 제약 조건이다.  
>   이 값이 작아질수록 잠재분포는  
>   표준정규분포에 더 잘 정렬된다.  
>
> - 디코더 $p_\theta(x \mid z)$는 잠재변수 $z$로부터  
>   원래 입력 $x$를 재구성하는 역할을 한다.  
>   여기서 $\theta$는 디코더의 학습 파라미터이며,  
>   학습의 목표는 입력 $x$와 재구성된 $x'$의 차이를  
>   최소화하는 것이다.  
>
> - 결국 VAE의 학습 과정은  
>   (1) 데이터를 잘 재구성하는 능력과  
>   (2) 잠재공간의 확률적 구조를 유지하는 능력  
>   두 가지를 동시에 최적화하는 과정이라고 볼 수 있다.

---

## p23. 첫 번째 항: 재구성 손실 (Reconstruction Loss)

<img src="/assets/img/lecture/probstat/9/image_19.png" alt="image" width="600px">

**예시: L2 손실 (L2 loss)**  

- 1단계 몬테카를로(Monte Carlo) 샘플링:  
  $z \sim q_\phi(z \mid x)$  

- 디코더 네트워크에 의한 매핑:  
  $g_\theta(z) \rightarrow x'$  
  (network estimates distribution’s parameters)

- 가우시안 분포로 모델링:  
  $p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)$  
  (assume fixed std)

- 음의 로그우도(negative log-likelihood):  

  $$
  -\log p_\theta(x \mid z)
  =
  \frac{1}{2\sigma_0^2}\|x - x'\|^2 + \text{const}
  $$

- L2 손실은 데이터 포인트 $x$ 주변의  
  가우시안 근방(Gaussian neighborhood)을 의미함

> **강의 내용**  
> 
> 그래서 이 Reconstruction Loss는 제가 디테일한 건 얘기는 안 드리겠습니다만  
> 결국에는 Reconstruction이라는 게 이제 결국에는 구조적으로 같게 만들어야 되는데  
> 이 같게 만드는 것에서 우리가 가장 많이 사용하는 메트릭 중 하나가 L2 Loss 유클리디언 디스턴스거든요.  
> 
> 그래서 이제 Negative Log-likehood 이런 거 계산을 하다 보면  
> 결국에는 Input으로 들어가는 x와 Output으로 나오는 x' 사이에  
> 이제 유클리디언 디스턴스를 취하고  
> 거기서 이제 $\sigma_0$라는 걸 통해서 어떤 스케일을 조절하는 이런 형태로 나옵니다.  
> 
> 그래서 Reconstruction Loss는 다른 게 아니라  
> 이 Input x와 뭔가 안에서 찰흙처럼 빚어진 x'에 대한 거리다.  
> 이게 만약에 0이 되면 모양이 완전히 똑같겠죠.  
> 그게 Reconstruction Loss의 형태입니다.  
> 
> 근데 이렇게 Reconstruction loss를 해 놓고  
> 그 다음에 이제 Regularization을 하는 거죠.

---

> **1. 몬테카를로 샘플링 (Monte Carlo Sampling)**  
> - 기댓값  
> 
>   $$
>   \mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]
>   $$  
> 
>   은 잠재변수 $z$ 에 대한 적분 형태로 표현되며 해석적으로 계산하기 어렵다.  
> - 따라서 $q_\phi(z \mid x)$ 에서 샘플링한 $z$ 들을 이용해  
>   $\log p_\theta(x \mid z)$ 값을 평균하여 근사한다.  
>   이를 **몬테카를로 근사(Monte Carlo approximation)** 라고 한다.  
> - 샘플링 과정은 **재매개변수화 기법(Reparameterization trick)** 으로  
>   미분 가능하게 만들어, 인코더와 디코더 모두를 역전파로 학습할 수 있다.  
>
> **2. 디코더 매핑 $g_\theta(z) \rightarrow x'$**  
> - 디코더 $g_\theta$ 는 잠재변수 $z$ 를 입력받아 생성 데이터의 평균값 $x'$ 을 출력한다.  
> - 디코더는 단순 복원 함수가 아니라  
>   **확률분포 $p_\theta(x \mid z)$ 의 모수(parameter)를 추정하는 함수** 로 해석된다.  
> - 가장 단순한 경우 디코더는 평균만 출력한다고 두며,  
> 
>   $$
>   x'=\mu_\theta(z)
>   $$  
> 
>   분산은 고정 상수 $\sigma_0^2$ 로 둔다.  
>   즉, 디코더는 “데이터가 존재할 법한 중심(mean)”을 학습한다.  
> - 따라서 디코더는 **확률적 생성 모델의 평균 함수(mean function)** 이다.  
>
> **3. 가우시안 분포로 모델링하는 이유**  
> - 실제 데이터는 노이즈와 불확실성을 포함하므로 $x$ 와 $x'$ 를 완전히 일치시키기보다  
>   $x$ 가 $x'$ 주변에서 나올 확률을 모델링하는 것이 타당하다.  
> - VAE는 다음과 같이 가정한다.  
> 
>   $$
>   p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
>   $$  
> 
> - 여기서  
>   - $x'=g_\theta(z)$ : 평균  
>   - $\sigma_0^2 I$ : 분산  
>   - $x$ : 관측값  
> - 이는 “데이터는 평균 $x'$ 를 중심으로 정규분포 형태에 따라 생성된다”는  
>   확률적 가정을 의미한다.  
> - 이 가정 덕분에 모델은 불확실성을 표현할 수 있고,  
>   **로그우도(log-likelihood)가 닫힌형(closed form)** 으로 계산 가능해진다.  
>
> **4. 재구성 손실이 L2 손실이 되는 이유**  
> - 가우시안 가정하에서 로그 가능도는  
> 
>   $$
>   \log p_\theta(x \mid z)
>   =
>   -\frac{1}{2\sigma_0^2}\|x-x'\|^2
>   -\frac{d}{2}\log(2\pi\sigma_0^2)
>   $$
> 
>   로 전개된다.  
> - 따라서 음의 로그 가능도는  
> 
>   $$
>   -\log p_\theta(x \mid z)
>   =
>   \frac{1}{2\sigma_0^2}\|x-x'\|^2 + \text{const}
>   $$  
> 
>   이 되며, 이는 **L2 손실(Mean Squared Error)** 과 동일한 형태이다.  
> - 즉, 디코더가 출력하는 평균 $x'$ 을 기준으로 데이터 $x$ 를 설명하는 과정이  
>   곧 L2 거리 최소화와 같다.  
>
> **5. 전체적 관계 요약**  
> - $x$: 관측 데이터  
> - $z$: 인코더가 샘플링한 잠재변수  
> - $x'=g_\theta(z)$: 디코더가 추정한 평균  
> -  
>   $$
>   p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
>   $$  
> 
>   : 관측 $x$ 는 평균 $x'$ 중심의 정규분포에서 샘플링된 것으로 해석  
> - 재구성 손실 최소화는  
>   “실제 데이터 $x$” 와 “디코더 평균 $x'$” 사이의 거리를 줄이는 것과 같다.  

---

## p24. 두 번째 항: 정규화 손실 (Regularization Loss)

<img src="/assets/img/lecture/probstat/9/image_20.png" alt="image" width="600px">

**예시: 가우시안 사전분포 (Gaussian prior)**  

- $p(z) = \mathcal{N}(z \mid 0, I)$ 로 둔다.  

- $q_\phi(z \mid x)$ 를 가우시안으로 모델링한다:  
  $q_\phi(z \mid x) = \mathcal{N}(z \mid \mu, \sigma)$  

- 인코더 네트워크에 의한 매핑:  
  $f_\phi(x) \rightarrow (\mu, \sigma)$  
  (network estimates distribution’s parameters)

- 손실을 분석적으로 계산한다:  

  $$
  D_{\mathrm{KL}}\big(\mathcal{N}(z \mid \mu, \sigma)\,\|\,\mathcal{N}(z \mid 0, I)\big)
  $$

- 공분산을 고정한 경우:  
  fixed covariance → $\mu$ 에 대한 L2 손실

> **강의 내용**  
> 
> Regularization은 이것도 이제 디테일은 조금 생략을 하고  
> 이 Neural Network가 결국에는 이제 $\mu$와 $\sigma$를 만들어 내게 됩니다.  
> $q_{\phi}$에.  
>
> 그래서 $q_{\phi}$를 이제 Gaussian Distribution인데  
> 거기서 Gaussian parameter들이 Neural Network로부터 생성됐다고 가정을 하고  
> $p(z)$는 이제 아까 말씀드렸었던 것처럼 Standard Gaussian Distribution이라고 해서  
> 이렇게 이제 계산을 하면 밑에 이제 세 번째 수식과 같이  
> KL Divergence를 다른 Gaussian Distribution끼리 계산을 하면  
> 우리 앞에서 중간고사 전에 이런 거 비슷한 거 계산했었었습니다.  
>
> 그리고 L2와 되게 비슷한 형식으로 이 좀 explicit한 솔루션이 나오게 되고  
> 이거를 실제로 계산을 해 보면 이것도 뭐 L2랑 되게 비슷한 형태가 나오는데  
> 이런 것도 좀 앞으로 계산을 하면서 실제 코드에서 볼 거라는 거죠.

---

> **1. 정규화 항의 역할**  
> - 정규화 손실 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은  
>   인코더가 학습한 잠재 분포 $q_\phi(z \mid x)$ 이  
>   사전 분포 $p(z)$ (보통 표준 정규분포 $\mathcal{N}(0, I)$) 와  
>   얼마나 다른지를 측정한다.  
> - 이 항은 잠재공간이 지나치게 왜곡되지 않도록 제약을 주며,  
>   특정 데이터에 과도하게 맞춰진 잠재표현을 방지하여  
>   **일관된 잠재 구조**를 유지하게 만든다.  
>
> **2. KL 발산의 계산 방식**  
> - 두 가우시안 분포 사이의 KL 발산은 닫힌형(closed-form)으로 계산된다.  
>
>   $$
>   D_{\mathrm{KL}}\!\big(\mathcal{N}(\mu,\sigma^2)\,\|\,\mathcal{N}(0,1)\big)
>   =\frac{1}{2}(\mu^2+\sigma^2-\log\sigma^2-1)
>   $$  
>
> - 이 표현은 VAE 학습에서 매우 효율적으로 사용되며,  
>   손실을 직접 계산해 최적화할 수 있게 한다.  
>
> **3. 공분산 고정 시 L2 손실과의 관계**  
> - 공분산 $\sigma^2$ 를 고정하면 KL 항은  
>   $\mu^2$ 에 비례하는 형태가 된다.  
>
>   $$
>   D_{\mathrm{KL}} \propto \|\mu\|^2
>   $$  
>
> - 즉, KL 항은 잠재변수 평균 $\mu$ 에 대한  
>   **L2 정규화(L2 penalty)** 처럼 동작한다.  
> - 이는 잠재벡터가 사전분포의 중심(0 근처)에 있도록  
>   압박하는 효과를 낸다.  
>
> **4. 직관적 해석**  
> - 인코더는 입력 $x$ 에 따라 $\mu$ 와 $\sigma$ 를 출력한다.  
> - KL 항은 “너무 특이한” 잠재벡터를 생성하지 않도록 억제하며,  
>   전체 잠재공간이 사전분포 $p(z)$ 와 유사한 모양을 유지하게 만든다.  
> - 그 결과, 학습이 끝난 후 임의의 $z \sim p(z)$ 를 샘플링해도  
>   **자연스럽고 일관된 생성 결과**를 얻을 수 있게 된다.  

---

## p25. 역전파는 어떻게 이루어질까? (Backpropagation?)

<img src="/assets/img/lecture/probstat/9/image_21.png" alt="image" width="800px">

---

> **1. 인코더와 샘플링의 관계**  
> 인코더는 입력 $x$ 로부터 잠재 변수의 분포 $q_\phi(z \mid x)$ 를 학습한다.  
> 평균 $\mu_\phi(x)$ 와 표준편차 $\sigma_\phi(x)$ 를 추정하여 확률적으로 $z$ 를 샘플링하고,  
> 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 로 전달되어 재구성된 출력 $x'$ 를 생성한다.
>
> **2. 역전파의 문제점**  
> 샘플링 과정은 확률적이므로  
>
> $$
> z \sim q_\phi(z \mid x)
> $$  
>
> 와 같이 난수에 의해 결정된다.  
> 이 연산은 비결정적이며 미분 불가능하므로,  
> 역전파는 $z$ 에서 인코더 파라미터 $\phi$ 로 기울기를 전달할 수 없다.  
> 즉, 샘플링 순간에 역전파 경로가 끊긴다.
>
> **3. 직관적 비유**  
> 인코더는 분포의 모양(평균·분산)을 제시하고,  
> 샘플링은 그 분포에서 주사위를 던지는 과정이다.  
> 주사위의 결과값 $z$ 에 대해 $\mu$ 또는 $\sigma$ 로 직접 미분할 수 없기 때문에  
> 일반적인 역전파 규칙을 적용할 수 없다.
>
> **4. 해결책의 방향**  
> 이를 해결하기 위해 재매개변수화 기법(Reparameterization Trick)을 사용한다.  
> 이 방법은 확률적 샘플링 과정을 결정적 함수 형태로 다시 표현하여  
> 미분이 가능하도록 만들어, 끊겼던 역전파 경로를 복원해 준다.

---

## p26. 재매개변수화 (Reparameterization)

<img src="/assets/img/lecture/probstat/9/image_22.png" alt="image" width="800px">

가우시안 매개변수들은 신경망의 출력값에 의해 매개변수화되어(parameterized),  
중간 조건부 분포들(intermediate conditional distributions)을 근사하기 위해 사용된다!  

---

> **1. 재매개변수화의 핵심 아이디어**  
> 확률적 샘플링 $z \sim q_\phi(z \mid x)$ 은 미분 불가능하여 역전파가 단절된다.  
> 재매개변수화 기법(Reparameterization Trick)은 이 확률적 과정을  
> 결정적(deterministic) 함수로 변환하여 미분 가능하게 만든다.  
> 즉, 잠재 변수 $z$ 를 직접 샘플링하지 않고,  
> 표준 정규분포에서 샘플링한 잡음 $\varepsilon$ 을 이용해 다음과 같이 계산한다:
>
> $$
> z = \mu_\phi(x) + \sigma_\phi(x)\,\varepsilon,
> \qquad \varepsilon \sim \mathcal{N}(0, I)
> $$
>
> **2. 수식의 의미**  
> $\varepsilon$ 은 고정된 분포 $\mathcal{N}(0, I)$ 에서만 샘플링되므로  
> 랜덤성은 $\varepsilon$ 에만 존재한다.  
> 반면 $\mu_\phi(x)$, $\sigma_\phi(x)$ 는 결정적 함수이므로  
> $z$ 는 $\phi$ 에 대해 미분 가능한 형태가 된다.  
> 따라서 역전파를 통해 인코더 파라미터 $\phi$ 까지 기울기가 전달된다.  
> 이로써 샘플링 단계가 신경망의 연산 그래프에 포함된다.
>
> **3. 직관적 이해**  
> 원래는 “분포로부터 직접 샘플링”했지만,  
> 이제는 “고정된 분포에서 노이즈를 샘플링하고  
> 그 노이즈를 평균과 분산으로 변환하는 과정”으로 바뀐 것이다.  
> 즉, 확률적 샘플링을  
> 노이즈를 입력으로 받는 결정적 함수로 바꾸어  
> 학습 가능한 형태로 만든다.
>
> **4. 전체 구조의 연결**  
> 인코더는 입력 $x$ 로부터 $(\mu, \sigma)$ 를 출력하고,  
> 표준 가우시안 잡음 $\varepsilon$ 을 사용해  
> $z = \mu + \sigma \varepsilon$ 을 계산한다.  
> 디코더는 이 $z$ 를 입력받아 $p_\theta(x \mid z)$ 를 통해 데이터를 재구성한다.  
> 이 구조를 통해 확률적 생성 모델이  
> 전부 미분 가능한 신경망 형태로 구현된다.

---

## p27. 변분 오토인코더 (Variational Autoencoder) 

지금까지는 하나의 $x$ 에 대한 목적함수를 논의해왔다:

<img src="/assets/img/lecture/probstat/9/image_23.png" alt="image" width="600px">

전체 손실(overall loss)은  
데이터 분포에 대한 기대값으로 표현된다:

<img src="/assets/img/lecture/probstat/9/image_24.png" alt="image" width="600px">

---

> **1. 단일 데이터 샘플 $x$ 에 대한 손실**  
> 위의 첫 번째 식은 단일 입력 샘플 $x$ 에 대한 손실 함수 $$\mathcal{L}_{\theta,\phi}(x)$$ 를 정의한 것이다.  
> 첫 번째 항  
>
> $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$  
>
> 은 재구성 손실(Reconstruction Loss)로, 디코더가 입력 $x$ 를 얼마나 잘 복원하는지 측정한다.  
> 두 번째 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은 정규화 손실(Regularization Loss)로,  
> 인코더가 생성한 잠재공간 분포 $q_\phi(z \mid x)$ 가 사전분포 $p(z)$ 와 얼마나 다른지를 측정한다.
>
> **2. 전체 데이터셋에 대한 손실**  
> 실제 학습에서는 한 개의 샘플이 아니라 데이터셋 전체에 대해 평균 손실을 계산한다.  
> 손실 함수는 데이터 분포 $p_{\text{data}}(x)$ 에 대한 기대값으로 확장되며  
>
> $$
> \mathbb{E}_{x \sim p_{\text{data}}(x)}[\mathcal{L}_{\theta,\phi}(x)]
> $$  
>
> 으로 표현된다.  
> 이 기대값은 실질적으로는 미니배치 평균(mini-batch mean)으로 근사되어 학습 중에 최적화된다.
>
> **3. 전체 목적함수의 의미**  
> 최종 손실 $\mathcal{L}_{\theta,\phi}$ 는  
> 데이터 복원 성능과 잠재공간의 규칙성 사이의 균형을 조절하는 역할을 한다.  
> 즉, 인코더가 잠재공간에서 의미 있는 구조를 학습하도록 하면서  
> 디코더가 입력을 잘 복원할 수 있도록 두 항을 함께 최소화하는 것이 VAE 학습의 핵심이다.

---

## p28. 추론 (Inference)

<img src="/assets/img/lecture/probstat/9/image_25.png" alt="image" width="720px">

**추론 (생성):**

- 잠재 변수 $z$ 를 다음 분포에서 샘플링함:  

  $$
  z \sim \mathcal{N}(0, I)
  $$

- 디코더 네트워크에 의해 $z$ 를 매핑함:  

  $$
  g_\theta(z)
  $$

**디코더(Decoder)는 한 분포에서 다른 분포로의 결정적 매핑(deterministic mapping)이다.**

---

> **1. 추론(생성)의 단계**  
> 학습이 완료된 후에는 인코더는 사용하지 않는다.  
> 잠재공간에서 직접 $z \sim \mathcal{N}(0, I)$ 를 샘플링한다.  
> 이는 학습 과정의 KL 발산 항이 $q_\phi(z \mid x)$ 를 $p(z)$ 와 유사하게 만들도록  
> 인코더를 학습시켰기 때문에 가능하다.  
> 따라서 학습이 끝난 뒤 $p(z)$ 에서 샘플링하는 것은  
> 실제 데이터 공간에서 의미 있는 위치를 선택하는 것과 같다.  
> 이렇게 얻은 $z$ 를 디코더 $g_\theta(z)$ 에 입력하면  
> 새로운 샘플을 생성할 수 있다.
>
> **2. 학습 전과 학습 후의 차이**  
> 학습 전에는 $\mathcal{N}(0, I)$ 가 단순한 랜덤 노이즈일 뿐이며  
> 그 안의 점들은 의미가 없다.  
> 학습 후에는 인코더 $q_\phi(z \mid x)$ 가 데이터를 잠재공간으로  
> 의미 있게 매핑하고, KL 발산 항이 이 공간을 정규분포 형태로 정렬한다.  
> 그 결과 $\mathcal{N}(0, I)$ 상의 점들은 실제 데이터의  
> 의미적 표현을 반영하는 좌표가 된다.  
> 즉, 학습 전에는 의미 없던 점들이  
> 학습 후에는 데이터 구조를 보존하는 의미 있는 코드가 된다.
>
> **3. 디코더의 역할**  
> 디코더는 결정적 함수로, $z$ 를 입력받아  
> $p_\theta(x \mid z)$ 혹은 그 평균을 생성한다.  
> 같은 $z$ 에 대해 같은 출력이 생성되지만,  
> $z$ 자체가 확률적으로 샘플링되므로  
> 전체 모델은 확률적 생성 모델 성격을 유지한다.
>
> **4. 요약**  
> 학습 중에는 인코더·디코더가 함께 작동하여  
> 데이터 구조를 정규분포 형태의 잠재공간으로 매핑한다.  
> 학습이 끝난 뒤에는 $\mathcal{N}(0,I)$ 자체가 의미 있는 잠재공간이 되므로  
> 인코더 없이 디코더만으로 새로운 샘플을 생성할 수 있다.

---

## p29. 개요 (Overview)

- 인코더(encoder): 데이터 분포를 잠재 분포로 매핑함  

- 디코더(decoder): 잠재 분포를 데이터 분포로 매핑함  

<img src="/assets/img/lecture/probstat/9/image_26.png" alt="image" width="800px">

> **강의 내용**  
> 
> 네, 이제 여기가 훈련에 대한 얘기였고  
> 이제 훈련은 이 두 개를 통해서 $L$이라는 걸 통해서 지금 보면 Neural Network가 두 개가 있죠.  
> $\theta$라는 Neural Network가 있고, $\phi$라는 Neural Network가 있었습니다.  
>   
> 그래서 $\theta$는 디코더로서 $z$라는 Random Variable로부터 원본 데이터를 이제 복원하는 Neural Network고  
> $\phi$라는 Neural Network는 Gaussian Parameter를 만들어내서  
> 이 $p(z)$를 Approximation 하기 위해서 만들어내는 그런 Neural Network였습니다.  
>   
> 그래서 이 두 개를 이제 동시에 학습하게 됩니다.  
> 두 개의 Neural Network를 만들어 놓고.  
> 그래서 이제 그게 VAE의 학습 과정이었고요.  
>   
> 근데 GAN도 그렇지만 이 VAE의 정말 치명적인 단점이 있는데요.  
> 뭔가 보면 Neural Network가 두 개잖아요.  
> 왜 두 개지?  
> 라고 물어보실 수도 있을 것 같아요.  
>   
> 뭔가 이제 어떻게 보면 이제 우리가 비즈니스 하기 위해서 엄청나게 큰 어떤 시스템을 만들어 놓은 데 있어서  
> 이게 하나에서 두 개가 되는 거는 Complexity가 두 배가 된다는 건데  
> 그러면 거기에 대한 인프라도 두 배가 필요한 거거든요.  
> 똑같은 양의 데이터를 처리하기 위해서 인프라가 두 배가 있어야 한다.  
> 말이 안 되는 거예요 사실.  
>   
> VAE는 현대 생성 모델에서 잘 안 쓰는 이유가 그런 겁니다.  
> 학습하는 파라미터가 너무 많이 필요해요.  
> 두 개의 Neural Network가 동시다발적으로 학습이 되어야 되기 때문에.  
> 심지어 그렇게 학습하더라도 데이터 퀄리티가 나오는 것도 아니고  
> Diffusion 모델 등의 어떤 조금 더 선진화된 모델들이 더 데이터의 퀄리티가 더 좋고요.  
> 그래서 이제 그런 어떤 단점이 거시적인 관점에서 봤을 때 있다는 거고.  
>   
> 그러면 이렇게 훈련을 할 때 두 개의 네트워크를 이런 식으로 학습하는 건 알겠는데  
> 그럼 이제 아까 앞에서 모든 생성 모델들은 이렇게 크게 두 가지를 따른다고 했잖아요.  
> 트레이닝하는 과정이 있고 그리고 샘플링하는 과정이 또 있다.  
>   
> 근데 지금 샘플링하는 이 모양 보면 지금 아까 VAE의 뭐와 똑같이 생겼죠.  
> 뒤에 디코더 파트랑 되게 똑같이 생겼거든요.  
>   
> 그 말은 뭐냐면 샘플링할 때는 심지어 훈련할 때 두 개의 Neural Network가 필요한데,  
> 우리가 이제 서비스를 하기 위해서 샘플링을 하는 시간대에는 앞 부분을 다 버립니다. 안 써요.  
> 훈련만 시켜 놓고 버리는 겁니다.  
>   
> 실제로 쓰는 것은 디코더만이고,  
> 인코더에도 수많은 Neural Network의 파라미터들이 존재하고,  
> Convolutional 필터, 데이터를 생성하기 위한 여러가지 장치들이 있을텐데 그런 것들이 버려지는거에요.  
> inference 타임때는.  
>   
> 그래서 inference 타임 때 데이터를 실제로 생성할 때는 VAE 같은 경우는 이 뒤의 파트만 사용합니다.  
> Gaussian Random Variable로.  
>   
> 그래서 이런 엄청난 단점이 있지만, 근데 VAE에 또 장점이 있습니다.  
> 보통 GAN 같은 경우는 $z$라는 것을 레이턴트 스페이스라고 해서  
> $q_\phi$가 대상으로 되어야 하는 공간, 거기를 설계를 할 수가 없는데  
> VAE 같은 경우는 이런 독특한 구조 때문에 어느 곳에 쓸 수 있냐면 Anomaly detection이라고 해요.  
>   
> 우리가 훈련한 데이터에서 벗어난 데이터들을 탐지할 때 이런 구조들이 되게 재밌습니다.  
> 그래서 $x$가 아니라 input이 $y$가 들어갔다고 생각해볼게요.  
> 그럼 $y$가 들어가서 인코딩을 한 다음에 디코더를 거치면 $y'$이 나오겠죠.  
>   
> 그럼 $y$랑 $y'$이 얼마나 distortion 됐는지를 재면  
> 그게 이제 이게 우리 훈련 과정에서 썼던 데이터인지 아닌지를 구별할 수 있습니다.  
> 수학적인 이유도 있구요.  
> 왜냐하면 우리가 $x$랑 $x'$을 0으로 만들게끔 학습을 했는데 그건 $x$만인거고,  
> 그건 트레이닝 데이터 안에 있는 $x$에 해당하는 데이터인거고  
> 완전히 새로운 $y$라는 데이터가 들어오게 되면  
> 걔가 인코더 디코더로 structure해서 $y'$이 나왔을 때 $y$랑 $y'$의 거리가 0이 된다는 보장은 없겠죠.  
> 우리가 그걸 훈련을 안 했으니까  
>   
> 그런 어떤 다름을 구별할 때 VAE 스트럭처를 많이 씁니다.  
> 그래서 좀 몇몇 산업 AI에서 사용하는  
> 제가 과제로 진행하고 했었는데 사용하는 이런 Anomaly Detection  
>   
> Anomaly Detection이란 그런 겁니다.  
> 우리가 훈련이나 이런 상황이 아니라 실제 상황, 온라인 상황에서  
> 그래서 품질 검사 같은 거 할 때 되게 defect가 존재하는 어떤 그런 프로덕트들을 감지를 어떻게 할 것이냐  
> 비주얼 센싱을 통해서 할 수도 있고 일반적인 센서들을 통해서 할 수도 있는데  
> 타임 시리즈가 될 수도 있고  
>   
> 그럴 때 완전히 다른 뭔가 defect를 갖고 있는 그런 프로덕트를 어떻게 탐지할 수 있는지  
> 이런 것들이 Anomaly Detection이라는 태스크인데  
> 그런 데에 의하면 보통 오토 인코더 스트럭처들이 응용될 수 있다.  
> 이렇게 알아주시면 될 것 같습니다.  
>   
> 그래서 아까 말씀드렸었던 것처럼 inference 타임 때는 디코더만 사용을 한다.  
> $p_\theta$라는 것만 사용을 한다.  
>   
> 그래서 지금 보면 여러 가지 Gaussian Distribution, Gaussian Random Variable들이  
> 정말 다른 종류의 이미지에 맵핑이 돼서 결국에 이런 관점으로 우리 KL divergence를 추렸기 때문에  
> Many to Many, 다대다 매칭을 실행할 수 있는  
> 그런 Neural Network Decoder Model, $p_\theta$를 학습할 수 있다.  
>   
> 여기까지가 이제 어떤 큰 모양이고  
> 전체적으로 수학적으로 한번 봅시다.  
>   
> 그러면 마지막으로 다시 정리를 해보자면  
> 우리는 $p_{\text{data}}(x)$가 있었고 이건 이제 $x$에 대한 것이었죠.  
> 그래서 $x$가 $q_\phi(z \mid x)$라는 인코더 스트럭처를 통해서 $q_\phi(z)$라는 것으로 바뀌게 됩니다.  
> 그래서 이건 인코딩하는 과정이었고 $q_\phi(z)$ 같은 경우는 우리가 Gaussian Random Variable로 모델링한다고 했었죠.  
> 되게 모달리티가 쉽고 샘플링이 편하게 할 수 있고 해석할 수 있는 그런 Distribution이라고 했습니다.  
>   
> 그리고 디코더에서 $p_\theta(x \mid z)$, $z$가 input이고 $x$가 output이 되는  
> 이런 디코더 스트럭처를 통해서 원래 데이터 $x$가 되기를 희망을 하는 겁니다.  
>   
> 그래서 $p_\theta$로부터 샘플링된 $x'$들이랑  
> $x$랑 Reconstruction Loss를 통해서 같게 만들었다.  
> 이것이 VAE의 큰 내용이라고 생각합니다.  
>   
> 그래서 오늘 큰 강의의 줄기는 이 정도가 될 것 같은데  
> 인코더랑 디코더가 무엇인지,  
> 그리고 이게 도대체 어떠한 철학적인 배경으로 우리가 어디에 응용될 수 있는지  
> 이런 것들을 기억해 주시면 좋을 것 같고  

---

> **1. 전체 구조의 흐름**  
> 입력 데이터 $x$ 는 인코더 $q_\phi(z \mid x)$ 를 거쳐 잠재 변수 $z$ 의 확률분포로 변환된다.  
> 이 분포는 데이터의 내재된 구조나 의미적 특성을 요약한 표현이다.  
> 인코더를 통해 얻은 $z$ 는 잠재 공간에서의 점이며,  
> 이 공간 전체가 표준 정규분포 $\mathcal{N}(0, I)$ 형태로 정렬되도록 학습된다.  
> 이후 디코더 $p_\theta(x \mid z)$ 는 이 $z$ 로부터 원래 데이터 분포를 복원하여  
> $x'$ 를 생성하는 과정을 학습한다.
>
> **2. 인코더와 디코더의 관계**  
> 인코더는 데이터 분포 $p_{\text{data}}(x)$ 를 잠재 분포 $q_\phi(z)$ 로 압축하는 역할을 한다.  
> 이는 고차원 데이터(이미지, 음성, 언어 등)를 의미적으로 요약된 표현으로 변환하는 과정이다.  
> 디코더는 이 잠재 분포를 다시 데이터 분포 $p_\theta(x)$ 로 확장하여  
> 원본 데이터에 가까운 샘플을 생성한다.  
> 이 과정이 VAE가 생성 모델로 기능하는 핵심이다.
>
> **3. 학습의 목표**  
> 학습 과정에서 인코더와 디코더는 상호 보완적으로 최적화된다.  
> 인코더는 $x \rightarrow z$, 디코더는 $z \rightarrow x'$ 를 수행하며  
> 두 네트워크는 $p_{\text{data}}(x)$ 와 모델 분포 $p_\theta(x)$ 가  
> 최대한 유사해지도록 동시에 학습된다.
>
> **4. 요약적 해석**  
> 인코더는 데이터 공간에서 잠재 공간으로의 압축(encoding)을 담당하고,  
> 디코더는 잠재 공간에서 데이터 공간으로의 복원(decoding)을 담당한다.  
> 결국 VAE는  
> 데이터 ↔ 잠재 표현 ↔ 데이터  
> 로 이어지는 양방향 확률적 매핑을 학습하는 모델이다.

---

## p30. 변분 오토인코더 (Variational Autoencoder)

- 인코딩된 잠재 분포(encoded latent distribution):

  $$
  q_\phi(z)
  =
  \int_x q_\phi(z \mid x) \, p_{\text{data}}(x) \, dx
  $$

<img src="/assets/img/lecture/probstat/9/image_27.png" alt="image" width="800px">

---

> **1. 인코딩된 잠재 분포의 의미**  
> $q_\phi(z)$ 는 전체 데이터 분포 $p_{\text{data}}(x)$ 에 대해  
> 인코더가 생성한 잠재 변수 분포들의 평균적 형태를 나타낸다.  
> 즉, 각 데이터 $x$ 가 인코더를 거쳐 $z$ 로 변환될 때  
> 그 모든 $z$ 들이 형성하는 전역적 분포 구조를 의미한다.  
> 이 관계는  
>
> $$
> q_\phi(z)=\mathbb{E}_{x \sim p_{\text{data}}(x)}[\,q_\phi(z \mid x)\,]
> $$  
>
> 으로 표현되며, 인코더가 전체 데이터셋을 통해 형성한  
> 잠재공간의 전역 구조를 나타낸다.
>
> **2. $p(z)$ 와 $q_\phi(z)$ 의 관계**  
> $p(z)$ 는 사전에 정의한 단순한 분포(prior)로 보통 $\mathcal{N}(0, I)$ 이다.  
> 이는 학습의 기준점 역할을 한다.  
> 반면 $q_\phi(z)$ 는 실제 데이터에서 인코더가 추정한 복잡한 잠재 분포이다.  
> KL 발산 항 $D_{KL}(q_\phi(z)\,\|\,p(z))$ 이 이를 최소화하도록 유도하여  
> 학습이 진행될수록 $q_\phi(z)$ 가 $p(z)$ 와 유사해지도록 만든다.  
> 따라서 이 KL 항은 잠재공간을 정규화하는 정규화 제약이다.
>
> **3. 전체 흐름의 의미**  
> 1) 데이터 분포 $p_{\text{data}}(x)$ 에서 샘플된 $x$ 가  
>    인코더를 통해 $q_\phi(z \mid x)$ 로 변환된다.  
> 2) 이를 모든 $x$ 에 대해 통합하면 전체 잠재 분포 $q_\phi(z)$ 가 형성된다.  
> 3) KL 발산 항은 $q_\phi(z)$ 가 $p(z)$ 와 유사해지도록 학습을 유도한다.  
> 4) 디코더 $p_\theta(x \mid z)$ 는 잠재 변수로부터 데이터 분포를 복원한다.
>
> **4. 직관적 해석**  
> 인코더는 실제 데이터 분포를 잠재 변수 분포 $q_\phi(z)$ 로 변환하고,  
> KL 발산 항은 이를 정규분포 $p(z)$ 에 정렬한다.  
> 이 과정 덕분에 복잡한 데이터의 구조가 단순하고 해석 가능한 잠재공간으로 매핑된다.  
> 결국 VAE는  
> “데이터 분포 → 인코더 → 잠재공간 정규화 → 디코더 → 복원된 데이터 분포”  
> 로 이어지는 완전한 확률적 경로를 학습한다.

---

## p31. 예시 그림 (Example Illustration)

<img src="/assets/img/lecture/probstat/9/image_28.png" alt="image" width="600px">

- 각 데이터 포인트 $x_1$, $x_2$, $x_3$ 는  
  인코더 $q_\phi(z \mid x)$ 를 통해  
  잠재공간(latent space)의 분포 $q_\phi(z \mid x_i)$ 로 매핑된다.

- 각 분포 $q_\phi(z \mid x_i)$ 는  
  잠재공간 내에서 서로 다른 위치에  
  데이터의 의미적 특징을 반영하여 분포하게 된다.

- 디코더는 각 $z$ 로부터 대응되는  
  **재구성된 데이터(generated data)** 를 복원한다.

---

> **1. 데이터 포인트와 잠재 분포의 대응 관계**  
> 원래의 데이터 포인트 $x_i$ 들은 인코더를 통과하면서 각각 잠재 분포 $q_\phi(z \mid x_i)$ 로 표현된다.  
> 이 분포들은 데이터의 고유한 특성을 반영하며, 비슷한 데이터일수록 잠재공간에서 가까운 위치를 갖는다.  
> 예를 들어 $x_1, x_2, x_3$ 가 유사한 클래스에 속하면,  
> 이들의 잠재 분포 $q_\phi(z \mid x_i)$ 는 잠재공간에서 서로 겹치거나 인접한 영역에 위치하게 된다.
>
> **2. 생성 과정의 시각적 의미**  
> 각 $q_\phi(z \mid x_i)$ 에서 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 를 통해  
> 재구성된 데이터 $\hat{x}_i$ 를 생성한다.  
> 이 과정 전체가 “입력 데이터 → 잠재공간 표현 → 데이터 복원”이라는  
> 확률적 생성 경로를 학습하는 것이다.
>
> **3. 이상치 탐지(Anomaly Detection)와의 연관**  
> VAE는 정상 데이터의 분포를 학습하므로 정상 데이터는 잠재공간에서 $p(z)$ 근처에 정렬된다.  
> 반면 이상치는 학습된 $q_\phi(z)$ 와 잘 맞지 않아 낮은 복원 확률을 가지게 된다.  
> 따라서 VAE는 복원 오차나 잠재 확률을 기반으로 이상치를 탐지하는 데 활용될 수 있다.
>
> **4. 데이터 정화(Purification) 관점**  
> 입력 데이터가 노이즈를 포함하거나 왜곡되었더라도,  
> 인코더를 거쳐 잠재공간으로 투영되고 디코더를 통해 복원되는 과정에서  
> 학습된 데이터 분포에 맞춰 정제된 형태로 출력될 수 있다.  
> 즉, VAE는 생성 모델임과 동시에 데이터 복원 및 정화 모델로도 작동할 수 있다.

---

## p32. MNIST의 2차원 잠재공간 (2D Latent Space on MNIST)

<img src="/assets/img/lecture/probstat/9/image_29.png" alt="image" width="800px">

왼쪽: 각 숫자 클래스(0~9)가 인코딩된 잠재변수 공간의 분포  
오른쪽: 잠재공간 상의 위치에 따라 디코더가 생성한 숫자 이미지

> **강의 내용**  
> 
> 일단 몇 가지 재미있는 예제를 보고 마무리하겠습니다.  
> 그래서 VAE가 이런 레이턴트 스페이스, 레이턴트 인포메이션을 매니플레이션하기 위해  
> 굉장히 많은 장점들을 갖고 있는데 마지막 장의 예제를 보시면 좋을 것 같아요.  
> 왼쪽 그림은 하이 디멘저널 스페이스, 레이턴트 스페이스가 바로 하이 디멘저널로 잡은 겁니다.  
> 128, 256도.  
> 거기서 각각의 숫자에 해당하는 것들을 레이블링을 한 다음에 그것들을 그냥 그림으로 표현을 한 건데  
> 이것은 누가 시킨 게 아니면서도 불구하고 뭔가 레이블을 주고 학습한 게 아닙니다.  
> 컨디셔널하게 준 게 아닙니다.  
> 언컨디셔널하게 학습했음에도 불구하고  
> 0에 대한 레이턴트 배리어블, 1에 대한 레이턴트 배리어블  
> 모양이 같으면 뭉치게 되고 클러스터링을 하게 되는데 이것이 굉장히 재미있는 현상이거든요.  
>   
> 그래서 이런 현상 때문에 여기 위에서 직선을 그어서 레이턴트 배리어블들을 인터폴레이션 한다고 가정을 하면  
> $z$라는 스페이스에서 인터폴레이션을 했기 때문에  
> 어떤 한 두 점을 갖고 움직이게 했기 때문에 거기에 해당하는 디코더를 꺼내가지고 이미지를 생성하면  
> 거기에 해당하는 첫 번째 시작점이 예를 들어서 6이고 그리고 끝점이 4였다고 하면  
> 이 오른쪽에 MNIST 숫자를 보면 맨 위에 row를 보면 6에서 4로 스무스하게 체인지가 되잖아요.  
> 그래서 이런 형상을 보여주는 게 이 VAE의 굉장히 재미있는 특성입니다.  
>   
> 그래서 이런 레이턴트 스페이스에서 정보들을 이렇게 알아서 클러스터링 해주는 걸  
> 이제 linearized effect라고 하는데 생성 모델들의 이런 것들을 통해 가지고  
> 여러분들 이제 이게 어떤 의미냐면 이게 숫자로 보면 재미가 없을 수 있는데 여러분들 많이 하셨잖아요.  
> 지브리 풍으로 바꾸는 거.  
> 그게 이거예요. 사실.  
> 그거의 철학이 사실 여기 있다고 보시면 될 것 같습니다.  
> 하나의 모달리티에서 다른 걸로 바꾸는 거.  
> 이거를 이제 이 피규어가 처음 나오고 거기까지 가는 게 딱 6년이 걸렸거든요.  
> 그러니까 이제 이런 fundamental을 배워두셔야  
> 이제 앞으로 나오는 이제 기막힌 생성 모델의 그런 것들의 어떤 철학 같은 것을 이해하실 수 있을 것 같습니다.  
>   
> 그래서 오늘 좀 말을 굉장히 빨리 해서 진행을 했는데 질문 있으시면 질문하시면 좋을 것 같습니다.  
>   
> (질문)  
> 마지막 그림에서 약간 한시 방향으로는 distribution으로 좀 많이 섞인 것 같은데  
> 그거는 좀 차원을 늘려서 뭔가 모델링하면 구분을 할 수 있는 레이블이 형성이 되나요?  
>   
> (답변)  
> 차원을 단순히 늘리면 차원이 늘어나면 대신에 차원이 늘어났기 때문에  
> 걔를 표현하는 표현력이 떨어지게 되면 차원이 늘어나면 어려워지겠죠.  
> 더 정확한 말은 생성 인코더랑 디코더의 파라미터 숫자를 키우고 표현력을 키우고  
> 학습이 잘 되게끔 하는 Neural Network의 structure를 찾아서 잘 학습하면 걔가 분리가 됩니다.  
>   
> (질문)  
> 아니면 이게 시각화를 2D로 해서 그렇지  
> 뭐 3D로 한다던가 이러면 더 잘 구분되는데  
> 2D로만 시각화했기 때문에 섞여 보이는 걸 수도 있지 않을까요?  
>   
> (답변)  
> 네 그것도 있습니다.  
> 그것도 아주 좋은 말씀이시고 그것도 명확하게 있는 말입니다.  
> 그런데 확실한 거는 파라미터.  
> 그러니까 인코더 디코더 Neural Network가 파라미터 개수를 갖고 있고 학습력이 있거든요.  
> 학습력이 안 좋은 상태로 이렇게 VAE를 학습하게 되면 이 Separation, Separatability가 되게 떨어지게 됩니다.  
> 그러니까 그 말은 뭐냐면 지브리가 안 된다는 거예요.  
> 그래서 여기 또 특징점에 보면 잘 분리되는 애들의 모양들이 명확하거든요.  
> 그런데 잘 분리가 안 되는 애들은 그 사이사이가 좀 헷갈립니다.  
> 6 그리고 9, 5, 2 이런 스트럭처들이 헷갈리잖아요.  
> 그래서 이제 그런 거라고 보시면 됩니다.  
>   
> 그래서 현대 생성 모델들에서는 얘네들에 대해서 웨이트를 주는 어려운 부위와  
> 어렵지 않은 부위를 다르게 이제 distribution 웨이트를 주는 방식으로  
> 데이터의 어떤 학습력을 다르게 해가지고 학습을 하고  
> 그런 어떤 테크닉들이 이제 되게 많은데 아마 저희 강의에서는 못 할 것 같습니다.  
> 그게 어드밴스드한 것들이에요.  
>   
> 또 질문 있으실까요?  
>   
> (질문)  
> 네, reparameterization은 오늘 아까 설명하고 가신 건지 제가 잘 못 들어가지고 이 부분도 중요한 건지?  
> 아니면 이 수업에서 이거는 약간 좀 덜 중요한 건지  
>   
> (답변)  
> 덜 중요하고요.  
> 그런데 보고 그냥 이해하시면 될 거 같아요.  
> 설명을 따로 드릴 필요는 없을 것 같습니다.  
> 여기에 그냥 쉽게 말해서 $q_\phi$라는 어떤 모델이  
> $\phi$라는 neural network의 parameter를 parameterization 하면 되는데  
> $\mu, \sigma$의 파라미터를 가지고 랜덤 배리어블을 어떻게 만들 것인지에 대한 거고  
> 이거는 그냥 스킵을 해도 그게 문제는 없을 것 같습니다.  
>   
> (질문)  
> 아까 VAE로 Anomaly Detection에 강점이 있다고 하셨는데  
> 생성형인데 Anomaly Detection을 어떻게 할 수 있는지 이해가 안 되서요  
> 다른 방향으로 그러니까  
>   
> (답변)  
> 이제 설명을 길어 줄 수도 있을 것 같아요.  
> 최대한 짧게 해보겠습니다.  
> Anomaly Detection 같은 경우는 두 가지의 데이터셋이 있어요.  
> 하나를 purified된 데이터셋이 있어가지고 데이터가 굉장히 클린한 보통의 경우에요 많은 세팅에서.  
> 그렇지 않은 경우도 있죠 거의 그렇게 합니다.  
> 그러니까 우리가 트레이닝 데이터 같은 경우는 expert들이 다 분류를 해서 Anomaly가 없다고 가정하는 거예요.  
> 다 분리를 해야겠죠 이거는 정상 데이터라는 것을 통해서.  
>   
> 그래서 아까 온라인 환경이라고 얘기를 드렸는데  
> 온라인 환경에서는 defect가 있는지 없는지 클린한지 아닌지 모르는 상황에서 쓰고 싶은 거잖아요.  
> 그래서 훈련 때 우리가 정상적인 expert들이 다 분류를 해가지고  
> 깔끔하다는 데이터로 훈련을 VAE를 이렇게 진행을 했을 때  
> 그럼 $x$랑 $x'$의 페어가 나오겠죠.  
> 그걸 훈련을 했기 때문에.  
>   
> 그런데 온라인 환경에서 $y$라는 defect가 있을 수도 있고 없을 수도 있는 데이터를 인코더에 넣으면  
> $x$와 $x'$의 어떤 거리와 $y$와 $y'$의 거리가 완전히 달라집니다.  
>   
> $x$랑 $x'$ 같은 경우는 트레이닝 데이터로 깔끔하게 우리가 만들었기 때문에 semantic도 분리가 됐고요.  
> 그리고 $x$랑 $x'$의 사이에 거리를 줄이도록 그렇게 학습을 했잖아요.  
> 그러니까 거리가 줄어든 상태일 겁니다.  
>   
> 그런데 온라인 환경에서 $y$라는 게 만약에 defect가 있다고 가정을 해봅시다.  
> 그럼 걔는 어떻게 될까요.  
> $y'$로 만들었을 때 거리가 어떻게 될까요.  
> 거리가 엄청나게 튀겠죠.  
>   
> 그리고 $y$가 만약에 defect가 없는 데이터가 들어오게 되면  
> $y$랑 $y'$의 거리를 재게 되면 작아지게 되겠죠.  
>   
> 그래서 그걸 스코어링을 해가지고  
> 거리가 100보다 크면 이건 anomaly인 거다,  
> 100보다 작으면 anomaly가 아니다  
> 이렇게 태스크를 만들어요.  
>   
> 그래서 VAE가 현재도 굉장히 많이 쓰이고  
> Anomaly Detection의 표준이라고 할 수 있는 것 같아요.  
>   
> (질문)  
> 그런데 inference 할 때는 인코더는 안 쓰고 디코더만 쓴다고 하셨는데  
>   
> (답변)  
> 아 그건 이제 그런 겁니다.  
> VAE의 목적이 원래 데이터를 생성하는 목적이잖아요.  
> 그런데 지금 Anomaly Detection에서 쓰겠다고 하는 거는  
> 생성의 목적은 버리고 생성은 안 하고  
> Anomaly로 이제 그 스트럭처를 다 갖고 와서 인코더, 디코더를 같이 쓰는 거죠.  
> 원래는 그렇게 태어난 애가 아닌데.  
>   
> 그래서 VAE가 먼저 생성 모델로서 태어나고  
> 그 다음에 얘를 너무 아까우니까, 인프라가 두 배 드는 이걸 어디다 갖다 쓸까 고민하다가  
> 오케이 그러면 그런 데에 한번 써볼까 하고  
> VAE의 어떤 어플리케이션으로 Anomaly Detection을 쓰면 좋겠다는 아이디어가 생겼고  
> 그렇게 이제 사용하고 있는 것 같아요.  

---

> **1. 잠재공간의 구조**  
> 이 그림은 MNIST 데이터셋으로 VAE를 학습한 뒤 잠재공간(latent space)을 2차원으로 시각화한 결과이다.  
> 각 점은 인코더 $q_\phi(z \mid x)$ 를 통해 얻어진 잠재벡터 $z$ 를 나타내며,  
> 점의 색깔은 해당 데이터의 실제 숫자 레이블(0~9)에 대응된다.  
> 서로 유사한 숫자들은 잠재공간에서 인접한 영역에 분포하며,  
> 클래스 간 경계도 매끄럽게 이어진다.
>
> **2. 연속적(latent-continuous)인 공간의 특징**  
> 잠재공간이 2차원으로 제한되어 있음에도 각 숫자 클래스는 클러스터 형태로 잘 구분된다.  
> 또한 그 사이 영역에서도 연속적인 변형이 가능하다.  
> 잠재공간의 한 점에서 인접한 점으로 이동하면  
> 디코더가 생성하는 숫자의 형태가 점진적으로 변화하며,  
> “6 → 0”, “4 → 9” 등 자연스러운 전이가 나타난다.  
> 이러한 연속성은 라벨을 사용하지 않는 unconditional VAE에서도  
> 잠재공간이 구조적으로 정렬되도록 학습되었음을 의미한다.
>
> **3. 잠재공간이 의미를 갖게 되는 이유**  
> 학습 전의 $z \sim \mathcal{N}(0,I)$ 샘플들은 단순한 무작위 가우시안이다.  
> 그러나 학습이 진행되면 인코더 $q_\phi(z \mid x)$ 가 데이터 구조를 반영하여  
> $p(z)$ 공간에 의미 있는 좌표계를 형성하게 된다.  
> 그 결과 잠재공간의 각 영역은 특정 숫자 형태나 패턴을 나타내는  
> 의미적 지역(semantic region)으로 변환된다.
>
> **4. 응용: 이상치 탐지 및 데이터 보간**  
> 잠재공간이 구조적으로 정렬되어 있으므로  
> 이상치 탐지(anomaly detection)나 데이터 보간(interpolation)이 가능하다.  
> 학습된 분포 영역 바깥의 $z$ 에서 생성된 샘플은  
> 비정상적이거나 왜곡된 형태를 띠므로,  
> 이는 VAE가 학습 데이터 분포를 벗어난 입력을 탐지하는 근거가 된다.

---
layout: post
title: "[확률과 통계] 9주차"
date: 2025-10-28 23:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. 생성 모델의 일반 개념 (General Concept of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_1.png" alt="image" width="720px">

---

### 보충 설명  

- 이 그림은 **생성 모델(Generative Model)**의 일반적인 구조를 보여준다.  
- 생성 모델은 이름 그대로 **데이터를 생성하는 모델**로, 예를 들어 텍스트가 주어졌을 때 그에 맞는 **이미지나 형태(Shape)**를 만들어내는 AI 모델을 말한다.  
- 이러한 모델의 핵심 구성요소는 **생성자(Generator)**이며, 실제로 데이터를 만들어내는 역할을 한다.  

- 생성자에는 두 가지 주요 입력이 존재한다.  
  1. **조건부 입력(conditional input)**:  
    - 예를 들어 “Bird(새)”라는 단어, 혹은 텍스트 토큰(token) 시퀀스 등이다.  
    - 이미지 생성 모델의 경우, 텍스트나 개념(Concept)을 벡터로 표현한 형태가 입력으로 들어간다.  
  2. **무작위 입력(random input)**:  
    - 생성 모델은 확률적 특성을 가지므로, **랜덤성(randomness)**을 반드시 포함해야 한다.  
    - 이는 통계적 확률 모델에서 매우 중요한 개념으로, **랜덤 변수(random variable)**를 통해 표현된다.  
    - 그림 속 주사위는 이러한 **확률적 입력(latent variable)**을 상징한다.  

- 이 무작위 입력은 모델이 단일 이미지만 반복해서 생성하지 않도록 도와준다.  
  - 예를 들어, 조건이 “Bird”일 때 항상 같은 새의 이미지만 나온다면 생성 모델의 의미가 없다.  
  - 랜덤성을 주입함으로써 “Bird”라는 조건 안에서도 다양한 **새의 변형(variation)**과 **다양성(diversity)**을 표현할 수 있게 된다.  

- 따라서 생성 모델은 **조건부 정보(conditional information)**와 **확률적 요소(randomness)**를 결합하여  
  주어진 조건에 맞는 다양한 샘플들을 생성하도록 학습되는 모델이다.  

---

## p3. 생성 모델의 확률적 표현 (Probabilistic Representation of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_2.png" alt="image" width="720px">

---

### 보충 설명  

- 현대적인 **생성 모델(Generative Model)**은 기본적으로 확률적 랜덤성을 입력으로 받는 **파이프라인 구조**를 가진다.  
- 여기서 주사위는 **랜덤 변수(random variable)**를 의미하며, 각각의 주사위는 생성될 이미지의 특정 속성(feature)에 영향을 준다.  
  - 예를 들어,  
    - 첫 번째 랜덤 변수는 색상(color)을,  
    - 두 번째 랜덤 변수는 각도(angle)를,  
    - 세 번째 랜덤 변수는 크기(size)를 결정하도록 작용할 수 있다.  
- 즉, **랜덤성의 각 요소가 이미지의 다양한 속성을 통계적으로 결정**하는 역할을 한다.  

- 이러한 랜덤 변수들은 단일 차원으로 존재하지 않고, **고차원(high-dimensional) 확률 공간**에서 정의된다.  
  - 다시 말해, 생성 모델의 입력으로 들어가는 랜덤 벡터는 보통 **다변량 가우시안 분포(multivariate Gaussian distribution)**를 따른다.  
  - 이 벡터의 각 차원은 처음에는 의미 없는 수치이지만, 학습이 진행되면서 특정한 **의미적 속성(semantic feature)**과 자연스럽게 연관된다.  

- 초기에는 이 벡터의 축(axis)에 “이건 색상, 이건 각도”와 같은 의미가 부여되어 있지 않다.  
  그러나 모델이 충분히 학습되면, **첫 번째 차원은 색상 변화**, **두 번째 차원은 각도 변화**, **세 번째 차원은 크기 변화**처럼  
  실제 데이터의 속성과 대응되는 구조가 **자연스럽게 형성된다.**  

- 이 현상은 생성 모델의 매우 흥미로운 특성 중 하나로,  
  **명시적인 피처(feature) 정의 없이도 학습을 통해 의미적 공간(semantic space)이 형성되는 과정**을 보여준다.  

---

## p4. 데이터 생성기의 분류 (Categorization of Data Generators)  

두 가지 접근 방식이 있다.  

1. **직접 접근(Direct approach)**: 데이터를 직접 생성하는 함수를 학습한다.  
(혼동스럽게도, 때때로 “암묵적 생성 모델(implicit generative model)”이라고도 불린다.)

   $$
   G : \mathcal{Z} \rightarrow \mathcal{X}
   $$

2. **간접 접근(Indirect approach)**: 데이터를 평가(score)하는 함수를 학습하고,  
   이 함수 아래에서 점수가 높은 지점을 찾아 데이터를 생성한다.  

   $$
   E : \mathcal{X} \rightarrow \mathbb{R}
   $$

---

### 보충 설명  

- 데이터 생성 모델은 **직접 접근 방식**과 **간접 접근 방식**으로 나뉜다.  
  이 두 접근은 데이터가 생성되는 **함수의 형태**와 **확률적 구조를 반영하는 방식**에서 차이가 있다.  

#### 1. 직접 접근 (Direct Approach)  
- **정의**: 랜덤 변수를 입력으로 받아 **데이터를 직접 생성하는 함수**를 학습하는 방식이다.  
  예를 들어, 잠재 변수 $ \mathbf{z} $ 를 입력받아 이미지 $ \mathbf{x} $ 를 생성한다.  
- **대표 모델**:  
  - **GAN(Generative Adversarial Network)**  
  - **VAE(Variational Autoencoder)** (직접 접근과 간접 접근의 중간적 성격을 가짐)  
- **특징**:  
  - 랜덤 변수 $ \mathbf{z} $ 로부터 바로 샘플을 생성한다.  
  - 즉, $ \mathbf{z} $ 가 주어지면 $ G(\mathbf{z}) $ 가 바로 데이터 샘플이 된다.  
  - 이러한 모델은 **명시적 확률 분포를 정의하지 않아도** 데이터를 직접 생성할 수 있기 때문에  
    “암묵적 생성 모델(implicit generative model)”이라고도 불린다.  

#### 2. 간접 접근 (Indirect Approach)  
- **정의**: 데이터를 직접 생성하지 않고, 데이터의 **좋은 정도(goodness)** 혹은 **우도(likelihood)**를 평가하는  
  **스코어(score)** 또는 **에너지(energy)** 함수를 학습한다.  
- **대표 모델**:  
  - **Diffusion model**, **Energy-based model**, **Score-based model** 등이 이에 해당한다.  
- **특징**:  
  - 단순히 랜덤 변수 $ \mathbf{z} $ 를 네트워크에 넣는 것이 아니라,  
    여러 단계의 **파이프라인**을 거쳐 데이터를 점진적으로 생성한다.  
  - 생성 과정에서 **에너지 함수 $ E(\mathbf{x}) $** 또는 **스코어 함수**를 이용해  
    “얼마나 데이터가 잘 생성되었는가”를 반복적으로 평가하고 조정한다.  

#### 3. 정리 및 비교  
- 직접 접근은 **생성 함수 $ G $**를 학습하여 데이터를 바로 만들어내는 반면,  
  간접 접근은 **평가 함수 $ E $**를 학습하고 이를 통해 생성 과정을 제어한다.  
- **VAE**는 두 접근 방식의 중간에 위치한 모델로,  
  **확률적 인코더-디코더 구조**를 통해 데이터를 생성하면서도 잠재 공간의 분포를 명시적으로 모델링한다.  

---

## p5. 직접 접근(Direct Approach)의 학습과 샘플링 과정  

<img src="/assets/img/lecture/probstat/9/image_3.png" alt="image" width="800px">

---

### 보충 설명  

- 생성 모델의 전체 과정을 **학습(Training)** 단계와 **샘플링(Sampling)** 단계로 나눌 수 있다.  
- 학습 과정은 주어진 **데이터셋(Data)**을 바탕으로 **모델의 파라미터(θ)**를 학습하는 단계이며,  
  샘플링 과정은 학습된 파라미터를 이용해 새로운 데이터를 생성하는 단계이다.  

#### 1. 학습(Training) 단계  
- 왼쪽의 데이터셋은 사람 얼굴 이미지처럼 대량의 실제 데이터를 의미한다.  
- **Learner**(또는 생성 네트워크)는 이 데이터로부터 **최적의 파라미터 θ**를 학습한다.  
- 이 파라미터 θ는 학습이 끝난 후 **생성기(generator)**의 내부 가중치로 사용된다.  
- 즉, 학습 단계에서는 “주어진 데이터로부터 어떻게 새로운 데이터를 생성할 것인가”를 배우는 과정이다.  

#### 2. 샘플링(Sampling) 단계  
- 학습이 끝난 후, 테스트 혹은 추론 시점(**inference time / test time**)에는  
  학습된 파라미터 $ \theta $ 를 고정한 채로, **랜덤 변수 $ z $**를 입력으로 주입한다.  
- 이 랜덤 벡터 $ z $는 잠재 공간(latent space)의 확률적 입력으로,  
  이를 **디코더(decoder)** 혹은 생성기 $ g_\theta $에 통과시켜 새로운 샘플(이미지)을 생성한다.  
- 즉,  

  $$
  \mathbf{x}_{\text{sample}} = g_\theta(\mathbf{z})
  $$

  의 형태로 새로운 데이터가 만들어진다.  

#### 3. 분류(classification) 문제와의 차이  
- 일반적인 분류 모델(classification model)은  
  학습 시점과 추론 시점의 입력–출력 구조가 거의 동일하다.  
- 반면 **생성 모델(generative model)**은  
  학습(Training)과 샘플링(Sampling)의 **파이프라인이 분리되어 있다는 점**이 큰 차이이다.  
  - 학습 단계에서는 데이터로부터 파라미터를 학습하고,  
  - 샘플링 단계에서는 확률적 입력으로부터 새로운 데이터를 생성한다.  
- 이러한 구조적 분리는 생성 모델의 핵심적인 특성이며,  
  **트레이닝 파이프라인과 생성 파이프라인이 서로 다른 형태로 존재한다는 점**을 이해하는 것이 중요하다.  

---

## p6. 간접 접근 (Indirect Approach)  

<img src="/assets/img/lecture/probstat/9/image_4.png" alt="image" width="800px">

---

### 보충 설명  

- **간접 접근(Indirect Approach)**은 데이터를 직접 생성하지 않고,  
  데이터의 “좋은 정도(goodness)”를 평가하는 **스코어링 함수(Scoring function)**를 학습하는 방식이다.  
- 이 스코어링 함수는 데이터의 **우도(likelihood)**, **에너지(energy)**, 혹은 **스코어(score)** 개념으로 해석될 수 있다.  

#### 1. 학습(Training) 단계  
- 주어진 데이터셋 $ \{ \mathbf{x}^{(i)} \}_{i=1}^{N} $ 을 이용해 **학습자(Learner)** 가  
  각 데이터의 위치에 대해 확률적 “품질”을 평가하는 함수를 학습한다.  
- 이 함수는 모델의 종류에 따라 다음과 같이 달라진다.  
  - **에너지 기반 모델(Energy-based model)**:  
    실제 데이터의 **에너지 $E_\theta(\mathbf{x})$를 낮추고**,  
    비현실적인 샘플의 에너지를 높이도록 학습한다.  
  - **스코어 기반 모델(Score-based model)**:  
    데이터의 로그 확률의 기울기, 즉 **스코어 함수 $\nabla_{\mathbf{x}} \log p_\theta(\mathbf{x})$**를 직접 근사하도록 학습한다.  
- 이 과정을 통해 모델은 “어떤 데이터가 더 자연스럽고 가능성 높은가”를 구분할 수 있는 함수를 얻게 된다.  


#### 2. 샘플링(Sampling) 단계  
- 학습된 스코어 함수나 에너지 함수를 활용하여  
  새로운 데이터를 생성하기 위해 **샘플링 알고리즘(sampling algorithm)**을 사용한다.  
- 대표적인 예로 **MCMC(Markov Chain Monte Carlo)** 방법이 있으며,  
  이는 스코어 함수가 높은 영역(즉, 가능성이 높은 데이터 영역)을 따라 새로운 샘플을 생성한다.  
- 수식적으로 표현하면,  

  $$
  \{ \hat{\mathbf{x}}^{(i)} \}_{i=1}^{N} \sim p_\theta(\mathbf{x}) \propto \exp(-E_\theta(\mathbf{x}))
  $$

  와 같이, 에너지 함수 $E_\theta(\mathbf{x})$가 낮을수록 샘플이 생성될 확률이 높아진다.  

#### 3. 직접 접근과의 비교  
- 직접 접근에서는 **랜덤 변수 $z$**를 입력으로 받아 데이터를 바로 생성하는 반면,  
  간접 접근은 **스코어 함수**를 학습한 후, 그 함수를 기반으로 **샘플링 알고리즘**을 통해 데이터를 생성한다.  
- 즉, 직접 접근은 “데이터를 바로 생성하는 함수”를 학습하는 것이고,  
  간접 접근은 “데이터가 얼마나 좋은지를 평가하는 함수”를 학습한 뒤  
  이 함수를 기반으로 데이터를 찾아내는 방식이다.  

- 이러한 접근 방식은 **디퓨전 모델(Diffusion Model)**이나  
  **에너지 기반 모델(Energy-based Model)** 등에서 핵심적인 역할을 하며,  
  뒤에서 배울 **Score-based Model**의 이론적 기반이 된다.  

---

## p7. 생성 모델 (Generative Models)  

목표는 학습 데이터를 그대로 복제하는 것이 아니라,  
**새로운(new)** 데이터를 만드는 것이다.  
그 데이터는 **현실적인(realistic)** 데이터여야 하며,  
실제 데이터의 **본질적인 속성(essential properties)**을 포착해야 한다.  

이것을 정량화하는 한 가지 방법은  
모델 하에서의 **테스트 데이터의 가능도(likelihood)**를 이용하는 것이다.  
(학습 데이터를 기억하는 모델은,  
분류기(classifier)가 과적합(overfit)되는 것과  
정확히 같은 의미에서 과적합된 것이다.)  

$$
\{x_{\text{test}}^{(i)}\}_{i=1}^{N}, \quad x_{\text{test}}^{(i)} \sim p_{\text{data}}
$$  

$$
\text{generalization error} = \sum_i \log p_\theta (x_{\text{test}}^{(i)})
$$  

---

### 보충 설명  

- 생성 모델의 목표는 학습 데이터를 그대로 복제하는 것이 아니라,  
  학습 데이터의 분포를 잘 포착하여 **그와 닮은(realistic)** 새로운 데이터를 생성하는 것이다.  

- 학습 데이터를 완벽히 재현하는 모델은  
  데이터를 단순히 암기한 것이며,  
  이는 분류기에서의 과적합(overfitting)과 동일하다.  

- 좋은 생성 모델은 학습 데이터 분포를 일반화(generalization)하여  
  보지 못한 데이터(test data)에 대해서도  
  높은 가능도(likelihood)를 부여할 수 있어야 한다.  

- GPT 같은 대형 언어 모델 또한 이러한 생성 모델의 예로,  
  기존 문장을 복사하지 않고  
  학습된 통계적·의미적 구조를 바탕으로 새로운 문장을 만들어낸다.  
  이때 새로운 데이터가 현실의 지식(real-world knowledge)과 잘 부합하면  
  “창의적 일반화(extrapolation)”로 볼 수 있지만,  
  현실과 어긋나면 **할루시네이션(hallucination)**으로 간주된다.  

- 따라서 생성 모델의 성능 평가는  
  “학습 데이터를 얼마나 잘 복제하는가?”가 아니라  
  “학습 데이터의 본질을 얼마나 잘 포착하고,  
   현실적인 새로운 데이터를 얼마나 잘 만들어내는가?”에 초점을 맞춘다.  

- 테스트 데이터의 로그 가능도(log-likelihood)는  
  이러한 일반화 능력을 수치로 평가하는 지표가 된다.  
  일반화 오차(generalization error)가 0이면  
  학습 데이터와 테스트 데이터가 완전히 일치한다는 뜻으로,  
  이는 과적합 상태를 의미한다.  
  반대로 오차가 너무 크면  
  학습된 분포를 벗어나 비현실적인 데이터를 생성할 수 있다.  

- 결국 생성 모델의 목표는  
  **현실적인(realistic) 데이터 생성**과 **새로운 정보 창출(extrapolation)** 사이의  
  균형을 유지하는 것이다.  

---

## p8. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_5.png" alt="image" width="720px">

---

### 보충 설명  

- **밀도 기반 모델(Density-based Model)**은 데이터의 **확률 밀도(probability density)**를 직접 모델링하는 생성 모델이다.  
- 이때 확률 밀도 함수 $p_\theta(x)$는 모든 가능한 $x$에 대해 정의되며,  
  그 값은 0 이상 무한대($[0, \infty)$)의 범위를 가진다.  

- 학습 데이터 $$ \{x^{(i)}\}_{i=1}^{N} $$ 가 주어졌을 때,  
  모델은 이 데이터들이 나올 확률 밀도 $$p_\theta(x)$$를 최대화하도록 학습된다.  

- 즉, 모델이 학습 데이터 근처에서 높은 확률 밀도 값을 가지도록 만들고,  
  전체 확률 공간에 대해 밀도의 합(적분)이 1이 되도록 조정한다.  
  이것은 우리가 이전에 배웠던 **확률 밀도 함수의 성질**—  
  “전체 영역에서의 면적(합)은 1이 된다”—와 같은 원리이다.  

- 따라서 밀도 기반 모델의 핵심은  
  주어진 데이터 분포를 잘 근사하는 **연속적인 확률 밀도 함수 $p_\theta(x)$**를 학습하는 것이다.  

- 이러한 방식은 생성 모델을 평가할 때 사용되는 **우도(likelihood)** 기반 접근과 밀접한 관련이 있으며,  
  모델이 학습 데이터의 분포를 얼마나 잘 설명하는지를 수치적으로 평가할 수 있게 해준다.  

---

## p10. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_6.png" alt="image" width="720px">

---

### 보충 설명  

- 그림은 확률 밀도 함수 $p_\theta(x)$의 형태를 보여준다.  
- **Constant mass(질량 보존)**은 전체 확률 질량(probability mass), 즉  
  확률 밀도의 적분값이 항상 1로 유지되어야 함을 의미한다.  
- 따라서 특정 구간에서 밀도가 높아지면,  
  다른 구간에서는 상대적으로 낮아져 전체 면적(확률의 총합)이 일정하게 유지된다.  
- 이 원리는 모든 확률 밀도 기반 생성 모델이 따라야 하는  
  기본적인 확률적 제약 조건이다.  

---

## p11. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_7.png" alt="image" width="800px">

$$
\begin{aligned}
p_\theta^* 
&= \arg \min_{p_\theta} \text{KL}(p_{\text{data}}, p_\theta) \\
&= \arg \min_{p_\theta} \mathbb{E}_{x \sim p_{\text{data}}} 
   \left[- \log \frac{p_\theta(x)}{p_{\text{data}}(x)} \right] \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ] 
   - \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_{\text{data}}(x) ] \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ]
   \quad \text{(두 번째 항은 } p_\theta \text{에 의존하지 않기 때문에 생략)} \\
&\approx \arg \max_{p_\theta} 
   \frac{1}{N} \sum_{i=1}^{N} \log p_\theta(x^{(i)})
\end{aligned}
$$  

**max likelihood**

---

### 보충 설명  

- 밀도 기반 모델은 데이터의 확률 밀도 함수 $p_\theta(x)$를 직접 추정(estimation)하는 생성 모델이다.  
- 학습의 목적은 **실제 데이터 분포 $p_{\text{data}}$와 모델 분포 $p_\theta$의 차이(KL divergence)**를 최소화하는 것이다.  

- 직관적으로 말하면,  
  - 데이터가 존재하는 구간에서는 확률 밀도(높이)를 **높게** 평가하고,  
  - 데이터가 존재하지 않는 구간에서는 확률 밀도를 **낮게** 평가하도록 학습된다.  
- 이렇게 함으로써 모델은 학습 데이터의 분포를 따라가는 형태로  
  확률 질량(probability mass)을 재분배하게 된다.  

- 오른쪽 그림에서 보듯이,  
  - 회색 곡선은 모델 분포 $p_\theta$를,  
  - 점과 초록색 화살표는 실제 데이터 분포 $p_{\text{data}}$를 나타낸다.  
  - 학습이 진행되면, 데이터가 있는 부분에서는 확률이 점점 증가하고 (초록색 영역),  
    데이터가 없는 부분에서는 확률이 감소한다 (빨간색 영역).  

- 이러한 최적화는 단 한 번에 이루어지는 것이 아니라,  
  **반복적인(iterative) 최대 우도 추정(maximum likelihood estimation)** 과정을 통해 점진적으로 이루어진다.  

- 수학적으로 보면, 최적의 분포 $p_\theta^*$는 다음과 같이  
  KL 발산을 최소화하는 분포로 정의된다.  

  $$
  p_\theta^* = \arg\min_{p_\theta} \text{KL}(p_{\text{data}} \,||\, p_\theta)
  $$

  이 식을 전개하면 결국 **로그 가능도(log-likelihood)**를 최대화하는 형태로 귀결된다.  

- 즉, **최대우도추정(Maximum Likelihood Estimation)**은  
  “데이터가 주어진 모델에서 나올 가능도를 가장 크게 만드는”  
  확률 밀도 함수를 찾는 과정이며,  
  이는 곧 KL 발산 최소화 문제와 동등하다.  

- 이러한 방식은 **에너지 기반 모델(Energy-based Model)**이나  
  **디퓨전 모델(Diffusion Model)**에서도 동일한 원리로 적용되며,  
  모델이 학습 데이터의 분포를 점진적으로 근사하도록 만든다.  

---

## p12. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

<img src="/assets/img/lecture/probstat/9/image_8.png" alt="image" width="480px">

---

### 보충 설명  

- 그림에서는 데이터 생성 과정을 **잠재 변수 $z$**와 **관측 변수 $x$**로 구분하여 표현한다.  
- **$z$ (latent variable)**은 데이터의 내재된 요인들을 나타내며,  
  예를 들어 이미지의 경우에는 **자세(pose)**, **크기(size)**, **색상(color)**, **종(breed)** 등의  
  보이지 않는 속성들이 이에 해당한다.  
- 이러한 잠재 변수들은 사람이 직접 정의하지 않아도,  
  모델이 학습 과정에서 스스로 학습하여 의미 있는 형태로 인코딩하게 된다.  

- **$x$ (observed variable)**은 실제로 관측 가능한 데이터이다.  
  예를 들어 이미지, 비디오, 오디오 등 현실에서 측정되거나 수집된 데이터가 이에 해당한다.  

- **Generator(생성기)**는 잠재 변수 $z$를 입력받아 실제 데이터 $x$를 생성하는 역할을 한다.  
  즉, $z$에서 $x$로의 매핑(mapping)을 학습하는 구조로,  
  확률적 생성 과정을 통해 새로운 데이터를 만들어낸다.  

- 이러한 구조는 단순히 이미지 생성뿐 아니라  
  **물리 기반 모델(physics model)**, **렌더러(renderer)**, **월드 모델(world model)** 등  
  다양한 형태의 생성 시스템에 동일하게 적용된다.  
- 다시 말해, 현대의 모든 생성 모델(generative model)은  
  기본적으로 잠재 공간(latent space)에서 관측 공간(observed space)으로  
  데이터를 변환하는 이와 같은 공통된 구조를 갖는다.  

- 따라서 변분 오토인코더(VAE)는  
  앞서 설명된 **직접 생성 접근(direct approach)** 모델 중 하나로,  
  잠재 변수 $z$를 통해 관측 변수 $x$를 생성하는 대표적인 구조로 이해할 수 있다.  

---

## p13. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

잠재 변수는 사전 분포(prior distribution)로부터 샘플링된다.  

$$
z \sim p(z)
$$  

그리고 생성기(generator)는 잠재 변수 $z$를 입력으로 받아  
관측 변수 $x$의 분포(distribution)를 생성한다.  

<img src="/assets/img/lecture/probstat/9/image_9.png" alt="image" width="720px">

---

### 보충 설명  

- 이 그림은 **데이터 생성의 확률적 구조**를 보여준다.  
  즉, 단순한 분포로부터 복잡한 실제 데이터 분포로의 매핑(mapping)이  
  **생성기(generator)**를 통해 이루어진다.  

- **잠재 변수 $z$**는 사전에 정의된 간단한 확률 분포(예: 정규분포)에서 샘플링된다.  
  이 분포는 **정보가 거의 없는 단순한 형태**로,  
  학습 이전에는 데이터에 대한 구체적인 의미를 담고 있지 않다.  

- **생성기(generator)**는 이러한 단순한 분포 $p(z)$를  
  실제 데이터의 복잡한 분포 $p(x)$로 변환하도록 학습된다.  
  즉, $z$ 공간의 간단한 형태를 **비선형 매핑**을 통해  
  현실적인 고차원 데이터 분포(high-dimensional distribution)로 바꾸는 역할을 한다.  

- 실제 데이터의 분포 $p(x)$는 매우 **복잡하고 다봉(multimodal)** 구조를 가지며,  
  여러 개의 로컬 최대점(local maxima)과 지역적인 패턴이 존재한다.  
  생성 모델은 이러한 복잡한 구조를 잘 근사할 수 있도록 학습되어야 한다.  

- 따라서 VAE의 생성 과정은 수학적으로 보면,  
  단순한 확률 분포(예: $p(z)$)를  
  복잡한 현실 세계의 데이터 분포(예: $p(x)$)로 매핑하는 변환 과정으로 볼 수 있다.  

- 다시 말해, **단순한 잠재 공간에서 복잡한 데이터 공간으로의 확률적 변환**이  
  바로 생성 모델(generator model)의 핵심 개념이다.  

---

## p14. 변분 오토인코더 (Variational Autoencoder)  

신경망(neural network)을 이용하여 확률 분포(distribution)를 표현한다.  

- $ \theta $ : 학습 가능한 파라미터(learnable parameters)  
- 표현되는 함수:  

  $$
  p_\theta(x \mid z)
  $$  

<img src="/assets/img/lecture/probstat/9/image_10.png" alt="image" width="600px">

---

### 보충 설명  

- **생성기(generator)**는 확률적 함수 $p_\theta(x \mid z)$로 표현되며,  
  이는 **잠재 변수 $z$가 주어졌을 때 데이터 $x$가 생성될 확률 분포**를 의미한다.  
- 즉, 생성기는 “$z$라는 조건이 주어졌을 때 어떤 $x$가 나타날 가능성이 높은가”를  
  모델링하는 확률적 맵핑(probabilistic mapping)이다.  

- 여기서 $\theta$는 신경망의 학습 가능한 파라미터로,  
  생성기의 형태와 출력을 결정한다.  
  따라서 학습을 통해 $\theta$가 조정되면서  
  $p_\theta(x \mid z)$가 실제 데이터의 분포를 점점 더 잘 근사하도록 한다.  

- **잠재 변수 분포 $p(z)$**는 단순한 형태(예: 정규분포)를 가진 반면,  
  **조건부 분포 $p_\theta(x \mid z)$**는 매우 복잡하고 고차원적이다.  
  신경망은 이러한 복잡한 비선형 관계를 학습하여  
  단순한 잠재 공간에서 복잡한 데이터 공간으로의 변환을 수행한다.  

- 이 구조를 통해 VAE는  
  단순히 하나의 확정적(deterministic) 매핑을 학습하는 것이 아니라,  
  **확률적으로 데이터의 다양성을 포착(capture)**하는 모델로 확장된다.  

- 다시 말해,  
  $p_\theta(x \mid z)$는 **조건부 확률(conditional probability)**로서의  
  생성 과정을 수학적으로 정의하며,  
  이는 앞서 배운 **결합 확률(joint probability)**,  
  **조건부 확률(conditional probability)**,  
  **주 marginalization** 개념들과 직접 연결된다.  

- 이처럼 VAE의 생성기는  
  잠재 변수의 분포에 조건화된 확률적 모델로서 작동하며,  
  “$z$를 입력받아 다양한 $x$를 생성할 수 있는”  
  **확률적 생성 구조(probabilistic generative structure)**를 갖는다.  

---

## p15. 최대우도추정 (Maximum Likelihood Estimation)  

---

### 본문 내용  

**Kullback–Leibler (KL) 발산 최소화:**  

$$
\min_{\theta} \, D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
$$  

> KL발산 외에 고려할 수 있는 다른 기준은?

**즉, 우도 최대화(Maximize likelihood):**  

$$
\max_{\theta} \, \mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
$$  

<img src="/assets/img/lecture/probstat/9/image_11.png" alt="image" width="480px">

전개 과정:  

$$
\begin{aligned}
\arg \min_{\theta} D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
&= \arg \min_{\theta} \sum_{x} p_{\text{data}}(x) 
\log \frac{p_{\text{data}}(x)}{p_{\theta}(x)} \\
&= \arg \min_{\theta} 
\left[- \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) + \text{const}\right] \\
&= \arg \max_{\theta} \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) \\
&= \arg \max_{\theta} 
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
\end{aligned}
$$  

---

### 보충 설명  

- **생성 모델의 학습 목표**는  
  실제 데이터 분포 $p_{\text{data}}$와 모델 분포 $p_{\theta}$ 사이의  
  **차이(Divergence)**를 줄이는 것이다.  
  이를 수학적으로 표현한 것이 **KL 발산(Kullback–Leibler divergence)**이다.  

- 다시 말해, $D_{\mathrm{KL}}(p_{\text{data}} \| p_{\theta})$를  
  가능한 한 작게 만드는 것이 학습의 목적이다.  
  그러나 실제로 KL 발산을 **0으로 완전히 줄이는 것은 불가능**하다.  
  - 그 이유는 실제 데이터의 분포가 매우 복잡하고 고차원적이며,  
    모델의 파라미터 $\theta$가 유한한 용량(capacity)을 가지기 때문이다.  
  - 따라서 우리는 **글로벌 최소(global minimum)** 대신,  
    **로컬 최소(local minimum)**를 향해 근사적으로 수렴하게 된다.  

- 수학적으로 KL 발산을 최소화하는 것은  
  **로그 가능도(log-likelihood)**를 최대화하는 것과 동치이다.  
  즉, **최대우도추정(Maximum Likelihood Estimation, MLE)**은  
  다음과 같은 형태로 표현된다.  
  $$
  \max_{\theta} \, \mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
  $$
  이는 실제 데이터 샘플을 모델이 얼마나 잘 설명하는지를 평가하는 과정이다.  

- 직관적으로 말하면,  
  모델이 생성한 분포 $p_{\theta}(x)$가  
  실제 데이터 분포 $p_{\text{data}}(x)$와 최대한 유사해지도록  
  모델 파라미터 $\theta$를 조정하는 것이다.  
  이때 두 분포는 개별 데이터 포인트가 아니라  
  **분포 전체(distribution as a whole)**의 형태로 맞춰진다.  

- **중요한 철학적 차이점:**  
  - 분류(classification) 문제에서는  
    입력 이미지 하나에 대해 대응하는 정답 레이블 하나가 존재한다.  
    즉, “1대1(one-to-one)” 매칭 구조이다.  
  - 반면, 생성 모델에서는  
    두 확률 분포 $p_{\text{data}}$와 $p_{\theta}$ 사이의  
    “다대다(many-to-many)” 관계를 학습한다.  
    데이터 간의 직접적인 페어링(pairing)이 존재하지 않으며,  
    전체 분포 수준에서의 **확률적 매칭(distributional matching)**을 수행한다.  

- 이러한 이유로 생성 모델은  
  단일 데이터 복제(copy)가 아니라,  
  **확률적으로 유사한 새로운 데이터 생성**을 목표로 한다.  
  즉, 모델이 샘플링한 새로운 데이터가  
  실제 데이터와 “닮은(distributionally similar)” 형태로 나타나게 된다.  

- 따라서 KL 발산을 최소화한다는 것은  
  단순히 두 데이터 집합을 맞추는 것이 아니라,  
  **확률 공간 전체에서의 통계적 일치(statistical alignment)**를 의미한다.  

---

## p16. 최대우도추정 (Maximum Likelihood Estimation)

우리는 다음 식을 최대화하고자 한다.

$$
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_\theta(x)]
$$  

여기서 $p_\theta(x)$는 다음과 같이 표현된다.

$$
p_\theta(x) = \int_z p_\theta(x \mid z) \, p(z) \, dz
$$  

<img src="/assets/img/lecture/probstat/9/image_12.png" alt="image" width="480px">

이때 두 가지 미지항(unknowns)이 존재한다.

1. **최적화 대상:** $\theta$ — 학습 가능한 파라미터  
2. **제어 불가능한 요소:** “진짜” 사전 분포 $p(z)$  

따라서 다음과 같은 아이디어가 제시된다.  
→ **“제어 가능한(controllable)” 분포 $q(z)$**를 도입한다.

---

### 보충 설명

- 앞서 살펴본 것처럼, 최대우도추정(MLE)은  
  실제 데이터 분포 $p_{\text{data}}$에 대해  
  모델 분포 $p_\theta(x)$의 로그 가능도 $\log p_\theta(x)$를  
  최대화하는 것을 목표로 한다.

- 그런데 $p_\theta(x)$는 단순한 형태가 아니라  
  **잠재 변수(latent variable) $z$에 대한 적분 형태**로 표현된다.  
  이는 조건부 확률의 정의를 사용해 다음과 같이 나타낼 수 있다.

  $$
  p_\theta(x) = \int_z p_\theta(x \mid z) \, p(z) \, dz
  $$

  여기서  
  - $p(z)$는 **잠재 변수의 사전 분포(prior distribution)**이며,  
    보통 **가우시안 랜덤 변수(Gaussian random variable)**로 가정한다.  
  - $p_\theta(x \mid z)$는 **생성기(generator)**로,  
    잠재 변수 $z$가 주어졌을 때 데이터 $x$가 생성될 확률을 나타낸다.

- 이 식은 우리가 앞서 직관적으로 이해했던  
  “잠재 변수를 입력받아 데이터를 생성하는 과정”을  
  **수학적으로 공식화(formalization)**한 형태이다.  
  즉, 이전에 설명했던 개념적 파이프라인(데이터 생성 절차)을  
  수학적으로 표현하면 바로 이 적분식 형태가 된다.

- 하지만 이 식을 직접 최적화하는 것은 어렵다.  
  이유는 두 가지이다.
  1. $p_\theta(x)$는 $z$에 대한 적분 형태이므로 **폐형식(closed form)**으로 계산이 어렵다.  
  2. $p(z)$, 즉 “진짜” 사전 분포는 우리가 **직접 제어할 수 없다.**

- 따라서 실제 학습에서는  
  직접적인 사전 분포 $p(z)$ 대신  
  **“제어 가능한(controllable)” 근사 분포 $q(z)$**를 도입하여  
  계산과 최적화를 가능하게 만든다.

- 이 아이디어가 바로 **변분 오토인코더(VAE)**의 핵심 동기 중 하나이다.  
  즉, 단순히 $p_\theta(x)$를 계산하는 대신,  
  잠재 공간에서의 근사 분포 $q(z)$를 활용해  
  효율적으로 로그 가능도를 최대화할 수 있도록 구조를 재정의한다.

---

## p17. 잠재 변수 모델 (Latent Variable Model)

<img src="/assets/img/lecture/probstat/9/image_13.png" alt="image" width="800px">

---

### 보충 설명

- 목표는 $\log p_\theta(x)$를 **최대화**하는 것이다.  
  이를 다루기 위해 임의의 보조 분포 $q(z)$를 곱해 적분 형태로 바꾸면,  
  $z$에 무관한 상수 $\log p_\theta(x)$를 적분 안으로 옮길 수 있다.

- 베이즈 규칙으로 $p_\theta(z\mid x)=\frac{p_\theta(x\mid z)p_\theta(z)}{p_\theta(x)}$를 대입하고,  
  $q(z)$를 곱하고 나누어(즉, 1을 곱한 것) 로그 성질 $\log a - \log b$를 이용해 항들을 분리한다.

---

## p18. 계산 불가능한 식에서 계산 가능한 형태로 (From Intractable to Tractable Formulation)

<img src="/assets/img/lecture/probstat/9/image_14.png" alt="image" width="800px">

---

### 보충 설명

- 우리가 다루는 $\log p_\theta(x)$는 **직접 계산이 불가능(intractable)** 하다.  
  그 이유는 모델링 대상이 이미지, 음성, 언어 등 **고차원(high-dimensional)** 데이터이기 때문이다.  
  이러한 복잡한 데이터 공간에서는 확률의 적분을 정확하게 계산할 수 없다.

- 따라서 $\log p_\theta(x)$를 그대로 최적화하는 대신,  
  위 식처럼 **부분적으로 계산 가능한(tractable)** 항들로 분리한다.  
  앞의 두 항(기대 로그 가능도와 정칙화 항)은 계산할 수 있지만,  
  마지막 항은 **Bayes 규칙**에서 유도된 $p_\theta(z\mid x)$가 포함되어 있어 직접 다룰 수 없다.

- 그러나 이 마지막 항 $D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$은  
  항상 0 이상이며, 우리가 이를 **무시하더라도 발산하지 않는다**는 점을 이용한다.  
  즉, 이 항을 완벽히 계산하지 않아도  
  앞의 두 항(계산 가능한 부분)을 최적화하는 것만으로  
  $\log p_\theta(x)$를 간접적으로 최대화할 수 있다.

- 이 아이디어가 바로 **변분추론(Variational Inference)** 의 핵심이다.  
  계산이 불가능한 항을 무시하고,  
  계산 가능한 하한(ELBO)을 최대화하는 방식으로  
  원래의 복잡한 목적 함수를 근사적으로 최적화한다.

---

## p19. 증거 하한 (Evidence Lower Bound, ELBO)

<img src="/assets/img/lecture/probstat/9/image_15.png" alt="image" width="720px">

- 이것을 **Evidence Lower Bound (ELBO)** 라고 부른다.  
- 이는 $\log p_\theta(x)$의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.

### 해설

- 위의 등식에서 왼쪽 부분  
  $\log p_\theta(x) - D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$  
  은 **계산 불가능(intractable)** 하다.  
  왜냐하면 $p_\theta(z\mid x)$, 즉 사후분포(posterior distribution)를  
  직접 구할 수 없기 때문이다.

- 오른쪽의 두 항  
  $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]$$ 와  
  $$-D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))$$  
  은 **계산 가능(tractable)** 하다.  
  이 두 항이 결합된 형태가 바로 우리가 다룰 수 있는 항이다.

- 따라서 이 표현은 다음 부등식으로 쓸 수 있다:

  $$
  \log p_\theta(x)
  \ge
  \mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]
  - D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))
  $$

  오른쪽의 표현이 바로 **Evidence Lower Bound (ELBO)** 이며,  
  이는 $\log p_\theta(x)$의 **하한(lower bound)** 을 제공한다.

- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 항상 성립한다.  
  즉, 우리가 $q(z)$를 어떻게 정의하든  
  ELBO는 항상 $\log p_\theta(x)$보다 작거나 같다.

- 따라서 $\log p_\theta(x)$를 직접 최대화하는 대신,  
  그 하한인 ELBO를 최대화하는 것이  
  변분 오토인코더(VAE)의 핵심 학습 목표가 된다.

---

## p20. 매개변수화(Parameterization)

<img src="/assets/img/lecture/probstat/9/image_16.png" alt="image" width="600px">

- 이것은 **Evidence Lower Bound (ELBO)** 라고 불린다.  
- 이는 $\log p_\theta(x)$ 의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.  
- 이제 $q(z)$를 직접 다루기 어려우므로,  
  이를 **매개변수화(parameterize)** 하여  
  **$q_\phi(z \mid x)$** 로 표현한다.  
- 여기서 $\phi$ 는 **추론 네트워크(inference network)** 의  
  학습 가능한 파라미터이다.  
- 반면, **$p_\theta(z)$** 는 단순하고 알려진 **사전분포(prior)** 로 둔다.

---

### 보충 설명

- 실제로 $q(z)$는 임의의 형태를 가질 수 있지만,  
  그 분포를 명시하거나 직접 계산하는 것은 불가능하다.  
  따라서 이를 **신경망으로 근사(parameterize)** 하여  
  $q_\phi(z \mid x)$ 형태로 표현한다.  
  이때 $\phi$는 인코더(추론 네트워크)의 학습 가능한 파라미터이다.

- 인코더 $q_\phi(z \mid x)$는 **입력 데이터 $x$로부터 잠재변수 $z$를 추정**하고,  
  디코더 $p_\theta(x \mid z)$는 **잠재변수 $z$로부터 데이터를 복원 또는 생성**한다.  
  이렇게 두 확률모델이 짝을 이루어 작동한다.

- 사전분포 $p_\theta(z)$는 보통 **표준정규분포 $\mathcal{N}(0, I)$** 로 설정한다.  
  이는 계산을 단순하게 하고, 잠재공간을 일정한 구조로 유지시킨다.

- 결국, 인코더와 디코더의 파라미터 $\phi, \theta$를 조정하여  
  **ELBO를 최대화**하는 것이 VAE의 학습 과정이다.  
  이 과정은 **잠재변수의 분포 추정과 데이터 생성 과정**을 동시에 학습한다.

---

## p21. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_17.png" alt="image" width="800px">

---

### 보충 설명

- 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를 받아  
  잠재변수 $z$의 분포를 추정하는 역할을 한다.  
  일반적으로 이 분포는 **가우시안(정규분포)** 형태로 가정된다.  

- 디코더 $p_\theta(x \mid z)$는 샘플링된 $z$로부터  
  원래의 입력 $x$를 재구성(reconstruct)하도록 학습된다.  
  즉, 인코더가 정보를 요약하고,  
  디코더가 그 정보를 바탕으로 데이터를 복원하는 구조이다.  

- 전체 손실 함수는 두 부분으로 구성된다.  
  - 첫 번째 항 $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$ 는  
    **재구성 손실**로서, 입력 $x$와 복원된 $x'$ 간의 차이를 최소화한다.  
  - 두 번째 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p_\theta(z))$ 는  
    **정칙화 항**으로서, 인코더가 추정한 분포가  
    사전분포 $p_\theta(z)$ (보통 $\mathcal{N}(0, I)$)와  
    유사하도록 만드는 역할을 한다.  

- 이 두 항의 균형을 조정함으로써  
  VAE는 잠재공간(latent space)을 구조적으로 유지하면서  
  새로운 데이터를 생성할 수 있는 능력을 갖추게 된다.  

- 이러한 구조는 단순히 생성 모델로서뿐만 아니라,  
  **이상치 탐지(Anomaly Detection)** 와 같은 응용에서도  
  널리 활용된다.  
  학습된 모델은 정상 데이터의 잠재공간을 학습하므로,  
  재구성 오차가 큰 데이터는 이상치로 판별된다.

---

## p22. 변분 오토인코더(Variational Autoencoder)

---

$$
\mathcal{L}_{\theta, \phi}(x)
= 
-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]
+ 
D_{\mathrm{KL}}\!\big(q_\phi(z \mid x)\,\|\,p(z)\big)
$$

---

### 보충 설명

- 이 식은 변분 오토인코더(VAE)의 **최적화 목표 함수**이다.  
  앞의 항은 **재구성 손실(Reconstruction Loss)**,  
  뒤의 항은 **정칙화 손실(Regularization Loss)** 을 의미한다.  

- 인코더 $q_\phi(z \mid x)$는 입력 $x$로부터 잠재변수 $z$의 분포를 추정하며,  
  이 분포가 **사전분포(prior) $p(z)$** 와 최대한 유사해지도록 학습된다.  

- 즉, **KL 발산 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$** 은  
  인코더가 만든 분포가 $p(z)$ (보통 표준정규분포 $\mathcal{N}(0, I)$)를 따르도록 유도한다.  
  이로써 잠재공간이 구조화되고, 새로운 샘플을 쉽게 생성할 수 있다.  

- 디코더 $p_\theta(x \mid z)$는 추출된 잠재변수 $z$를 바탕으로  
  입력 데이터 $x$를 복원(reconstruct)하도록 학습된다.  
  이 과정에서 첫 번째 항의 기댓값은  
  **입력과 복원된 출력 간의 유사도**를 최대화하도록 작용한다.  

- 결과적으로, VAE는  
  ① **데이터 재구성 능력**을 유지하면서,  
  ② **잠재변수 분포를 정규화된 형태로 정렬(regularize)** 하는  
  두 가지 목표를 동시에 달성한다.  

- 이러한 구조 덕분에 VAE는 **샘플링 가능한 생성 모델**로 작동하며,  
  $z \sim p(z)$ 로부터 임의의 잠재변수를 뽑아  
  $p_\theta(x \mid z)$ 를 통해 새로운 데이터를 생성할 수 있다.

---

## p22. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_18.png" alt="image" width="800px">

---

### 보충 설명

- 위 식은 **ELBO를 최대화하는 대신, 동등하게 손실을 최소화하는 형태**로 표현된 것이다.  
  왼쪽 항은 **재구성 손실(reconstruction loss)**,  
  오른쪽 항은 **정칙화 손실(regularization loss)** 에 해당한다.  

- 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를  
  잠재공간(latent space) 상의 확률분포로 압축하여 표현한다.  
  이때 $\phi$는 인코더의 학습 파라미터이며,  
  인코더는 잠재변수 $z$의 분포가  
  **사전분포(prior) $p(z)$** 와 유사해지도록 학습된다.  

- 사전분포 $p(z)$는 보통  
  **가우시안 분포 $\mathcal{N}(0, I)$** 로 설정된다.  
  이는 잠재공간이 구조적으로 안정적이면서  
  샘플링 가능한 형태를 가지게 하기 위함이다.  

- 정칙화 항 $D_{\mathrm{KL}}\\big(q_\phi(z \mid x)\,\|\,p(z)\big)$ 은  
  인코더가 학습하는 분포 $q_\phi(z \mid x)$가  
  $p(z)$와 **가깝게 유지되도록 하는 제약 조건**으로 작용한다.  
  이 항이 작을수록, 인코더가 만든 잠재분포는  
  표준정규분포에 더 근접하게 된다.  

- 디코더 $p_\theta(x \mid z)$는 잠재변수 $z$로부터  
  원래의 입력 $x$를 재구성하는 역할을 한다.  
  이때 $\theta$는 디코더의 학습 파라미터이며,  
  학습의 목적은 $x$와 복원된 $x'$ 간의 차이를 최소화하는 것이다.  

- 결국, VAE의 학습은  
  ① **데이터를 재구성할 수 있는 능력**과  
  ② **잠재공간의 확률적 구조를 유지하는 능력**  
  두 가지를 동시에 최적화하는 과정이다.

---

## p23. 첫 번째 항: 재구성 손실 (Reconstruction Loss)

<img src="/assets/img/lecture/probstat/9/image_19.png" alt="image" width="720px">

**예시: L2 손실 (L2 loss)**  

- 1단계 몬테카를로(Monte Carlo) 샘플링:  
  $z \sim q_\phi(z \mid x)$  

- 디코더 네트워크에 의한 매핑:  
  $g_\theta(z) \rightarrow x'$  
  (network estimates distribution’s parameters)

- 가우시안 분포로 모델링:  
  $p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)$  
  (assume fixed std)

- 음의 로그우도(negative log-likelihood):  

  $$
  -\log p_\theta(x \mid z)
  =
  \frac{1}{2\sigma_0^2}\|x - x'\|^2 + \text{const}
  $$

- L2 손실은 데이터 포인트 $x$ 주변의  
  가우시안 근방(Gaussian neighborhood)을 의미함

---

### 보충 설명

#### 1. 몬테카를로 샘플링 (Monte Carlo Sampling)
- 기댓값  
  $$
  \mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]
  $$
  은 잠재변수 $z$ 에 대한 적분 형태로 표현되며,  
  해석적으로 계산하기 어렵다.  
- 따라서 $q_\phi(z \mid x)$ 에서 샘플링한 $z$ 들을 이용해  
  $\log p_\theta(x \mid z)$ 값을 평균하여 근사한다.  
  이 방법을 **몬테카를로 근사(Monte Carlo approximation)** 라 한다.  
- 샘플링 과정은 **재매개변수화 기법(Reparameterization trick)** 으로  
  미분 가능하게 만들어, 인코더와 디코더 모두를  
  역전파로 학습할 수 있다.

#### 2. 디코더 네트워크에 의한 매핑 $g_\theta(z) \rightarrow x'$
- 디코더 $g_\theta$ 는 잠재변수 $z$ 를 입력받아  
  생성 데이터의 평균값(예측값) $x'$ 을 출력한다.
- 이때 디코더는 단순히 이미지를 “복원”하는 함수가 아니라,  
  **확률분포 $p_\theta(x \mid z)$** 의 **모수(parameter)** 를 추정하는 함수로 해석된다.
- 가장 단순한 경우, 디코더는 평균만 출력한다고 가정한다:
  $$
  x' = \mu_\theta(z)
  $$
  이때 분산은 고정된 상수 $\sigma_0^2$ 로 둔다.  
  즉, 디코더는 “이 데이터가 존재할 법한 중심(mean)”을 학습하는 것이다.
- 따라서 디코더는 **확률적 생성 모델의 평균 함수(mean function)** 로서 동작한다.

#### 3. 가우시안 분포로 모델링하는 이유
- 현실의 데이터는 완전히 결정론적이지 않고,  
  노이즈나 불확실성을 포함한다.  
  따라서 $x$ 와 $x'$ 가 완전히 일치하도록 학습하는 대신,  
  $x$ 가 $x'$ 주변에서 나올 확률을 모델링한다.
- 이를 위해 VAE는
  $$
  p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
  $$
  로 가정한다.
- 여기서  
  - $x' = g_\theta(z)$ 는 **평균(mean)**  
  - $\sigma_0^2 I$ 는 **분산(covariance)**  
  - $x$ 는 **그 분포로부터의 관측값(sample)** 이다.
- 즉, 디코더는 “데이터 $x$ 가 평균 $x'$ 를 중심으로  
  정규분포 형태로 분포한다”는 확률적 가정을 학습한다.
- 이러한 확률 모델링을 통해  
  모델은 데이터의 불확실성을 표현할 수 있고,  
  수학적으로도 로그우도를 닫힌형(closed form)으로 계산할 수 있다.

#### 4. 재구성 손실이 L2 손실이 되는 이유
- 위 가정하에서 로그 가능도는
  $$
  \log p_\theta(x \mid z)
  =
  -\frac{1}{2\sigma_0^2}\|x - x'\|^2
  -\frac{d}{2}\log(2\pi\sigma_0^2)
  $$
  로 전개된다.
- 따라서 음의 로그 가능도는
  $$
  -\log p_\theta(x \mid z)
  =
  \frac{1}{2\sigma_0^2}\|x - x'\|^2 + \text{const}
  $$
- 이 항은 데이터 $x$ 와 복원된 샘플 $x'$ 의 거리 제곱항(L2 norm)으로 표현된다.  
  즉, 디코더의 출력이 가우시안 분포의 평균으로 해석될 때,  
  **재구성 손실(Reconstruction Loss)** 은 곧  
  **L2 손실(Mean Squared Error)** 과 동일한 의미를 갖는다.

#### 5. 전체적 관계 요약
- $x$: 관측 데이터 (입력)  
- $z$: 잠재변수 (인코더가 샘플링)  
- $x' = g_\theta(z)$: 디코더가 예측한 분포의 평균  
- $p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)$:  
  관측 $x$ 가 평균 $x'$ 을 중심으로 한 확률분포에서  
  샘플링된 결과로 해석됨.  
- 따라서 재구성 손실을 최소화하는 것은  
  “실제 데이터 $x$”와  
  “디코더가 생성한 평균 $x'$” 사이의 거리를 줄이는 것과 같다.

---

## p24. 두 번째 항: 정규화 손실 (Regularization Loss)

<img src="/assets/img/lecture/probstat/9/image_20.png" alt="image" width="720px">

**예시: 가우시안 사전분포 (Gaussian prior)**  

- $p(z) = \mathcal{N}(z \mid 0, I)$ 로 둔다.  

- $q_\phi(z \mid x)$ 를 가우시안으로 모델링한다:  
  $q_\phi(z \mid x) = \mathcal{N}(z \mid \mu, \sigma)$  

- 인코더 네트워크에 의한 매핑:  
  $f_\phi(x) \rightarrow (\mu, \sigma)$  
  (network estimates distribution’s parameters)

- 손실을 분석적으로 계산한다:  

  $$
  D_{\mathrm{KL}}\big(\mathcal{N}(z \mid \mu, \sigma)\,\|\,\mathcal{N}(z \mid 0, I)\big)
  $$

- 공분산을 고정한 경우:  
  fixed covariance → $\mu$ 에 대한 L2 손실

---

### 보충 설명

#### 1. 정규화 항의 역할  
- 정규화 손실 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은  
  인코더가 학습한 **잠재 분포 $q_\phi(z \mid x)$** 가  
  사전 분포 **$p(z)$ (보통 표준 정규분포 $\mathcal{N}(0, I)$)** 와  
  얼마나 다른지를 측정한다.  
- 이 항은 **잠재공간(latent space)** 이  
  지나치게 왜곡되지 않도록 제약을 주는 역할을 한다.  
  즉, 인코더가 만든 $z$ 가  
  특정 데이터 $x$ 에 과도하게 맞춰지지 않고,  
  **일관된 잠재 구조**를 유지하도록 돕는다.

#### 2. KL 발산의 계산 방식  
- 두 가우시안 분포 간의 KL 발산은  
  닫힌 형태(closed-form)로 계산 가능하다:  

  $$
  D_{\mathrm{KL}}(\mathcal{N}(\mu, \sigma^2)\,\|\,\mathcal{N}(0, 1))
  =
  \frac{1}{2}\big(\mu^2 + \sigma^2 - \log \sigma^2 - 1\big)
  $$

- 이는 VAE 학습 시 매우 효율적이며,  
  손실 항을 직접 계산할 수 있게 한다.

#### 3. 공분산 고정 시 L2 손실과의 관계  
- 공분산 $\sigma^2$ 를 고정하면,  
  위 KL 항은 $\mu^2$ 에 비례하는 형태가 된다.  
  즉,  

  $$
  D_{\mathrm{KL}} \propto \|\mu\|^2
  $$

  이므로 L2 손실과 동일한 형태로 동작한다.  
- 따라서 정규화 항은  
  잠재변수 $z$ 의 평균 $\mu$ 가  
  원점 근처(즉, 사전 분포의 중심)로  
  모이도록 압박하는 효과를 낸다.

#### 4. 직관적 해석  
- 인코더가 임의의 입력 $x$ 를 받아  
  $\mu$ 와 $\sigma$ 를 출력할 때,  
  이 항은 "너무 특이한" 잠재 벡터를 피하게 만든다.  
  즉, 학습된 잠재공간이  
  사전분포 $p(z)$ 와 유사한 모양을 유지하게 되어,  
  샘플링 시에도 자연스럽고 일관된  
  데이터 생성을 가능하게 한다.

---

## p25. 역전파는 어떻게 이루어질까? (Backpropagation?)

<img src="/assets/img/lecture/probstat/9/image_21.png" alt="image" width="800px">

---

### 보충 설명

#### 1. 인코더와 샘플링의 관계  
- 인코더는 입력 $x$ 로부터  
  잠재 변수의 분포 $q_\phi(z \mid x)$ 를 학습한다.  
  이때 분포의 평균 $\mu_\phi(x)$ 와 표준편차 $\sigma_\phi(x)$ 를 추정하여  
  확률적으로 $z$ 를 샘플링한다.  
- 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 로 전달되어  
  재구성된 출력 $x'$ 를 생성한다.  

#### 2. 역전파의 문제점  
- 문제는 이 샘플링 과정이 **확률적(stochastic)** 이라는 점이다.  
  즉,  

  $$
  z \sim q_\phi(z \mid x)
  $$

  에서 $z$ 는 난수(random variable)에 의해 결정되므로,  
  이 연산은 **비결정적(non-deterministic)** 이며  
  **미분 불가능(non-differentiable)** 하다.  
- 신경망 학습은 손실 함수의 기울기를 계산하여  
  파라미터를 업데이트하는 방식으로 동작하는데,  
  확률적 샘플링은 그 경로를 따라 기울기를 계산할 수 없게 만든다.  
  즉, $z$ 를 뽑는 순간 역전파가 단절된다.

#### 3. 직관적 비유  
- 인코더는 “분포의 모양(평균과 분산)”만 제시하고,  
  샘플링은 “그 분포로부터 주사위를 던지는 과정”에 해당한다.  
- 주사위 결과(즉, $z$)는 확률적으로만 정해지기 때문에,  
  그 결과값에 대해 $\mu$ 나 $\sigma$ 로 직접 미분할 수 없다.  
- 따라서 일반적인 역전파 규칙을 그대로 적용할 수 없다.

#### 4. 해결책의 방향  
- 이 한계를 극복하기 위해  
  다음 단계에서는 **재매개변수화 기법(Reparameterization Trick)** 을 도입한다.  
- 이 기법은 샘플링 과정을  
  결정적(deterministic) 형태로 변환하여  
  **미분 가능한 형태로 다시 표현**함으로써  
  역전파 경로를 복원할 수 있게 해 준다.

---

## p26. 재매개변수화 (Reparameterization)

<img src="/assets/img/lecture/probstat/9/image_22.png" alt="image" width="800px">

가우시안 매개변수들은 신경망의 출력값에 의해 매개변수화되어,  
중간 조건부 분포들을 근사하기 위해 사용된다!  
(Gaussian parameters are parameterized by neural network output to  
approximate intermediate conditional distributions!)

---

### 보충 설명

#### 1. 재매개변수화의 핵심 아이디어  
- 이전 단계에서 보았듯이,  
  확률적 샘플링 $z \sim q_\phi(z \mid x)$ 은  
  미분 불가능하기 때문에 역전파가 단절된다.  
- **재매개변수화 기법(Reparameterization Trick)** 은  
  이 확률적 과정을 **결정적(deterministic)** 함수로 변환하여  
  미분 가능한 형태로 만든다.  
- 즉, 잠재 변수 $z$ 를 직접 샘플링하지 않고  
  표준 정규분포에서 샘플링한 잡음 $\varepsilon$ 을 이용해  
  다음과 같이 계산한다:  

  $$
  z = \mu_\phi(x) + \sigma_\phi(x) \cdot \varepsilon, 
  \quad \varepsilon \sim \mathcal{N}(0, I)
  $$

#### 2. 수식의 의미  
- $\varepsilon$ 은 고정된 확률 분포 $\mathcal{N}(0, I)$ 에서만 샘플링되므로,  
  **랜덤성은 $\varepsilon$ 에 존재**하고  
  $\mu_\phi(x)$, $\sigma_\phi(x)$ 는 **결정적(deterministic)** 함수가 된다.  
- 따라서 $z$ 는 $\phi$ 의 미분 가능한 함수가 되어,  
  역전파를 통해 인코더 파라미터 $\phi$ 도 함께 학습할 수 있다.  
- 이 과정을 통해 샘플링 단계가 신경망 내부의  
  연산 그래프에 포함될 수 있게 된다.

#### 3. 직관적 이해  
- 원래는 "분포로부터 직접 샘플링"했지만,  
  이제는 "고정된 분포에서 잡음을 뽑고"  
  그 잡음을 **평균과 분산으로 변환**하는 과정으로 바뀐 것이다.  
- 즉, 확률적 샘플링을  
  “노이즈 입력을 받는 결정적 함수”로 바꾸어  
  **학습 가능한 형태**로 만든다.

#### 4. 전체 구조의 연결  
- 인코더는 입력 $x$ 로부터 $(\mu, \sigma)$ 를 출력하고,  
  표준 가우시안 잡음 $\varepsilon$ 를 이용해  
  $z = \mu + \sigma \cdot \varepsilon$ 을 계산한다.  
- 디코더는 이 $z$ 를 입력받아  
  $p_\theta(x \mid z)$ 를 통해 데이터를 재구성한다.  
- 이 구조를 통해  
  **확률적 생성 모델이 완전히 미분 가능한 신경망 형태**로 구현된다.

---

## p27. 변분 오토인코더 (Variational Autoencoder) 

지금까지는 하나의 $x$ 에 대한 목적함수를 논의해왔다:

<img src="/assets/img/lecture/probstat/9/image_23.png" alt="image" width="800px">

전체 손실(overall loss)은  
데이터 분포에 대한 기대값으로 표현된다:

<img src="/assets/img/lecture/probstat/9/image_24.png" alt="image" width="800px">

---

### 보충 설명

#### 1. 단일 데이터 샘플 $x$ 에 대한 손실  
- 위의 첫 번째 식은 **단일 입력 샘플 $x$** 에 대한  
  손실 함수 $\mathcal{L}_{\theta, \phi}(x)$ 를 정의한 것이다.  
- 첫 번째 항 $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$ 은  
  **재구성 손실(Reconstruction Loss)** 로,  
  디코더가 입력 $x$ 를 얼마나 잘 복원하는지를 측정한다.  
- 두 번째 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은  
  **정규화 손실(Regularization Loss)** 로,  
  인코더가 생성하는 잠재공간 분포 $q_\phi(z \mid x)$ 가  
  사전분포 $p(z)$ 와 얼마나 다른지를 측정한다.

#### 2. 전체 데이터셋에 대한 손실  
- 실제 학습에서는 한 개의 샘플이 아니라  
  데이터셋 전체에 대해 평균 손실을 계산한다.  
- 따라서 손실 함수는 데이터 분포 $p_{\text{data}}(x)$ 에 대한  
  기대값으로 확장된다:

  $$
  \mathbb{E}_{x \sim p_{\text{data}}(x)}[\mathcal{L}_{\theta, \phi}(x)]
  $$

- 이 기댓값은 실제로는 **미니배치 평균(mini-batch mean)** 으로 근사되어  
  학습 중에 최적화된다.

#### 3. 전체 목적함수의 의미  
- 최종 손실 $\mathcal{L}_{\theta, \phi}$ 는  
  “데이터 복원 성능”과 “잠재공간의 규칙성” 사이의  
  균형을 맞추는 역할을 한다.  
- 즉,  
  인코더가 잠재공간에서 의미 있는 구조를 학습하도록 하면서,  
  동시에 디코더가 입력을 잘 복원할 수 있도록  
  두 항을 함께 최소화하는 것이 VAE 학습의 핵심이다.

---

## p28. 추론 (Inference)

<img src="/assets/img/lecture/probstat/9/image_25.png" alt="image" width="720px">

**추론 (생성):**

- 잠재 변수 $z$ 를 다음 분포에서 샘플링함:  

  $$
  z \sim \mathcal{N}(0, I)
  $$

- 디코더 네트워크에 의해 $z$ 를 매핑함:  

  $$
  g_\theta(z)
  $$

**디코더(Decoder)는 한 분포에서 다른 분포로의 결정적 매핑(deterministic mapping)이다.**

---

## p28. 추론 (Inference)

<img src="/assets/img/lecture/probstat/9/image_24.png" alt="image" width="800px">

**추론 (생성, Inference / Generation):**

- 잠재 변수 $z$ 를 다음 분포에서 샘플링함:  
  $$
  z \sim \mathcal{N}(0, I)
  $$

- 디코더 네트워크에 의해 $z$ 를 매핑함:  
  $$
  g_\theta(z)
  $$

**디코더(Decoder)는 한 분포에서 다른 분포로의 결정적 매핑(deterministic mapping)이다.**

---

### 보충 설명

#### 1. 추론(생성)의 단계
- 학습이 완료된 후에는 **인코더는 사용하지 않는다.**  
  대신 잠재공간(latent space)에서 직접 샘플링을 수행한다.
- $z$ 를 표준 정규분포 $\mathcal{N}(0, I)$ 에서 샘플링하는 이유는,  
  학습 과정에서 **KL 발산 항**이 $q_\phi(z \mid x)$ 와 $p(z)$ 가  
  최대한 유사해지도록 학습되었기 때문이다.  
  따라서 학습이 끝난 시점에서 $p(z)$ 에서 샘플링하는 것은  
  실제 데이터 공간에서 의미 있는 위치를 선택하는 것과 같다.
- 이렇게 얻은 $z$ 를 **디코더(Decoder)** $g_\theta(z)$ 에 통과시키면,  
  학습 데이터와 유사한 새로운 샘플(예: 이미지, 음성, 텍스트 등)을 생성할 수 있다.

#### 2. 학습 전과 학습 후의 차이
- **학습 전:**  
  $\mathcal{N}(0, I)$ 는 단순한 랜덤 노이즈 공간이며,  
  그 안의 점 $z$ 들은 아무런 의미가 없다.
- **학습 후:**  
  인코더 $q_\phi(z \mid x)$ 가 데이터를 잠재공간으로  
  **의미 있게 매핑(mapping)** 하면서,  
  KL 발산 항이 이 공간을 정규분포 형태로 **정렬(alignment)** 시킨다.  
  따라서 $\mathcal{N}(0, I)$ 상의 점들은  
  이제 실제 데이터의 **의미적 표현(semantic latent code)** 을 반영하게 된다.
- 즉,  
  학습 전에는 의미 없던 정규분포의 점들이,  
  학습 후에는 인코더의 학습 덕분에  
  “데이터의 구조를 보존하는 의미 있는 좌표들”로 바뀌는 것이다.

#### 3. 디코더의 역할
- 디코더는 **결정적 함수(deterministic function)** 로,  
  잠재 변수 $z$ 를 입력받아 출력 공간의 확률 분포 $p_\theta(x \mid z)$  
  혹은 그 평균값(예측값)을 생성한다.  
- 같은 $z$ 가 입력되면 항상 동일한 $x'$ 를 생성하지만,  
  $z$ 자체가 확률적으로 샘플링되므로  
  전체 모델은 여전히 **확률적 생성 모델(probabilistic generative model)** 의 성격을 가진다.

#### 4. 요약
- 학습 단계에서는  
  인코더와 디코더가 함께 작동하여  
  데이터의 잠재 구조를 정규분포 공간으로 매핑한다.  
- 학습이 완료된 후에는  
  **정규분포 $\mathcal{N}(0, I)$ 자체가 의미 있는 잠재공간이 되므로**,  
  인코더 없이도 디코더만으로 새로운 샘플을 생성할 수 있다.

---

## p29. 개요 (Overview)

- 인코더(encoder): 데이터 분포를 잠재 분포로 매핑함  
  (maps data distribution to latent distribution)

- 디코더(decoder): 잠재 분포를 데이터 분포로 매핑함  
  (maps latent distribution to data distribution)

<img src="/assets/img/lecture/probstat/9/image_26.png" alt="image" width="800px">

---

### 보충 설명

#### 1. 전체 구조의 흐름
- 입력 데이터 $x$ 는 **인코더(encoder)** $q_\phi(z \mid x)$ 를 거쳐  
  잠재 변수 $z$ 의 확률분포로 변환된다.  
  이 분포는 데이터의 **내재된 구조나 의미적 특성(semantic feature)** 을  
  요약하여 표현한 것이다.

- 인코더를 통해 얻은 $z$ 는  
  **잠재 공간(latent space)** 상에서의 점이며,  
  이 공간 전체가 표준 정규분포 $\mathcal{N}(0, I)$ 형태로  
  정렬되도록 학습된다.

- 이후, **디코더(decoder)** $p_\theta(x \mid z)$ 는  
  이 잠재 변수 $z$ 로부터 원래 데이터 공간의 분포를 복원(reconstruction)한다.  
  즉, $z$ 가 주어졌을 때 그에 대응하는 $x'$ 를 생성하는 과정을 학습한다.

#### 2. 인코더와 디코더의 관계
- 인코더는 **데이터 분포 $p_{\text{data}}(x)$** 를  
  **잠재 분포 $q_\phi(z)$** 로 압축하는 역할을 한다.  
  이는 고차원 데이터(예: 이미지, 음성, 언어 등)를  
  의미적으로 요약된 표현으로 변환하는 과정이다.

- 디코더는 이 잠재 분포를 다시 **데이터 분포 $p_\theta(x)$** 로 확장하여  
  원본 데이터에 가까운 샘플을 생성한다.  
  이 과정을 통해 **생성 모델(generative model)** 로서의 기능이 완성된다.

#### 3. 학습의 목표
- 학습 과정에서 인코더와 디코더는  
  **상호 보완적인 방향으로 최적화된다.**
  - 인코더: $x \rightarrow z$  
  - 디코더: $z \rightarrow x'$
- 두 네트워크가 함께 작동하여  
  데이터의 분포 $p_{\text{data}}(x)$ 와  
  모델의 분포 $p_\theta(x)$ 가 최대한 유사해지도록 학습된다.

#### 4. 요약적 해석
- 인코더는 “**데이터 공간에서 잠재 공간으로의 압축(encoding)**”을 담당하고,  
- 디코더는 “**잠재 공간에서 데이터 공간으로의 복원(decoding)**”을 담당한다.  
- 결국 VAE는  
  **데이터 ↔ 잠재 표현 ↔ 데이터**  
  로 이어지는 **양방향 확률적 매핑(probabilistic bidirectional mapping)** 을 학습한다.

---

## p30. 변분 오토인코더 (Variational Autoencoder)

- 인코딩된 잠재 분포(encoded latent distribution):

  $$
  q_\phi(z)
  =
  \int_x q_\phi(z \mid x) \, p_{\text{data}}(x) \, dx
  $$

<img src="/assets/img/lecture/probstat/9/image_27.png" alt="image" width="800px">

---

### 보충 설명

#### 1. 인코딩된 잠재 분포의 의미
- $q_\phi(z)$ 는 **전체 데이터 분포 $p_{\text{data}}(x)$** 에 대해  
  인코더가 생성한 **잠재 변수 분포들의 평균적 형태**를 나타낸다.  
  즉, 각 데이터 $x$ 가 인코더를 거쳐 $z$ 로 변환될 때,  
  그 모든 $z$ 들이 어떤 분포를 형성하는지를 나타내는 것이다.  
  이 식은 “데이터 분포에 대한 적분”을 통해 표현된다.

- 따라서  

  $$
  q_\phi(z)
  =
  \mathbb{E}_{x \sim p_{\text{data}}(x)}[\,q_\phi(z \mid x)\,]
  $$

  로도 해석할 수 있으며,  
  이는 **인코더가 전체 데이터셋을 통해 형성한 잠재공간의 전역 구조(global structure)** 를 의미한다.

#### 2. $p(z)$ 와 $q_\phi(z)$ 의 관계
- $p(z)$ 는 우리가 **사전에 정의한 단순한 분포(prior)** 로,  
  보통 $\mathcal{N}(0, I)$ 로 설정된다.  
  이는 학습의 기준점(regularization target) 역할을 한다.

- 반면 $q_\phi(z)$ 는 실제 데이터에서 인코더가 추정한  
  **복잡한 잠재 분포**이다.  
  학습 초기에 $q_\phi(z)$ 는 $p(z)$ 와 전혀 다를 수 있지만,  
  학습이 진행되면서 **KL 발산 항 $D_{KL}(q_\phi(z) \| p(z))$** 을 최소화하도록  
  점점 $p(z)$ 에 근접하게 된다.

- 즉, KL 발산 항은 “인코더가 학습 데이터로부터 만들어내는 잠재 분포 $q_\phi(z)$”가  
  “사전에 정의된 기준 분포 $p(z)$”와 유사해지도록 만드는 정규화 제약이다.

#### 3. 전체 흐름의 의미
1. 데이터 분포 $p_{\text{data}}(x)$ 에서 샘플된 $x$ 가  
   인코더를 통해 $q_\phi(z \mid x)$ 로 변환된다.
2. 모든 $x$ 에 대해 이러한 변환을 통합하면  
   전체 잠재 공간의 분포 $q_\phi(z)$ 가 형성된다.
3. 이 $q_\phi(z)$ 가 사전 분포 $p(z)$ 와 유사해지도록  
   KL 발산 항이 학습을 유도한다.
4. 이후 디코더 $p_\theta(x \mid z)$ 가  
   이 잠재 변수들로부터 원래 데이터 분포 $p_\theta(x)$ 를 복원한다.

#### 4. 직관적 해석
- 인코더는 실제 데이터 분포 $p_{\text{data}}(x)$ 를  
  **잠재 변수 분포 $q_\phi(z)$** 로 변환하며,  
  KL 발산 항은 이를 **정규분포 $p(z)$** 로 정렬한다.  
- 이 과정을 통해, 복잡한 데이터의 구조가  
  단순하고 해석 가능한 잠재공간으로 매핑된다.  
- 결과적으로 VAE는  
  “데이터 분포 → 인코더 → 잠재공간 정규화 → 디코더 → 복원된 데이터 분포”  
  라는 완전한 확률적 경로를 학습한다.

---

## p31. 예시 그림 (Example Illustration)

<img src="/assets/img/lecture/probstat/9/image_28.png" alt="image" width="720px">

- 각 데이터 포인트 $x_1$, $x_2$, $x_3$ 는  
  인코더 $q_\phi(z \mid x)$ 를 통해  
  잠재공간(latent space)의 분포 $q_\phi(z \mid x_i)$ 로 매핑된다.

- 각 분포 $q_\phi(z \mid x_i)$ 는  
  잠재공간 내에서 서로 다른 위치에  
  데이터의 의미적 특징을 반영하여 분포하게 된다.

- 디코더는 각 $z$ 로부터 대응되는  
  **재구성된 데이터(generated data)** 를 복원한다.

---

### 보충 설명

#### 1. 데이터 포인트와 잠재 분포의 대응 관계
- 원래의 데이터 포인트 $x_i$ 들은  
  인코더를 통과하면서 각각의 잠재 분포 $q_\phi(z \mid x_i)$ 로 표현된다.  
  이 분포들은 데이터의 **고유한 특성(feature)** 을 반영하며,  
  비슷한 데이터일수록 잠재공간에서 가까운 위치를 갖게 된다.
  
- 예를 들어, $x_1$, $x_2$, $x_3$ 가 서로 유사한 클래스에 속하면,  
  이들의 잠재 분포 $q_\phi(z \mid x_i)$ 들은  
  잠재공간에서 서로 겹치거나 인접한 영역에 위치하게 된다.

#### 2. 생성 과정의 시각적 의미
- 각 $q_\phi(z \mid x_i)$ 에서 샘플링된 $z$ 는  
  디코더 $p_\theta(x \mid z)$ 를 통해  
  대응되는 재구성된 데이터 $\hat{x}_i$ 를 생성한다.
  
- 이 과정을 통해 VAE는  
  “**입력 데이터 → 잠재공간 표현 → 데이터 복원**”의  
  확률적 생성 경로를 학습한다.

#### 3. 이상치 탐지(Anomaly Detection)와의 연관
- VAE는 데이터의 분포를 학습하기 때문에,  
  **정상 데이터(normal data)** 는  
  잠재공간 내에서 $p(z)$ 근처에 잘 정렬된다.  
- 반면 **이상치(anomaly)** 는  
  학습된 분포 $q_\phi(z)$ 와 잘 맞지 않아  
  낮은 복원 확률(reconstruction likelihood)을 가지게 된다.
- 따라서 VAE는  
  입력 데이터의 복원 오차나 잠재 확률을 이용해  
  **이상치 탐지(Anomaly Detection)** 에 활용될 수 있다.

#### 4. 데이터 정화(Purification) 관점
- 입력 데이터가 노이즈를 포함하거나 왜곡되었더라도,  
  인코더를 통해 잠재공간으로 투영되고  
  디코더를 통해 복원될 때,  
  학습된 데이터 분포에 맞춰 **정제(purify)** 된 형태로  
  출력될 수 있다.  
- 즉, VAE는 단순히 생성 모델일 뿐 아니라  
  **데이터 복원 및 정화 모델**로도 작동할 수 있다.

---

## p32. MNIST의 2차원 잠재공간 (2D Latent Space on MNIST)

<img src="/assets/img/lecture/probstat/9/image_29.png" alt="image" width="800px">

왼쪽: 각 숫자 클래스(0~9)가 인코딩된 잠재변수 공간의 분포  
오른쪽: 잠재공간 상의 위치에 따라 디코더가 생성한 숫자 이미지

---

### 보충 설명

#### 1. 잠재공간의 구조
- 이 그림은 **MNIST 데이터셋**을 이용해  
  VAE를 학습한 후, 잠재공간(latent space)을  
  **2차원으로 시각화한 결과**이다.

- 각 점은 인코더 $q_\phi(z \mid x)$ 를 통해 얻어진  
  잠재벡터 $z$ 를 나타내며,  
  점의 색깔은 해당 데이터의 실제 숫자 레이블(0~9)에 대응된다.

- 서로 유사한 숫자(예: 6과 0, 4와 9)는  
  **잠재공간에서 인접한 영역**에 분포하며,  
  클래스 간의 경계도 매끄럽게 이어진다.

#### 2. 연속적(latent-continuous)인 공간의 특징
- 잠재공간이 2차원으로 제한되어 있음에도 불구하고,  
  각 숫자 클래스는 **클러스터 형태로 잘 구분**되며  
  그 사이 구간에서도 **연속적인 변형(smooth transition)** 이 가능하다.

- 오른쪽 그림에서 볼 수 있듯이,  
  잠재공간의 한 점에서 인접한 점으로 이동할 때  
  디코더가 생성하는 숫자의 형태가  
  점진적으로 변하는 것을 확인할 수 있다.  
  예를 들어, “6”의 형태가 조금씩 변화하여 “0” 또는 “4”로  
  자연스럽게 이어지는 모습이다.

- 이러한 연속성은  
  **unconditional VAE** (라벨 정보를 사용하지 않는 모델)에서도  
  잠재공간이 구조적으로 정렬되도록 학습되었음을 의미한다.

#### 3. 잠재공간이 의미를 갖게 되는 이유
- 학습 전의 $z \sim \mathcal{N}(0, I)$ 샘플들은  
  단순히 무작위 가우시안 분포에 불과하다.  
- 그러나 학습이 진행되면,  
  인코더 $q_\phi(z \mid x)$ 가 데이터의 구조를 반영하여  
  $p(z)$ 공간에 의미 있는 좌표계를 형성한다.  
- 그 결과, 잠재공간의 각 영역은  
  **특정 숫자 형태나 패턴에 해당하는 의미적 지역(semantic region)** 으로 변환된다.

#### 4. 응용: 이상치 탐지 및 데이터 보간
- 잠재공간이 이렇게 구조적으로 정렬되어 있기 때문에,  
  **이상치 탐지(Anomaly Detection)** 나  
  **데이터 보간(interpolation)** 같은 응용이 가능하다.
- 예를 들어, 학습된 분포 영역 바깥의 $z$ 에서 생성된 샘플은  
  **비정상적이거나 왜곡된 데이터**가 되며,  
  이는 VAE가 학습 데이터 분포를 벗어난 입력을 탐지하는 근거로 활용된다.

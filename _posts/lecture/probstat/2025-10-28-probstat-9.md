---
layout: post
title: "[확률과 통계] 9주차"
date: 2025-10-28 23:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. 생성 모델의 일반 개념 (General Concept of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_1.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이제 화면 보시면서 얘기를 하시는데  
> 그러면 이제 생성 모델이 무엇이냐, 이런 거를 먼저 조금 생각해 보면 좋을 것 같아요.  
> 예를 들어 텍스트가 주어지고, 그 텍스트에 대해서 어떤 shape이나 이미지를 생성하는  
> 그런 AI 모델을 떠올려 보면, 여기서 생성 모델이라는 것은  
> 결국 무언가를 생성하는 모델이기 때문에 생성자가 필요하잖아요.  
> 그래서 그 생성자를 보통 제너레이터라고 부릅니다.  
> 제네리티브 모델이기 때문에요.  
> 
> 그리고 이 제너레이터에는 크게 두 가지 인풋이 들어가는데요.  
> 첫 번째 인풋은 컨디션 인풋입니다.  
> 예를 들어 텍스트-이미지 생성이라고 한다면  
> 텍스트 청크들, 토큰의 시리즈, 혹은 원핫 벡터로 표현된 어떤 컨셉들  
> 그런 것들이 첫 번째 인풋으로 들어가게 됩니다.  
> 
> 그리고 두 번째 인풋은 랜덤성입니다. 랜덤성.  
> 제네리티브 모델이라는 것이 확률·통계에서 아주 잘 정의된 학문인데  
> 거기서 가장 중요한 것은 인풋으로 랜덤 배리어블이 반드시 들어가야 한다는 점입니다.  
> 
> 그러면 이 랜덤성이 무엇을 표현하느냐 하면,  
> 랜덤 배리어블, 즉 주사위처럼 표현된 랜덤성이 들어갔을 때  
> Output Distribution, 이미지 분포의 여러 가지 surface를  
> 다양하게 표현할 수 있도록 만들어 준다는 겁니다.  
> 
> 인풋이 Bird라고 했을 때  
> 항상 똑같은 이미지만 출력되면 안 되잖아요.  
> Bird에 대한 다양한 variation이 나와야 하기 때문에  
> 그 랜덤성을 표현하기 위해 랜덤 배리어블이 들어가는 것입니다.  
> 
> 그래서 현대 생성 모델들은, 아주 컨셉추얼하게 간소화해서 보면  
> 대부분 이런 파이프라인 구조를 가지고 있다고 생각하시면 될 것 같습니다.  

---

## p3. 생성 모델의 확률적 표현 (Probabilistic Representation of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_2.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 그러면 이제 이런 걸 한 번 생각해 볼게요.  
> Bird라고 했을 때, 그 Bird의 어떤 latent information을 통해  
> 새의 각각의 모양들을 어떻게 표현할 수 있을까 하는 부분이 핵심입니다.  
> 
> 랜덤 배리어블, 즉 여러 개의 주사위가 있다고 할 때  
> 이 주사위 각각이 무엇을 의미하느냐를 생각해 보면  
> 결국 그 랜덤성의 개별 feature들이  
> 생성되는 이미지의 어떤 요소들을 결정하게 된다고 볼 수 있어요.  
> 
> 예를 들어 첫 번째 주사위는 색을 결정하는 것,  
> 두 번째 주사위는 각 컴포넌트들이 어떻게 결합되는지,  
> 혹은 각도를 결정하는 것,  
> 또 다른 주사위는 새의 크기를 결정하는 것처럼  
> 여러 가지 요소들을 statistical하게 결정하는 역할을 하게 됩니다.  
> 
> 이런 식으로 표현한다는 것 자체가 무엇을 의미하냐 하면  
> 결국 high dimensional한 랜덤 배리어블이 인풋으로 들어간다는 겁니다.  
> 앞에서 배웠던 multivariate Gaussian 랜덤 배리어블이  
> 이러한 랜덤성의 입력으로 들어간다는 것이죠.  
> 
> 재미있는 점은 multivariate Gaussian distribution 자체는  
> semantic을 가지고 있지 않다는 겁니다.  
> 각 축이 “색을 표현해라”, “각도를 표현해라” 하고  
> 직접적으로 설정해 준 적이 없어요.  
> 
> 그런데 생성 모델을 학습시키다 보면  
> 비록 우리가 명확하게 “첫 번째 feature는 색이다”라고 지정하지 않았어도  
> 결과적으로 latent space가 semantic하게 분리되는 현상이 나타납니다.  
> 나중에 실습에서 보시겠지만  
> 학습이 진행되면 high dimensional space 안에서  
> 이러한 feature들이 자연스럽게 association이 되는 거죠.  
> 
> 이런 점들이 generative 모델의 아주 흥미로운 특성 중 하나이고  
> 실습을 통해 더 자세히 살펴보도록 하겠습니다.  

---

## p4. 데이터 생성기의 분류 (Categorization of Data Generators)  

두 가지 접근 방식이 있다.  

1. **직접 접근(Direct approach)**: 데이터를 직접 생성하는 함수를 학습한다.  
(혼동스럽게도, 때때로 “암묵적 생성 모델(implicit generative model)”이라고도 불린다.)

   $$
   G : \mathcal{Z} \rightarrow \mathcal{X}
   $$

2. **간접 접근(Indirect approach)**: 데이터를 평가(score)하는 함수를 학습하고,  
   이 함수 아래에서 점수가 높은 지점을 찾아 데이터를 생성한다.  

   $$
   E : \mathcal{X} \rightarrow \mathbb{R}
   $$

> **강의 내용**  
> 
> 그래서 이제 Data Generator에는 크게 두 가지 방법이 있을 수 있습니다.  
> 하나는 Direct Approach입니다.  
> 앞에서 이야기했던 GAN 같은 모델이  
> 이 Direct Approach를 사용하는 대표적인 예라고 볼 수 있어요.  
> 
> 이게 무슨 뜻이냐면,  
> Random Variable을 인풋으로 넣었을 때  
> 그 Random Variable을 기반으로  
> Output 데이터를 직접적으로 생성해 주는 방식의 모델들을  
> Direct Approach라고 부릅니다.  
> 
> 그리고 또 하나는 Indirect Approach입니다.  
> 전형적으로 Diffusion 모델 같은 것들이  
> 이 Indirect Approach에 해당됩니다.  
> 
> 이런 모델들은  
> Neural Network의 인풋에 Random Variable을 넣으면  
> 곧바로 결과가 나오는 구조가 아니라,  
> 그 앞뒤로 추가적인 파이프라인이 하나 더 존재합니다.  
> 그리고 그 파이프라인의 한 컴포넌트로 Neural Network가 작동하는 형태죠.  
> 
> 보통 이런 구조들은  
> Energy Function이라든지 Score Function이라든지  
> 그런 함수들을 Neural Network로 모델링하고,  
> 그 함수가 “데이터가 잘 생성되었는가, 안 되었는가”를 평가하면서  
> 점진적으로 데이터를 생성해 나가는 방식입니다.  
> 
> 아까 언급했던 Diffusion 모델이나  
> Normalizing Flows 모델들이 여기에 포함된다고 보시면 됩니다.  
> 
> 오늘 배울 VAE는  
> 이 Direct Approach와 Indirect Approach의 중간 정도에 위치한 모델이라고 볼 수 있어요.  
> 그래도 조금 더 Direct Approach에 가깝다고 보는 게 맞을 것 같습니다.  

---

## p5. 직접 접근(Direct Approach)의 학습과 샘플링 과정  

<img src="/assets/img/lecture/probstat/9/image_3.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 네, 그래서 크게 보면  
> 데이터 생성을 위한 전체 파이프라인을 이렇게 이해하시면 될 것 같습니다.  
> 
> 예를 들어 사람 얼굴을 생성한다고 하면,  
> 먼저 왼쪽과 같은 사람 얼굴 이미지를 아주 많이 모아놓은  
> 거대한 데이터셋이 준비되어 있어야 합니다.  
> 그리고 그 데이터셋 위에서 learner가 존재해서  
> 옵티멀한 파라미터를 찾게 되고,  
> 그 파라미터가 결국 Neural Network,  
> 즉 앞서 말했던 Generator의 파라미터로 작용하게 됩니다.  
> 
> 이런 과정이 바로 트레이닝 과정이고,  
> 반대로 샘플링을 하는 시점은 Inference Time,  
> 테스트 타임이라고 부르기도 하죠.  
> 
> 샘플링할 때는  
> Gaussian Random Variable을 Generator에 주입해서  
> 우리가 원하는 이미지를 생성해 내기를 기대하는 것입니다.  
> 
> 그래서 대부분의 생성 모델들은  
> 이처럼 트레이닝 타임과 테스트 타임이  
> 명확하게 구분된 형태의 구조를 가지고 있습니다.  
> 
> 반면 앞에서 잠깐 보았던 classification 모델 같은 경우는  
> 이런 스킴을 사용하지 않습니다.  
> 인풋과 아웃풋의 형태는 동일하게 유지되고,  
> 트레이닝할 때와 테스트할 때의 데이터 모양만 다를 뿐  
> 파이프라인 자체가 크게 나뉘어 있지 않죠.  
> 
> 하지만 생성 모델에서는  
> 트레이닝 과정과 샘플링(또는 Inference) 과정이  
> 이렇게 완전히 분리된 파이프라인으로 구성된다는 점을  
> 꼭 알고 계셔야 합니다.  

---

## p6. 간접 접근 (Indirect Approach)  

<img src="/assets/img/lecture/probstat/9/image_4.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 네, 그래서 그 Indirect Approach라는 것들을  
> 잠깐 살펴보자면 이렇습니다.  
> 
> 데이터가 존재하고, 또 learner가 존재해서  
> Score Function을 학습하게 되는데  
> 이 Score Function이라는 것이  
> 아까 말씀드렸던 Energy라든지 Likelihood라든지  
> 그런 개념들을 스코어링해 주는 함수라고 보시면 됩니다.  
> 
> 학습자, 즉 학습하는 어떤 트레이닝 methodology가 존재해서  
> 이 Score Function의 값을 높인다든지,  
> 혹은 낮추는 방향으로 학습을 하게 되고  
> 그렇게 간접적으로 스코어링을 하게 되는 방식이죠.  
> 
> 그리고 이렇게 스코어링이 최적으로 된  
> 어떤 데이터의 위치들이  
> 실제로 샘플링을 했을 때 생성되는 데이터라고  
> 이해하시면 될 것 같습니다.  
> 
> 앞에서 봤듯이  
> 트레이닝과 샘플링이 이렇게 구분되어 있죠.  
> 트레이닝에서는 Score Function,  
> 즉 Score를 높이거나 낮추는 과정이고  
> 샘플링에서는 그렇게 학습된 learner의 파라미터를 사용해서  
> MCMC라든지 그런 알고리즘을 통해 실제로 샘플링을 하게 됩니다.  
> 
> 지금 이 파이프라인을 보면  
> 아마 바로 이해가 잘 안 되실 수도 있는데요.  
> 뒤에서 Normalizing Flow와 Diffusion Model을 배우시면  
> 이 구조가 어떤 의미인지 완벽하게 이해가 되실 겁니다.  
> 
> 오늘 강의는 이 부분에 초점을 맞추는 것은 아니고  
> 강의가 계속 진행되면서 자연스럽게 다시 등장할 것 같습니다.  

---

## p7. 생성 모델 (Generative Models)  

목표는 학습 데이터를 그대로 복제하는 것이 아니라,  
**새로운(new)** 데이터를 만드는 것이다.  
그 데이터는 **현실적인(realistic)** 데이터여야 하며,  
실제 데이터의 **본질적인 속성(essential properties)**을 포착해야 한다.  

이것을 정량화하는 한 가지 방법은  
모델 하에서의 **테스트 데이터의 가능도(likelihood)**를 이용하는 것이다.  
(학습 데이터를 기억하는 모델은,  
분류기(classifier)가 과적합(overfit)되는 것과  
정확히 같은 의미에서 과적합된 것이다.)  

$$
\{x_{\text{test}}^{(i)}\}_{i=1}^{N}, \quad x_{\text{test}}^{(i)} \sim p_{\text{data}}
$$  

$$
\text{generalization error} = \sum_i \log p_\theta (x_{\text{test}}^{(i)})
$$  

> **강의 내용**  
> 
> 그럼 이제 생성 모델의 목표는 무엇이냐라고 한다면  
> 여러분들이 헷갈릴 수도 있을 것 같아서  
> 명확하게 해야 될 것 같아요.  
> 우리는 사실 트레이닝 데이터를 가지고  
> 트레이닝 데이터를 완벽하게 똑같이 만드는 게 목표가 아닙니다.  
> 트레이닝 데이터에 어떤 디스트리뷰션이 생겼다고 했을 때  
> 그 디스트리뷰션과 닮은 애를 만들어야 해요.  
> 그게 목적입니다.  
> 
> 만약에 트레이닝 데이터를 완벽하게 똑같은 애를 만든다고 가정을 하면  
> GPT 같은 것도 Generative Model, Generative AI 기술의 하나라고 볼 수 있는데  
> 생성할 때마다 데이터셋과 완벽하게 align된 데이터들이 생성이 되겠죠.  
> 완전히 똑같은 트레이닝 데이터를 복원을 하는 게 목적이라고 한다면요.  
> 
> 근데 아시다시피 새로운 가치를, extrapolation이 되는 게  
> 현대 Generative AI 모델들의 큰 특징점이거든요.  
> 새로운 정보가 창출돼요.  
> 많이 잘 창출되지는 않는데요.  
> 그런데 그 창출된 지식이  
> 현실의 physical knowledge들과 위반이 됐을 때  
> 그걸 hallucination이라고 하죠.  
> 그 두 가지 사이에 항상 줄다리기가 있습니다.  
> 
> 그래서 extrapolation을 하기 위해서는  
> 트레이닝 데이터에 완벽하게 매칭을 하는 게 아니라  
> realistic하고 world knowledge를 잘 반영할 수 있는  
> 새로운 데이터를 만드는 것,  
> 그런 것들이 생성 모델의 목표라고 보시면 될 것 같아요.  
> 
> 그래서 이제 그럼 이걸 어떻게 quantification 하느냐.  
> 이게 language 모델 같은 경우  
> 어떻게 evaluation 하느냐, 어떻게 평가를 하느냐와  
> 비슷한 느낌인데  
> 사실 똑같은 철학적인 목적, 철학적인 배경이 있다고  
> 생각하면 될 것 같아요.  
> 
> 이제 test data를 생각을 하는 거죠.  
> test data에 대해서  
> 저기 보면 $ \log p_\theta $라고 얘기하는데  
> 이게 앞에서 배웠던 log-likelihood 개념에서 나온 notation이죠.  
> $p_\theta$는 여기서 statistical model이 되는 거고요.  
> 
> 그래서 트레이닝을 훈련한 다음에  
> test data에다가 우리가 만들어 놓은  
> statistical model에 대한 likelihood estimation을 했을 때  
> 얼마나 많은 에러가 생기느냐,  
> 이게 generalization 에러가 얼마나 생기느냐입니다.  
> 
> 이게 크면 클수록  
> 아까 말씀드렸던 extrapolation과 hallucination 사이에 있는  
> 그런 것들을 표현하는 거다  
> 그렇게 생각하시면 될 것 같고요.  
> 
> generalization 에러가 크다고  
> 무조건 나쁜 것도 아니고  
> generalization 에러가 0이면  
> 트레이닝 데이터가 똑같은 거거든요, test data는.  
> 또 그게 좋은 것도 아니고요.  
> 요즘엔 갑론을박이 있는 것 같습니다.  
> extrapolation에 대한 철학적 정의가 어떻게 돼야 되는지,  
> 새로운 정보의 창출이 어떻게 정의가 돼야 되는지  
> 아직도 말이 많은 것 같습니다.  
> 
> 그래서 language model을 평가하기 위한  
> 최적의 metric이 무엇이냐,  
> 이런 것도 다 거기서 그런 생각에서 오는 것 같고요.  
> 그래서 이런 느낌이고.  

---

## p8. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_5.png" alt="image" width="600px">

> **강의 내용**  
> 
> 이제 Density Based Model을 한번 생각을 해보자면,  
> 트레이닝 데이터가 N개가 이렇게 주어진다고 했을 때  
> Probability Density의 특징이  
> sum 했을 때 1이라고 했었잖아요.  
> normalization equation을 따라가지고.     

---

## p9. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_6.png" alt="image" width="600px">

> **강의 내용**  
> 
> 트레이닝 데이터가 이렇게 있을 때,  
> 이건 이제 discrete한 케이스라서 봉들이 생길 텐데  
> 트레이닝 데이터의 Y축에 해당하는 값들을  
> 다 summation 했을 때 1이 돼야 하는 조건이 있는  
> 그런 것들을 한번 생각해볼 수 있을 것 같아요.  

---

## p10. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_6_1.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 데이터가 있는 곳에서는  
> mass가 표현되어야 되니까  
> 데이터가 있는 곳에서는 높이가 좀 높게 평가가 될 것이고  
> 데이터가 없는 곳에서는 높이가 낮게 평가가 돼야겠죠.  
> 
> 그래서 Density Based Model들,  
> Energy Model, Diffusion Model들 같은 경우는  
> 학습을 한 다음 실제로 density를 이렇게 estimation 해보면  
> 이런 모양이 많이 나옵니다.  
> 
> 이런 모양이 잘 나오면  
> 전문가가 봤을 때  
> 트레이닝이 잘 됐다고 판단하는 경우도 많습니다.  

---

## p11. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_7.png" alt="image" width="800px">

$$
\begin{aligned}
p_\theta^* 
&= \arg \min_{p_\theta} \text{KL}(p_{\text{data}}, p_\theta) \\
&= \arg \min_{p_\theta} \mathbb{E}_{x \sim p_{\text{data}}} 
   \left[- \log \frac{p_\theta(x)}{p_{\text{data}}(x)} \right] \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ] 
   - \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_{\text{data}}(x) ]  
   \quad\quad\quad \text{(max likelihood)} \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ]
   \quad\quad\quad \text{(두 번째 항은 } p_\theta \text{에 의존하지 않기 때문에 생략)} \\
&\approx \arg \max_{p_\theta} 
   \frac{1}{N} \sum_{i=1}^{N} \log p_\theta(x^{(i)})
\end{aligned}
$$  

> **강의 내용**  
> 
> 이제 이거죠. 이 내용 보시고  
> 꼭 처음 보시는 내용처럼 생각하시면 안 돼요.  
> 시험에도 나왔고 앞에서 많이 다뤘습니다.  
> 
> 그래서 Maximum Likelihood Estimation,  
> $p_{\theta^\*}$, 최적의 Probability Distribution은  
> KL divergence를 줄이는 거였었고,  
> 계산을 쭉 따라서 constant 항이 나오고,  
> 그리고 $p_{\text{data}}$와 $p_\theta$의 관계들,  
> log 함수를 통한 decompose 이런 것들을 하다 보면  
> 맨 마지막에 $\arg\max \log p_\theta$를 하는 것이 됩니다.  
> 
> 이걸 물리적으로 보면  
> 위에서 그림으로 표현한 것처럼  
> 데이터가 있는 데는 확률을 높이고,  
> 데이터가 없는 데는 확률을 낮추는 형식으로  
> 표현된다고 보시면 될 것 같아요.  
> 
> 그래서 우리가 앞에 수학적으로만 배웠는데  
> 이런 물리적인 성질을 가지고  
> Maximum Likelihood를 정의한 것이고,  
> 이런 물리적인 특징을 사용하는 것이  
> 생성 모델의 학습 방법입니다.  
> 이렇게 생각하시면 될 것 같습니다.  
> 
> (질문) 회색의 실선이 $p_\theta$고  
> 점들이 $p_{\text{data}}$라고 보면 될까요?  
> 점에 녹색 화살표가 있는 게 $p_{\text{data}}$고?  
> 
> (답변) 아, 왼쪽 그림 말씀하시는 거죠? 예.  
> 알고리즘을 통해 maximization을 하다 보면  
> 예를 들어 왼쪽에 어떤 회색의 영역이 있었는데  
> maximization을 취하다 보면,  
> optimization이라는 건 한 번에 딱 되는 게 아니라  
> 시간을 걸쳐 iteratively 되는 거거든요.  
> 그래서 점진적으로  
> mass가 존재하는 데는 초록색을 통해 확률이 높아지고,  
> mass가 없는 데는 빨간색으로 표현해서  
> 확률이 낮아지고,  
> 이렇게 된다는 거죠.  
> 
> (질문) 그럼 오른쪽 그림에서  
> 회색이 $p_\theta$이고,  
> 녹색과 빨간색이 있는 그 영역이  
> $p_{\text{data}}$라고 보면 될까요?  
> 
> (답변) 그게 업데이트된 영역이에요.  
> $p_{\text{data}}$는 X축에 있고요.  
> 그래서 그렇게 생각하시면 될 것 같고.      

---

## p12. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

<img src="/assets/img/lecture/probstat/9/image_8.png" alt="image" width="480px">

> **강의 내용**  
> 
> 여기 그림을 보면,  
> 우리가 가정하는 데이터 생성 과정이 이렇게 표현되어 있습니다.  
> 
> 먼저 $z$는 latent variable이고  
> pose, size, color, breed 같은 정보들을  
> 사람이 직접 정의하지 않았더라도  
> 학습 과정에서 자연스럽게 mapping되는  
> 그런 특징들을 담고 있습니다.  
> 
> 그리고 $x$는 observed variable,  
> 즉 우리가 실제 데이터셋 안에서 관찰하는  
> 이미지, 비디오, 오디오 같은 데이터입니다.  
> 
> 이 latent variable $z$가  
> generator를 통해 $x$로 mapping되는 구조를 갖고 있고,  
> world model, physics model, renderer 같은 개념들을  
> 이 프레임에 모두 포함시킬 수 있습니다.  
> 
> 그래서 현대의 모든 생성 모델들은  
> 기본적으로 이 그림처럼  
> latent variable $z$가 존재하고  
> generator를 통해 observed data $x$를 생성하는  
> 이런 구조로 표현이 가능합니다.  
> 
> 예를 들어 얀 르쿤이 말했던 world model이라든지,  
> 최근 3D 비디오를 인터랙티브하게 만드는 모델들도  
> 이런 형태의 pipeline을 뜯어보면  
> 결국 다 이 구조를 따르고 있습니다.  
> 
> 그래서 VAE를 이해하실 때도  
> 이 그림처럼 $z$와 $x$, 그리고 generator라는  
> 세 가지 구성요소를 중심으로  
> 개념을 잡아두시면 될 것 같습니다.      

---

## p13. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

잠재 변수는 사전 분포(prior distribution)로부터 샘플링된다.  

$$
z \sim p(z)
$$  

그리고 생성기(generator)는 잠재 변수 $z$를 입력으로 받아  
관측 변수 $x$의 분포(distribution)를 생성한다.  

<img src="/assets/img/lecture/probstat/9/image_9.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그래서 이제 distributional한 센스로 얘기를 해보면,  
> latent variable을 샘플링합니다.  
> $p(z)$라는 probability density로부터  
> $z$라는 random sample, latent variable이 있고  
> 지금 보면 distribution에서 distribution으로 가는 걸로  
> 우리의 이야기가 격상이 됐죠.  
> 
> 이 파란색 distribution으로부터 샘플링을 하는데  
> 이 파란색 distribution은 굉장히 간단합니다.  
> 정보가 없어요.  
> 
> 아까 피규어에서 봤던 것처럼  
> 저건 1-dimensional한 데이터를 고려한 예시인데  
> 실제 데이터는 굉장히 high-dimensional하잖아요.  
> high-dimensional하고,  
> 그런 density를 z축으로 봉우리 형태로 표현하기도 어려운데  
> 이런 식으로 오른쪽처럼  
> 굉장히 multi-modal한 density,  
> 로컬 미니멈, 로컬 맥시멈들이 굉장히 많은  
> 복잡한 공간으로 mapping을 해주는 것이  
> generator다, 이렇게 생각하시면 될 것 같아요.  
> 
> 그래서 앞에서 단순하게 verbal하게 정의했던  
> pose, size 같은 것들이  
> 사실 수학적으로 생각해 보면  
> 쉬운 distribution에서  
> 어려운 distribution으로 보내는 것이  
> generator 모델이라고 보시면 됩니다.  
> 
> 이게 사실 굉장히 심오한 이론들로 연결되는데  
> 그런 것들은 뒤에서 차분히 얘기하도록 하겠습니다.      

---

## p14. 변분 오토인코더 (Variational Autoencoder)  

신경망(neural network)을 이용하여 확률 분포(distribution)를 표현한다.  

- $ \theta $ : 학습 가능한 파라미터(learnable parameters)  
- 표현되는 함수:  

  $$
  p_\theta(x \mid z)
  $$  

<img src="/assets/img/lecture/probstat/9/image_10.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 그럼 제네레이터가 무엇이냐.  
> 수학적으로 조금 더 생각을 해보면  
> $p(z)$는 latent variable에 대한 distribution이라고 하고  
> $p_\theta(x)$는 제네레이터가 $\theta$라는 파라미터로  
> parameterization 됐기 때문에  
> 그 파라미터를 지나서 나온 결과물의 distribution이라서  
> $p_\theta(x)$로 표현했습니다.  
> 
> 그럼 이제 제네레이터는  
> 우리가 컨디셔널 probability를 배웠었는데  
> 그 관점에서 확률적으로 생각할 수 있어요.  
> 
> 그래서 우리가 컨디셔닝,  
> 그리고 마지널라이제이션 이런 부분을 했잖아요.  
> 
> $z$라는 랜덤 배리어블이 주어졌을 때,  
> 컨디션이 걸렸을 때 나오는  
> $x$ 데이터의 모양이 어떠하냐,  
> 그걸 표현하는 것이 제네레이터고  
> 그래서 제네레이터는  
> $p_\theta(x \mid z)$라는  
> 수학적 객체로 표현할 수 있다는 겁니다.  
> 
> 여기서부터는 우리가 앞에서 배웠던,  
> 되게 재미없다고 느꼈던 확률 도구들이  
> 이걸 다루기 위한 중요한 도구들로  
> 탈바꿈을 하게 됩니다.  
> 
> 마지널라이제이션 같은 경우는  
> 얘의 평균치를 어떻게 움직이느냐 이런 게 되는 거고,  
> latent variable이 하나일 때와  
> 여러 개일 때 정보량이 어떻게 연결되는지  
> 그런 것들도 앞에서 수식으로 공부했었습니다.  
> 
> 이런 내용들이  
> 우리가 뒤에서 생성 모델을 학습하기 위한  
> 수학적 백그라운드가 되는 것이고,  
> 앞의 내용들이 어떻게 연결되는지  
> 계속 보시면서 따라오시면 될 것 같습니다.      

---

## p15. 최대우도추정 (Maximum Likelihood Estimation)  

**Kullback–Leibler (KL) 발산 최소화:**  

$$
\min_{\theta} \, D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
$$  

> KL발산 외에 고려할 수 있는 다른 기준은?

**즉, 우도 최대화(Maximize likelihood):**  

$$
\max_{\theta} \, \mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
$$  

<img src="/assets/img/lecture/probstat/9/image_11.png" alt="image" width="480px">

전개 과정:  

$$
\begin{aligned}
\arg \min_{\theta} D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
&= \arg \min_{\theta} \sum_{x} p_{\text{data}}(x) 
\log \frac{p_{\text{data}}(x)}{p_{\theta}(x)} \\
&= \arg \min_{\theta} 
\left[- \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) + \text{const}\right] \\
&= \arg \max_{\theta} \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) \\
&= \arg \max_{\theta} 
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
\end{aligned}
$$  

> **강의 내용**  
> 
> 네 그래서 우리가 KL Divergence이라는 것을 공부를 했는데,  
> 그리고 total variance도 공부를 했는데  
> KL Divergence를 우리가 메인으로 많이 쓴다고 했잖아요.  
> 제가 그때 분명히 얘기를 했던 게  
> 거의 모든 생성 모델은 KL Divergence와 커플링되어 있다,  
> 라고 얘기를 했고  
> 그래서 여기서 그게 다시 나왔습니다.  
> KL Divergence를 줄이는 게 우리의 목표인 거예요.  
> 
> 그런데 이걸 줄이는 관점에서 보면  
> 데이터가 굉장히 크면  
> $\theta$가 아무리 커도  
> KL Divergence를 일정 이하로만 줄일 수 있고  
> 0으로 만들 수는 없습니다.  
> 데이터가 너무 크고  
> 그걸 표현하기 위한 파라미터는 한정되어 있기 때문에요.  
> 
> 그래서 KL Divergence를 계산하지만,  
> 즉 minimization을 하지만  
> 이건 로컬 미니멈적인 minimization이고  
> 글로벌 minimization은 불가능합니다.  
> 뉴럴 네트워크라는 논리니어한 머신을 다루고 있기 때문에요.  
> 
> 그러면 KL Divergence가 어떤 의미였는지 다시 생각해보면  
> 두 분포의 다름을 정의하는 functional이었잖아요.  
> 그래서 데이터에 대한 distribution이 있고  
> 모델이 만들어낸 생성된 데이터들에 대한 distribution  
> $p_\theta(x)$가 있을 때  
> 이 둘을 최대한 같게,  
> 즉 이 둘의 차이를 최대한 줄이는 것이  
> 우리의 목적입니다.  
> 
> 그래서 만약 이 KL Divergence가 정말 작은 값이라면  
> 우리가 기대할 수 있는 건  
> 우리가 만들어낸 $x$에 대한 probability distribution  
> $p_\theta(x)$가 $p_{\text{data}}$와 매우 닮았을 것이고  
> 그러니까 생성된 이미지가  
> 데이터에 있는 이미지와 닮을 것이라는 기대를 갖는 거죠.  
> 
> 이게 훈련에 대한 철학입니다.  
> 앞에서는 input과 output에 대한 철학적 이야기를 했고  
> 지금은 훈련 방법론에 대한 철학입니다.  
> 
> 그래서 classification은 어땠었죠?  
> classification은 하나의 이미지가 있고  
> 그에 해당하는 레이블이 존재해서  
> one-to-one 매칭을 합니다.  
> 그래서 벡터와 벡터를 매칭하고  
> one-to-one dependent한 objective function을 갖습니다.  
> 
> 그런데 여기서는 그렇지 않습니다.  
> 여기서는 probability distribution을 매칭하는 것이기 때문에  
> 다대다 매칭이에요.  
> $p_{\text{data}}$ 안에는 수많은 데이터가 있고  
> $p_\theta$가 생성할 수 있는 데이터 역시 매우 많고  
> 그 둘 사이에 pairing이 없습니다.  
> distribution으로 매칭을 하는 겁니다.  
> 
> 그래서 우리가 KL Divergence 같은 것을 공부하는 거고  
> 다대다 매칭을 하기 위해서입니다.  
> 
> 다대다 매칭을 한다는 것이 어떤 의미냐면  
> 다시 처음 슬라이드로 돌아가 보면  
> 랜덤 베리어블을 뽑을 때마다 다른 데이터가 나오게끔 하는  
> 그 파이프라인을  
> 학습 방법론으로부터 끌고 왔다는 거죠.  
> 
> 랜덤 베리어블이 계속 달라지는데  
> 같은 값만 나온다면 말이 안 되잖아요.  
> 랜덤 베리어블을 샘플링한다는 말에는  
> 같은 값을 주더라도  
> 생성을 하면 다른 이미지가 나와요.  
> 굉장히 재밌는 현상인데  
> 그런 철학이 들어 있는 겁니다.  
> 
> 그래서 우리는 KL Divergence와  
> maximum likelihood estimation을 연결했었고  
> KL Divergence를 주면  
> maximum likelihood가 변경이 됐고  
> 생성 모델을 푸는 방식이 그렇게 연결된다,  
> 그렇게 이해하시면 됩니다.  
> 
> 그래서 그 도구들을 우리가 앞에서 배웠던 겁니다.      

---

## p16. 최대우도추정 (Maximum Likelihood Estimation)

우리는 다음 식을 최대화하고자 한다.

$$
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_\theta(x)]
$$  

여기서 $p_\theta(x)$는 다음과 같이 표현된다.

$$
p_\theta(x) = \int_z p_\theta(x \mid z) \, p(z) \, dz
$$  

<img src="/assets/img/lecture/probstat/9/image_12.png" alt="image" width="480px">

이때 두 가지 미지항(unknowns)이 존재한다.

1. **최적화 대상:** $\theta$ — 학습 가능한 파라미터  
2. **제어 불가능한 요소:** “진짜” 사전 분포 $p(z)$  

따라서 다음과 같은 아이디어가 제시된다.  
→ **“제어 가능한(controllable)” 분포 $q(z)$**를 도입한다.

> **강의 내용**  
> 
> 네, 이제 조금 더 디테일하게 한번 가봅시다.  
> 우리가 $\log p_\theta(x)$가  
> 생성된 데이터에 대한 distribution이라고 얘기를 했었잖아요.  
> $\theta$는 다시 말해서 뉴럴 네트워크의 파라미터였고요.  
> 
> 그래서 이제 $p_\theta(x)$를  
> 앞에서 배웠던 마지널라이제이션,  
> 컨디셔닝하는 룰을 통해서  
> 중간에 이 적분 형식으로 한 번 쪼개 보자고 했을 때  
> 이게 정확하게 equal이 성립을 하거든요,  
> 컨디셔널 프로바빌리티의 정의에 따라서.  
> 
> 즉,  
> $$p_\theta(x) = \int_z p_\theta(x \mid z)\, p(z)\, dz$$  
> 이렇게 쓸 수 있고,  
> 여기서 $p(z)$는 Gaussian random variable이고  
> $p_\theta(x \mid z)$는 제네레이터였습니다.  
> 
> 이렇게 했을 때  
> $p_\theta(x)$,  
> 그러니까 데이터 생성에 대한 distribution이  
> 이 식으로 연결되는 겁니다.  
> 
> 우리가 앞에서는 그냥 파이프라인 그림으로  
> “모델에다가 랜덤 베리어블을 넣었다,  
> latent variable을 넣었다”  
> 이런 식으로 인포멀하게 얘기를 했는데  
> 지금은 그걸 수학적으로 명확하게 정의한 거예요.  
> 인포멀했던 설명을  
> 포멀한 단계로 바꾼 겁니다.  
> 
> 그래서 이 적분 형태로 표현하는 것이  
> 제네레이터를 표현할 수 있는 방법 중 하나다,  
> 이렇게 볼 수 있고요.  
> 
> 그런데 여기서 문제는 뭐냐 하면,  
> 이제 이렇게 컨디셔널한 입장에서 봤을 때  
> $\theta$를 어떻게 optimization 할 것이냐,  
> 그게 문제가 되겠죠.  

---

> - 최대우도추정(MLE)은 실제 데이터 분포 $p_{\text{data}}$에 대해  
>   모델 분포 $p_\theta(x)$의 로그 가능도 $\log p_\theta(x)$를 최대화하는 것을 목표로 한다.  
>
> - 그런데 $p_\theta(x)$는 단순한 형태가 아니라  
>   **잠재 변수 $z$에 대한 적분 형태**로 표현된다. 조건부 확률의 정의를 이용하면 다음과 같다.  
>
>   $$
>   p_\theta(x) = \int_z p_\theta(x \mid z)\, p(z)\, dz
>   $$
>
> - 여기서  
>   - $p(z)$는 **잠재 변수의 사전 분포(prior distribution)**이며 보통 가우시안으로 가정한다.  
>   - $p_\theta(x \mid z)$는 **생성기(generator)**로, “$z$가 주어졌을 때 $x$가 생성될 확률”을 나타낸다.  
>
> - 이 적분식은 우리가 앞서 직관적으로 이해했던  
>   “잠재 변수 $z$를 입력받아 데이터를 생성한다”는 개념을  
>   **수학적으로 공식화한 표현**이다.  
>
> - 하지만 이 식을 직접 최적화하는 것은 매우 어렵다. 그 이유는 다음과 같다.  
>   1) $p_\theta(x)$는 $z$에 대한 적분이므로 **폐형식(closed form)**으로 계산이 불가능하다.  
>   2) $p(z)$는 우리가 직접 제어할 수 없는 **고정된 분포**이다.  
>
> - 따라서 실제 학습에서는  
>   직접적인 사전 분포 $p(z)$ 대신  
>   **제어 가능한(controllable) 근사 분포 $q(z)$**를 도입하여  
>   계산과 최적화를 가능하게 만든다.  
>
> - 이 발상이 바로 **변분 오토인코더(VAE)**의 핵심 동기이다.  
>   - 즉, $p_\theta(x)$를 직접 계산하는 대신  
>   - 잠재 공간의 “근사 posterior”인 $q(z)$를 활용하여  
>     효율적으로 로그 가능도를 최대화할 수 있는 구조를 만든다.  
>
> - 다시 말해, VAE는  
>   **잠재 변수 적분 때문에 계산 불가능한 MLE 문제를  
>   변분 근사(variational approximation)를 이용해 해결하려는 방법**이다.  

---

## p17. 잠재 변수 모델 (Latent Variable Model)

<img src="/assets/img/lecture/probstat/9/image_13.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이제,  
> 오늘의 사실 제가 정말 하고 싶은 거는  
> 요 페이지입니다.  
> 요게 이제 사실 VAE라는,  
> 오늘 배우는 이 스트럭처의 모든 걸  
> 다 표현한다고 생각하시면 될 것 같아요.  
> 
> 이게 어떻게 보면 어려울 수도 있는데  
> 또 막상 보면 어렵진 않거든요.  
> 이걸 완벽하게 수학적으로 이해를 하면  
> “아 VAE가 그래서 이렇게 수학적으로 모델링돼서  
> 이런 의미가 되는구나” 하고  
> 바로 깨달을 수가 있습니다.  
> 
> 그래서 이런 식의 수식을 묘사하는 것을  
> 레이턴트 베리어블 모델이라고 합니다.  
> probability, applied statistics에서  
> 굉장히 많이 쓰이는 모델이고,  
> 통계학 하시는 분들,  
> 특히 베이지안 통계 하시는 분들이  
> 굉장히 이런 걸 많이 하십니다.  
> 
> 그래서 $\log p_\theta(x)$를  
> 어떻게 여러 개의 텀으로,  
> 이해할 수 있는 텀으로 쪼개느냐  
> 이것에 대한 이야기인데  
> 하나씩 한번 살펴봅시다.  
> 
> 첫 번째 $\log p_\theta(x)$가 있고  
> 이것을 맥시마이제이션 하는 것이  
> 우리의 목표였었죠.  
> 
> 다음 줄을 보면  
> 어떤 $q(z)\log p_\theta(x)\,dz$라는 것으로  
> 표현을 합니다.  
> 
> 그런데 이게 적분을 했을 때  
> equality가 성립하는 이유는  
> $\log p_\theta(x)$는 $z$와 관련이 없는 거잖아요.  
> 그래서 $\log p_\theta(x)$가  
> 사실 밖으로 나오면  
> $q(z)$를 적분하는 겁니다.  
> 그리고 모든 probability distribution을  
> 적분하면 1이었죠.  
> 그러니까 이게 성립을 하는 거예요.  
> 
> 그리고 이제 $\log p_\theta(x)$를  
> 우리가 앞에서 generator라고  
> 컨디셔닝이 갑자기 나오는데  
> 그러면 $p_\theta(x)$에서  
> 그것을 conditioning하는 무언가로  
> 뽑아내기 위해서  
> 이 Bayes rule이라는 것을 사용합니다.  
> 
> 그래서 $p_\theta(x)$를  
> 여기 괄호 안에 들어가 있는 게  
> 다 똑같은 모양이에요.  
> 이게 Bayes rule이라고 합니다.  
> 굉장히 중요한 철학이라  
> 이 강의에서 디테일하게 다루진 않겠지만  
> 직접 찾아보시면 좋을 것 같아요.  
> 
> 그래서 $p_\theta(x)$는  
> 이렇게 쪼개질 수 있는데요.  
> $p_\theta(x\mid z)$, $p_\theta(z)$,  
> 그거를 $p_\theta(z\mid x)$로 나누는 거.  
> 그래서 지금 보면  
> condition이 뒤집혀졌었죠.  
> 
> 그다음에  
> 이걸 한 번 더 가서  
> 이제 $q(z)/q(z)$를  
> 동시에 곱해줍니다.  
> 이걸 곱하는 게 가능한 이유는  
> 1이니까 약분이 되고요.  
> 
> 그리고 이 밑으로 나누는 것은  
> log 함수의 특징에 따라서  
> 나눠질 수 있어요.  
> 고등학교 때 배웠던  
> “$\log ab = \log a + \log b$”  
> 그 성질 때문에요.  
> 
> 그래서 이걸 잘 조립해서  
> 표현을 하면  
> 최종적인 식이 나옵니다.  
> 
> 그래서 총 3개가 있는데  
> 이 3개를 neural network로  
> 잘 표현하는 게  
> 그냥 VAE라고 보면 될 것 같아요.  
> 
> 그래서 이제 하나씩  
> 한 번 알아봅시다.  
> 
> 우리는 intractable한  
> $p_\theta(x)$라는 것을  
> 직접적으로 수학적으로 표현하는 것이  
> 불가능해요.  
> 
> 왜냐하면 엄청난 굴곡이 많고  
> 정말 특수한 경우가 아닌 이상  
> 표현할 수가 없습니다.  
> 아예 불가능합니다.  
> 
> 왜냐하면 우리가 $x$가 모델링하는 것은  
> 이미지, 음성, language 같은  
> 굉장히 high-dimensional한 스페이스잖아요.  
> 
> 그래서 이렇게 바꿔서 하는 겁니다.  

---

> - 목표는 $\log p_\theta(x)$를 **최대화**하는 것이다.  
> - 이를 다루기 위해, 임의의 보조 분포 $q(z)$를 곱해 적분 형태로 변환하면  
>   $z$에 무관한 상수항인 $\log p_\theta(x)$를 적분 내부로 옮길 수 있다.  
>
> - 베이즈 규칙  
>
>   $$
>   p_\theta(z \mid x)=\frac{p_\theta(x\mid z)\,p_\theta(z)}{p_\theta(x)}
>   $$  
>
>   을 대입하고,  
>   $q(z)$를 곱하고 나누어(즉, 1을 곱한 것과 동일)  
>   로그의 성질 $\log a - \log b$를 사용해 각 항을 분리한다.  

---

## p18. 계산 불가능한 식에서 계산 가능한 형태로 (From Intractable to Tractable Formulation)

<img src="/assets/img/lecture/probstat/9/image_14.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그래서 첫 번째 우리가 $\log p_\theta(x)$를  
> 이런 수식을 통해서 유도해서  
> 맨 마지막 항을 남겨놨는데  
> 여기서 tractable하다는 것은  
> 우리가 계산할 수 있다는 것이고  
> intractable하다는 것은  
> 계산할 수 없다는 겁니다.  
> 
> 그러면 계산할 수 없는데  
> 왜 이런 모델이 필요하냐고 하면,  
> 컴퓨터 공학을 하시는 분들은  
> (저는 수학을 깊게 공부한 입장이라  
> 참을 수가 없긴 한데)  
> intractable한 것을 그냥 무시합니다.  
> 
> 어떠한 KL divergence를 계산하면  
> 항상 양수 혹은 constrained된 값을 갖게 되거든요.  
> 그래서 세 번째 term을  
> 굳이 control하지 않고  
> 그냥 발산하게 놔두더라도  
> 앞의 두 개 term을 control해서  
> 최종적으로 $\log p_\theta(x)$를  
> control할 수 있다,  
> 이런 철학이 있습니다.  
> 
> 그래서 intractable한  
> 맨 마지막 term은 그냥 무시하시면 된다,  
> 이런 접근이 실제로 많이 사용됩니다.  
> 
> 그런데 만약 이 term까지  
> 아주 잘 control할 수 있는  
> 새로운 방법이 나온다면  
> 맨 왼쪽의 $\log p_\theta(x)$를  
> 더 잘 묘사할 수 있겠죠.  
> 
> 다만 현실에서는  
> 그렇게까지 하지 않아도  
> 생각보다 잘 됩니다.  

---

> - 우리가 다루는 $\log p_\theta(x)$는 **직접 계산이 불가능(intractable)** 하다.  
>   그 이유는 잠재변수 $z$에 대해  
>   $$p_\theta(x)=\int p_\theta(x\mid z)p_\theta(z)\,dz$$  
>   와 같은 **고차원 적분**을 닫힌 형태(closed-form)로 계산하기 어렵기 때문이다.  
>
> - 이를 우회하기 위해, $\log p_\theta(x)$를  
>   $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]  
>   \;-\; D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))  
>   \;+\; D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$$  
>   와 같이 세 항으로 분해한다.  
>
> - **초록색의 두 항(앞의 두 항)은 ‘원래는’ 계산이 불가능(intractable)** 하지만,  
>   아래 두 가지 이유로 실제 학습 과정에서는 **계산 가능(tractable)** 하다:  
>
>   > ① 첫 번째 항 $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]$$는  
>   >     **몬테카를로 샘플링(Monte-Carlo estimation)** 을 이용하면  
>   >     충분히 정확하게 추정할 수 있기 때문이다.  
>   >     즉, $z\sim q(z)$ 를 샘플링한 후  
>   >     $\log p_\theta(x\mid z)$ 값을 평균 내면 된다.  
>
>   > ② 두 번째 항 $D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))$는  
>   >     **q(z)와 p(z)가 모두 가우시안인 경우(표준 VAE의 기본 설정)**  
>   >     **해석적(analytic) 닫힌형 해(closed-form solution)** 이 존재한다.  
>   >     따라서 이 항은 직접 계산이 가능해진다.  
>
> - 반면 마지막 항  
>   $$D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$$  
>   은 **여전히 계산 불가능(intractable)** 하다.  
>   이유는 $p_\theta(z\mid x)$ 를 구하려면  
>
>   $$p_\theta(z\mid x)=\frac{p_\theta(x\mid z)p_\theta(z)}{p_\theta(x)}$$  
>
>   이 되는데, 여기서 또다시 **계산 불가능한 $\log p_\theta(x)$가 등장하기 때문**이다.  
>
> - 하지만 이 항은 항상 **0 이상**이며,  
>   우리는 이를 직접 계산하지 않아도  
>   앞의 두 항(ELBO)의 합을 최대화하는 것만으로  
>   원래 목적 함수 $\log p_\theta(x)$를 **간접적으로 최대화**할 수 있다.  
>
> - 이것이 바로 변분추론(VI)의 핵심 아이디어이다.  
>   **계산 불가능한 목적을 직접 최적화하지 않고**,  
>   **계산 가능한 하한(ELBO)** 을 최대화함으로써  
>   $\log p_\theta(x)$에 최대한 가까운 값을 찾는다.  

---

## p19. 증거 하한 (Evidence Lower Bound, ELBO)

<img src="/assets/img/lecture/probstat/9/image_15.png" alt="image" width="600px">

- 이것을 **Evidence Lower Bound (ELBO)** 라고 부른다.  
- 이는 $\log p_\theta(x)$의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.

> **강의 내용**  
> 
> 그래서 이제 이런 모양이 나온 겁니다.  
> 좌변(왼쪽)에는 intractable한 두 항을 두고,  
> 우변(오른쪽)에는 tractable한 두 항을 두어서  
> 이렇게 정리를 한 거죠.  
> 
> 그리고 이 형태를 inequality로만  
> 표현할 수 있게 되면  
> 그걸 evidence lower bound라고 부르는  
> 굉장히 중요한 개념이 등장합니다.  
> 
> lower bound, upper bound 들어보신 적 있죠?  
> 예를 들어  
> $f(x) = -x^2 + c$ 라는 함수가 있다고 하면  
> 이 함수의 upper bound는 $c$입니다.  
> 어떤 값이 변하더라도  
> 넘어설 수 없는 최댓값을 upper bound라고 하고  
> lower bound는 그 반대 개념이죠.  
> 
> 그래서 우리가 intractable한 항을  
> 그냥 오른쪽으로 넘기고  
> 그걸 양수로 유지한다는 성질을 활용하면  
> equality를 inequality로 바꿀 수 있고  
> 그러면 $\log p_\theta(x)$에 대한  
> 명확한 lower bound가 나오게 됩니다.  
> 그게 evidence lower bound, ELBO입니다.  
> evidence라는 말은  
> 우리가 tractable한 항만 가지고  
> 판단을 내리게 된다는 의미입니다.  
> 
> **(질문)**  
> 아까 가장 오른쪽 항도 intractable한 이유가  
> given $x$인데,  
> $x$가 intractable하니까  
> 마지막 항도 intractable한 것 아닌가요?  
> 
> **(답변)**  
> 그 이유는 $p_\theta(z\mid x)$를  
> 알 수 없기 때문입니다.  
> 지금 말씀하신 슬라이드의  
> 맨 마지막 term 말씀이죠?  
> 
> **(질문)**  
> 네.  
> 그럼 첫 번째 $p_\theta(x\mid z)$는 왜 tractable한가요?  
> 
> **(답변)**  
> 그건 generator이기 때문입니다.  
> $z$를 넣었을 때  
> 어떤 출력이 나오는지에 대한 모델을  
> 우리가 이미 갖고 있기 때문이죠.  
> 
> 여기에 정보량(information)의 차이가 있습니다.  
> $z$는 우리가 스스로 모델링한 latent variable이라  
> 정보가 매우 적습니다.  
> 그래서 $p_\theta(x\mid z)$는  
> conditional expectation을 계산할 수 있습니다.  
> 
> 그런데 $p_\theta(z\mid x)$는 다릅니다.  
> $x$는 이미지·오디오·텍스트처럼  
> 정보량이 엄청난 데이터이고  
> $z$는 정보가 거의 없는 latent variable입니다.  
> 
> 즉, 정보가 많은 것을 input으로 넣어서  
> 정보가 없는 것을 output으로 만드는 모델은  
> 존재하지 않습니다.  
> 그래서 이 항이 intractable합니다.  
> 
> 이 모든 구조는 사실 bayes rule에서 비롯된 철학인데  
> 사전확률(prior)과 사후확률(posterior) 관계를  
> 깊게 이해하면 정확히 납득이 됩니다.  
> 다만 지금 단계에서는  
> 제가 설명드린 수준으로 이해하시면 됩니다.  
> 
> 그래서 이 intractable한 posterior를 대신하기 위해  
> 새로운 distribution $q(z)$를 도입하는 것이 핵심입니다.  
> 이 $q(z)$가 바로 뒤에서 다룰 가장 중요한 개념입니다.  

---

## p20. 매개변수화(Parameterization)

<img src="/assets/img/lecture/probstat/9/image_16.png" alt="image" width="500px">

- 이것은 **Evidence Lower Bound (ELBO)** 라고 불린다.  
- 이는 $\log p_\theta(x)$ 의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.  
- 이제 $q(z)$를 직접 다루기 어려우므로,  
  이를 **매개변수화(parameterize)** 하여  
  **$q_\phi(z \mid x)$** 로 표현한다.  
- 여기서 $\phi$ 는 **추론 네트워크(inference network)** 의  
  학습 가능한 파라미터이다.  
- 반면, **$p_\theta(z)$** 는 단순하고 알려진 **사전분포(prior)** 로 둔다.

> **강의 내용**  
> 
> 그래서 우리가 q(z)를 직접 다루기가 어려우니까  
> q를 어떤 파라미터로 파라미터라이즈하게 됩니다.  
> 즉, 뉴럴 네트워크 구조를 사용하겠다는 뜻입니다.  
> 
> 그래서 q(z)를  
> $q_\phi(z \mid x)$  
> 이런 형태로 바꾸게 되고,  
> 여기서 $\phi$는 학습 가능한 파라미터가 됩니다.  
> 
> 그리고 $p_\theta(z)$는  
> 굳이 복잡하게 만들 필요 없이  
> 우리가 이미 알고 있는 아주 단순한 prior,  
> 예를 들어 가우시안 같은  
> 그런 $p(z)$로 대체할 수 있습니다.  

---

> - 실제로 $q(z)$는 임의의 형태를 가질 수 있지만,  
>   그 분포를 명시하거나 직접 계산하는 것은 불가능하다.  
>   따라서 이를 **신경망으로 근사(parameterize)** 하여  
>   $q_\phi(z \mid x)$ 형태로 표현한다.  
>   이때 $\phi$는 인코더(추론 네트워크)의 학습 가능한 파라미터이다.  
>
> - 인코더 $q_\phi(z \mid x)$는 **입력 데이터 $x$로부터 잠재변수 $z$를 추정**하고,  
>   디코더 $p_\theta(x \mid z)$는 **잠재변수 $z$로부터 데이터를 복원 또는 생성**한다.  
>   이렇게 두 확률 모델이 짝을 이루어 작동한다.  
>
> - 사전분포 $p_\theta(z)$는 보통 **표준정규분포 $\mathcal{N}(0, I)$** 로 설정한다.  
>   이는 계산을 단순하게 하고, 잠재공간의 구조를 일정하게 유지시킨다.  
>
> - 결국 인코더와 디코더의 파라미터 $\phi, \theta$를 조정하여  
>   **ELBO를 최대화**하는 것이 VAE의 학습 과정이다.  
>   이는 곧 **잠재변수 분포 추정**과 **데이터 생성 과정 학습**을  
>   동시에 수행하는 절차이다.  

---

## p21. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_17.png" alt="image" width="800px">

---

> - 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를 받아  
>   잠재변수 $z$의 분포를 추정하는 역할을 한다.  
>   일반적으로 이 분포는 가우시안(정규분포) 형태로 가정된다.  
>
> - 디코더 $p_\theta(x \mid z)$는 샘플링된 $z$로부터  
>   원래의 입력 $x$를 재구성하도록 학습된다.  
>   즉, 인코더가 정보를 요약하고,  
>   디코더가 그 정보를 바탕으로 데이터를 복원하는 구조이다.  
>
> - 전체 손실 함수는 두 부분으로 구성된다.  
>
>   (1) $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$  
>       재구성 손실로서, 입력 $x$와 복원된 $x'$의 차이를 최소화한다.  
>
>   (2) $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p_\theta(z))$  
>       정칙화 항으로서, 인코더가 추정한 분포가  
>       사전분포 $p_\theta(z)$(보통 $\mathcal{N}(0, I)$)와  
>       유사하도록 만드는 역할을 한다.  
>
> - 이 두 항의 균형을 조정함으로써  
>   VAE는 잠재공간을 구조적으로 유지하면서  
>   새로운 데이터를 생성할 수 있는 능력을 갖추게 된다.  
>
> - 이러한 구조는 생성 모델로서뿐 아니라  
>   이상치 탐지(Anomaly Detection)와 같은 응용에서도 널리 활용된다.  
>   학습된 모델은 정상 데이터의 잠재공간을 학습하므로,  
>   재구성 오차가 큰 데이터는 이상치로 판별된다.

---

## p22. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_18.png" alt="image" width="800px">

---

> - 위 식은 ELBO를 최대화하는 대신, 동등하게 손실을 최소화하는 형태로 표현된 것이다.  
>   왼쪽 항은 재구성 손실(reconstruction loss),  
>   오른쪽 항은 정칙화 손실(regularization loss)에 대응한다.  
>
> - 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를  
>   잠재공간(latent space) 상의 확률분포로 압축하여 표현한다.  
>   여기서 $\phi$는 인코더의 학습 파라미터이며,  
>   인코더는 $q_\phi(z \mid x)$가 사전분포(prior) $p(z)$에  
>   가깝도록 학습된다.  
>
> - 사전분포 $p(z)$는 일반적으로  
>   가우시안 분포 $\mathcal{N}(0, I)$로 설정된다.  
>   이렇게 단순한 분포를 prior로 두는 이유는  
>   잠재공간이 구조적으로 안정적이고,  
>   샘플링이 쉬운 공간이 되도록 만들기 위함이다.  
>
> - 정칙화 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$은  
>   인코더가 만든 분포 $q_\phi(z \mid x)$가  
>   $\mathcal{N}(0, I)$와 멀어지지 않도록 제한하는 제약 조건이다.  
>   이 값이 작아질수록 잠재분포는  
>   표준정규분포에 더 잘 정렬된다.  
>
> - 디코더 $p_\theta(x \mid z)$는 잠재변수 $z$로부터  
>   원래 입력 $x$를 재구성하는 역할을 한다.  
>   여기서 $\theta$는 디코더의 학습 파라미터이며,  
>   학습의 목표는 입력 $x$와 재구성된 $x'$의 차이를  
>   최소화하는 것이다.  
>
> - 결국 VAE의 학습 과정은  
>   (1) 데이터를 잘 재구성하는 능력과  
>   (2) 잠재공간의 확률적 구조를 유지하는 능력  
>   두 가지를 동시에 최적화하는 과정이라고 볼 수 있다.

---

## p23. 첫 번째 항: 재구성 손실 (Reconstruction Loss)

<img src="/assets/img/lecture/probstat/9/image_19.png" alt="image" width="600px">

**예시: L2 손실 (L2 loss)**  

- 1단계 몬테카를로(Monte Carlo) 샘플링:  
  $z \sim q_\phi(z \mid x)$  

- 디코더 네트워크에 의한 매핑:  
  $g_\theta(z) \rightarrow x'$  
  (network estimates distribution’s parameters)

- 가우시안 분포로 모델링:  
  $p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)$  
  (assume fixed std)

- 음의 로그우도(negative log-likelihood):  

  $$
  -\log p_\theta(x \mid z)
  =
  \frac{1}{2\sigma_0^2}\|x - x'\|^2 + \text{const}
  $$

- L2 손실은 데이터 포인트 $x$ 주변의  
  가우시안 근방(Gaussian neighborhood)을 의미함

---

> **1. 몬테카를로 샘플링 (Monte Carlo Sampling)**  
> - 기댓값  
> 
>   $$
>   \mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]
>   $$  
> 
>   은 잠재변수 $z$ 에 대한 적분 형태로 표현되며 해석적으로 계산하기 어렵다.  
> - 따라서 $q_\phi(z \mid x)$ 에서 샘플링한 $z$ 들을 이용해  
>   $\log p_\theta(x \mid z)$ 값을 평균하여 근사한다.  
>   이를 **몬테카를로 근사(Monte Carlo approximation)** 라고 한다.  
> - 샘플링 과정은 **재매개변수화 기법(Reparameterization trick)** 으로  
>   미분 가능하게 만들어, 인코더와 디코더 모두를 역전파로 학습할 수 있다.  
>
> **2. 디코더 매핑 $g_\theta(z) \rightarrow x'$**  
> - 디코더 $g_\theta$ 는 잠재변수 $z$ 를 입력받아 생성 데이터의 평균값 $x'$ 을 출력한다.  
> - 디코더는 단순 복원 함수가 아니라  
>   **확률분포 $p_\theta(x \mid z)$ 의 모수(parameter)를 추정하는 함수** 로 해석된다.  
> - 가장 단순한 경우 디코더는 평균만 출력한다고 두며,  
> 
>   $$
>   x'=\mu_\theta(z)
>   $$  
> 
>   분산은 고정 상수 $\sigma_0^2$ 로 둔다.  
>   즉, 디코더는 “데이터가 존재할 법한 중심(mean)”을 학습한다.  
> - 따라서 디코더는 **확률적 생성 모델의 평균 함수(mean function)** 이다.  
>
> **3. 가우시안 분포로 모델링하는 이유**  
> - 실제 데이터는 노이즈와 불확실성을 포함하므로 $x$ 와 $x'$ 를 완전히 일치시키기보다  
>   $x$ 가 $x'$ 주변에서 나올 확률을 모델링하는 것이 타당하다.  
> - VAE는 다음과 같이 가정한다.  
> 
>   $$
>   p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
>   $$  
> 
> - 여기서  
>   - $x'=g_\theta(z)$ : 평균  
>   - $\sigma_0^2 I$ : 분산  
>   - $x$ : 관측값  
> - 이는 “데이터는 평균 $x'$ 를 중심으로 정규분포 형태에 따라 생성된다”는  
>   확률적 가정을 의미한다.  
> - 이 가정 덕분에 모델은 불확실성을 표현할 수 있고,  
>   **로그우도(log-likelihood)가 닫힌형(closed form)** 으로 계산 가능해진다.  
>
> **4. 재구성 손실이 L2 손실이 되는 이유**  
> - 가우시안 가정하에서 로그 가능도는  
> 
>   $$
>   \log p_\theta(x \mid z)
>   =
>   -\frac{1}{2\sigma_0^2}\|x-x'\|^2
>   -\frac{d}{2}\log(2\pi\sigma_0^2)
>   $$
> 
>   로 전개된다.  
> - 따라서 음의 로그 가능도는  
> 
>   $$
>   -\log p_\theta(x \mid z)
>   =
>   \frac{1}{2\sigma_0^2}\|x-x'\|^2 + \text{const}
>   $$  
> 
>   이 되며, 이는 **L2 손실(Mean Squared Error)** 과 동일한 형태이다.  
> - 즉, 디코더가 출력하는 평균 $x'$ 을 기준으로 데이터 $x$ 를 설명하는 과정이  
>   곧 L2 거리 최소화와 같다.  
>
> **5. 전체적 관계 요약**  
> - $x$: 관측 데이터  
> - $z$: 인코더가 샘플링한 잠재변수  
> - $x'=g_\theta(z)$: 디코더가 추정한 평균  
> -  
>   $$
>   p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
>   $$  
> 
>   : 관측 $x$ 는 평균 $x'$ 중심의 정규분포에서 샘플링된 것으로 해석  
> - 재구성 손실 최소화는  
>   “실제 데이터 $x$” 와 “디코더 평균 $x'$” 사이의 거리를 줄이는 것과 같다.  

---

## p24. 두 번째 항: 정규화 손실 (Regularization Loss)

<img src="/assets/img/lecture/probstat/9/image_20.png" alt="image" width="600px">

**예시: 가우시안 사전분포 (Gaussian prior)**  

- $p(z) = \mathcal{N}(z \mid 0, I)$ 로 둔다.  

- $q_\phi(z \mid x)$ 를 가우시안으로 모델링한다:  
  $q_\phi(z \mid x) = \mathcal{N}(z \mid \mu, \sigma)$  

- 인코더 네트워크에 의한 매핑:  
  $f_\phi(x) \rightarrow (\mu, \sigma)$  
  (network estimates distribution’s parameters)

- 손실을 분석적으로 계산한다:  

  $$
  D_{\mathrm{KL}}\big(\mathcal{N}(z \mid \mu, \sigma)\,\|\,\mathcal{N}(z \mid 0, I)\big)
  $$

- 공분산을 고정한 경우:  
  fixed covariance → $\mu$ 에 대한 L2 손실

---

> **1. 정규화 항의 역할**  
> - 정규화 손실 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은  
>   인코더가 학습한 잠재 분포 $q_\phi(z \mid x)$ 이  
>   사전 분포 $p(z)$ (보통 표준 정규분포 $\mathcal{N}(0, I)$) 와  
>   얼마나 다른지를 측정한다.  
> - 이 항은 잠재공간이 지나치게 왜곡되지 않도록 제약을 주며,  
>   특정 데이터에 과도하게 맞춰진 잠재표현을 방지하여  
>   **일관된 잠재 구조**를 유지하게 만든다.  
>
> **2. KL 발산의 계산 방식**  
> - 두 가우시안 분포 사이의 KL 발산은 닫힌형(closed-form)으로 계산된다.  
>
>   $$
>   D_{\mathrm{KL}}\!\big(\mathcal{N}(\mu,\sigma^2)\,\|\,\mathcal{N}(0,1)\big)
>   =\frac{1}{2}(\mu^2+\sigma^2-\log\sigma^2-1)
>   $$  
>
> - 이 표현은 VAE 학습에서 매우 효율적으로 사용되며,  
>   손실을 직접 계산해 최적화할 수 있게 한다.  
>
> **3. 공분산 고정 시 L2 손실과의 관계**  
> - 공분산 $\sigma^2$ 를 고정하면 KL 항은  
>   $\mu^2$ 에 비례하는 형태가 된다.  
>
>   $$
>   D_{\mathrm{KL}} \propto \|\mu\|^2
>   $$  
>
> - 즉, KL 항은 잠재변수 평균 $\mu$ 에 대한  
>   **L2 정규화(L2 penalty)** 처럼 동작한다.  
> - 이는 잠재벡터가 사전분포의 중심(0 근처)에 있도록  
>   압박하는 효과를 낸다.  
>
> **4. 직관적 해석**  
> - 인코더는 입력 $x$ 에 따라 $\mu$ 와 $\sigma$ 를 출력한다.  
> - KL 항은 “너무 특이한” 잠재벡터를 생성하지 않도록 억제하며,  
>   전체 잠재공간이 사전분포 $p(z)$ 와 유사한 모양을 유지하게 만든다.  
> - 그 결과, 학습이 끝난 후 임의의 $z \sim p(z)$ 를 샘플링해도  
>   **자연스럽고 일관된 생성 결과**를 얻을 수 있게 된다.  

---

## p25. 역전파는 어떻게 이루어질까? (Backpropagation?)

<img src="/assets/img/lecture/probstat/9/image_21.png" alt="image" width="800px">

---

> **1. 인코더와 샘플링의 관계**  
> 인코더는 입력 $x$ 로부터 잠재 변수의 분포 $q_\phi(z \mid x)$ 를 학습한다.  
> 평균 $\mu_\phi(x)$ 와 표준편차 $\sigma_\phi(x)$ 를 추정하여 확률적으로 $z$ 를 샘플링하고,  
> 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 로 전달되어 재구성된 출력 $x'$ 를 생성한다.
>
> **2. 역전파의 문제점**  
> 샘플링 과정은 확률적이므로  
>
> $$
> z \sim q_\phi(z \mid x)
> $$  
>
> 와 같이 난수에 의해 결정된다.  
> 이 연산은 비결정적이며 미분 불가능하므로,  
> 역전파는 $z$ 에서 인코더 파라미터 $\phi$ 로 기울기를 전달할 수 없다.  
> 즉, 샘플링 순간에 역전파 경로가 끊긴다.
>
> **3. 직관적 비유**  
> 인코더는 분포의 모양(평균·분산)을 제시하고,  
> 샘플링은 그 분포에서 주사위를 던지는 과정이다.  
> 주사위의 결과값 $z$ 에 대해 $\mu$ 또는 $\sigma$ 로 직접 미분할 수 없기 때문에  
> 일반적인 역전파 규칙을 적용할 수 없다.
>
> **4. 해결책의 방향**  
> 이를 해결하기 위해 재매개변수화 기법(Reparameterization Trick)을 사용한다.  
> 이 방법은 확률적 샘플링 과정을 결정적 함수 형태로 다시 표현하여  
> 미분이 가능하도록 만들어, 끊겼던 역전파 경로를 복원해 준다.

---

## p26. 재매개변수화 (Reparameterization)

<img src="/assets/img/lecture/probstat/9/image_22.png" alt="image" width="800px">

가우시안 매개변수들은 신경망의 출력값에 의해 매개변수화되어(parameterized),  
중간 조건부 분포들(intermediate conditional distributions)을 근사하기 위해 사용된다!  

---

> **1. 재매개변수화의 핵심 아이디어**  
> 확률적 샘플링 $z \sim q_\phi(z \mid x)$ 은 미분 불가능하여 역전파가 단절된다.  
> 재매개변수화 기법(Reparameterization Trick)은 이 확률적 과정을  
> 결정적(deterministic) 함수로 변환하여 미분 가능하게 만든다.  
> 즉, 잠재 변수 $z$ 를 직접 샘플링하지 않고,  
> 표준 정규분포에서 샘플링한 잡음 $\varepsilon$ 을 이용해 다음과 같이 계산한다:
>
> $$
> z = \mu_\phi(x) + \sigma_\phi(x)\,\varepsilon,
> \qquad \varepsilon \sim \mathcal{N}(0, I)
> $$
>
> **2. 수식의 의미**  
> $\varepsilon$ 은 고정된 분포 $\mathcal{N}(0, I)$ 에서만 샘플링되므로  
> 랜덤성은 $\varepsilon$ 에만 존재한다.  
> 반면 $\mu_\phi(x)$, $\sigma_\phi(x)$ 는 결정적 함수이므로  
> $z$ 는 $\phi$ 에 대해 미분 가능한 형태가 된다.  
> 따라서 역전파를 통해 인코더 파라미터 $\phi$ 까지 기울기가 전달된다.  
> 이로써 샘플링 단계가 신경망의 연산 그래프에 포함된다.
>
> **3. 직관적 이해**  
> 원래는 “분포로부터 직접 샘플링”했지만,  
> 이제는 “고정된 분포에서 노이즈를 샘플링하고  
> 그 노이즈를 평균과 분산으로 변환하는 과정”으로 바뀐 것이다.  
> 즉, 확률적 샘플링을  
> 노이즈를 입력으로 받는 결정적 함수로 바꾸어  
> 학습 가능한 형태로 만든다.
>
> **4. 전체 구조의 연결**  
> 인코더는 입력 $x$ 로부터 $(\mu, \sigma)$ 를 출력하고,  
> 표준 가우시안 잡음 $\varepsilon$ 을 사용해  
> $z = \mu + \sigma \varepsilon$ 을 계산한다.  
> 디코더는 이 $z$ 를 입력받아 $p_\theta(x \mid z)$ 를 통해 데이터를 재구성한다.  
> 이 구조를 통해 확률적 생성 모델이  
> 전부 미분 가능한 신경망 형태로 구현된다.

---

## p27. 변분 오토인코더 (Variational Autoencoder) 

지금까지는 하나의 $x$ 에 대한 목적함수를 논의해왔다:

<img src="/assets/img/lecture/probstat/9/image_23.png" alt="image" width="600px">

전체 손실(overall loss)은  
데이터 분포에 대한 기대값으로 표현된다:

<img src="/assets/img/lecture/probstat/9/image_24.png" alt="image" width="600px">

---

> **1. 단일 데이터 샘플 $x$ 에 대한 손실**  
> 위의 첫 번째 식은 단일 입력 샘플 $x$ 에 대한 손실 함수 $$\mathcal{L}_{\theta,\phi}(x)$$ 를 정의한 것이다.  
> 첫 번째 항  
>
> $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$  
>
> 은 재구성 손실(Reconstruction Loss)로, 디코더가 입력 $x$ 를 얼마나 잘 복원하는지 측정한다.  
> 두 번째 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은 정규화 손실(Regularization Loss)로,  
> 인코더가 생성한 잠재공간 분포 $q_\phi(z \mid x)$ 가 사전분포 $p(z)$ 와 얼마나 다른지를 측정한다.
>
> **2. 전체 데이터셋에 대한 손실**  
> 실제 학습에서는 한 개의 샘플이 아니라 데이터셋 전체에 대해 평균 손실을 계산한다.  
> 손실 함수는 데이터 분포 $p_{\text{data}}(x)$ 에 대한 기대값으로 확장되며  
>
> $$
> \mathbb{E}_{x \sim p_{\text{data}}(x)}[\mathcal{L}_{\theta,\phi}(x)]
> $$  
>
> 으로 표현된다.  
> 이 기대값은 실질적으로는 미니배치 평균(mini-batch mean)으로 근사되어 학습 중에 최적화된다.
>
> **3. 전체 목적함수의 의미**  
> 최종 손실 $\mathcal{L}_{\theta,\phi}$ 는  
> 데이터 복원 성능과 잠재공간의 규칙성 사이의 균형을 조절하는 역할을 한다.  
> 즉, 인코더가 잠재공간에서 의미 있는 구조를 학습하도록 하면서  
> 디코더가 입력을 잘 복원할 수 있도록 두 항을 함께 최소화하는 것이 VAE 학습의 핵심이다.

---

## p28. 추론 (Inference)

<img src="/assets/img/lecture/probstat/9/image_25.png" alt="image" width="720px">

**추론 (생성):**

- 잠재 변수 $z$ 를 다음 분포에서 샘플링함:  

  $$
  z \sim \mathcal{N}(0, I)
  $$

- 디코더 네트워크에 의해 $z$ 를 매핑함:  

  $$
  g_\theta(z)
  $$

**디코더(Decoder)는 한 분포에서 다른 분포로의 결정적 매핑(deterministic mapping)이다.**

---

> **1. 추론(생성)의 단계**  
> 학습이 완료된 후에는 인코더는 사용하지 않는다.  
> 잠재공간에서 직접 $z \sim \mathcal{N}(0, I)$ 를 샘플링한다.  
> 이는 학습 과정의 KL 발산 항이 $q_\phi(z \mid x)$ 를 $p(z)$ 와 유사하게 만들도록  
> 인코더를 학습시켰기 때문에 가능하다.  
> 따라서 학습이 끝난 뒤 $p(z)$ 에서 샘플링하는 것은  
> 실제 데이터 공간에서 의미 있는 위치를 선택하는 것과 같다.  
> 이렇게 얻은 $z$ 를 디코더 $g_\theta(z)$ 에 입력하면  
> 새로운 샘플을 생성할 수 있다.
>
> **2. 학습 전과 학습 후의 차이**  
> 학습 전에는 $\mathcal{N}(0, I)$ 가 단순한 랜덤 노이즈일 뿐이며  
> 그 안의 점들은 의미가 없다.  
> 학습 후에는 인코더 $q_\phi(z \mid x)$ 가 데이터를 잠재공간으로  
> 의미 있게 매핑하고, KL 발산 항이 이 공간을 정규분포 형태로 정렬한다.  
> 그 결과 $\mathcal{N}(0, I)$ 상의 점들은 실제 데이터의  
> 의미적 표현을 반영하는 좌표가 된다.  
> 즉, 학습 전에는 의미 없던 점들이  
> 학습 후에는 데이터 구조를 보존하는 의미 있는 코드가 된다.
>
> **3. 디코더의 역할**  
> 디코더는 결정적 함수로, $z$ 를 입력받아  
> $p_\theta(x \mid z)$ 혹은 그 평균을 생성한다.  
> 같은 $z$ 에 대해 같은 출력이 생성되지만,  
> $z$ 자체가 확률적으로 샘플링되므로  
> 전체 모델은 확률적 생성 모델 성격을 유지한다.
>
> **4. 요약**  
> 학습 중에는 인코더·디코더가 함께 작동하여  
> 데이터 구조를 정규분포 형태의 잠재공간으로 매핑한다.  
> 학습이 끝난 뒤에는 $\mathcal{N}(0,I)$ 자체가 의미 있는 잠재공간이 되므로  
> 인코더 없이 디코더만으로 새로운 샘플을 생성할 수 있다.

---

## p29. 개요 (Overview)

- 인코더(encoder): 데이터 분포를 잠재 분포로 매핑함  

- 디코더(decoder): 잠재 분포를 데이터 분포로 매핑함  

<img src="/assets/img/lecture/probstat/9/image_26.png" alt="image" width="800px">

---

> **1. 전체 구조의 흐름**  
> 입력 데이터 $x$ 는 인코더 $q_\phi(z \mid x)$ 를 거쳐 잠재 변수 $z$ 의 확률분포로 변환된다.  
> 이 분포는 데이터의 내재된 구조나 의미적 특성을 요약한 표현이다.  
> 인코더를 통해 얻은 $z$ 는 잠재 공간에서의 점이며,  
> 이 공간 전체가 표준 정규분포 $\mathcal{N}(0, I)$ 형태로 정렬되도록 학습된다.  
> 이후 디코더 $p_\theta(x \mid z)$ 는 이 $z$ 로부터 원래 데이터 분포를 복원하여  
> $x'$ 를 생성하는 과정을 학습한다.
>
> **2. 인코더와 디코더의 관계**  
> 인코더는 데이터 분포 $p_{\text{data}}(x)$ 를 잠재 분포 $q_\phi(z)$ 로 압축하는 역할을 한다.  
> 이는 고차원 데이터(이미지, 음성, 언어 등)를 의미적으로 요약된 표현으로 변환하는 과정이다.  
> 디코더는 이 잠재 분포를 다시 데이터 분포 $p_\theta(x)$ 로 확장하여  
> 원본 데이터에 가까운 샘플을 생성한다.  
> 이 과정이 VAE가 생성 모델로 기능하는 핵심이다.
>
> **3. 학습의 목표**  
> 학습 과정에서 인코더와 디코더는 상호 보완적으로 최적화된다.  
> 인코더는 $x \rightarrow z$, 디코더는 $z \rightarrow x'$ 를 수행하며  
> 두 네트워크는 $p_{\text{data}}(x)$ 와 모델 분포 $p_\theta(x)$ 가  
> 최대한 유사해지도록 동시에 학습된다.
>
> **4. 요약적 해석**  
> 인코더는 데이터 공간에서 잠재 공간으로의 압축(encoding)을 담당하고,  
> 디코더는 잠재 공간에서 데이터 공간으로의 복원(decoding)을 담당한다.  
> 결국 VAE는  
> 데이터 ↔ 잠재 표현 ↔ 데이터  
> 로 이어지는 양방향 확률적 매핑을 학습하는 모델이다.

---

## p30. 변분 오토인코더 (Variational Autoencoder)

- 인코딩된 잠재 분포(encoded latent distribution):

  $$
  q_\phi(z)
  =
  \int_x q_\phi(z \mid x) \, p_{\text{data}}(x) \, dx
  $$

<img src="/assets/img/lecture/probstat/9/image_27.png" alt="image" width="800px">

---

> **1. 인코딩된 잠재 분포의 의미**  
> $q_\phi(z)$ 는 전체 데이터 분포 $p_{\text{data}}(x)$ 에 대해  
> 인코더가 생성한 잠재 변수 분포들의 평균적 형태를 나타낸다.  
> 즉, 각 데이터 $x$ 가 인코더를 거쳐 $z$ 로 변환될 때  
> 그 모든 $z$ 들이 형성하는 전역적 분포 구조를 의미한다.  
> 이 관계는  
>
> $$
> q_\phi(z)=\mathbb{E}_{x \sim p_{\text{data}}(x)}[\,q_\phi(z \mid x)\,]
> $$  
>
> 으로 표현되며, 인코더가 전체 데이터셋을 통해 형성한  
> 잠재공간의 전역 구조를 나타낸다.
>
> **2. $p(z)$ 와 $q_\phi(z)$ 의 관계**  
> $p(z)$ 는 사전에 정의한 단순한 분포(prior)로 보통 $\mathcal{N}(0, I)$ 이다.  
> 이는 학습의 기준점 역할을 한다.  
> 반면 $q_\phi(z)$ 는 실제 데이터에서 인코더가 추정한 복잡한 잠재 분포이다.  
> KL 발산 항 $D_{KL}(q_\phi(z)\,\|\,p(z))$ 이 이를 최소화하도록 유도하여  
> 학습이 진행될수록 $q_\phi(z)$ 가 $p(z)$ 와 유사해지도록 만든다.  
> 따라서 이 KL 항은 잠재공간을 정규화하는 정규화 제약이다.
>
> **3. 전체 흐름의 의미**  
> 1) 데이터 분포 $p_{\text{data}}(x)$ 에서 샘플된 $x$ 가  
>    인코더를 통해 $q_\phi(z \mid x)$ 로 변환된다.  
> 2) 이를 모든 $x$ 에 대해 통합하면 전체 잠재 분포 $q_\phi(z)$ 가 형성된다.  
> 3) KL 발산 항은 $q_\phi(z)$ 가 $p(z)$ 와 유사해지도록 학습을 유도한다.  
> 4) 디코더 $p_\theta(x \mid z)$ 는 잠재 변수로부터 데이터 분포를 복원한다.
>
> **4. 직관적 해석**  
> 인코더는 실제 데이터 분포를 잠재 변수 분포 $q_\phi(z)$ 로 변환하고,  
> KL 발산 항은 이를 정규분포 $p(z)$ 에 정렬한다.  
> 이 과정 덕분에 복잡한 데이터의 구조가 단순하고 해석 가능한 잠재공간으로 매핑된다.  
> 결국 VAE는  
> “데이터 분포 → 인코더 → 잠재공간 정규화 → 디코더 → 복원된 데이터 분포”  
> 로 이어지는 완전한 확률적 경로를 학습한다.

---

## p31. 예시 그림 (Example Illustration)

<img src="/assets/img/lecture/probstat/9/image_28.png" alt="image" width="600px">

- 각 데이터 포인트 $x_1$, $x_2$, $x_3$ 는  
  인코더 $q_\phi(z \mid x)$ 를 통해  
  잠재공간(latent space)의 분포 $q_\phi(z \mid x_i)$ 로 매핑된다.

- 각 분포 $q_\phi(z \mid x_i)$ 는  
  잠재공간 내에서 서로 다른 위치에  
  데이터의 의미적 특징을 반영하여 분포하게 된다.

- 디코더는 각 $z$ 로부터 대응되는  
  **재구성된 데이터(generated data)** 를 복원한다.

---

> **1. 데이터 포인트와 잠재 분포의 대응 관계**  
> 원래의 데이터 포인트 $x_i$ 들은 인코더를 통과하면서 각각 잠재 분포 $q_\phi(z \mid x_i)$ 로 표현된다.  
> 이 분포들은 데이터의 고유한 특성을 반영하며, 비슷한 데이터일수록 잠재공간에서 가까운 위치를 갖는다.  
> 예를 들어 $x_1, x_2, x_3$ 가 유사한 클래스에 속하면,  
> 이들의 잠재 분포 $q_\phi(z \mid x_i)$ 는 잠재공간에서 서로 겹치거나 인접한 영역에 위치하게 된다.
>
> **2. 생성 과정의 시각적 의미**  
> 각 $q_\phi(z \mid x_i)$ 에서 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 를 통해  
> 재구성된 데이터 $\hat{x}_i$ 를 생성한다.  
> 이 과정 전체가 “입력 데이터 → 잠재공간 표현 → 데이터 복원”이라는  
> 확률적 생성 경로를 학습하는 것이다.
>
> **3. 이상치 탐지(Anomaly Detection)와의 연관**  
> VAE는 정상 데이터의 분포를 학습하므로 정상 데이터는 잠재공간에서 $p(z)$ 근처에 정렬된다.  
> 반면 이상치는 학습된 $q_\phi(z)$ 와 잘 맞지 않아 낮은 복원 확률을 가지게 된다.  
> 따라서 VAE는 복원 오차나 잠재 확률을 기반으로 이상치를 탐지하는 데 활용될 수 있다.
>
> **4. 데이터 정화(Purification) 관점**  
> 입력 데이터가 노이즈를 포함하거나 왜곡되었더라도,  
> 인코더를 거쳐 잠재공간으로 투영되고 디코더를 통해 복원되는 과정에서  
> 학습된 데이터 분포에 맞춰 정제된 형태로 출력될 수 있다.  
> 즉, VAE는 생성 모델임과 동시에 데이터 복원 및 정화 모델로도 작동할 수 있다.

---

## p32. MNIST의 2차원 잠재공간 (2D Latent Space on MNIST)

<img src="/assets/img/lecture/probstat/9/image_29.png" alt="image" width="800px">

왼쪽: 각 숫자 클래스(0~9)가 인코딩된 잠재변수 공간의 분포  
오른쪽: 잠재공간 상의 위치에 따라 디코더가 생성한 숫자 이미지

---

> **1. 잠재공간의 구조**  
> 이 그림은 MNIST 데이터셋으로 VAE를 학습한 뒤 잠재공간(latent space)을 2차원으로 시각화한 결과이다.  
> 각 점은 인코더 $q_\phi(z \mid x)$ 를 통해 얻어진 잠재벡터 $z$ 를 나타내며,  
> 점의 색깔은 해당 데이터의 실제 숫자 레이블(0~9)에 대응된다.  
> 서로 유사한 숫자들은 잠재공간에서 인접한 영역에 분포하며,  
> 클래스 간 경계도 매끄럽게 이어진다.
>
> **2. 연속적(latent-continuous)인 공간의 특징**  
> 잠재공간이 2차원으로 제한되어 있음에도 각 숫자 클래스는 클러스터 형태로 잘 구분된다.  
> 또한 그 사이 영역에서도 연속적인 변형이 가능하다.  
> 잠재공간의 한 점에서 인접한 점으로 이동하면  
> 디코더가 생성하는 숫자의 형태가 점진적으로 변화하며,  
> “6 → 0”, “4 → 9” 등 자연스러운 전이가 나타난다.  
> 이러한 연속성은 라벨을 사용하지 않는 unconditional VAE에서도  
> 잠재공간이 구조적으로 정렬되도록 학습되었음을 의미한다.
>
> **3. 잠재공간이 의미를 갖게 되는 이유**  
> 학습 전의 $z \sim \mathcal{N}(0,I)$ 샘플들은 단순한 무작위 가우시안이다.  
> 그러나 학습이 진행되면 인코더 $q_\phi(z \mid x)$ 가 데이터 구조를 반영하여  
> $p(z)$ 공간에 의미 있는 좌표계를 형성하게 된다.  
> 그 결과 잠재공간의 각 영역은 특정 숫자 형태나 패턴을 나타내는  
> 의미적 지역(semantic region)으로 변환된다.
>
> **4. 응용: 이상치 탐지 및 데이터 보간**  
> 잠재공간이 구조적으로 정렬되어 있으므로  
> 이상치 탐지(anomaly detection)나 데이터 보간(interpolation)이 가능하다.  
> 학습된 분포 영역 바깥의 $z$ 에서 생성된 샘플은  
> 비정상적이거나 왜곡된 형태를 띠므로,  
> 이는 VAE가 학습 데이터 분포를 벗어난 입력을 탐지하는 근거가 된다.

---
layout: post
title: "[확률과 통계] 9주차"
date: 2025-10-28 23:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. 생성 모델의 일반 개념 (General Concept of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_1.png" alt="image" width="600px">

---

> - 이 그림은 **생성 모델(Generative Model)**의 일반적인 구조를 나타낸다.  
> - 생성 모델은 이름 그대로 **데이터를 생성**하는 모델이며, 예를 들어 텍스트가 주어지면 그에 대응하는 **이미지나 형태(Shape)**를 만들어내는 방식으로 동작한다.  
> - 이러한 모델의 핵심 구성요소는 **생성자(Generator)**이며, 실제로 데이터를 만들어내는 역할을 담당한다.  
>
> **1. 생성자의 두 가지 입력**  
> - 생성자에는 다음 두 종류의 입력이 존재한다.  
>  
>   1) **조건부 입력(conditional input)**  
>      - “Bird(새)” 같은 단어, 텍스트 토큰(token) 시퀀스 등이 해당한다.  
>      - 이미지 생성 모델에서는 텍스트나 개념(Concept)을 벡터로 표현한 형태가 입력된다.  
>  
>   2) **무작위 입력(random input)**  
>      - 생성 모델이 확률적 특성을 가지기 때문에 **랜덤성(randomness)**을 포함해야 한다.  
>      - 이는 **랜덤 변수(latent variable)**로 표현되며, 그림 속 주사위는 이러한 확률적 입력을 상징한다.  
>
> **2. 무작위 입력의 필요성**  
> - 무작위 입력은 생성 모델이 항상 같은 이미지만 반복해서 생성하는 것을 방지한다.  
> - 예를 들어 조건이 “Bird”여도, 랜덤성을 통해 다양한 새의 형태를 만들어낼 수 있다.  
> - 즉, **변형(variation)**과 **다양성(diversity)**을 표현하는 핵심 요소이다.  
>
> **3. 개념적 정리**  
> - 생성 모델은 **조건부 정보(conditional information)**와 **확률적 요소(randomness)**를 결합하여  
>   주어진 조건에 맞으면서도 다양한 샘플들을 생성하도록 학습된 모델이다.    

---

## p3. 생성 모델의 확률적 표현 (Probabilistic Representation of Generative Models)  

<img src="/assets/img/lecture/probstat/9/image_2.png" alt="image" width="600px">

---

> - 현대적인 생성 모델(Generative Model)은 기본적으로 확률적 랜덤성을 입력으로 받는 **파이프라인 구조**를 가진다.  
> - 그림에서 주사위는 **랜덤 변수(random variable)**를 상징하며, 각각의 랜덤 변수는 생성될 이미지의 특정 속성(feature)에 영향을 준다.  
>   - 예:  
>     - 첫 번째 랜덤 변수 → 색상(color)  
>     - 두 번째 랜덤 변수 → 각도(angle)  
>     - 세 번째 랜덤 변수 → 크기(size)  
> - 즉, 랜덤성의 여러 요소가 이미지의 다양한 속성을 **통계적으로 결정하는 역할**을 한다.  
>
> **고차원 확률 공간에서의 랜덤 벡터**  
> - 이러한 랜덤 변수들은 하나의 값이 아니라 **고차원(high-dimensional) 확률 공간**에서 정의된다.  
> - 생성 모델의 입력으로 사용되는 랜덤 벡터는 보통  
>   **다변량 가우시안 분포(multivariate Gaussian distribution)**  
>   를 따른다.  
> - 이 벡터의 각 차원은 처음에는 아무 의미가 없지만, 학습을 거치면서  
>   특정한 **의미적 속성(semantic feature)**과 점차 연관된다.  
>
> **학습이 진행되며 형성되는 의미적 구조**  
> - 훈련 초기에는 벡터의 축이  
>   “이 차원은 색상”, “이 차원은 각도” 같은 의미를 갖지 않는다.  
> - 하지만 모델이 충분히 학습되면  
>   - 첫 번째 차원 → 색상 변화  
>   - 두 번째 차원 → 각도 변화  
>   - 세 번째 차원 → 크기 변화  
>   와 같은 방식으로 **데이터의 실제 속성과 대응되는 의미적 구조가 자연스럽게 형성된다.**  
>
> **핵심 요약**  
> - 생성 모델은 명시적으로 피처(feature)를 지정하지 않아도,  
>   학습 과정에서 **의미적 공간(semantic space)을 스스로 조직**한다.  
> - 이는 생성 모델의 매우 흥미로운 특성 중 하나로,  
>   고차원 확률 벡터가 데이터의 속성과 자연스럽게 연결되는 과정을 보여준다.    

---

## p4. 데이터 생성기의 분류 (Categorization of Data Generators)  

두 가지 접근 방식이 있다.  

1. **직접 접근(Direct approach)**: 데이터를 직접 생성하는 함수를 학습한다.  
(혼동스럽게도, 때때로 “암묵적 생성 모델(implicit generative model)”이라고도 불린다.)

   $$
   G : \mathcal{Z} \rightarrow \mathcal{X}
   $$

2. **간접 접근(Indirect approach)**: 데이터를 평가(score)하는 함수를 학습하고,  
   이 함수 아래에서 점수가 높은 지점을 찾아 데이터를 생성한다.  

   $$
   E : \mathcal{X} \rightarrow \mathbb{R}
   $$

---

> - 데이터 생성 모델은 **직접 접근 방식**과 **간접 접근 방식**으로 나눌 수 있으며,  
>   두 방식은 데이터가 생성되는 함수의 구조와 확률적 정보의 사용 방식에서 차이가 있다.  
>
> **1. 직접 접근 (Direct Approach)**  
> - 정의: 랜덤 변수 $\mathbf{z}$를 입력받아 **데이터를 직접 생성하는 함수**를 학습한다.  
> - 예: $G(\mathbf{z}) = \mathbf{x}$ 와 같이, 생성자 $G$가 잠재변수로부터 바로 샘플을 만든다.  
> - 대표 모델: GAN, VAE(직접/간접 사이의 중간적 성격)  
> - 특징:  
>   - $\mathbf{z}$가 주어지면 즉시 $G(\mathbf{z})$가 데이터가 된다.  
>   - 명시적 확률분포를 쓰지 않아도 모델이 데이터를 생성할 수 있다.  
>   - 그래서 **암묵적 생성 모델(implicit generative model)**이라고도 불린다.  
>
> **2. 간접 접근 (Indirect Approach)**  
> - 정의: 데이터를 직접 생성하지 않고, 데이터의 **좋은 정도(goodness)** 혹은 우도(likelihood)를 평가하는  
>   스코어(score) 또는 에너지(energy) 함수를 학습한다.  
> - 대표 모델: Diffusion model, Energy-based model, Score-based model  
> - 특징:  
>   - 단순히 $\mathbf{z}$를 한 번 네트워크에 넣어 결과를 만드는 방식이 아니다.  
>   - 여러 단계의 파이프라인을 거쳐 점진적으로 데이터를 생성한다.  
>   - 생성 과정 내내 **에너지 함수 $E(\mathbf{x})$** 또는 **스코어 함수**를 이용하여  
>     생성된 샘플이 “얼마나 데이터처럼 보이는지”를 평가하며 수정한다.  
>
> **3. 정리 및 비교**  
> - 직접 접근: 생성 함수 $G$를 통해 **바로 데이터 생성**  
> - 간접 접근: 평가 함수 $E$를 통해 **생성 과정을 단계적으로 조정**  
> - VAE: 두 방식의 중간.  
>   - 확률적 인코더–디코더 구조를 사용하여 데이터를 생성하고  
>   - 잠재 공간의 분포까지 명시적으로 모델링한다.    

---

## p5. 직접 접근(Direct Approach)의 학습과 샘플링 과정  

<img src="/assets/img/lecture/probstat/9/image_3.png" alt="image" width="600px">

---

> - 생성 모델의 전체 과정은 **학습(Training)** 단계와 **샘플링(Sampling)** 단계로 나눌 수 있다.  
> - 학습 단계는 주어진 **데이터셋(Data)**을 기반으로 **모델 파라미터(θ)**를 학습하는 과정이며,  
>   샘플링 단계는 학습된 파라미터를 이용해 새로운 데이터를 생성하는 과정이다.  
>
> **1. 학습(Training) 단계**  
> - 왼쪽의 데이터셋은 사람 얼굴 이미지 같은 실제 데이터를 의미한다.  
> - **Learner**(또는 생성 네트워크)는 이 데이터로부터 **최적 파라미터 θ**를 학습한다.  
> - 학습된 파라미터 θ는 생성기(generator)의 내부 가중치가 된다.  
> - 즉, 학습 단계는 “주어진 데이터로부터 새로운 데이터를 어떻게 생성할 것인가”를 배우는 과정이다.  
>
> **2. 샘플링(Sampling) 단계**  
> - 학습이 끝난 후, 추론 시점(test time)에는 학습된 파라미터 θ를 고정한다.  
> - 대신 **랜덤 변수 $z$**를 입력으로 넣어 생성기를 작동시킨다.  
> - 이 랜덤 벡터 $z$는 잠재 공간(latent space)에서 온 확률적 입력이며,  
>   이를 생성기(또는 디코더) $g_\theta$에 통과시키면 새로운 샘플이 생성된다:  
>
>   $$
>   \mathbf{x}_{\text{sample}} = g_\theta(\mathbf{z})
>   $$  
>
> - 즉, 학습된 모델은 랜덤성을 바탕으로 새로운 데이터를 생성하는 역할을 수행한다.  
>
> **3. 분류(classification) 문제와의 차이**  
> - 일반적인 분류 모델은 학습 단계와 추론 단계의 입력–출력 구조가 거의 동일하다.  
> - 반면 생성 모델은 **학습 파이프라인과 샘플링 파이프라인이 분리**되어 있다는 점에서 구조적으로 다르다.  
>   - 학습 단계: 데이터로부터 파라미터를 학습  
>   - 샘플링 단계: 확률적 입력으로부터 새로운 데이터 생성  
> - 이러한 구조적 분리는 생성 모델의 중요한 특징이며,  
>   **트레이닝 파이프라인과 생성 파이프라인이 서로 다른 역할을 수행한다는 점**을 이해하는 것이 핵심이다.    

---

## p6. 간접 접근 (Indirect Approach)  

<img src="/assets/img/lecture/probstat/9/image_4.png" alt="image" width="600px">

---

> - 간접 접근(Indirect Approach)은 데이터를 직접 생성하지 않고,  
>   데이터의 “좋은 정도(goodness)”를 평가하는 **스코어링 함수(scoring function)**를 학습하는 방식이다.  
> - 이 스코어링 함수는 모델에 따라 **우도(likelihood)**, **에너지(energy)**, **스코어(score)** 개념으로 해석된다.  
>
> **1. 학습(Training) 단계**  
> - 데이터셋 $\{\mathbf{x}^{(i)}\}_{i=1}^N$ 을 기반으로 **학습자(Learner)** 가  
>   각 데이터의 위치에서의 확률적 “품질”을 평가하는 함수를 학습한다.  
> - 모델 종류에 따라 학습되는 함수가 다르다.  
>   - 에너지 기반 모델(Energy-based model):  
>     - 실제 데이터의 **에너지 $E_\theta(\mathbf{x})$를 낮추고**,  
>       비현실적 샘플의 에너지는 높이는 방식으로 학습한다.  
>   - 스코어 기반 모델(Score-based model):  
>     - 데이터의 로그 확률의 기울기  
>       **스코어 $\nabla_{\mathbf{x}}\log p_\theta(\mathbf{x})$** 를 직접 근사한다.  
> - 학습 결과, 모델은 “어떤 데이터가 더 자연스럽고 가능성 높은가”를 구분할 수 있는 함수를 얻게 된다.  
>
> **2. 샘플링(Sampling) 단계**  
> - 학습된 스코어 함수 또는 에너지 함수를 활용하여  
>   새로운 데이터를 생성하기 위해 **샘플링 알고리즘**을 사용한다.  
> - 대표적으로 **MCMC(Markov Chain Monte Carlo)** 기반의 절차를 사용하며,  
>   이는 스코어가 높은 영역(즉, 실제 데이터와 가까운 영역)을 따라 샘플을 만들어낸다.  
> - 수식적으로는  
>
>   $$
>   \{\hat{\mathbf{x}}^{(i)}\}_{i=1}^N \sim p_\theta(\mathbf{x}) \propto \exp(-E_\theta(\mathbf{x}))
>   $$  
>
>   와 같이, 에너지가 낮은 샘플일수록 생성될 확률이 높아진다.  
>
> **3. 직접 접근과의 비교**  
> - 직접 접근: 랜덤 변수 $z$를 입력으로 받아 **데이터를 바로 생성**하는 함수 $G$를 학습한다.  
> - 간접 접근: 데이터의 “품질” 평가 함수(스코어 또는 에너지)를 학습한 뒤,  
>   그 함수를 기반으로 **샘플링 알고리즘**을 통해 데이터를 생성한다.  
> - 즉, 직접 접근은 “데이터 생성 함수”를 학습하는 것이고,  
>   간접 접근은 “데이터의 좋은 정도를 평가하는 함수”를 학습한 뒤  
>   그 함수에 맞추어 데이터를 찾아가는 방식이다.  
>
> - 이러한 간접 접근 방식은 **Diffusion Model**, **Energy-based Model**, **Score-based Model** 등의 핵심 이론적 배경이 되며,  
>   이후 등장하는 현대 생성 모델들의 토대가 된다.    

---

## p7. 생성 모델 (Generative Models)  

목표는 학습 데이터를 그대로 복제하는 것이 아니라,  
**새로운(new)** 데이터를 만드는 것이다.  
그 데이터는 **현실적인(realistic)** 데이터여야 하며,  
실제 데이터의 **본질적인 속성(essential properties)**을 포착해야 한다.  

이것을 정량화하는 한 가지 방법은  
모델 하에서의 **테스트 데이터의 가능도(likelihood)**를 이용하는 것이다.  
(학습 데이터를 기억하는 모델은,  
분류기(classifier)가 과적합(overfit)되는 것과  
정확히 같은 의미에서 과적합된 것이다.)  

$$
\{x_{\text{test}}^{(i)}\}_{i=1}^{N}, \quad x_{\text{test}}^{(i)} \sim p_{\text{data}}
$$  

$$
\text{generalization error} = \sum_i \log p_\theta (x_{\text{test}}^{(i)})
$$  

---

> - 생성 모델의 목표는 학습 데이터를 그대로 복제하는 것이 아니라,  
>   학습 데이터의 분포를 포착하여 **그와 닮은(realistic)** 새로운 데이터를 생성하는 것이다.  
>
> - 학습 데이터를 완벽히 재현하는 모델은 데이터를 단순히 암기한 것이며,  
>   이는 분류기에서의 과적합(overfitting)과 동일한 문제다.  
>
> - 좋은 생성 모델은 학습 데이터 분포를 일반화(generalization)하여  
>   보지 못한 데이터(test data)에 대해서도 높은 가능도(likelihood)를 부여해야 한다.  
>
> - GPT 같은 대형 언어 모델 또한 생성 모델의 예로,  
>   기존 문장을 복사하지 않고 학습된 통계적·의미적 구조를 활용해  
>   새로운 문장을 만들어낸다.  
>   - 이때 새로운 문장이 현실 지식과 조화를 이루면 **창의적 일반화(extrapolation)**로 볼 수 있지만,  
>     현실과 어긋나면 **할루시네이션(hallucination)**으로 간주된다.  
>
> - 따라서 생성 모델의 성능 평가는  
>   “학습 데이터를 얼마나 잘 복제했는가?”가 아니라  
>   “데이터의 본질적 분포를 얼마나 잘 포착했는가?”,  
>   “얼마나 현실적인 새로운 데이터를 만들어내는가?”에 초점을 맞춘다.  
>
> - 테스트 데이터의 로그 가능도(log-likelihood)는  
>   이러한 일반화 능력을 평가하는 핵심 지표이다.  
>   - 일반화 오차(generalization error)가 0이면  
>     학습 데이터와 테스트 데이터가 완전히 일치한다는 의미로, 이는 과적합 상태다.  
>   - 오차가 너무 크면 학습된 분포를 벗어나 비현실적인 데이터를 생성할 위험이 있다.  
>
> - 결국 생성 모델의 목표는  
>   **현실적인(realistic) 데이터 생성**과  
>   **새로운 정보 창출(extrapolation)** 사이의 균형을 유지하는 것이다.    

---

## p8. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_5.png" alt="image" width="600px">

---

> - 밀도 기반 모델(Density-based Model)은 데이터의 **확률 밀도(probability density)**를 직접 모델링하는 생성 모델이다.  
> - 확률 밀도 함수 $p_\theta(x)$는 모든 가능한 $x$에 대해 정의되며, 값의 범위는 $[0,\infty)$이다.  
>
> - 학습 데이터 $$\{x^{(i)}\}_{i=1}^N$$ 이 주어지면,  
>   모델은 이 데이터들이 나타날 확률 밀도 $p_\theta(x)$를 **최대화**하도록 학습된다.  
>
> - 즉, 모델은  
>   - 학습 데이터 근처에서는 높은 밀도를 갖도록 하고  
>   - 전체 공간에서의 확률 밀도 적분이 1이 되도록 조정한다.  
>   - 이는 확률 밀도 함수의 기본 성질인 “전체 영역에서의 면적이 1”이라는 조건을 그대로 따른다.  
>
> - 따라서 밀도 기반 모델의 핵심은  
>   주어진 데이터 분포를 잘 근사하도록 하는 **연속적인 확률 밀도 함수 $p_\theta(x)$**를 학습하는 것이다.  
>
> - 이러한 접근은 생성 모델 평가에서 사용되는 **우도(likelihood)** 기반 평가와 직결되며,  
>   모델이 학습 데이터의 분포를 얼마나 정확히 설명하는지를 수치적으로 평가할 수 있게 해준다.    

---

## p10. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_6.png" alt="image" width="600px">

---

> - 그림은 확률 밀도 함수 $p_\theta(x)$의 형태를 나타낸 것이다.  
> - **Constant mass(질량 보존)**은 전체 확률 질량(probability mass), 즉  
>   확률 밀도의 적분값이 항상 1로 유지되어야 한다는 의미이다.  
> - 따라서 특정 구간에서 밀도가 높아지면,  
>   다른 구간에서는 밀도가 낮아져 전체 면적(확률의 총합)이 일정하게 유지된다.  
> - 이 원리는 모든 확률 밀도 기반 생성 모델이 반드시 따라야 하는  
>   기본적인 확률적 제약 조건이다.    

---

## p11. 밀도 기반 모델 (Density-based Models)  

<img src="/assets/img/lecture/probstat/9/image_7.png" alt="image" width="800px">

$$
\begin{aligned}
p_\theta^* 
&= \arg \min_{p_\theta} \text{KL}(p_{\text{data}}, p_\theta) \\
&= \arg \min_{p_\theta} \mathbb{E}_{x \sim p_{\text{data}}} 
   \left[- \log \frac{p_\theta(x)}{p_{\text{data}}(x)} \right] \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ] 
   - \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_{\text{data}}(x) ]  
   \quad\quad\quad \text{(max likelihood)} \\
&= \arg \max_{p_\theta} 
   \mathbb{E}_{x \sim p_{\text{data}}} [ \log p_\theta(x) ]
   \quad\quad\quad \text{(두 번째 항은 } p_\theta \text{에 의존하지 않기 때문에 생략)} \\
&\approx \arg \max_{p_\theta} 
   \frac{1}{N} \sum_{i=1}^{N} \log p_\theta(x^{(i)})
\end{aligned}
$$  

---

> - 밀도 기반 모델은 데이터의 확률 밀도 함수 $p_\theta(x)$를 직접 추정하는 생성 모델이다.  
> - 학습의 목적은 실제 데이터 분포 $p_{\text{data}}$와 모델 분포 $p_\theta$의 차이(KL divergence)를 최소화하는 것이다.  
>
> - 직관적으로는  
>   - 데이터가 존재하는 구간에서는 확률 밀도를 높게,  
>   - 데이터가 없는 구간에서는 확률 밀도를 낮게 평가하도록 학습된다.  
> - 이를 통해 모델은 학습 데이터의 분포를 따라가도록 확률 질량을 재분배하게 된다.  
>
> - 오른쪽 그림에서  
>   - 회색 곡선은 모델 분포 $p_\theta$,  
>   - 점과 초록색 화살표는 실제 데이터 분포 $p_{\text{data}}$를 나타낸다.  
>   - 학습이 진행되면 데이터가 있는 구간(초록색 영역)에서는 확률이 증가하고,  
>     데이터가 없는 구간(빨간색 영역)에서는 확률이 감소한다.  
>
> - 이러한 최적화는 반복적인 최대 우도 추정(maximum likelihood estimation) 과정을 통해 점진적으로 수행된다.  
>
> - 최적의 분포 $p_\theta^*$는 다음과 같이 KL 발산을 최소화하는 분포이다.  
>
>   $$
>   p_\theta^* = \arg\min_{p_\theta} \mathrm{KL}(p_{\text{data}}\,||\,p_\theta)
>   $$
>
> - 이 식을 전개하면 로그 가능도(log-likelihood)를 최대화하는 형태가 된다.  
>
> - 즉, 최대우도추정(MLE)은 데이터가 모델에서 나올 가능도를 가장 크게 만드는 확률 밀도 함수를 찾는 과정이며,  
>   이는 KL 발산 최소화와 동등하다.  
>
> - 이러한 원리는 에너지 기반 모델(Energy-based Model)이나  
>   디퓨전 모델(Diffusion Model)에서도 동일하게 적용되어  
>   모델이 학습 데이터 분포를 점진적으로 근사하도록 만든다.    

---

## p12. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

<img src="/assets/img/lecture/probstat/9/image_8.png" alt="image" width="480px">

---

> - 그림에서는 데이터 생성 과정을 **잠재 변수 $z$**와 **관측 변수 $x$**로 구분하여 표현한다.  
> - **$z$ (latent variable)**은 데이터의 내재된 요인들을 의미하며,  
>   이미지의 경우 **자세(pose)**, **크기(size)**, **색상(color)**, **종(breed)** 등  
>   눈에 보이지 않는 속성들이 이에 해당한다.  
> - 이러한 잠재 변수들은 사람이 직접 정의하지 않아도  
>   모델이 학습 과정에서 스스로 의미 있는 형태로 인코딩한다.  
>
> - **$x$ (observed variable)**은 실제로 관측 가능한 데이터이며  
>   이미지, 영상, 오디오 등 현실에서 수집된 데이터가 여기에 포함된다.  
>
> - **Generator(생성기)**는 잠재 변수 $z$를 입력받아 실제 데이터 $x$를 생성하는 역할을 한다.  
>   즉, $z \rightarrow x$ 로 이어지는 매핑(mapping)을 학습하여  
>   확률적 생성 과정을 통해 새로운 데이터를 만들어낸다.  
>
> - 이 구조는 이미지 생성뿐 아니라  
>   **물리 기반 모델(physics model)**, **렌더러(renderer)**, **월드 모델(world model)** 등  
>   다양한 생성 시스템에 공통적으로 적용된다.  
> - 다시 말해, 현대의 생성 모델들은  
>   **잠재 공간(latent space)**에서 **관측 공간(observed space)**으로  
>   데이터를 변환하는 동일한 구조적 원리를 공유한다.  
>
> - 따라서 변분 오토인코더(VAE)는  
>   이러한 **직접 생성 접근(direct approach)**의 대표적인 모델로,  
>   잠재 변수 $z$를 이용해 관측 변수 $x$를 생성하는 구조를 따른다.    

---

## p13. 변분 오토인코더 (Variational Autoencoder)  

데이터 생성 과정을 다음과 같이 가정한다.  

- $z$: 잠재 변수(latent variables)  
- $x$: 관측 변수(observed variables)  

잠재 변수는 사전 분포(prior distribution)로부터 샘플링된다.  

$$
z \sim p(z)
$$  

그리고 생성기(generator)는 잠재 변수 $z$를 입력으로 받아  
관측 변수 $x$의 분포(distribution)를 생성한다.  

<img src="/assets/img/lecture/probstat/9/image_9.png" alt="image" width="720px">

---

> - 이 그림은 **데이터 생성의 확률적 구조**를 보여준다.  
>   즉, 단순한 분포로부터 복잡한 실제 데이터 분포로의 매핑(mapping)이  
>   **생성기(generator)**를 통해 이루어진다는 점을 시각적으로 표현한 것이다.  
>
> - **잠재 변수 $z$**는 사전에 정의된 단순한 확률 분포(예: 표준 정규분포)에서 샘플링된다.  
>   이 분포는 **정보가 거의 없는 단순 구조**이며,  
>   학습 이전에는 실제 데이터에 대한 의미를 전혀 담고 있지 않다.  
>
> - **생성기(generator)**는 이러한 단순 분포 $p(z)$를  
>   실제 데이터의 복잡한 분포 $p(x)$로 변환하도록 학습된다.  
>   즉, $z$ 공간의 간단한 형태를 **비선형 매핑**을 통해  
>   현실적인 고차원 데이터 분포로 바꾸는 역할을 한다.  
>
> - 현실 데이터의 분포 $p(x)$는 매우 **복잡하고 다봉(multimodal)** 구조를 가진다.  
>   여러 지역적 패턴, 여러 개의 모드(mode), 로컬 최대점들이 존재하며,  
>   이러한 복잡성을 생성 모델이 학습을 통해 근사해야 한다.  
>
> - 따라서 VAE의 생성 과정은 수학적으로 보면  
>   단순한 확률 분포(예: $p(z)$)를  
>   복잡한 실제 데이터 분포(예: $p(x)$)로 매핑하는 확률적 변환으로 이해할 수 있다.  
>
> - 결국 **단순한 잠재 공간 → 복잡한 데이터 공간**으로 이어지는  
>   이 확률적 변환 구조가 생성 모델(generative model)의 핵심 개념이다.    

---

## p14. 변분 오토인코더 (Variational Autoencoder)  

신경망(neural network)을 이용하여 확률 분포(distribution)를 표현한다.  

- $ \theta $ : 학습 가능한 파라미터(learnable parameters)  
- 표현되는 함수:  

  $$
  p_\theta(x \mid z)
  $$  

<img src="/assets/img/lecture/probstat/9/image_10.png" alt="image" width="600px">

---

> - **생성기(generator)**는 확률적 함수 $p_\theta(x \mid z)$로 표현되며,  
>   이는 **잠재 변수 $z$가 주어졌을 때 데이터 $x$가 생성될 확률 분포**를 의미한다.  
> - 즉, 생성기는 “$z$라는 조건 아래에서 어떤 $x$가 나타날 가능성이 높은가”를  
>   모델링하는 **확률적 맵핑(probabilistic mapping)**이다.  
>
> - 여기서 $\theta$는 신경망의 학습 가능한 파라미터이며,  
>   생성기의 출력 형태를 결정한다.  
>   학습이 진행되면서 $\theta$가 조정되어  
>   $p_\theta(x \mid z)$가 실제 데이터 분포를 점점 더 잘 근사하게 된다.  
>
> - **잠재 변수 분포 $p(z)$**는 단순한 형태(예: 정규분포)를 가지지만,  
>   **조건부 분포 $p_\theta(x \mid z)$**는 매우 복잡하고 고차원적이다.  
>   신경망은 이러한 복잡한 비선형 관계를 학습하여  
>   단순한 잠재 공간을 복잡한 데이터 공간으로 변환한다.  
>
> - 이 구조를 통해 VAE는  
>   단순한 결정적(deterministic) 매핑을 학습하는 것이 아니라,  
>   **데이터의 다양성과 불확실성을 확률적으로 포착(capture)**하는 모델이 된다.  
>
> - 다시 말해, $p_\theta(x \mid z)$는 **조건부 확률(conditional probability)**의 형태로  
>   생성 과정을 수학적으로 정의하며,  
>   이는 결합 확률(joint probability), 조건부 확률, 주변화(marginalization)과  
>   직접적으로 연결된다.  
>
> - 따라서 VAE의 생성기는  
>   잠재 변수의 분포에 조건화된 **확률적 생성 구조(probabilistic generative structure)**로 작동하며,  
>   “$z$를 입력받아 다양한 $x$를 생성할 수 있는 모델”이라는 의미를 갖는다.    

---

## p15. 최대우도추정 (Maximum Likelihood Estimation)  

**Kullback–Leibler (KL) 발산 최소화:**  

$$
\min_{\theta} \, D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
$$  

> KL발산 외에 고려할 수 있는 다른 기준은?

**즉, 우도 최대화(Maximize likelihood):**  

$$
\max_{\theta} \, \mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
$$  

<img src="/assets/img/lecture/probstat/9/image_11.png" alt="image" width="480px">

전개 과정:  

$$
\begin{aligned}
\arg \min_{\theta} D_{\mathrm{KL}}(p_{\text{data}} \, \| \, p_{\theta})
&= \arg \min_{\theta} \sum_{x} p_{\text{data}}(x) 
\log \frac{p_{\text{data}}(x)}{p_{\theta}(x)} \\
&= \arg \min_{\theta} 
\left[- \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) + \text{const}\right] \\
&= \arg \max_{\theta} \sum_{x} p_{\text{data}}(x) \log p_{\theta}(x) \\
&= \arg \max_{\theta} 
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_{\theta}(x)]
\end{aligned}
$$  

---

> - 생성 모델의 학습 목표는 실제 데이터 분포 $p_{\text{data}}$와 모델 분포 $p_\theta$ 사이의  
>   **차이(Divergence)**를 줄이는 것이다. 이를 수학적으로 표현한 것이 **KL 발산**이다.  
>
> - 따라서 $D_{\mathrm{KL}}(p_{\text{data}} \| p_\theta)$를 가능한 한 작게 만드는 것이 학습 과정의 핵심이다.  
>   하지만 KL 발산을 완전히 0으로 만드는 것은 현실적으로 불가능하다.  
>   - 실제 데이터 분포는 복잡하고 고차원적이며  
>   - 모델의 파라미터 $\theta$는 유한한 용량(capacity)을 가지기 때문이다.  
>   → 결국 우리는 **글로벌 최소(global minimum)**가 아니라 **로컬 최소(local minimum)**를 향해 수렴하게 된다.  
>
> **로그 가능도(log-likelihood)와의 관계**  
> - KL 발산 최소화는 다음과 같은 로그 가능도 최대화와 동치이다.  
>
>   $$
>   \max_{\theta}\, \mathbb{E}_{x\sim p_{\text{data}}}[\log p_\theta(x)]
>   $$  
>
> - 즉, 모델이 실제 데이터를 얼마나 잘 설명하는지를 평가하고,  
>   그 설명 능력이 최대가 되도록 파라미터 $\theta$를 조정하는 과정이다.  
>
> **직관적 의미**  
> - 모델 분포 $p_\theta(x)$가 실제 분포 $p_{\text{data}}(x)$와 최대한 비슷해지도록  
>   두 분포 전체의 형태를 맞추는 것이 목표이다.  
> - 여기서 중요한 점은,  
>   **개별 데이터 포인트를 맞추는 것이 아니라  
>   두 확률 분포 전체를 일치시키는 과정**이라는 점이다.  
>
> **분류 문제와의 철학적 차이**  
> - 분류 문제는 “1대1(one-to-one)” 매칭 구조로,  
>   하나의 입력 이미지에 하나의 정답 레이블이 존재한다.  
> - 반면 생성 모델은 “다대다(many-to-many)” 구조로,  
>   두 확률 분포 $p_{\text{data}}$와 $p_\theta$ 사이의  
>   **확률적 매칭(distributional matching)**을 학습한다.  
> - 데이터 간의 직접적인 페어링(pairing)은 존재하지 않는다.  
>
> **생성 모델이 복제를 하지 않는 이유**  
> - 생성 모델의 목표는 특정 데이터를 복제(copy)하는 것이 아니라  
>   **확률적으로 유사한 새로운 데이터 생성**이다.  
> - 모델이 생성한 샘플은 실제 데이터와 “닮은(distributionally similar)” 형태를 띠게 된다.  
>
> **요약**  
> - KL 발산 최소화는  
>   단순히 데이터 집합을 맞추는 문제가 아니라,  
>   **확률 공간 전체에서 두 분포의 통계적 일치(statistical alignment)**를 이루는 과정이다.    

---

## p16. 최대우도추정 (Maximum Likelihood Estimation)

우리는 다음 식을 최대화하고자 한다.

$$
\mathbb{E}_{x \sim p_{\text{data}}} [\log p_\theta(x)]
$$  

여기서 $p_\theta(x)$는 다음과 같이 표현된다.

$$
p_\theta(x) = \int_z p_\theta(x \mid z) \, p(z) \, dz
$$  

<img src="/assets/img/lecture/probstat/9/image_12.png" alt="image" width="480px">

이때 두 가지 미지항(unknowns)이 존재한다.

1. **최적화 대상:** $\theta$ — 학습 가능한 파라미터  
2. **제어 불가능한 요소:** “진짜” 사전 분포 $p(z)$  

따라서 다음과 같은 아이디어가 제시된다.  
→ **“제어 가능한(controllable)” 분포 $q(z)$**를 도입한다.

---

> - 최대우도추정(MLE)은 실제 데이터 분포 $p_{\text{data}}$에 대해  
>   모델 분포 $p_\theta(x)$의 로그 가능도 $\log p_\theta(x)$를 최대화하는 것을 목표로 한다.  
>
> - 그런데 $p_\theta(x)$는 단순한 형태가 아니라  
>   **잠재 변수 $z$에 대한 적분 형태**로 표현된다. 조건부 확률의 정의를 이용하면 다음과 같다.  
>
>   $$
>   p_\theta(x) = \int_z p_\theta(x \mid z)\, p(z)\, dz
>   $$
>
> - 여기서  
>   - $p(z)$는 **잠재 변수의 사전 분포(prior distribution)**이며 보통 가우시안으로 가정한다.  
>   - $p_\theta(x \mid z)$는 **생성기(generator)**로, “$z$가 주어졌을 때 $x$가 생성될 확률”을 나타낸다.  
>
> - 이 적분식은 우리가 앞서 직관적으로 이해했던  
>   “잠재 변수 $z$를 입력받아 데이터를 생성한다”는 개념을  
>   **수학적으로 공식화한 표현**이다.  
>
> - 하지만 이 식을 직접 최적화하는 것은 매우 어렵다. 그 이유는 다음과 같다.  
>   1) $p_\theta(x)$는 $z$에 대한 적분이므로 **폐형식(closed form)**으로 계산이 불가능하다.  
>   2) $p(z)$는 우리가 직접 제어할 수 없는 **고정된 분포**이다.  
>
> - 따라서 실제 학습에서는  
>   직접적인 사전 분포 $p(z)$ 대신  
>   **제어 가능한(controllable) 근사 분포 $q(z)$**를 도입하여  
>   계산과 최적화를 가능하게 만든다.  
>
> - 이 발상이 바로 **변분 오토인코더(VAE)**의 핵심 동기이다.  
>   - 즉, $p_\theta(x)$를 직접 계산하는 대신  
>   - 잠재 공간의 “근사 posterior”인 $q(z)$를 활용하여  
>     효율적으로 로그 가능도를 최대화할 수 있는 구조를 만든다.  
>
> - 다시 말해, VAE는  
>   **잠재 변수 적분 때문에 계산 불가능한 MLE 문제를  
>   변분 근사(variational approximation)를 이용해 해결하려는 방법**이다.  

---

## p17. 잠재 변수 모델 (Latent Variable Model)

<img src="/assets/img/lecture/probstat/9/image_13.png" alt="image" width="600px">

---

> - 목표는 $\log p_\theta(x)$를 **최대화**하는 것이다.  
> - 이를 다루기 위해, 임의의 보조 분포 $q(z)$를 곱해 적분 형태로 변환하면  
>   $z$에 무관한 상수항인 $\log p_\theta(x)$를 적분 내부로 옮길 수 있다.  
>
> - 베이즈 규칙  
>
>   $$
>   p_\theta(z \mid x)=\frac{p_\theta(x\mid z)\,p_\theta(z)}{p_\theta(x)}
>   $$  
>
>   을 대입하고,  
>   $q(z)$를 곱하고 나누어(즉, 1을 곱한 것과 동일)  
>   로그의 성질 $\log a - \log b$를 사용해 각 항을 분리한다.  

---

## p18. 계산 불가능한 식에서 계산 가능한 형태로 (From Intractable to Tractable Formulation)

<img src="/assets/img/lecture/probstat/9/image_14.png" alt="image" width="720px">

---

> - 우리가 다루는 $\log p_\theta(x)$는 **직접 계산이 불가능(intractable)** 하다.  
>   그 이유는 잠재변수 $z$에 대해  
>   $$p_\theta(x)=\int p_\theta(x\mid z)p_\theta(z)\,dz$$  
>   와 같은 **고차원 적분**을 닫힌 형태(closed-form)로 계산하기 어렵기 때문이다.  
>
> - 이를 우회하기 위해, $\log p_\theta(x)$를  
>   $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]  
>   \;-\; D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))  
>   \;+\; D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$$  
>   와 같이 세 항으로 분해한다.  
>
> - **초록색의 두 항(앞의 두 항)은 ‘원래는’ 계산이 불가능(intractable)** 하지만,  
>   아래 두 가지 이유로 실제 학습 과정에서는 **계산 가능(tractable)** 하다:  
>
>   > ① 첫 번째 항 $$\mathbb{E}_{z\sim q(z)}[\log p_\theta(x\mid z)]$$는  
>   >     **몬테카를로 샘플링(Monte-Carlo estimation)** 을 이용하면  
>   >     충분히 정확하게 추정할 수 있기 때문이다.  
>   >     즉, $z\sim q(z)$ 를 샘플링한 후  
>   >     $\log p_\theta(x\mid z)$ 값을 평균 내면 된다.  
>
>   > ② 두 번째 항 $D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z))$는  
>   >     **q(z)와 p(z)가 모두 가우시안인 경우(표준 VAE의 기본 설정)**  
>   >     **해석적(analytic) 닫힌형 해(closed-form solution)** 이 존재한다.  
>   >     따라서 이 항은 직접 계산이 가능해진다.  
>
> - 반면 마지막 항  
>   $$D_{\mathrm{KL}}(q(z)\,\|\,p_\theta(z\mid x))$$  
>   은 **여전히 계산 불가능(intractable)** 하다.  
>   이유는 $p_\theta(z\mid x)$ 를 구하려면  
>
>   $$p_\theta(z\mid x)=\frac{p_\theta(x\mid z)p_\theta(z)}{p_\theta(x)}$$  
>
>   이 되는데, 여기서 또다시 **계산 불가능한 $\log p_\theta(x)$가 등장하기 때문**이다.  
>
> - 하지만 이 항은 항상 **0 이상**이며,  
>   우리는 이를 직접 계산하지 않아도  
>   앞의 두 항(ELBO)의 합을 최대화하는 것만으로  
>   원래 목적 함수 $\log p_\theta(x)$를 **간접적으로 최대화**할 수 있다.  
>
> - 이것이 바로 변분추론(VI)의 핵심 아이디어이다.  
>   **계산 불가능한 목적을 직접 최적화하지 않고**,  
>   **계산 가능한 하한(ELBO)** 을 최대화함으로써  
>   $\log p_\theta(x)$에 최대한 가까운 값을 찾는다.  

---

## p19. 증거 하한 (Evidence Lower Bound, ELBO)

<img src="/assets/img/lecture/probstat/9/image_15.png" alt="image" width="600px">

- 이것을 **Evidence Lower Bound (ELBO)** 라고 부른다.  
- 이는 $\log p_\theta(x)$의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.

---

## p20. 매개변수화(Parameterization)

<img src="/assets/img/lecture/probstat/9/image_16.png" alt="image" width="500px">

- 이것은 **Evidence Lower Bound (ELBO)** 라고 불린다.  
- 이는 $\log p_\theta(x)$ 의 하한(lower bound)이다.  
- 이 식은 **임의의 분포 $q(z)$** 에 대해서도 성립한다.  
- 이제 $q(z)$를 직접 다루기 어려우므로,  
  이를 **매개변수화(parameterize)** 하여  
  **$q_\phi(z \mid x)$** 로 표현한다.  
- 여기서 $\phi$ 는 **추론 네트워크(inference network)** 의  
  학습 가능한 파라미터이다.  
- 반면, **$p_\theta(z)$** 는 단순하고 알려진 **사전분포(prior)** 로 둔다.

---

> - 실제로 $q(z)$는 임의의 형태를 가질 수 있지만,  
>   그 분포를 명시하거나 직접 계산하는 것은 불가능하다.  
>   따라서 이를 **신경망으로 근사(parameterize)** 하여  
>   $q_\phi(z \mid x)$ 형태로 표현한다.  
>   이때 $\phi$는 인코더(추론 네트워크)의 학습 가능한 파라미터이다.  
>
> - 인코더 $q_\phi(z \mid x)$는 **입력 데이터 $x$로부터 잠재변수 $z$를 추정**하고,  
>   디코더 $p_\theta(x \mid z)$는 **잠재변수 $z$로부터 데이터를 복원 또는 생성**한다.  
>   이렇게 두 확률 모델이 짝을 이루어 작동한다.  
>
> - 사전분포 $p_\theta(z)$는 보통 **표준정규분포 $\mathcal{N}(0, I)$** 로 설정한다.  
>   이는 계산을 단순하게 하고, 잠재공간의 구조를 일정하게 유지시킨다.  
>
> - 결국 인코더와 디코더의 파라미터 $\phi, \theta$를 조정하여  
>   **ELBO를 최대화**하는 것이 VAE의 학습 과정이다.  
>   이는 곧 **잠재변수 분포 추정**과 **데이터 생성 과정 학습**을  
>   동시에 수행하는 절차이다.  

---

## p21. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_17.png" alt="image" width="800px">

---

> - 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를 받아  
>   잠재변수 $z$의 분포를 추정하는 역할을 한다.  
>   일반적으로 이 분포는 가우시안(정규분포) 형태로 가정된다.  
>
> - 디코더 $p_\theta(x \mid z)$는 샘플링된 $z$로부터  
>   원래의 입력 $x$를 재구성하도록 학습된다.  
>   즉, 인코더가 정보를 요약하고,  
>   디코더가 그 정보를 바탕으로 데이터를 복원하는 구조이다.  
>
> - 전체 손실 함수는 두 부분으로 구성된다.  
>
>   (1) $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$  
>       재구성 손실로서, 입력 $x$와 복원된 $x'$의 차이를 최소화한다.  
>
>   (2) $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p_\theta(z))$  
>       정칙화 항으로서, 인코더가 추정한 분포가  
>       사전분포 $p_\theta(z)$(보통 $\mathcal{N}(0, I)$)와  
>       유사하도록 만드는 역할을 한다.  
>
> - 이 두 항의 균형을 조정함으로써  
>   VAE는 잠재공간을 구조적으로 유지하면서  
>   새로운 데이터를 생성할 수 있는 능력을 갖추게 된다.  
>
> - 이러한 구조는 생성 모델로서뿐 아니라  
>   이상치 탐지(Anomaly Detection)와 같은 응용에서도 널리 활용된다.  
>   학습된 모델은 정상 데이터의 잠재공간을 학습하므로,  
>   재구성 오차가 큰 데이터는 이상치로 판별된다.

---

## p22. 변분 오토인코더(Variational Autoencoder)

<img src="/assets/img/lecture/probstat/9/image_18.png" alt="image" width="800px">

---

> - 위 식은 ELBO를 최대화하는 대신, 동등하게 손실을 최소화하는 형태로 표현된 것이다.  
>   왼쪽 항은 재구성 손실(reconstruction loss),  
>   오른쪽 항은 정칙화 손실(regularization loss)에 대응한다.  
>
> - 인코더 $q_\phi(z \mid x)$는 입력 데이터 $x$를  
>   잠재공간(latent space) 상의 확률분포로 압축하여 표현한다.  
>   여기서 $\phi$는 인코더의 학습 파라미터이며,  
>   인코더는 $q_\phi(z \mid x)$가 사전분포(prior) $p(z)$에  
>   가깝도록 학습된다.  
>
> - 사전분포 $p(z)$는 일반적으로  
>   가우시안 분포 $\mathcal{N}(0, I)$로 설정된다.  
>   이렇게 단순한 분포를 prior로 두는 이유는  
>   잠재공간이 구조적으로 안정적이고,  
>   샘플링이 쉬운 공간이 되도록 만들기 위함이다.  
>
> - 정칙화 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$은  
>   인코더가 만든 분포 $q_\phi(z \mid x)$가  
>   $\mathcal{N}(0, I)$와 멀어지지 않도록 제한하는 제약 조건이다.  
>   이 값이 작아질수록 잠재분포는  
>   표준정규분포에 더 잘 정렬된다.  
>
> - 디코더 $p_\theta(x \mid z)$는 잠재변수 $z$로부터  
>   원래 입력 $x$를 재구성하는 역할을 한다.  
>   여기서 $\theta$는 디코더의 학습 파라미터이며,  
>   학습의 목표는 입력 $x$와 재구성된 $x'$의 차이를  
>   최소화하는 것이다.  
>
> - 결국 VAE의 학습 과정은  
>   (1) 데이터를 잘 재구성하는 능력과  
>   (2) 잠재공간의 확률적 구조를 유지하는 능력  
>   두 가지를 동시에 최적화하는 과정이라고 볼 수 있다.

---

## p23. 첫 번째 항: 재구성 손실 (Reconstruction Loss)

<img src="/assets/img/lecture/probstat/9/image_19.png" alt="image" width="600px">

**예시: L2 손실 (L2 loss)**  

- 1단계 몬테카를로(Monte Carlo) 샘플링:  
  $z \sim q_\phi(z \mid x)$  

- 디코더 네트워크에 의한 매핑:  
  $g_\theta(z) \rightarrow x'$  
  (network estimates distribution’s parameters)

- 가우시안 분포로 모델링:  
  $p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)$  
  (assume fixed std)

- 음의 로그우도(negative log-likelihood):  

  $$
  -\log p_\theta(x \mid z)
  =
  \frac{1}{2\sigma_0^2}\|x - x'\|^2 + \text{const}
  $$

- L2 손실은 데이터 포인트 $x$ 주변의  
  가우시안 근방(Gaussian neighborhood)을 의미함

---

> **1. 몬테카를로 샘플링 (Monte Carlo Sampling)**  
> - 기댓값  
> 
>   $$
>   \mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]
>   $$  
> 
>   은 잠재변수 $z$ 에 대한 적분 형태로 표현되며 해석적으로 계산하기 어렵다.  
> - 따라서 $q_\phi(z \mid x)$ 에서 샘플링한 $z$ 들을 이용해  
>   $\log p_\theta(x \mid z)$ 값을 평균하여 근사한다.  
>   이를 **몬테카를로 근사(Monte Carlo approximation)** 라고 한다.  
> - 샘플링 과정은 **재매개변수화 기법(Reparameterization trick)** 으로  
>   미분 가능하게 만들어, 인코더와 디코더 모두를 역전파로 학습할 수 있다.  
>
> **2. 디코더 매핑 $g_\theta(z) \rightarrow x'$**  
> - 디코더 $g_\theta$ 는 잠재변수 $z$ 를 입력받아 생성 데이터의 평균값 $x'$ 을 출력한다.  
> - 디코더는 단순 복원 함수가 아니라  
>   **확률분포 $p_\theta(x \mid z)$ 의 모수(parameter)를 추정하는 함수** 로 해석된다.  
> - 가장 단순한 경우 디코더는 평균만 출력한다고 두며,  
> 
>   $$
>   x'=\mu_\theta(z)
>   $$  
> 
>   분산은 고정 상수 $\sigma_0^2$ 로 둔다.  
>   즉, 디코더는 “데이터가 존재할 법한 중심(mean)”을 학습한다.  
> - 따라서 디코더는 **확률적 생성 모델의 평균 함수(mean function)** 이다.  
>
> **3. 가우시안 분포로 모델링하는 이유**  
> - 실제 데이터는 노이즈와 불확실성을 포함하므로 $x$ 와 $x'$ 를 완전히 일치시키기보다  
>   $x$ 가 $x'$ 주변에서 나올 확률을 모델링하는 것이 타당하다.  
> - VAE는 다음과 같이 가정한다.  
> 
>   $$
>   p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
>   $$  
> 
> - 여기서  
>   - $x'=g_\theta(z)$ : 평균  
>   - $\sigma_0^2 I$ : 분산  
>   - $x$ : 관측값  
> - 이는 “데이터는 평균 $x'$ 를 중심으로 정규분포 형태에 따라 생성된다”는  
>   확률적 가정을 의미한다.  
> - 이 가정 덕분에 모델은 불확실성을 표현할 수 있고,  
>   **로그우도(log-likelihood)가 닫힌형(closed form)** 으로 계산 가능해진다.  
>
> **4. 재구성 손실이 L2 손실이 되는 이유**  
> - 가우시안 가정하에서 로그 가능도는  
> 
>   $$
>   \log p_\theta(x \mid z)
>   =
>   -\frac{1}{2\sigma_0^2}\|x-x'\|^2
>   -\frac{d}{2}\log(2\pi\sigma_0^2)
>   $$
> 
>   로 전개된다.  
> - 따라서 음의 로그 가능도는  
> 
>   $$
>   -\log p_\theta(x \mid z)
>   =
>   \frac{1}{2\sigma_0^2}\|x-x'\|^2 + \text{const}
>   $$  
> 
>   이 되며, 이는 **L2 손실(Mean Squared Error)** 과 동일한 형태이다.  
> - 즉, 디코더가 출력하는 평균 $x'$ 을 기준으로 데이터 $x$ 를 설명하는 과정이  
>   곧 L2 거리 최소화와 같다.  
>
> **5. 전체적 관계 요약**  
> - $x$: 관측 데이터  
> - $z$: 인코더가 샘플링한 잠재변수  
> - $x'=g_\theta(z)$: 디코더가 추정한 평균  
> -  
>   $$
>   p_\theta(x \mid z) = \mathcal{N}(x \mid x', \sigma_0^2 I)
>   $$  
> 
>   : 관측 $x$ 는 평균 $x'$ 중심의 정규분포에서 샘플링된 것으로 해석  
> - 재구성 손실 최소화는  
>   “실제 데이터 $x$” 와 “디코더 평균 $x'$” 사이의 거리를 줄이는 것과 같다.  

---

## p24. 두 번째 항: 정규화 손실 (Regularization Loss)

<img src="/assets/img/lecture/probstat/9/image_20.png" alt="image" width="600px">

**예시: 가우시안 사전분포 (Gaussian prior)**  

- $p(z) = \mathcal{N}(z \mid 0, I)$ 로 둔다.  

- $q_\phi(z \mid x)$ 를 가우시안으로 모델링한다:  
  $q_\phi(z \mid x) = \mathcal{N}(z \mid \mu, \sigma)$  

- 인코더 네트워크에 의한 매핑:  
  $f_\phi(x) \rightarrow (\mu, \sigma)$  
  (network estimates distribution’s parameters)

- 손실을 분석적으로 계산한다:  

  $$
  D_{\mathrm{KL}}\big(\mathcal{N}(z \mid \mu, \sigma)\,\|\,\mathcal{N}(z \mid 0, I)\big)
  $$

- 공분산을 고정한 경우:  
  fixed covariance → $\mu$ 에 대한 L2 손실

---

> **1. 정규화 항의 역할**  
> - 정규화 손실 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은  
>   인코더가 학습한 잠재 분포 $q_\phi(z \mid x)$ 이  
>   사전 분포 $p(z)$ (보통 표준 정규분포 $\mathcal{N}(0, I)$) 와  
>   얼마나 다른지를 측정한다.  
> - 이 항은 잠재공간이 지나치게 왜곡되지 않도록 제약을 주며,  
>   특정 데이터에 과도하게 맞춰진 잠재표현을 방지하여  
>   **일관된 잠재 구조**를 유지하게 만든다.  
>
> **2. KL 발산의 계산 방식**  
> - 두 가우시안 분포 사이의 KL 발산은 닫힌형(closed-form)으로 계산된다.  
>
>   $$
>   D_{\mathrm{KL}}\!\big(\mathcal{N}(\mu,\sigma^2)\,\|\,\mathcal{N}(0,1)\big)
>   =\frac{1}{2}(\mu^2+\sigma^2-\log\sigma^2-1)
>   $$  
>
> - 이 표현은 VAE 학습에서 매우 효율적으로 사용되며,  
>   손실을 직접 계산해 최적화할 수 있게 한다.  
>
> **3. 공분산 고정 시 L2 손실과의 관계**  
> - 공분산 $\sigma^2$ 를 고정하면 KL 항은  
>   $\mu^2$ 에 비례하는 형태가 된다.  
>
>   $$
>   D_{\mathrm{KL}} \propto \|\mu\|^2
>   $$  
>
> - 즉, KL 항은 잠재변수 평균 $\mu$ 에 대한  
>   **L2 정규화(L2 penalty)** 처럼 동작한다.  
> - 이는 잠재벡터가 사전분포의 중심(0 근처)에 있도록  
>   압박하는 효과를 낸다.  
>
> **4. 직관적 해석**  
> - 인코더는 입력 $x$ 에 따라 $\mu$ 와 $\sigma$ 를 출력한다.  
> - KL 항은 “너무 특이한” 잠재벡터를 생성하지 않도록 억제하며,  
>   전체 잠재공간이 사전분포 $p(z)$ 와 유사한 모양을 유지하게 만든다.  
> - 그 결과, 학습이 끝난 후 임의의 $z \sim p(z)$ 를 샘플링해도  
>   **자연스럽고 일관된 생성 결과**를 얻을 수 있게 된다.  

---

## p25. 역전파는 어떻게 이루어질까? (Backpropagation?)

<img src="/assets/img/lecture/probstat/9/image_21.png" alt="image" width="800px">

---

> **1. 인코더와 샘플링의 관계**  
> 인코더는 입력 $x$ 로부터 잠재 변수의 분포 $q_\phi(z \mid x)$ 를 학습한다.  
> 평균 $\mu_\phi(x)$ 와 표준편차 $\sigma_\phi(x)$ 를 추정하여 확률적으로 $z$ 를 샘플링하고,  
> 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 로 전달되어 재구성된 출력 $x'$ 를 생성한다.
>
> **2. 역전파의 문제점**  
> 샘플링 과정은 확률적이므로  
>
> $$
> z \sim q_\phi(z \mid x)
> $$  
>
> 와 같이 난수에 의해 결정된다.  
> 이 연산은 비결정적이며 미분 불가능하므로,  
> 역전파는 $z$ 에서 인코더 파라미터 $\phi$ 로 기울기를 전달할 수 없다.  
> 즉, 샘플링 순간에 역전파 경로가 끊긴다.
>
> **3. 직관적 비유**  
> 인코더는 분포의 모양(평균·분산)을 제시하고,  
> 샘플링은 그 분포에서 주사위를 던지는 과정이다.  
> 주사위의 결과값 $z$ 에 대해 $\mu$ 또는 $\sigma$ 로 직접 미분할 수 없기 때문에  
> 일반적인 역전파 규칙을 적용할 수 없다.
>
> **4. 해결책의 방향**  
> 이를 해결하기 위해 재매개변수화 기법(Reparameterization Trick)을 사용한다.  
> 이 방법은 확률적 샘플링 과정을 결정적 함수 형태로 다시 표현하여  
> 미분이 가능하도록 만들어, 끊겼던 역전파 경로를 복원해 준다.

---

## p26. 재매개변수화 (Reparameterization)

<img src="/assets/img/lecture/probstat/9/image_22.png" alt="image" width="800px">

가우시안 매개변수들은 신경망의 출력값에 의해 매개변수화되어(parameterized),  
중간 조건부 분포들(intermediate conditional distributions)을 근사하기 위해 사용된다!  

---

> **1. 재매개변수화의 핵심 아이디어**  
> 확률적 샘플링 $z \sim q_\phi(z \mid x)$ 은 미분 불가능하여 역전파가 단절된다.  
> 재매개변수화 기법(Reparameterization Trick)은 이 확률적 과정을  
> 결정적(deterministic) 함수로 변환하여 미분 가능하게 만든다.  
> 즉, 잠재 변수 $z$ 를 직접 샘플링하지 않고,  
> 표준 정규분포에서 샘플링한 잡음 $\varepsilon$ 을 이용해 다음과 같이 계산한다:
>
> $$
> z = \mu_\phi(x) + \sigma_\phi(x)\,\varepsilon,
> \qquad \varepsilon \sim \mathcal{N}(0, I)
> $$
>
> **2. 수식의 의미**  
> $\varepsilon$ 은 고정된 분포 $\mathcal{N}(0, I)$ 에서만 샘플링되므로  
> 랜덤성은 $\varepsilon$ 에만 존재한다.  
> 반면 $\mu_\phi(x)$, $\sigma_\phi(x)$ 는 결정적 함수이므로  
> $z$ 는 $\phi$ 에 대해 미분 가능한 형태가 된다.  
> 따라서 역전파를 통해 인코더 파라미터 $\phi$ 까지 기울기가 전달된다.  
> 이로써 샘플링 단계가 신경망의 연산 그래프에 포함된다.
>
> **3. 직관적 이해**  
> 원래는 “분포로부터 직접 샘플링”했지만,  
> 이제는 “고정된 분포에서 노이즈를 샘플링하고  
> 그 노이즈를 평균과 분산으로 변환하는 과정”으로 바뀐 것이다.  
> 즉, 확률적 샘플링을  
> 노이즈를 입력으로 받는 결정적 함수로 바꾸어  
> 학습 가능한 형태로 만든다.
>
> **4. 전체 구조의 연결**  
> 인코더는 입력 $x$ 로부터 $(\mu, \sigma)$ 를 출력하고,  
> 표준 가우시안 잡음 $\varepsilon$ 을 사용해  
> $z = \mu + \sigma \varepsilon$ 을 계산한다.  
> 디코더는 이 $z$ 를 입력받아 $p_\theta(x \mid z)$ 를 통해 데이터를 재구성한다.  
> 이 구조를 통해 확률적 생성 모델이  
> 전부 미분 가능한 신경망 형태로 구현된다.

---

## p27. 변분 오토인코더 (Variational Autoencoder) 

지금까지는 하나의 $x$ 에 대한 목적함수를 논의해왔다:

<img src="/assets/img/lecture/probstat/9/image_23.png" alt="image" width="600px">

전체 손실(overall loss)은  
데이터 분포에 대한 기대값으로 표현된다:

<img src="/assets/img/lecture/probstat/9/image_24.png" alt="image" width="600px">

---

> **1. 단일 데이터 샘플 $x$ 에 대한 손실**  
> 위의 첫 번째 식은 단일 입력 샘플 $x$ 에 대한 손실 함수 $$\mathcal{L}_{\theta,\phi}(x)$$ 를 정의한 것이다.  
> 첫 번째 항  
>
> $$-\mathbb{E}_{z \sim q_\phi(z \mid x)}[\log p_\theta(x \mid z)]$$  
>
> 은 재구성 손실(Reconstruction Loss)로, 디코더가 입력 $x$ 를 얼마나 잘 복원하는지 측정한다.  
> 두 번째 항 $D_{\mathrm{KL}}(q_\phi(z \mid x)\,\|\,p(z))$ 은 정규화 손실(Regularization Loss)로,  
> 인코더가 생성한 잠재공간 분포 $q_\phi(z \mid x)$ 가 사전분포 $p(z)$ 와 얼마나 다른지를 측정한다.
>
> **2. 전체 데이터셋에 대한 손실**  
> 실제 학습에서는 한 개의 샘플이 아니라 데이터셋 전체에 대해 평균 손실을 계산한다.  
> 손실 함수는 데이터 분포 $p_{\text{data}}(x)$ 에 대한 기대값으로 확장되며  
>
> $$
> \mathbb{E}_{x \sim p_{\text{data}}(x)}[\mathcal{L}_{\theta,\phi}(x)]
> $$  
>
> 으로 표현된다.  
> 이 기대값은 실질적으로는 미니배치 평균(mini-batch mean)으로 근사되어 학습 중에 최적화된다.
>
> **3. 전체 목적함수의 의미**  
> 최종 손실 $\mathcal{L}_{\theta,\phi}$ 는  
> 데이터 복원 성능과 잠재공간의 규칙성 사이의 균형을 조절하는 역할을 한다.  
> 즉, 인코더가 잠재공간에서 의미 있는 구조를 학습하도록 하면서  
> 디코더가 입력을 잘 복원할 수 있도록 두 항을 함께 최소화하는 것이 VAE 학습의 핵심이다.

---

## p28. 추론 (Inference)

<img src="/assets/img/lecture/probstat/9/image_25.png" alt="image" width="720px">

**추론 (생성):**

- 잠재 변수 $z$ 를 다음 분포에서 샘플링함:  

  $$
  z \sim \mathcal{N}(0, I)
  $$

- 디코더 네트워크에 의해 $z$ 를 매핑함:  

  $$
  g_\theta(z)
  $$

**디코더(Decoder)는 한 분포에서 다른 분포로의 결정적 매핑(deterministic mapping)이다.**

---

> **1. 추론(생성)의 단계**  
> 학습이 완료된 후에는 인코더는 사용하지 않는다.  
> 잠재공간에서 직접 $z \sim \mathcal{N}(0, I)$ 를 샘플링한다.  
> 이는 학습 과정의 KL 발산 항이 $q_\phi(z \mid x)$ 를 $p(z)$ 와 유사하게 만들도록  
> 인코더를 학습시켰기 때문에 가능하다.  
> 따라서 학습이 끝난 뒤 $p(z)$ 에서 샘플링하는 것은  
> 실제 데이터 공간에서 의미 있는 위치를 선택하는 것과 같다.  
> 이렇게 얻은 $z$ 를 디코더 $g_\theta(z)$ 에 입력하면  
> 새로운 샘플을 생성할 수 있다.
>
> **2. 학습 전과 학습 후의 차이**  
> 학습 전에는 $\mathcal{N}(0, I)$ 가 단순한 랜덤 노이즈일 뿐이며  
> 그 안의 점들은 의미가 없다.  
> 학습 후에는 인코더 $q_\phi(z \mid x)$ 가 데이터를 잠재공간으로  
> 의미 있게 매핑하고, KL 발산 항이 이 공간을 정규분포 형태로 정렬한다.  
> 그 결과 $\mathcal{N}(0, I)$ 상의 점들은 실제 데이터의  
> 의미적 표현을 반영하는 좌표가 된다.  
> 즉, 학습 전에는 의미 없던 점들이  
> 학습 후에는 데이터 구조를 보존하는 의미 있는 코드가 된다.
>
> **3. 디코더의 역할**  
> 디코더는 결정적 함수로, $z$ 를 입력받아  
> $p_\theta(x \mid z)$ 혹은 그 평균을 생성한다.  
> 같은 $z$ 에 대해 같은 출력이 생성되지만,  
> $z$ 자체가 확률적으로 샘플링되므로  
> 전체 모델은 확률적 생성 모델 성격을 유지한다.
>
> **4. 요약**  
> 학습 중에는 인코더·디코더가 함께 작동하여  
> 데이터 구조를 정규분포 형태의 잠재공간으로 매핑한다.  
> 학습이 끝난 뒤에는 $\mathcal{N}(0,I)$ 자체가 의미 있는 잠재공간이 되므로  
> 인코더 없이 디코더만으로 새로운 샘플을 생성할 수 있다.

---

## p29. 개요 (Overview)

- 인코더(encoder): 데이터 분포를 잠재 분포로 매핑함  

- 디코더(decoder): 잠재 분포를 데이터 분포로 매핑함  

<img src="/assets/img/lecture/probstat/9/image_26.png" alt="image" width="800px">

---

> **1. 전체 구조의 흐름**  
> 입력 데이터 $x$ 는 인코더 $q_\phi(z \mid x)$ 를 거쳐 잠재 변수 $z$ 의 확률분포로 변환된다.  
> 이 분포는 데이터의 내재된 구조나 의미적 특성을 요약한 표현이다.  
> 인코더를 통해 얻은 $z$ 는 잠재 공간에서의 점이며,  
> 이 공간 전체가 표준 정규분포 $\mathcal{N}(0, I)$ 형태로 정렬되도록 학습된다.  
> 이후 디코더 $p_\theta(x \mid z)$ 는 이 $z$ 로부터 원래 데이터 분포를 복원하여  
> $x'$ 를 생성하는 과정을 학습한다.
>
> **2. 인코더와 디코더의 관계**  
> 인코더는 데이터 분포 $p_{\text{data}}(x)$ 를 잠재 분포 $q_\phi(z)$ 로 압축하는 역할을 한다.  
> 이는 고차원 데이터(이미지, 음성, 언어 등)를 의미적으로 요약된 표현으로 변환하는 과정이다.  
> 디코더는 이 잠재 분포를 다시 데이터 분포 $p_\theta(x)$ 로 확장하여  
> 원본 데이터에 가까운 샘플을 생성한다.  
> 이 과정이 VAE가 생성 모델로 기능하는 핵심이다.
>
> **3. 학습의 목표**  
> 학습 과정에서 인코더와 디코더는 상호 보완적으로 최적화된다.  
> 인코더는 $x \rightarrow z$, 디코더는 $z \rightarrow x'$ 를 수행하며  
> 두 네트워크는 $p_{\text{data}}(x)$ 와 모델 분포 $p_\theta(x)$ 가  
> 최대한 유사해지도록 동시에 학습된다.
>
> **4. 요약적 해석**  
> 인코더는 데이터 공간에서 잠재 공간으로의 압축(encoding)을 담당하고,  
> 디코더는 잠재 공간에서 데이터 공간으로의 복원(decoding)을 담당한다.  
> 결국 VAE는  
> 데이터 ↔ 잠재 표현 ↔ 데이터  
> 로 이어지는 양방향 확률적 매핑을 학습하는 모델이다.

---

## p30. 변분 오토인코더 (Variational Autoencoder)

- 인코딩된 잠재 분포(encoded latent distribution):

  $$
  q_\phi(z)
  =
  \int_x q_\phi(z \mid x) \, p_{\text{data}}(x) \, dx
  $$

<img src="/assets/img/lecture/probstat/9/image_27.png" alt="image" width="800px">

---

> **1. 인코딩된 잠재 분포의 의미**  
> $q_\phi(z)$ 는 전체 데이터 분포 $p_{\text{data}}(x)$ 에 대해  
> 인코더가 생성한 잠재 변수 분포들의 평균적 형태를 나타낸다.  
> 즉, 각 데이터 $x$ 가 인코더를 거쳐 $z$ 로 변환될 때  
> 그 모든 $z$ 들이 형성하는 전역적 분포 구조를 의미한다.  
> 이 관계는  
>
> $$
> q_\phi(z)=\mathbb{E}_{x \sim p_{\text{data}}(x)}[\,q_\phi(z \mid x)\,]
> $$  
>
> 으로 표현되며, 인코더가 전체 데이터셋을 통해 형성한  
> 잠재공간의 전역 구조를 나타낸다.
>
> **2. $p(z)$ 와 $q_\phi(z)$ 의 관계**  
> $p(z)$ 는 사전에 정의한 단순한 분포(prior)로 보통 $\mathcal{N}(0, I)$ 이다.  
> 이는 학습의 기준점 역할을 한다.  
> 반면 $q_\phi(z)$ 는 실제 데이터에서 인코더가 추정한 복잡한 잠재 분포이다.  
> KL 발산 항 $D_{KL}(q_\phi(z)\,\|\,p(z))$ 이 이를 최소화하도록 유도하여  
> 학습이 진행될수록 $q_\phi(z)$ 가 $p(z)$ 와 유사해지도록 만든다.  
> 따라서 이 KL 항은 잠재공간을 정규화하는 정규화 제약이다.
>
> **3. 전체 흐름의 의미**  
> 1) 데이터 분포 $p_{\text{data}}(x)$ 에서 샘플된 $x$ 가  
>    인코더를 통해 $q_\phi(z \mid x)$ 로 변환된다.  
> 2) 이를 모든 $x$ 에 대해 통합하면 전체 잠재 분포 $q_\phi(z)$ 가 형성된다.  
> 3) KL 발산 항은 $q_\phi(z)$ 가 $p(z)$ 와 유사해지도록 학습을 유도한다.  
> 4) 디코더 $p_\theta(x \mid z)$ 는 잠재 변수로부터 데이터 분포를 복원한다.
>
> **4. 직관적 해석**  
> 인코더는 실제 데이터 분포를 잠재 변수 분포 $q_\phi(z)$ 로 변환하고,  
> KL 발산 항은 이를 정규분포 $p(z)$ 에 정렬한다.  
> 이 과정 덕분에 복잡한 데이터의 구조가 단순하고 해석 가능한 잠재공간으로 매핑된다.  
> 결국 VAE는  
> “데이터 분포 → 인코더 → 잠재공간 정규화 → 디코더 → 복원된 데이터 분포”  
> 로 이어지는 완전한 확률적 경로를 학습한다.

---

## p31. 예시 그림 (Example Illustration)

<img src="/assets/img/lecture/probstat/9/image_28.png" alt="image" width="600px">

- 각 데이터 포인트 $x_1$, $x_2$, $x_3$ 는  
  인코더 $q_\phi(z \mid x)$ 를 통해  
  잠재공간(latent space)의 분포 $q_\phi(z \mid x_i)$ 로 매핑된다.

- 각 분포 $q_\phi(z \mid x_i)$ 는  
  잠재공간 내에서 서로 다른 위치에  
  데이터의 의미적 특징을 반영하여 분포하게 된다.

- 디코더는 각 $z$ 로부터 대응되는  
  **재구성된 데이터(generated data)** 를 복원한다.

---

> **1. 데이터 포인트와 잠재 분포의 대응 관계**  
> 원래의 데이터 포인트 $x_i$ 들은 인코더를 통과하면서 각각 잠재 분포 $q_\phi(z \mid x_i)$ 로 표현된다.  
> 이 분포들은 데이터의 고유한 특성을 반영하며, 비슷한 데이터일수록 잠재공간에서 가까운 위치를 갖는다.  
> 예를 들어 $x_1, x_2, x_3$ 가 유사한 클래스에 속하면,  
> 이들의 잠재 분포 $q_\phi(z \mid x_i)$ 는 잠재공간에서 서로 겹치거나 인접한 영역에 위치하게 된다.
>
> **2. 생성 과정의 시각적 의미**  
> 각 $q_\phi(z \mid x_i)$ 에서 샘플링된 $z$ 는 디코더 $p_\theta(x \mid z)$ 를 통해  
> 재구성된 데이터 $\hat{x}_i$ 를 생성한다.  
> 이 과정 전체가 “입력 데이터 → 잠재공간 표현 → 데이터 복원”이라는  
> 확률적 생성 경로를 학습하는 것이다.
>
> **3. 이상치 탐지(Anomaly Detection)와의 연관**  
> VAE는 정상 데이터의 분포를 학습하므로 정상 데이터는 잠재공간에서 $p(z)$ 근처에 정렬된다.  
> 반면 이상치는 학습된 $q_\phi(z)$ 와 잘 맞지 않아 낮은 복원 확률을 가지게 된다.  
> 따라서 VAE는 복원 오차나 잠재 확률을 기반으로 이상치를 탐지하는 데 활용될 수 있다.
>
> **4. 데이터 정화(Purification) 관점**  
> 입력 데이터가 노이즈를 포함하거나 왜곡되었더라도,  
> 인코더를 거쳐 잠재공간으로 투영되고 디코더를 통해 복원되는 과정에서  
> 학습된 데이터 분포에 맞춰 정제된 형태로 출력될 수 있다.  
> 즉, VAE는 생성 모델임과 동시에 데이터 복원 및 정화 모델로도 작동할 수 있다.

---

## p32. MNIST의 2차원 잠재공간 (2D Latent Space on MNIST)

<img src="/assets/img/lecture/probstat/9/image_29.png" alt="image" width="800px">

왼쪽: 각 숫자 클래스(0~9)가 인코딩된 잠재변수 공간의 분포  
오른쪽: 잠재공간 상의 위치에 따라 디코더가 생성한 숫자 이미지

---

> **1. 잠재공간의 구조**  
> 이 그림은 MNIST 데이터셋으로 VAE를 학습한 뒤 잠재공간(latent space)을 2차원으로 시각화한 결과이다.  
> 각 점은 인코더 $q_\phi(z \mid x)$ 를 통해 얻어진 잠재벡터 $z$ 를 나타내며,  
> 점의 색깔은 해당 데이터의 실제 숫자 레이블(0~9)에 대응된다.  
> 서로 유사한 숫자들은 잠재공간에서 인접한 영역에 분포하며,  
> 클래스 간 경계도 매끄럽게 이어진다.
>
> **2. 연속적(latent-continuous)인 공간의 특징**  
> 잠재공간이 2차원으로 제한되어 있음에도 각 숫자 클래스는 클러스터 형태로 잘 구분된다.  
> 또한 그 사이 영역에서도 연속적인 변형이 가능하다.  
> 잠재공간의 한 점에서 인접한 점으로 이동하면  
> 디코더가 생성하는 숫자의 형태가 점진적으로 변화하며,  
> “6 → 0”, “4 → 9” 등 자연스러운 전이가 나타난다.  
> 이러한 연속성은 라벨을 사용하지 않는 unconditional VAE에서도  
> 잠재공간이 구조적으로 정렬되도록 학습되었음을 의미한다.
>
> **3. 잠재공간이 의미를 갖게 되는 이유**  
> 학습 전의 $z \sim \mathcal{N}(0,I)$ 샘플들은 단순한 무작위 가우시안이다.  
> 그러나 학습이 진행되면 인코더 $q_\phi(z \mid x)$ 가 데이터 구조를 반영하여  
> $p(z)$ 공간에 의미 있는 좌표계를 형성하게 된다.  
> 그 결과 잠재공간의 각 영역은 특정 숫자 형태나 패턴을 나타내는  
> 의미적 지역(semantic region)으로 변환된다.
>
> **4. 응용: 이상치 탐지 및 데이터 보간**  
> 잠재공간이 구조적으로 정렬되어 있으므로  
> 이상치 탐지(anomaly detection)나 데이터 보간(interpolation)이 가능하다.  
> 학습된 분포 영역 바깥의 $z$ 에서 생성된 샘플은  
> 비정상적이거나 왜곡된 형태를 띠므로,  
> 이는 VAE가 학습 데이터 분포를 벗어난 입력을 탐지하는 근거가 된다.

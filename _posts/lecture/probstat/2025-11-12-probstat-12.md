---
layout: post
title: "[확률과 통계] 12주차"
date: 2025-11-12 11:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. Review : Image Classification  

<img src="/assets/img/lecture/probstat/12/image_1.png" alt="image" width="600px">

> **강의 내용**  
> 
> 오늘 GAN에 대해서 공부를 할 건데  
> 그 전에 리뷰를 한번 해봅시다.  
>
> 이미지 classification은  
> input에 3D 이미지, 2D 이미지 등  
> 이미지 형태의 데이터가 들어왔을 때  
> classifier가 최종적으로 레이블을 output으로 만들어 내는 것  
> 그것이 이미지 classification 모델의 정의였습니다.  
>
> classifier라고 하는 뉴럴 네트워크가  
> 주어진 이미지를 컨볼루셔널한 오퍼레이션을 통해서  
> 레이블이 어떻게 되는지에 대해서 평가를 하는 거죠.  
>
> 이 레이블은 랭귀지 토큰이 될 수도 있고  
> 전통적인 classification 모델이라고 한다면  
> 원핫 벡터가 될 수도 있습니다.  
>
> 클래스가 1,000개가 있다고 하다면  
> 1,000차원짜리의 벡터에서  
> 해당되는 컴포넌트만 1이 있고 나머지 부분은 0인  
> 원핫 벡터를 통해서 classification을 하곤 합니다.  

---

## p3. Review : Image Generation

<img src="/assets/img/lecture/probstat/12/image_2.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 그러면 이제 이미지 제네레이션이라는 게 무엇이냐고 한다면  
>
> 이전 시간에 우리가 VAE를 통해 어느 정도 맛을 봤지만  
> 그건 unconditional한 거였죠.  
>
> 그래서 Gaussian Random Variable을 가지고  
> 디코더를 통해 생성하는 것이  
> VAE의 목적이었는데  
> 
> 여기에서는 conditional한 제네레이션을 생각을 해보죠.  
>
> Fish라는 랭귀지 토큰 혹은 원핫 벡터가 존재할 때  
> 제네레이터가 그 레이블 인포메이션을 가지고  
> 그것에 해당하는 어떤 이미지를 생성해야 되는 겁니다.  
>
> 생성 모델, 특히 멀티모달 생성 모델들은  
> 이미지 classification의  
> 프로세스를 역으로 돌리는 거다  
> 라고 생각하시면 될 것 같습니다.  
>
> 여기서 이제 뭐가 중요하니?라고 하면  
> 뉴럴 네트워크 스트럭처라고 하죠.  
>
> classifier 같은 경우는  
> 원래 큰 이미지를 컨볼루션 레이어를 통해서  
> 점차적으로 intermediate한 피쳐맵들이 작아지면서  
> 최종적으로 레이블을 뱉게 되거든요.  
>
> VAE 스트럭처를  
> 깊게 살펴보시면 이해를 하실 거라 생각을 하는데  
> 디코더도 마찬가지로 그렇게 생겼습니다.  
>
> 역순으로 생겼습니다.  
> 
> 디코더 스트럭처에  
> 이런 레이블이 들어가거나 레이턴트 인포메이션이 들어가면  
> 작은 정보들을 좀 더 키워나가면서  
> 최종적으로 이미지 resolution에 맞게끔  
> 그렇게 뉴럴 네트워크가 구성이 되어 있죠.  
>
> 그런 부분들이  
> classification과 제네레이션의 차이이고  
> 이런 구조상의 특징점으로 인해서  
> 제너레이터 뉴럴 네트워크 아키텍쳐가 구성이 됐다.  
>
> 그런 히스토리컬한 컨텍스트가 있다고  
> 이해를 해주시면 될 것 같습니다.  

---

## p4. Review : Image Generation

- 고차원 미관측 변수들(high-dimensional unobserved variables)의 모델  $P(\mathbf{X} \mid \mathbf{Y} = y)$  

- 무작위 이미지를 샘플링하는 것 이상의 많은 문제들에 유용하다!

> **강의 내용**  
> 
> 이미지 제네레이션 같은 경우는  
> high dimensional unobserved variable $X$를  
> $Y$라는 condition에 대해서 probability density를 찾는 거죠.  
> conditional probability를.  
>
> large $Y$가 있고 small $y$가 있는데  
> small $y$는 deterministic하게 세팅을 한 거예요.  
>
> large $Y$가 랜덤 Variable이니까  
> small $y$는 어떤 결정적인 값이 되는.  
>
> 그러니까 예를 들어서 fish.  
> 이렇게 레이블이 주어졌을 때  
> 최종적으로 $X$라는 데이터를 생성하는 것.  
>
> 그것을 어떻게 확률적으로 모델링할 것이냐.  
>
> 이것이 이미지 생성 모델  
> 혹은 더 동형적으로 conditional 생성 모델의  
> 핵심 철학이라고 생각하면 될 것 같습니다.  
>
> 그래서 이 $P(X \mid Y)$를 학습시킨다는 관점에서  
> VAE와 마찬가지로  
> maximum likelihood estimation을 하게 되는 거고요.  
>
> $P$에다가 로그를 씌우고  
> $\theta$라는 걸로 parameterization을 해서  
> $\log p_\theta$를  
> optimization을 통해서 학습을 시키겠다는 것  
>
> 그것이 이미지 생성 모델의 주된 목표라고 보시면 될 것 같습니다.  

---

## p5. Review : Generative Model

<img src="/assets/img/lecture/probstat/12/image_3.png" alt="image" width="600px">

> **강의 내용**  
> 
> 이건 추상적인 레벨에서 얘기를 드린 거고.  
>
> 생성 모델이라는 건 추상적인 레벨에서  
> conditional한 정보들을 어떻게 처리할까에 대해서  
> 얘기를 드린 거고.  
>
> 다시 돌아가서  
> 지난 번에 VAE를  
> 중간에 설명이 없이  
> 수식으로 바로 들어온 감이 있는데  
> 
> 조금 더 설명을 더 드리겠습니다.  
> 지난 주에 했던 게 무엇인지에 대해서.  
>
> Generative 모델이라는 것은 이런 걸 한다는 거죠.  
>
> $z$라는 Random variable이 존재합니다.  
> Gaussian noise를 고려를 하죠.  
> 평균이 $0$이고, 분산이 $1$인.  
>
> 하얀색 박스로 cascade하게 표현이 되어 있는데  
>
> 이것은 neural network layer를 여러 번에 거쳐서  
> 인포메이션을 바꾸게 된다는 거고  
> 결국에는 $x$라는 이미지를 만들게 되는 겁니다.  
>
> $z$를 넣었을 때 $x$가 나온다는  
> 이 파트가 VAE에서 어디 파트였었죠?  
> 디코더.  
> 그렇죠 디코더 파트였습니다.  
>
> 인코더는  
> 이미지를 $z$라는 Random variable에  
> 프로젝션 시키는 거였었고.  
> 디코더는 거꾸로 했던 거죠.  
>
> 그래서 VAE는 정확하게 말하면  
> 생성 모델이 아닙니다.  
>
> VAE는 어떤 생성 모델을 랩핑하고 있는  
> 큰 파이프라인 학습 방법론이라고  
> 얘기를 할 수 있습니다.  
>
> VAE에서 특별히 생성 모델이라고  
> 얘기할 수 있는 파트는  
> 디코더라고 얘기를 해야 되요.  
>
> 이 개념이 되게 중요한 거라,  
> 이 개념적 차이점을  
> 이해를 하고 계시면 좋을 것 같아요.  

---

## p6. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_4.png" alt="image" width="530px">

> **강의 내용**  
> 
> 이 디코더 파이프라인으로  
> conditional 제네러티브 모델을 생각을 해 보면  
>
> unconditional한 인포메이션이  
> conditional한 bird라는 레이턴트 인포메이션으로 변하게 되고  
> 뉴럴 네트워크를 통해서 생성을 한다.  
>
> 그 말은 뭐냐면  
> conditional한 VAE 같은 경우는,  
> 
> 우리가 conditional VAE를 보지는 않았습니다만  
> 하지만 conditional VAE로 확장하는 것은 쉽습니다.  
>
> 앞에서 봤었던 $z$라는 Random variable을,  
> 디코더 스트럭쳐에 넣어서 이미지를 생성했었는데,  
> $(z, y)$라는 추가적인 정보가 들어가서  
> 모델링하게 됩니다.  
>
> 그래서 이 파이프라인을 보면은  
>
> VAE도 마찬가지고,  
> Generative Adversarial Network,  
> 뒤에 디퓨전 모델,  
> 모든 생성 모델에 대해서,  
> 이 conditional한 인포메이션을 어떻게 다뤄야 되는지,  
> 그에 대한 철학을 보실 수 있습니다.  
>
> 그래서 마찬가지로,  
> $z$라는 어떤 unconditional한 랜덤성을 주는 것과,  
> 추가적으로 $y$라는 걸 통해서,  
> 시맨틱을 부여합니다.  
>
> 근데 앞에서 말씀드렸었던 것처럼  
> 이것은 bird라는,  
> 원핫 벡터 같은 것을 표현하려고 했던 것 같아요.  
> 여기 PPT에서는.  

---

## p7. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_5.png" alt="image" width="600px">

> **강의 내용**  
> 
> 여기에서는 더 정밀한 묘사를 할 수 있겠죠.  
> 
> 오브젝트의 종류에 대해서 묘사를 할 때,  
> 예를 들어서 새, 자동차, 고양이 이런 것들을 표현할 때에는,  
> 원핫 벡터가 좋은 것 같고,  
>
> 새인데 더 명확하게  
> 이게 어떤 새인지에 대해서 묘사를 해야 될 때는  
> $y$라는 conditional이 이렇게 랭귀지 토큰,  
> 문장으로 표현되는 게 중요한 발전 상황이라고 보면 될 것 같습니다.  
>
> 이런 류의 생성 모델은 우리가 항상 쓰는 거죠.  
>
> 사실 structure적으로 봤을 때는 굉장히 쉽죠.  
>
> 그런데 잘 발달된 인프라 structure에,  
> 데이터를 넣고 수많은 데이터들을 한꺼번에 처리할 수 있는,  
> 코어 컴퓨팅들, 그리고 클라우드 컴퓨팅,  
> 그리고 전력의 사용, 큐잉, MLops 없이 이런 것들이 사실 메인인 것이지.  
>
> 학습 방법론이나 이런 것들은,  
> 우리가 여기서 배우는 GAN도 그렇고, VAE도 그렇고, 디퓨전 모델도 그렇고,  
> 철학은 같습니다.  
>
> 이것을 어떻게 스케일러블하게 키울 것이냐가 프로덕트까지 연결되는 것이지,  
> 철학은 같다고 보시면 될 것 같아요.  
>
> 그래서 이렇게만 보면 너무 쉽죠.  
> 근데 이제 진짜 문제는 엔지니어링에 있다.  
> 이런 어떤 theoretical part가 아니다.  
> 그렇게 생각하시면 될 것 같습니다.  
>
> 이것은 랭귀지 토큰을 가지고  
> 컨디셔닝을 한다고 가정을 하는 것입니다.  

---

## p8. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_6.png" alt="image" width="570px">

> **강의 내용**  
> 
> 이런 것도 생각해 볼 수 있을 것 같아요.  
> $y$라는 흑백 이미지가 있고,  
> 
> 이것은 어떻게 만들었을까요?  
> 오른쪽에 원본 노란색 새 사진을 decolorization,  
> 
> 이건 deterministic한 알고리즘이 존재를 합니다.  
> 색깔을 없앨 수 있어요.  
>
> 색깔을 없애는 pair를 만들어 놓고,  
> 이것을 학습하게 만드는 거죠.  
>
> 그러면 이것의 목적은 무엇일까요?  
> Colorization 해주는 거죠.  
> 색깔이 없는 이미지를 넣었을 때 색깔이 나오게끔.  
>
> 여러분들 옛날 영상 같은 거,  
> 필름이 막 만들어진 시대의 영화나,  
> 그런 산업이 태동할 때의 영상을 보면,  
> 이렇게 블랙으로, 흑백으로 되어 있는 영화를 colorization 해주는  
> 그런 것들이 많이 있잖아요.  
>
> 그런 AI 모델들은,  
> 수많은 데이터셋의 이 pair들을,  
> 엄청나게 큰 인프라를 통해서 학습을 시켜 놓은 결과물이라고 보면 될 것 같아요.  
>
> $y$랑 $x$에 대한 컨디셔닝을 어떻게 하느냐는,  
> 생성 모델의 어떤 목적이냐,  
> 테스트, 시나리오에 따라 다른 거죠.  
>
> 우리가 생성 모델을 어떻게 훈련시켜서  
> 어디에다 사용할 것이냐가,  
> 컨디셔닝을 어떻게 할 것이냐랑 같은 말입니다.  
>
> 그걸 이것을 준비하는 여러 가지 방법이 있습니다.  

---

## p9. Data Preparation in Conditional Generation

<img src="/assets/img/lecture/probstat/12/image_7.png" alt="image" width="720px">

> **강의 내용**  
> 
> 생성 모델의 초창기에는 이런 걸 굉장히 많이 했습니다.  
>
> 첫 번째로, Object Labeling
>  
> 이런 페어링, conditional 페어링을  
> 만드는 것을 많이 했었던 거거든요.  
>
> 여러분들 Segmentation에 대해 들어보셨나요?  
> 예를 들어서, 사람 이미지를 주면,  
> 머리는 머리, 팔이면 팔,  
> 이렇게 나눠주는 Segmentation 모델도 있고,  
> 
> 요즘에 발달을 많이 해서,  
> 이미지를 던져주면 색깔을 칠해줍니다.  
> 이 시맨틱이 여기 어디인지,  
> 
> 삼성 카메라 같은 것을 보면  
> 이미지 보고 어디를 알려주면,  
> 거기를 다른 물체로 채워주고,  
> 
> 그것을 하기 위해서는 흔한 말로 누끼를 뜬다고 했죠?  
> 누끼를 뜨려면 이런 Segmentation이 들어가야 되거든요.  
>
> 그래서 그런 생성 모델에는  
> 기본적으로 Segmentation 하는 것이 들어가 있고,  
> 그 파트를 이제 바꿔주는 형태가 되는 거죠.  
>
> 예를 들어서  
> 이렇게 말타는 이미지가 오리지널 이미지인데,  
> 이 Object Labeling이라는 Segmentation 알고리즘을 통해서,  
> 우측의 마스크를 찾습니다.  
> 이렇게 페어링을 만들어요.  
>
> 훈련을 진행을 하고,  
> Inference 할 때는  
> 이 Label을 주고 왼쪽의 이미지를 생성하게 하는 거죠.  
>
> 이게 말 사진도 있고, 강아지 사진도 있고,  
> 사람의 형체들도 많이 있을 텐데,  
>
> 우리가 상상하는 건 그런 거죠.  
>
> 이렇게 말 모양이나 고양이 모양 같은 것을 사람이 핸드드로잉 하면  
> 거기에 맞는 뭔가 어울리는 이미지가 생성되지 않을까?  
> 라는 게 사실 지금의 나노바나나 같은,  
> 현대 생성 모델들에 다 들어가 있는 기능이라고 보면 됩니다.  
>
> 지브리 풍을 바꾸는 것을 제가 예제로 많이 드는데,  
> 그런 것도 사실 이런 합성 버전이라고 생각하시면 될 것 같아요.  
>
> 이건 Object Label을 통해서  
> 데이터와 conditional 페어를 만드는 거였고,  
>
> 두 번째는 Edge Detection을 생각해 볼 수 있을 것 같아요.  
>
> Edge Detection은 사실 고전적인 컨디셔너링 방법론으로,  
> 만들 수 있는 컨디셔닝하는 이미지를 생각할 수 있거든요.  
>
> 왼쪽에 복잡한 동물들이 있고,  
> 내추럴 오브젝트들이 있는 것에 대해서  
> Edge Filter를 가하게 되면 오른쪽과 같이,  
> 이 동물이나 어떤 내추럴 오브젝트의 겉만 나오게 됩니다.  
>
> 이렇게 만들어서 훈련을 한 다음에 Inference를 하면 어떻게 될까요?  
> 그러면 오른쪽에 어떤 엣지만 그려주면  
> 그 안에 컨텐츠를 채워주겠죠.  
> 왼쪽에 오브젝트 세그멘테이션과 같이.  
>
> 그리고 세 번째,  
> 텍스트 투 포토는 방금 말씀드렸었고  
>
> 또 이런 conditional 모델이 되게 중요하게 생각되고,  
> 여러분들 비디오 생성, 생성 모델을 많이 하잖아요.  
>
> 그것에 대한 철학이 무엇이냐.  
> 그것도 conditional하게 생성을 하거든요.  
>
> 바로 전 프레임이 주어졌을 때,  
> 그 다음 프레임에 대해서 생성하는,  
> 그러니까 전 프레임이 비디오의 컨디션이 되는 거고,  
> 거기에 해당하는 다음 프레임을 만들어내는 게 생성 모델의 목표인 거죠.  
>
> 이것을 여러 번 concatenation 하면 어떻게 될까요?  
> 그러면 주어진, 처음 이미지에 대해서 순서대로 만들어주는 거죠.  
>
> 마찬가지로 이것도 비디오 생성 모델들에 대해서  
> 철학을 제공해주는 거고,  
> 
> 파이프라인적으로 봤을 때는,  
> 물론 엄청나게 많은 엔지니어링이 있다고 말씀드렸습니다.  
>
> 근데 파이프라인적으로 봤을 때는,  
> 사실 이런 것을 하는 것과 다름이 없다.  
>
> 이 기술이 극한으로 발달돼서  
> 그런 형태까지 간 거겠죠.  
>
> 그래서 이렇게 conditional 제네레이션을 할 수 있다.  

---

## p10. Challenges?

1. 출력은 고차원(high-dimensional)이며, 구조화된 객체(structured object)이다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 매핑(mapping)에 불확실성이 존재하며, 가능한 출력들이 많다.

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

> **강의 내용**  
> 
> 이제 그러면, 이런 제너러티브 모델의 문제가 뭐냐?  
> 라고 하면은, 좀 여러 가지가 있는데,  
> 
> 일단 제너러티브 모델에서 가장 문제가 되는 것은,  
> 이 매핑에 대해서  
> one-to-one 매핑,  
> one-to-many 매핑이라는 문제가 있습니다.  
>
> 그게 뭐냐면,  
> $z$라는,  
> 그러니까 예를 들어서,  
> 이렇게 지워졌을 때,  
> 어떤 conditional 페어가 존재할 때,  
> 계속 똑같은 이미지만 생성을 하면,  
> 우리가 생성 모델을 쓸 필요가 없는 거잖아요.  
>
> 그러면 어떤 레이블을 줬을 때,  
> 생성할 때마다 들어가는 컨텐츠는 조금씩 다르지만,  
> 유저가 만족감을 얻는 정도의 퀄리티가 나와야 될 겁니다.  
>
> 그건 뭐냐면,  
> 분명히 컨디셔닝은 똑같은데,  
> 나와야 되는 아웃풋은 여러 개라는 거.  
> 그게 one-to-many correspondence라는 거거든요.  
>
> 그래서 conditional 생성 모델의 중요한 특성 중 하나는,  
> one-to-many의 correspondence를 만들어야 되는,  
> 그런 특성을 유지를 해야 됩니다.  
>
> 그렇기 때문에 probabilistic한 관점을 갖고 가는 거예요.  
> 랜덤성이라는 걸 갖고 가는 거거든요.  
> 뭔가 계속 새롭게 만들어야 되기 때문에.  
>
> 그렇게 정리할 수 있을 것 같습니다. 

---

## p11. Property of Generative Models?

1. 고차원적이고 구조화된 출력을 모델링한다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 불확실성을 모델링한다; 가능한 출력들의 전체 분포를 모델링한다.  

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

---

## p12. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_10.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이제,  
> 전통적인 관점의 Image-to-image Translation을 생각해봅시다.  
> 
> 아까 제가 pair를 만든다고 했었어요.  
> 
> 그것을 이제 Generative Model의 관점이 아니라,  
> 혹은 Generative Model이라고 하더라도,  
> 되게 좀 제네럴한 뭔가로 그 문제를 정의를 하고 싶은 것,  
> 수학적인 공식을 통해서.  
>
> Training Data는  
> black, decolorized에 대한 data와  
> color가 있는 것,  
> 이렇게 $x, y$ pair를 만들게 되고,  
> 
> 그러면 이제 우리가 뭘 목표로 하느냐 하면,  
> 
> Image-to-Image Translation에서는  
> 이런 수학 수식 같은 것을 목표로 합니다.  
>
> $F$는 neural network가 되는 거고,  
> $L$ 같은 경우는 objective function이 되는 거죠.  
>
> 그래서 neural network가 $X$를 통과시키고,  
> 그것을 $L$을 통해 $Y$와의 차이점을 measure하고,  
> expectation을 취했을 때,  
> 가장 작게 만드는 그런 function,  
> neural network를 찾게 됩니다.  

---

## p13. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_11.png" alt="image" width="540px">

> **강의 내용**  
> 
> 조금 더, 관점적으로 해석을 해보자면,  
> 
> $F$ 같은 경우는,  
> 어떠한 방식으로 우리가 $x$로 $y$로 만들 것이냐,  
> How should I do it?  
> 라는 질문에 대한 것을 묘사를 하는 거라고 보고,  
>
> $L$ 같은 경우는,  
> 어떻게 하는 건지는 알았는데,  
> 우리가 뭘 해야 되는 것이냐,  
> 어떻게 줄이고, 뭘 줄일 것이냐,  
> 라는 질문에 대한 요소라고 보시면 될 것 같습니다.  
>
> 그래서 $F$라는 neural network을 통해서 output이 나오면,  
> 
> $L$은,  
> 예를 들어서 $L2$ distance 같은 걸 생각을 하면,  
> $x$가 $y'$로 되고,  
> true $y$와의 거리를 줄임으로써,  
> color가 생성이 되기를 원하는 거죠.  

---

## p14. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_12.png" alt="image" width="720px">

> **강의 내용**  
> 
> 여러 가지 Loss Function을 고려해 볼 수 있는데,  
> 여기에서는 $L2$라는 Euclidean Distance를 고려했을 때의,  
> 결과물을 생각해 볼 수 있을 것 같아요.  
> 그리고 이것은 최적은 아니고,  
> 이런 식으로 나오는 게, 많이 관찰되는 형태다,  
> 이런 겁니다.  
>
> Neural Network을 잘 설계를 하면,  
> Output이 ground truth랑 비슷할 수도 있어요.  
> 
> 보통의 경우는, Neural Network을 키우더라도,  
> 이런 output regime에 빠지게 된다는 거죠.  
> (모델이 특정한 출력 방식 혹은 출력 패턴에 갇히게 된다는 뜻)  
>
> $Y'$라는 target이 존재를 하고,  
> $Y$는 Neural Network가 만들어 내는 거라고 생각해 봅시다.  
>
> $h$랑 $w$는 Image의 X축, Y축의 좌표에 대해서 표현을 하는 거구요.  
>   
> 이 수식이 설명을 하는 거는,  
> 각각의 pixel-wise로 L2 distance를 재서,  
> square를 한 다음에 다 더하는 것입니다.  
>
> 그러면 이 이미지가 얼마나 다른지에 대해서 묘사가 하는 것이 되겠죠.  
>
> Input을 넣고, Neural Network를 나왔을 때,  
> Output이 이 중간이고,  
> ground truth는 오른쪽과 같습니다.  
>
> 이 Output은 노란색이 아니기 때문에  
> 결과가 잘 나오지 않았다고 생각할 수 있습니다.  
>
> 이렇게 L2 loss로 deterministic하게,  
> 생성 모델적으로 수행하지 않는 모델들은,  
> 색깔의 차이가 많이 나면서,  
> pixel space 위에서 optimization이 잘 되지 않습니다.  
>
> colorization 방법론에,  
> 생성 모델을 많이 사용하는 것도,  
> 이런 문제가 있기 때문에 그런 것입니다.  
>
> 앞에서는 conditional항에 대해서 예제만 말씀드렸으니까,  
> 이게 실질적으로 deep neural net을 가지고 어떻게 학습되는지,  
> 진행을 해보도록 하겠습니다.  

---

## p15. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_13.png" alt="image" width="720px">

> **강의 내용**  
> 
> 이렇게 페어링을 하는 것 중에,  
> Colorization, 즉, 컬러를 채우는 것이 있고,  
> Super Resolution이라는 중요한 컴퓨터 비전 task도 있습니다.  
>
> conditioning을 걸 때,    
> resolution이 줄어든 이미지를 resolution이 키워진 이미지로 만들어야 되는 거,  
> 그러니까 정보를 채우는 거거든요.  
>
> 이런 종류도 image-to-image translation에서 많이 사용을 합니다.  
> 
> image-to-image translation을,  
> 생성 모델들이 잘 하기 때문에,  
> 이런 것들을 생성 모델로 많이 합니다.  
>
> 요즘에 Nano Banana를 제가 자꾸 말씀드리는데,  
> 유명한 교수님이 Nano Banana 모델로 super resolution을 해봤어요.  
> 
> 화질이 안 좋은 카메라로 찍은 다음에,  
> super resolution을 해 줘, 라고 하면,  
> 
> 전광판 같은 것들,  
> 한자들이 blurry해서 잘 안 보이는데,  
> 모델이 새로운 정보를 창조를 하게 됩니다.  
>
> 생성 모델은 다 이런 프레임워크 안에서 해석할 수 있습니다.  
> (특히 컴퓨터 비전적인 입장에서 봤을 때)  
>
> 우리가 생성 모델을 컴퓨터 비전에만 쓰진 않지만,  
> (이미지에만 쓰진 않지만)  
> 이미지의 예제로 봤을 때는, 이런 것들을 생각해 볼 수 있다는 거죠.  

---

## p16. Motivation : GANs

<img src="/assets/img/lecture/probstat/12/image_14.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그러면 여기까지의 내용이 GAN이랑 무슨 상관이냐,  
> 생성 모델이랑 무슨 상관이냐,  
> weak한 관계였는데,  
> 
> 이것은 문맥에 대해서 여러분들이 잘 모르시기 때문에,  
> 설명을 드리려고 얘기한 것이고,  
>
> 오늘 우리의 목표는 뭐었죠?  
> Generative Adversarial Network를 정의를 하는 것이었잖아요.  
>
> 그러면 이제 Generative Adversarial Network라고 하는,  
> 생성 모델을 정의해 봅시다.  
>
> 왼쪽 그림 같은 경우, 페어가 있습니다.  
> $y$라는 페어, 그리고 $x$라는 페어,  
> 우리가 다 생성할 수 있다고 했었죠.  
>
> 페어링을 만들어 놓은 것을 생성된 데이터라고 하다면,  
> 이것과 구별되는 리얼 포토들을 준비를 해 놓습니다.  
>
> 왼쪽은 $x$에서 $y$로 가는 명확한 가이드라인이 존재를 하는데,  
> 이것를 세트로 보는 거예요.  
>
> 이것은 one-to-one correspondence가 되는 건데,  
> 생성 모델은 그게 아니라고 했었잖아요.  
>
> 그냥 deterministic한 알고리즘을 통해서 학습을 하게 되면,  
> 블랙 이미지 하나가 들어가면,  
> 무조건 같은 색깔의 distribution을 갖는 같은 이미지만 나올 텐데,  
>
> 그게 싫으니까,  
> 이렇게 페어링을 다 한 다음에,  
> 리얼 포토와 전체적으로 비교를 하는 거예요.  
>
> 데이터셋 전체끼리.  
>
> 복잡한 개념인데,  
> 뒤에서 수학적으로 조금 더 명명하게 정리를 하도록 하겠습니다.  
>
> 그래서 Generative Adversarial Network가 뭐냐면,  
> 이렇게  
> set of fake 이미지,  
> set of real 이미지  
> 같은 것들을 구별을 하는  
> classifier가 들어간 생성 모델이라고 생각하시면 될 것 같아요.  
>
> 이것은 2014년도에 Ian Goodfellow라는 분이 만들었습니다.  
> 유명한 딥러닝 책의 저자이기도 하죠.  
>
> 한때, 생성 모델의 흐름을 아주 휩쓸었었던  
> 중요한 모델 중에 하나라고 생각을 합니다.  

---

## p17. Actor-critic Perspective

<img src="/assets/img/lecture/probstat/12/image_15.png" alt="image" width="600px">

> **강의 내용**  
> 
> 조금 더 들어가서,  
> GAN이라는 모델이 어떻게 작동을 하는지,  
> 생각을 해볼게요.  
>
> 일단 $x$라는 이미지 또는 컨디션이  
> $G$라는 generator라는 뉴럴 네트워크에 들어가게 됩니다.  
>
> generator의 목적은,  
> 어떤 이미지를 생성을 하는 거예요.  
> 그래서 generator가 $G(x)$라는 이미지를 생성했는데,  
> 
> 뒤에 또 다른 뉴럴 네트워크가 존재합니다.  
> discriminator라는,  
> 혹은 critic이라 불리는  
> 뉴럴 네트워크가 존재를 하는데,  
>
> 그 뉴럴 네트워크는  
> 앞에서 generator가 만든  
> 생성된 데이터가 진짜냐 가짜냐  
> 판별을 해주는 뉴럴 네트워크입니다.  
>
> 만약에 generator가 만든 데이터가  
> discriminator가 보기에  
> fake라고 판단이 된다?라고 한다면,  
> 
> fake라고 해서  
> generator한테 벌을 가한다고 해야 될까요?  
> negative signal을 주게 됩니다.  
>
> generator 입장에서는  
> discriminator가 negative signal을 주지 못하도록  
> 속여야 됩니다.  
>
> 그래서 generator와 discriminator가 서로  
> 공통된 자원,  
> $G(x)$라는 것을 어떻게 판별할 것이냐는  
> 공통된 자원을 가지고 서로 싸우게 됩니다.  
>
> 수학에서는 이걸 min-max, zero-sum 게임이라고 하거든요.  
>
> 어떤 수학적 formulation이 있는데,  
> 죄수의 딜레마를 아실 거라고 생각하는데,  
> 그것도 게임이론 시나리오 중에 하나거든요.  
>
> 그런 것처럼  
> 이 generative adversarial network를,  
> actor-critic perspective하게 봤을 때에는,  
>
> 두 개의 뉴럴 네트워크가  
> 모두 학습에 사용이 되는데,  
> generator와 discriminator는  
> 서로 하나의 자원, 생성된 데이터에 대해서  
> 싸우는 min-max, zero-sum 게임을 한다.  
>
> 밑에 영어로 표현이 되어 있는데,  
> $G$는 $D$를 속이기 위해서 가짜 이미지를 만들고,  
> $D$는 가짜 이미지가 가짜인지 진짜인지  
> discrimination을 하는 목표를 갖고 있습니다.  
>
> 이런 예제가 많더라고요.  
> 
> 범죄집단이 위조지폐를 만들면,  
> 그 위조지폐를 경찰들이 검사를 해서  
> 진짜인지 아닌지 판별을 해야 되는 것입니다.  
> 이런 예제들도 설명을 하는데 많이 쓰이구요.  
>
> 그것도 actor-critic perspective하게 보면  
> 비슷한 문제로 생각해 볼 수 있을 것 같아요.  
>
> 그러면 앞에서 generator와 discriminator  
> 두 개의 뉴럴 네트워크가 있다고 가정을 했는데,  
>
> 이게 VAE로 보면 신기해요.  
> VAE 관점에서 보면 뒤집혀진 VAE거든요.  
>
> 이게 무슨 뜻이냐면,  
>
> 원래 VAE에서서  
> 인코더는 데이터가 들어가고 latent variable이 나오잖아요.  
> 디코더는 latent variable이 들어가고 이미지가 나오죠.  
>
> 그런데 $G$는 앞에 있는데,  
> latent variable이 들어가고 데이터가 나오거든요.  
> 이게 디코더와 비슷한 역할이었고,  
>
> discriminator는 데이터가 들어가고 latent variable 같은 게 나오거든요.  
>
> 그래서 인코더, 디코더를  
> 거꾸로 꽂아놓은 구조라고 보면 될 것 같아요.  

---

## p18. Role of discriminator : critic

<img src="/assets/img/lecture/probstat/12/image_16.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그러면 discriminator의 목적과 훈련 방식에 대해서  
> 설명을 드리도록 하겠습니다.  
>
> 위에 그림을 생각해 봅시다.  
> 
> 먼저 generator가 존재하고,  
> $G(x)$라는 generator가 생성한 데이터를  
> discriminator에 넣게 됩니다.  
>
> 아래와 같은 objective function을 고려한다고 가정하면,  
>
> discriminator의 값이 크면 클수록  
> fake라고 생각을 하는 거고,  
> 
> discriminator의 값이 낮으면 낮을수록  
> real value라고 생각하는 거예요.  
>
> discriminator 입장에서 보면,  
> fake 이미지가 들어왔을 때  
> discriminator가 뱉어내는 값을 크게 만들어야 되는 거고,  
> 
> real 데이터가 들어왔을 때는  
> discriminator가 뱉어내는 데이터를 0으로 만들도록  
> 훈련을 해야 됩니다.  
>
> 아래의 표현이 이렇게 되어 있습니다.  
>
> $1 - D(y)$를 maximizing 하면  
> $D$는 최대한 값을 줄이도록 학습이 됩니다.  
> 그건 두 번째 초록색 term입니다.  
> 
> $G$가 만들어낸 fake 데이터는 $G(x)$로 표현되잖아요.  
>
> $G(x)$가 $\log D(\cdot)$에 들어가고  
> maximizing 하도록 옵티마이징이 되면  
> discriminator의 output이 최대한 커지게 됩니다.  
>
> 이 두 개의 purpose를 동시에 만족시키는  
> neural network parameter, $\theta$를 찾는 겁니다.  
>
> 그런데 이것은 재밌어요.  
> 이런 것은 기존의 머신러닝 알고리즘,  
> 인공지능 알고리즘에서 흔하지 않습니다.  
>
> 왜 흔하지 않냐면,  
> 옵티마이징이 굉장히 불안하기 때문입니다.  
>
> 트레이닝을 하다 보면  
> converge되는 형상을 보기가 힘들어요.  
>
> discriminator와 generator의 parameter나,  
> representation power에 대한 비율이 깨지게 되면  
> 트레이닝이 diverge되면서  
> 학습이 실패하는 경우가 많습니다.  
>
> GAN 같은 경우 모든 게 다 잘 되서 훈련이 끝나게 되면,  
> (물론 discriminator는 버리게 되지만)  
> $G$라는 생성 모델에 input을 넣게 되면  
> output이 바로 나오는 형상입니다.  
>
> VAE는 reconstruction loss에 대한 constraint가  
> neural network를 학습하기에 좋은 모양은 아닙니다.  
> 그런 수학 수식은 아니거든요.  
>
> 그래서 평균적으로 비슷한 정도의  
> parameter의 숫자를 갖고 있다고 했을 때,  
> VAE보다 GAN이 훨씬 더 좋은 것 같아요.  
> (학습만 잘 된다면)  
>
> 그런데 문제는,  
> 이런 식으로 $\log D(\cdot)$ 안에 $G$가 물려 있고,  
> 두 개의 loss에 대해서,  
>
> $\log$ function이 미분하면  
> 곤란한 성질이 있거든요.  
>
> $\log x$를 미분하면 $1/x$인가요?  
> 그럼 $x$가 0에 가까워지면 어떻게 되죠?  
> 폭발하겠죠, 미분값이.  
>
> gradient explosion 문제가  
> 굉장히 쉽게 생깁니다.  
>
> 그런 문제들이 있어서  
> 이런 object function을  
> 그냥 direct하게 고려하기 너무 힘듭니다.  
>
> 여하튼 그건 더 구체적인 얘기인 거고,  
> 이 discriminator, critic의 목표를 봤을 때는  
> 이런 행동을 하는 거다.  
>
> 이 그림, 위에 그림과 밑에 그림을  
> 방법론적으로 해석을 해보면,  
> 이게 의미가 뭐냐라고 하면,  
>
> 공부를 하는 거죠, discriminator가.  
> 진짜는 진짜라고 공부하고,  
> 가짜는 가짜라고 공부하는 거죠.  
>
> 가짜 시그널을 받고 공부하는 게 아니에요.  
> real에 대한 어떤 pivot이 있는 거죠.  
>
> discriminator는  
> real을 배우지 않고는 fake인지 모릅니다.  
>
> 그래서 그 부분이 중요합니다.  

---

## p19. Role of generator : actor

<img src="/assets/img/lecture/probstat/12/image_17.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그러면 이제 actor.  
> generator의 role이 무엇인가 하면,  
>
> 위에서 object function은  
> $D$에 대해서 $\arg\max$를 해서,  
> 
> fake면 숫자가 커지도록,  
> real이면 숫자가 작아지도록  
> 훈련이 된다고 했잖아요.  
>
> 그러면 generator는  
> 역방향으로 훈련을 하면 되겠죠.  
>
> fake일 때 real처럼 판단하도록 속이고,  
> real일 때 fake가 되게끔 속이면 되는 거잖아요.  
>
> 그죠?  
>
> 그런데 문제는 object function에서,  
> discriminator가  
> 진짜 샘플에 대해서 학습하는 걸 속일 수는 없습니다.  
>
> 거기에는 $G$가 개입하지 않기 때문에.  
>
> $G$가 개입하는 것은,  
> 이 수식에서 첫 번째 term입니다.  
>
> 내가 만든 것을 $D$라는 애한테 주기 전에  
> 최대한 속여야 되는 거죠.  
>
> 잘 속이면 discriminator는 혼란이 올 거예요.  
>
> $G$가 만들어 낸 가짜 데이터에 대해서,  
> 원래 fake여서 최대한 값이 높아져야 되는데,  
> 값이 낮아지게끔 설계를 했잖아요.  
>
> 그러면 discriminator 입장에서는,  
>
> 분명히 내가 공부한 거랑 다른데,  
> 내가 공부했던 거는 진짜 이미지가 있는데,  
> 왜 네가 만든 게 진짜라고 얘기하느냐처럼  
> 되게 교란이 되는 거죠.  
>
> 그래서 fool한다라고 표현을 하는 거예요.  
> objective function 입장에서.  
>
> 그럼 이제 똑같은 objective function,  
> 모양이 똑같아요, 잘 보면.  
>
> 여기 $\arg\max$랑 $\arg\min$을 취한다는 것만 다르고,  
> 그 안에 있는 내용은 똑같습니다.  
>
> 그러니까 이 안에 expectation이 취해져 있는 것은  
> 공통의 자원인 거고,  
>
> discriminator는 그거를 크게 하도록,  
> generator는 그걸 작게 하도록  
> 서로가 싸운다는 거죠.  

---

## p20. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_18.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이런 식으로 min-max game으로 고려한 겁니다.  
>
> 그런데 우리의 목표가 뭐죠?  
> 생성 모델.  
>
> 이 Generative Adversarial Network의 목표는 뭐가 되어야 될까요?  
> 잘 판별하는 게 목표가 될까요?  
> 아니면 잘 생성하는 게 목표가 되어야 될까요?  
>
> 생성하는 것이 목표가 되어야겠죠.  
>
> 그렇다면 이 싸움은 무조건 discriminator가 지게끔 설계를 해야 됩니다.  
> 최종적으로는.  
>
> discriminator는  
> generator가 좋은 퀄리티의 샘플을 만들어 내도록  
> 독려를 하고 도와줘야 하는 의무는 있지만,  
> 마지막 순간에는 generator가 승리를 하게 만들어야 돼요.  
>
> 그게 이렇게 표현되어 있는 거거든요.  
>
> mathematical operation을 할 때  
> 오른쪽에 있는 걸 먼저 합니다.  
>
> 그래서 $D$가 maximization을 먼저 하죠.  
>
> $D$가 최대한 잘 판별한 것에 대해서,  
> 즉, 최대 판별에 대해서,  
> generative가 그것을 최소로 만드는 거죠.  
>
> 네가 아무리 최대 노력을 하더라도  
> 난 그것을 줄일 것이다.  
> 라고 objective function이 고려가 되어 있는 거예요.  
>
> 이 전체가 어떻게 보면  
> 모든 GAN 모델, Adversarial Training의  
> 핵심 철학이라고 보면 될 것 같아요.  
>
> 이것을 그냥 단순히 생성 모델에 국한된 거냐?  
> 이렇게 볼 수도 있는데,  
> 
> 그게 아니고  
> 이것은 신뢰성과 관련된 많은 것에 연결이 되면서,  
> 매우 중요합니다.  
>
> 예를 들어서 이런 것을 생각해 볼 수 있거든요.  
> 
> 여러분들 혹시 Adversarial Attack이라고 들어봤어요?  
>
> Adversarial Attack이라는 것이 있어요.  
> 
> classifier에 이미지를 넣었을 때,  
>
> 앞에 예제를 보면서 얘기를 해보죠.  
>
> classifier에 생선 사진을 넣었으면  
> 생선에 대한 레이블이 나와야 되잖아요.  
>
> 그런데 Adversarial Attack은 뭐냐면,  
> 
> 이 classifier를 최대한 속일 수 있는 생성 모델이  
> 이 이미지에, 픽셀 레벨에서 굉장히 작은 값,  
> $0.00001$을 넣게 되면,  
> 이 이미지에 대한 output 값을 바꿔버릴 수 있어요.  
>
> 이런 min-max 게임 형식으로 forging을 해서,  
> GAN의 트레이닝 objective를 사용하거든요.  
>
> 사람의 눈으로 볼 때는 구별이 불가능합니다.  
> 왜냐하면 픽셀 레벨에서 $0.00001$은  
> 사람 눈으로 구별이 안 되니까.  
>
> 그런데 데이터로는 다르거든요.  
> 
> Neural Network는,  
> 우리가 long bit도 쓰긴 하지만  
> 기본적으로 double bit를 쓰는데,  
> double의 precision에서는  
> $0.00001$도 표현이 되거든요.  
>
> 그런데 그 값이 이런 min-max operation을 통해  
> 이미지에 injection이 되고  
> classifier를 속일 수 있도록 생성이 될 수 있어요.  
>
> 그런 것을 Adversarial Attack이라고 하거든요.  
>
> 사람 눈에는 전혀 구별 못하고  
> 실제로 $L2$ norm 같은 걸로도 구별하기 힘듭니다.  
>
> 그래서 가장 최근에 나오는 classifier도  
> Adversarial Attack을 하면 다 attack이 돼요.  
>
> 이건 엄청난 문제겠죠.  
>
> 공격자가 이미지에 악성 코드를 넣고,  
> 그 이미지를 인터넷에 뿌려서,  
> 누군가 그것을 classifier나 서비스에 업로드하면  
> output 값을 완전히 뒤집어 버리는 거예요.  
>
> 생명과 관련된 문제,  
> 예를 들어서 테슬라 이미지 classifier 같은 데서  
> detection을 한다고 해봅시다.  
>
> 만약 테슬라 센서에 adversarial 픽셀을 주입한다면  
> 앞에 사람을 표지판이라고 생각할 수 있겠죠.  
>
> 그래서 보안 이슈에서 굉장히 큰 문제였습니다.  
> 아직도 해결이 안 됐어요.  
>
> Neural Network structure의 한계 때문에  
> 근본적으로 해결이 안 되고,  
> 접근을 못하게 wrapping하는 방식만 존재합니다.  
>
> 생성 모델의 min-max 게임 구조를 통해서.  
> 이런 재밌는 문제들을 만들 수 있다.  
>
> 다시 돌아가자면,  
> 우리가 하는 것은 이제,  
> 최대한 노력을 한 discriminator를 속일 수 있는 generator를 만드는 것,  
> 그것이 목표고,  
>
> 그것을 $\arg\min_G\, \max_D$  
> objective function을 통해서 표현을 한다.  

---

## p21. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_19.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 G의 입장에서 봤을 때 D는 loss function입니다.  
> 왜냐하면, G가 지금 $G(x)$가 D의 input으로 들어갔잖아요.  
> 그래서 $\log D(\cdot)$가 G의 입장에서 봤을 때 loss function처럼 거동을 하는 거죠.  
>
> 왜냐, 우리가 앞에서 이렇게 얘기를 했습니다.  
> 그래서 Neural Network의 output이 뭔가의 objective function으로 래핑이 돼가지고 고려가 됐는데,  
> 이 모양이 똑같이 생겼잖아요 밑에가.  
>
> 그래서, 그...  
> generator 입장에서 봤을 때 D는 loss function이다.  
>
> 근데 이게 조금 재밌는 거죠.  
> 앞에서 우리가 Image-to-Image Translation 같은 거 할 때는  
> 이 $L$이라는 거를 Pixel-wise L2 Distance로 정의했었는데,  
> 이거는 움직이는 loss function인 거예요.  
>
> G 입장에서 보면.  
> D가 계속 학습되면서 바뀌니까.  
> G 입장에서 그걸 계속 풀어야 되고,  
> 그걸 계속 옵티마이제이션 해야 되니까,  
> G 입장에서는 시간에 따라 변하는 loss function이라고 볼 수 있어요.  
>
> 그래서 그렇게 생각하면 될 것 같고.  
>
> 그럼 이거를 실질적으로 훈련을 할 때는  
> 어떤 식으로 훈련을 하느냐.  
> 이제 앞으로 저희가 GAN 코드도 볼 겁니다.  
> 코드 implementation 하면서 확인을 할 텐데,  
> 이게 사실 Maximum D를 취한 다음에 Min G를 하면은,  
> 이게 사실 이게 정확하게 수학적으로는 잘 정리가 돼있지만,  
> 이거를 실질적인 어떤 코드 입장에서 우리가,  
> 코드 레벨에서 이걸 구현을 해서 학습시킨다는 건 사실 거의 불가능해요.  
>
> Maximizing D를 어떻게 할 것이냐.  
> $G$는 처음에 Initialization이 어떻게 되어 있을까요?  
> 파라미터를 만들면, Neural Network를 그냥 만들면.  
> 쓰레기 값으로 차 있거든요, 파라미터들이.  
>
> 그럼 그거를 아무리 속여봤자 아무런 의미가 없는 거잖아요.  
> 서로 발전하면서 뭔가 표현이 되어야 되는데.  
>
> 그리고 이 수학 수식이 그거를 묘사를 하고 있는데,  
> 그래서 실질적으로 우리가 이런 Neural Network의 어떤 두 개의 중첩에 대해서,  
> 하나는 Gradient Ascent를 하고,  
> 하나는 Gradient Descent를 하는 거를 반복하게 됩니다.  
>
> 그래서 이 discriminator 입장에서는  
> 어떤 Objective Function을 Maximizing 하는 거니까,  
> Gradient Descent는 Optimization의 Loss Function 값을 줄이는 거였잖아요.  
>
> 근데 discriminator 입장에서는 Maximization을 하니까  
> Gradient Ascent를 합니다.  
> 그러니까 Gradient가 원래 Minus 방향으로 줄이는 건데,  
> 역방향으로 하는 거죠.  
>
> 그럼 전체 Objective Function의 값이 커질 테니까.  
>
> 그래서 먼저 discriminator를 업데이트를 하고,  
> 그 다음에 Generator를 업데이트를 합니다.  
>
> 근데 Generator 업데이트를 할 때는  
> 우리가 이 Objective Function을 줄이는 게 목적이기 때문에,  
> Gradient Descent를 하는 거죠.  
>
> 그래서 discriminator는 Gradient Descent 한 번 하고  
> Generator를 잠그고,  
> Gradient Descent를 Generator가 하고,  
> 그때 또 discriminator를 잠그고 파라미터들을.  
>
> 그걸 무한 반복을 하는 거예요.  
>
> 그러면 이게, 아까 말씀드렸던 것처럼  
> 이런 식으로 학습을 하면 뭔가 좀 불안하지 않을까요?  
> 우리가 그걸 어떻게 컨트롤 할 수 있죠?  
>
> 이 큰 블랙박스 모델이  
> 그런 식으로 Gradient Ascent와 Descent가 번갈아가면서 표현됐을 때,  
> 그게 뭔가 우리가 원하는 대로 수렴할 거라고 믿는 건  
> 되게 바보인 거죠.  
>
> 그래서 바보들이었습니다.  
> 그래서 이게 잘 안 돼, 이게 힘들었어요.  
> 이걸 자꾸 Optimizing하고 결과를 뽑아낸 거예요.  
> 이거 갖고 Product 만드는 사람 없습니다.  
>
> 그래서 Image 생성 Model 같은 경우는  
> 요즘에 엄청나게 Product화 되는 거거든요.  
> 그 인프라를 유지하는 인력들은,  
> 그러니까 돈이 모이기 시작한 건 Diffusion Model 시대가 와서인 거예요.  
>
> 이 트레이닝을 한 번 하는데  
> 엄청난 돈이 들거든요.  
> 예를 들어서 여러분들 H100 20만장에다가  
> 이거 올려가지고 훈련을 하면,  
> 전기료만 해도 1초에 얼마가 나올까요?  
>
> 그거 생각해보면 끔찍해집니다.  
>
> 그리고 그 인프라를 유지보수하는 인력들의 인건비,  
> 그리고 그 인프라를 빌려온 걸 거 아니에요?  
> 임대료부터 시작해서.  
>
> 여러 가지가 이제 다 문제가 되는 건데,  
> 그래서 근데 그렇게 해서 훈련을 했는데,  
> 훈련 결과가 Converge 되지 않고  
> 이상한 값을 고려할 수 있고,  
> 그렇게 나온다고 한다면,  
> 그럼 그 비용은 어떻게 할 거에요?  
>
> 그죠?  
> 그래서 그런 문제가 굉장히 심각합니다, 사실.  
>
> 그래서 여러분들 Objective Function 막 설계를 하고  
> 이런 것도 되게 쉽게 볼 수도 있는데,  
> 여러분들 그냥 Colab에서 할 때는 아무런 문제 없지만,  
> 이게 진짜 우리가 뭔가 의미 있는 Semantic을 갖고,  
> 뭔가 사람처럼 행동하는 그런 스케일로 커지면은,  
>
> 이런 작은 Objective Function을 다르게 설계를 하는  
> 이 디테일의 차이가,  
> 사실 엄청난 비용의 문제가 생길 수가 있더라고요.  
>
> 제가 직접 경험을 해보니까.  
>
> 그래서 그런 것들을 실제로 스케일링 업하는 세계에서는  
> 되게 중요하다.  
>
> 그래서 GAN 모델은 이제  
> 현실 세상에서 잘 쓰지 않는 모델로 전락을 했다.  
>
> 아까 말씀드렸었던 Adversal Attack 이런 건 연구가 계속 됩니다.  
> 어떻게 공격할 것인가?  
>
> 이미지가 커지면 커질수록 더 쉬워져요.  
> 채울 수 있는 디테일이 많으니까.  
>
> 이미지 퀄리티가 높아지면 높아질수록 더 쉽습니다.  
> 되게 웃긴 거에요.  
>
> 그런데는 많이 연구되지만,  
> GAN 모델이 이런 어떤 트레이닝 스테이빌레이티의 문제 때문에  
> 좀 많이 사용되지는 않습니다.  
>
> 그래서 아까 다시 돌아가서,  
> Gradient Ascent와 Gradient Descent를  
> 번갈아 가면서 한다고 했는데,  
>
> 그럼 여기서 또 틀이 있어요.  
> 이거를 한 번씩 하면, 결과적으로,  
> 이것도 굉장히 노가다로 찾은 건데,  
>
> Gradient Descent 한 번 하고,  
> Gradient Ascent 한 번 하면은  
> 보통은 어떻게 되냐면,  
> 그냥 트레이닝 스킴이 다 망가져 버립니다.  
>
> 보통의 경우.  
> 최대한 수많은 노력을 해서,  
> discriminator와 generator의 파라미터 숫자를 막 조절하고 해봐도,  
>
> 1대1의 업데이트 룰을 갖고 가면,  
> 이 트레이닝의 전체가 다 collapse되요.  
>
> 그래서 보통은 어떻게 하냐면,  
> discriminator 5번 업데이트를 하고,  
> 그리고 generator를 한 번 업데이트하고,  
> 이거를 번갈아가면서 합니다.  
>
> 그리고 여기서 또 중요한 게 뭐냐면,  
> 이 파라미터, Representation Power를 잴 수 있거든요.  
>
> 어떤 특별한 metric을 써가지고,  
> Representation Power의 비율도 되게 잘 정의를 해야 돼요.  
>
> 우리가 러닝하는 트레이닝 데이터에 따라,  
> 우리가 러닝하는 아키텍처에 따라,  
> 그런 거에 따라 그것도 잘 조정을 해야 돼요.  
>
> 그래서 원래 스테이블한 어떤 GAN 러닝을 보장을 하려면,  
> 앞에서 웜업이라고 해야 되나요?  
>
> 우리가 그런 최적의 비율을 찾는 거를  
> 10번 만큼 해야 돼요.  
>
> 이 최종적으로, 아 이제 이 정도면 준비가 됐다.  
> 이제 우리 훈련 끝까지 다 돌려봐도  
> 뭔가 결과가 잘 나오겠다.  
>
> 이거 판단하는 데까지  
> 최소 10번 정도 돌려봐야 돼요.  
>
> 그래서 모든 생성 모델 하는 사람들이  
> 이것 때문에 엄청난 고통을 받아서요.  
>
> 그래서 그런 치명적인 단점이 있다는 거.  
>
> 그럼 그게 어디서 유발이 됐냐?  
> 이 min-max 게임을 이론적으로,  
> 솔루션이 없기 때문에,  
>
> 우리가 numerical하게 갖고 왔기 때문에,  
> 간접적인 방향으로 그걸 그냥 물 떠다 놓고  
> 되기를 기도했기 때문에 그런 거고,  
>
> 뭔가 명확한 이론적 솔루션이 존재한 게 아니라.  
>
> 그래서 여러분들 그런 거에 대한 문제들도  
> 잘 생각을 해보셔야 될 것 같아요.  
>
> VAE나 어떤 그 GAN 같은 경우는  
> 그런 성격이 되게 강해요.  
>
> 어떤 수학적인 contraint는 명확하게 주어지지 않고,  
> 뉴럴 네트워크로 그냥 모든 걸 다 풀어라.  
>
> 그 variation equation 배웠었는데 저번에.  
> 저저번 주에.  
>
> variation equation도 사실  
> 내가 upper bound 이러면서 막 뭐 생략한다고 했잖아요.  
>
> 근데 그게 제가 그때 뭐라고 했었죠?  
> 원래는 그거를 명확하게 계산을 할 수 있고,  
> 좀 어렵지만, 계산을 해야 정확하게 나오는데  
>
> 그걸 날렸다고 했잖아요.  
>
> 그것도 사실 이거랑 되게 비슷한 이유입니다.  
>
> 더 이론적으로 뭔가 파고들고,  
> 그걸 모델링했을 때의 어떤 complexity가 커지기 때문에  
> 다 날리고, upper bound만 러닝을 했기 때문에,  
>
> 걔네들도 instability가 똑같이 있고  
> 퀄리티도 떨어지고 하거든요.  
>
> 근데 이제 앞으로 배울  
> Normalizing Flow 라던지 디퓨전 모델은  
> 그런 거에 대한 어떤 mathmatical constraint를  
>
> 더 명확하게, 인간이 더 다루기 쉽게,  
> 컴퓨터 코드로 더 호환성 있게끔 설계를 해 놨습니다.  
>
> 그런 것들을 목적으로 오히려 만들었기 때문에.  
>
> 그래서 실제로 훈련을 하고 퀄리티를 재 보면,  
> 다른 모델들에 비해서  
> 굉장히 더 좋은 퀄리티,  
> 그리고 좋은 트레이닝 landscape를 볼 수가 있어요.  
>
> 그래서 그런 어떤 백그라운드의,  
> 엔지니어링적인 문제들도 존재한다.  
>
> 이 PPT에서는 알 수가 없는.  

---

## p22. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_20.png" alt="image" width="640px">

> **강의 내용**  
> 
> 네, 그래서 이제 앞에서 conditional한 그런 것들을 고려했었는데,  
> conditional GAN 같은 걸 어떻게 하느냐, 이걸 한번 생각해보자면,  
> $x$는 인풋 이미지였잖아요.  
>
> 그래서 인풋 이미지를 고려하고,  
> $G(x)$는 $G$가 만들어낸 페이크 데이터라고 했습니다.  
>
> 그럼 discriminator가,  
> 이 conditional GAN 같은 경우는,  
> 페이크 이미지랑,  
> 아니 그 인풋으로 간 컨디션 이미지랑,  
> 페이크 이미지 그 두 개를 동시에 받습니다.  
> 인풋으로.  
>
> 그리고 마찬가지로 리얼 데이터를 배울 때는,  
> conditional 리얼 데이터랑,  
> 그리고 이제 타겟 리얼 데이터를 페어링을 해가지고,  
> discriminator 인풋에 넣게 돼서,  
> 요것도 학습하게 되고요.  
>
> 그리고 이제 argmin하고 argmax 하는 거는 똑같습니다.  
> 리얼 페이크에 대해서,  
> 앞에서 마찬가지로,  
> 1에 가깝게 되면 discriminator가 가짜라고 판별을 하는 거고,  
> 0에 가까우면 리얼이라고 판별을 하는 거죠.  
>
> 근데 컨디셔닝만,  
> 요 인풋에 이렇게 들어간다.  
> 이렇게 보시면 될 것 같아요.  

---

## p23. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_21.png" alt="image" width="600px">

---

## p24. Conditional GANs for Image Translation

<img src="/assets/img/lecture/probstat/12/image_22.png" alt="image" width="600px">

> **강의 내용**  
> 
> 뭐 그 GAN이, 제가 앞에 말씀드렸었던 것처럼, generator와 discriminator가  
> 그 그래디언트 descent, ascent를 번갈아가면서, 굉장히 unstable 해진다고  
> 얘기를 드렸었고, 그러면 엔지니어들도 그걸 어쨌든, 봉합을 해야 될 거 아니에요.  
> 방법은 되게끔 만들면.  
>
> 그래서 이 Image Translation 같은 경우는, 뒤에 이제 $\mathcal{L}_{L1}$이라고 써있는데,  
> 요거를 이제 추가를 합니다.  
>
> 요거를 이제, regularization term이라고 얘기를 하는데,  
> 이제 $G(x)$, 만들어낸 데이터가, $y$라는 어떤 타겟 데이터가,  
> 서로 이제, L1 distance적으로 갖게끔 하는,  
> 요런 추가 regularization term을 둬요.  
>
> 그래서, generator와 discriminator가 좀 diverge 되려고 할 때,  
> 요 term이 발동을 해서, 그 diverge 되는 그, 형태를 최대한 막아주는 거죠.  
>
> 그래서 스테이블 트레이닝을 보장을 하고, 수렴도 빨리 됩니다.  
> 요거를 하면.

---

> 이 장표는 conditional GAN을 이용한 이미지 변환 과정을 설명한 것이다.  
> 먼저 입력 이미지 $x$가 주어지면, 생성기 $G$는 이를 입력받아 $G(x)$라는 출력 이미지를 생성한다.  
> 이후 생성된 이미지 $G(x)$와 실제 타깃 이미지 $y$를 비교하여, 두 이미지 간의 차이를 최소화하도록 학습이 이루어진다.  
>
> 상단의 수식은 생성기 $G$와 판별기 $D$가 서로 경쟁하는 구조를 나타낸다.  
> 판별기 $D$는 진짜 이미지와 생성된 이미지를 구분하기 위해 최대한 정확히 판별하려 하고,  
> 생성기 $G$는 판별기를 속이기 위해 진짜와 유사한 이미지를 생성하려 한다.  
> 이러한 경쟁 관계는 일반적으로 min-max 문제로 표현된다.  
>
> 또한 기본적인 GAN 손실인 $L_{\text{cGAN}}(G, D)$에 더하여  
> $\lambda \, \mathcal{L}_{L1}(G)$ 항이 추가되어 있다.  
> 여기에서 L1 정규화 항은 다음과 같이 정의된다.  
> $$\mathcal{L}_{L1}(G) = \mathbb{E}\left[\lVert y - G(x) \rVert_1 \right]$$  
> 이 항은 생성된 이미지가 실제 이미지 $y$와 픽셀 단위에서 가까워지도록 유도하는 역할을 한다.  
>
> 이러한 L1 항을 추가함으로써 학습의 안정성이 크게 향상되고,  
> 모델이 더 빠르게 수렴할 수 있게 된다.  
> 따라서 장표 하단에는 “Stable training + fast convergence”라는 문구가 제시되어 있다.  
>
> 정리하면, 입력 이미지 $x$는 생성기 $G$를 거쳐 $G(x)$로 변환되고,  
> 이 결과는 실제 이미지 $y$와 L1 기준으로 비교되며,  
> 동시에 판별기 $D$는 진짜와 가짜를 판별하는 과정에 참여한다.  
> 이러한 구성은 안정적이고 실용적인 이미지 변환 모델을 구현하기 위한 구조라고 할 수 있다.  

---

## p25. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_23.png" alt="image" width="800px">

> **강의 내용**  
> 
> 그래서 요거는 앞에서 말씀드렸었던 것처럼,  
> 블랙 앤 화이트에서, 컬러로 되는, 어떤 그런 예제들인 거고,  
> 이게 한 18년도 쯤에 나오는, 나왔었던 논문들의 퀄리티거든요?  
> 근데 지금은 뭐 어마어마하겠죠.  
> 이 colorization 뿐만 아니라, 정말 많은 conditional한 생성을,  
> 하나의 파운데이션 모델에서, 모두 처리할 수 있습니다.  
> 그래서 그런 정말, 획기적인 모델들이 많이 존재합니다.  

---

## p26. Edges2Cats

<img src="/assets/img/lecture/probstat/12/image_24.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그러면, 아까 전에, 그 엣지 디텍션 훈련된 모양들이,  
> 그럼 어떻게 결과물을 만들어낼까? 하는 생각을 해볼 수 있는데,  
> 이런 거 하는 거예요.  
> 그냥.  
>
> 고양이 사진을 실컷 훈련을 해놓고,  
> 엉뚱하게, 이 식빵처럼 생긴 거를, 엣지로 주고, 생성을 하라고 한 거죠.  
>
> 근데 생성은 고양이로 했지 않습니까?  
> 그럼 얘가 어떻게든, 내가 학습했었던, 고양이의 모양에  
> 어떤 위치를, 잘 배치를 해가지고 표현을 해요.  
>
> 그리고 되게 재밌는 게, 저게 눈이 있어야 될 것 같거든요?  
> 근데 눈이 있네요.  
>
> 동그라미로 그려주면, 거기 눈이 안 채워질 수도 있는데, 사실.  
> 근데 눈이 채워집니다.  
>
> 그게 고양이의 어떤, 얼굴에 기하학적인 걸 보면,  
> 눈이 항상 저기 있었기 때문에, 그 확률이 높았었던 거.  
> 그냥.  
>
> 그래서 이렇게 표현이 되는 거고,  
> 다른 모양들에 대해서 다 해도,  
> 되게 엉뚱하게, 재밌게, 잘 표현이 되는, 겁니다.  

---

## p27. Pix2Pix : Labels to Facades

<img src="/assets/img/lecture/probstat/12/image_25.png" alt="image" width="600px">

> **강의 내용**  
> 
> 요거 이제 생성 모델의, 픽스 투 픽스라는 되게 유명한, Image Translation,  
> 그, 하는 모델인데, 하여튼 요 인풋에 대해서, 요 캐스케이드한 요런 이미지들,  
> 그니까, 그 각각의 층들에 대해서, 뭐 창문이라던지, 틀 같은 거에 대해서,  
> 레이블링을 해주면, 오른쪽과 같이, 이제 행동을 해준다는 거죠.  
>
> 이제 뭐, 방이나 가구, 이런 각진 것들은, 생성이 더 잘 돼요.  
> 왜냐면 딱 정형화는 틀이 있기 때문에.  
>
> 그래서 여러분들 보면은, 생성 모델에서도 훈련을 하다 보면은,  
> 그리고 실제로 현대 생성 모델들도 그래요.  
> 여러분들은 잘 못 느끼겠지만, 자연에 있을 만한, 있을 법한,  
> 그리고 되게 각지고, 되게 정형화된, 그런 내추럴 오브젝트들 있잖아요.  
> 그런 것들을 이미지 생성을 해보면, 현대 생성 모델들도 퀄리티가 굉장히 더 높습니다.  
>
> 근데 이제 뭔가, 내가 잘 생각해봤을 때, 이제 정형화되지 않은, 그런 데이터라던지,  
> 약간 데이터를 취득하기 힘든 데이터의, 어떤 그런 내추럴 오브젝트의 모양이라던지,  
> 그런 것들을 생성하라고 하면은, 이 생성 모델을 평가를 하는 메트릭이 존재하거든요.  
> FID라고 있는데, Fresh Inception Distance를, Inception Distance라는 메트릭이 있는데,  
> 그런 메트릭이 또 압도적으로 떨어집니다.  
>
> 단순히 사람이 눈으로 보는 것 뿐만 아니라, 눈으로 보는 건 괜찮아도,  
> 수치적으로 보면 굉장히 떨어집니다.  
>
> 그래서 이런 정형화된 거를 되게 잘 만들기 시작합니다.  
> 그럼 뭘 잘 만들까요, 그러면?  
>
> 그러니까 어떤, 그런 사람의 얼굴 같은 거 되게 잘 만듭니다.  
> 그래서 어떤 정형화된 위치들이 있잖아요.  
> 어떤 눈, 코, 입 같은 거.  
> 명확하게 기학적으로 뒤틀리면 안 됩니다.  
> 입이 코의 위치에 있으면 안 되잖아요.  
>
> 그래서 여러분들 AI로 만든 사람을 보면, 평균 이미지라는 얘기를 많이 해요.  
> 뭔가 이질적인 게 있잖아요.  
> AI로 만든 사람을 보면.  
>
> 결국에는 그런 기하학적 패턴들을 확률적으로 정형화시켰기 때문에,  
> 우리가 느끼기에는 약간 이상하고 이질적인 것들이 평균치로 표현이 되는 건데요.  
> 컨볼루션 필터에 화상처럼 남게 되면서.  
>
> 그런 큰 모델들 컨볼루션 필터 들어가면,  
> 기하학적 위치에 따라 컨볼루션 필터들이 다 이렇게 배치가 되는 걸 볼 수가 있어요.  
>
> 실제로 되게 재밌는 현상들이다.  
> 확률적인 현상들이다.  
> 그런 것들이 다.  
> 이렇게 생각하시면 될 것 같아요.  

---

## p28. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_26.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그럼 이제 마지막으로 GAN과 VAE를 한번 비교해보도록 하겠습니다.  
> 그래서 GAN은 뭐였죠?  
> 데이터라는, 앞에서는 이제 다 재미를 위해서 conditional 생성 모델을 주로 했는데,  
> 원래 GAN의 초창기는 unconditional 한 거라,  
> $z$라는 가우시안 디스트리뷰션이 들어갔을 때,  
> 데이터가 $x$라는 게 나왔고,  
> 이 가우시안 디스트리뷰션에서 데이터 디스트리뷰션으로 맵핑을 해 주는 게  
> generator라는 거다.  
> 라는 거고, 그리고 이제 그 min-max 게임을 통해 가지고 학습이 되는 거고  

---

## p29. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_27.png" alt="image" width="800px">

> **강의 내용**  
> 
> 그 생성 퀄리티를 볼까요?  
> 이게 제 기억, 이것도 굉장히 오래된 논문인데,  
> 한 16년도, 17년도 논문에서 나왔었던 그 피규어라고 저는 기억을 하고 있어요.  
>
> 근데 VAE 같은 경우는 블러리한 모양이 많이 나오죠.  
> 이게 그 reconstruction loss의 upper bound를 무시를 하고,  
> approximation된 걸 사용했기 때문에 표현되는 거예요.  
> 그 정보들이 다 날라간 형태라고 보시면 될 것 같습니다.  
>
> 이거는 뉴럴 네트워크가 아무리 잘 구성이 되더라도,  
> 일정 수준 이상의 블러를 피할 수, 피할 수 있는 방법이 없어요.  
>
> 여기 보면은 제가 아까 말씀드렸었던,  
> 정형화된 패턴이 있는 얼굴 쪽은 되게 잘 생성이 되는데,  
> 뒤에 배경은 고주파수잖아요.  
> 사람이 사진 찍으면 배경이 막 달라지잖아요.  
> 어떤 데는 빨간색 배경이 있고, 어떤 데는 뭐,  
> 뒤에는 뭐 없고, 그냥 막혀있는 방일 수도 있고,  
> 그래서 얼굴 쪽은 그냥 명확하게 다 표현이 되는데,  
> 뒤에 고주파수는 다 날라갑니다.  
>
> 근데 GAN은 그래도 그런 게 조금 해결이 되는 거죠.  
>
> 근데 이것도 제가 말씀드렸었던 것처럼,  
> 그래도 훈련 퀄리티가 괜찮고,  
> 앞에 그 웜업하는 시간을 다 지나가고,  
> 스테이블한 트레이닝이 보장된 형태의 생성 모델을,  
> GAN을 고려했을 때, 그때 샘플 퀄리티인 거예요.  
> 여기까지 보기가 되게 힘듭니다.  
>
> 근데 VAE는 샘플 퀄리티가 이렇게 조금 나아질 수는 있지만,  
> 훈련하기에 그렇게 어렵진 않고요.  
>
> 그래서 이거 두 개의 차이점이 있다.  
> 이해하시면 될 것 같습니다.  

---

## p30. Theory : Global Convergence of Critic

<img src="/assets/img/lecture/probstat/12/image_28.png" alt="image" width="720px">

> **강의 내용**  
> 
> 글로벌 컨버전스, 이런 수학적인 얘기는 있는데, 이건 좀 생략을 하고

---

> **명제 1.**  G가 고정되었을 때, 최적의 판별기 D는  
> 
> > $$D_G^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
> 
> **증명**  
> 
> > $$V(G, D) = \int_x p_{\text{data}}(x) \log(D(x)) \, dx + \int_z p_z(z) \log(1 - D(g(z))) \, dz$$  
> 
> > $$= \int_x p_{\text{data}}(x) \log(D(x)) + p_g(x) \log(1 - D(x)) \, dx$$  
> 
> 임의의 $(a, b) \in \mathbb{R}^2 \setminus \{0, 0\}$ 에 대해,  
> 함수 $y \mapsto a\log(y) + b\log(1-y)$ 는  
> $[0,1]$ 에서 $\frac{a}{a+b}$ 일 때 최대값을 가진다.  
> 판별기(discriminator)는  
> $\text{Supp}(p_{\text{data}}) \cup \text{Supp}(p_g)$ 밖에서 정의될 필요가 없으며,  
> 이것으로 증명이 완료된다. □
>
> ---
>
> 이 정리는 “G(Generator)를 고정했을 때, 어떤 D가 가장 좋은가?”를 알려준다.  
> 즉, 생성 모델 G가 이미 정해져 있다면,  
> 판별기 D는 어떤 값을 출력해야  
> 전체 GAN 목적함수 $V(G, D)$ 가 최대가 되는지를  
> **정확히 계산한 결과**이다.  
>
> 핵심 아이디어는 다음과 같다.  
>
> > 1) GAN의 목적함수 $V(G,D)$ 는  
> >    데이터 분포와 생성 분포가 함께 등장하는  
> >    로그 형태의 합이다.  
>
> > 2) 이 적분을 $x$별로 바라보면,  
> >    각 $x$에 대해  
> >    $p_{\text{data}}(x)\log(D(x)) + p_g(x)\log(1 - D(x))$  
> >    를 최대화하는 문제가 된다.  
>
> > 3) 이는 일반적인 형태  
> >    $a\log(y) + b\log(1-y)$  
> >    의 최대화 문제와 동일하다.  
>
> > 4) 이 함수는 $y = \frac{a}{a+b}$ 일 때 최대가 된다.  
>
> 여기서 $a = p_{\text{data}}(x)$, $b = p_g(x)$ 로 두면  
> 각 $x$마다 최적의 판별기 출력은  
>
> > $$D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
>
> 이 된다.  
>
> 즉, **판별기의 최적 출력은  
> “이 $x$가 진짜 데이터일 확률의 정규화된 비율”** 이다.  
> 다시 말해, 데이터와 생성 분포의 상대적 확률비로  
> 진짜 여부를 판단하는 것이 최적이라는 뜻이다.  
>
> 마지막 문장에 따르면,  
> 판별기는 $p_{\text{data}}$ 또는 $p_g$ 가 0인 구간에서는  
> 정의될 필요가 없다.  
>
> > “두 분포가 실제로 존재하는 영역(지원집합)에서만 의미가 있으며,  
> > 그 바깥에서는 $V(G,D)$ 에 아무 영향도 없다.”  
>
> 이렇게 해서 최적 판별기 공식이 도출되며,  
> 이는 **GAN 이론의 가장 핵심적인 기반 공식**이다.

---

## p31. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_29.png" alt="image" width="600px">

---

## p32. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_30.png" alt="image" width="640px">

---

## p33. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_31.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 뭐 오늘은 이 정도 얘기를 하면 될 것 같은데요.  
> 이 그림에 대해서 얘기를 좀 해보자면,  
> 이게 앞에서 로그 펑션으로 되어 있었잖아요.  
> 로그 펑션으로 고려를 한 다음에 훈련을 해서,  
> 미분을 했을 때 나온 그 문제, 때문에  
> 정말 심각한 문제가 생깁니다.  
> 그게 되게 바닐라 형태로 훈련을 하게 되면.  
>
> 그래서 지금 보면,  
> GAN discriminator라고 빨간색으로 표현되는 경우가 있어요.  
> 근데 GAN discriminator 같은 경우는,  
> 로그 펑션에 물려있는 그 discriminator loss 항을  
> 표현을 하는 거거든요.  
>
> 그래서 어떤 특별한 경우에는,  
> loss가 그냥 0이 되는 vanishing gradient 현상이 나타난다.  
> 그런 거로 표현을 하는 거고,  
> 그래서 이제 GAN 말고, GAN의 어떤 확장 버전들이 있어요.  
>
> GAN을 수학 형식으로,  
> 또 generalized된 폼으로 표현된  
> Wasserstein GAN 같은 거, F-GAN  
> 이런 것들이 나오기 시작하는 거고요.  
>
> 그런 것들이 이제,  
> 어떻게 보면 KL divergence의 되게 general한 형태인  
> Wasserstein distance라는 어떤 매트릭을 통해 가지고,  
> 고려했었던 GAN 모양 같은 것들이 있는데,  
> 그런 것들을 고려하면은,  
> 이제 critic, discriminator function이  
> gradient vanishing이 안 된다.  
>
> 그래서 GAN 같은 경우도,  
> 그런 instability를, instability, 트레이닝에서 instability한  
> 그런 프로퍼티를 컨트롤 하려고,  
> 수학하시는 분들, AI 리서처들이 정말 지대한 노력을 많이 했습니다.  
> 정말 오랫동안.  
>
> 근데 이제 이 이후에  
> Normalizing Flow라는, 지금 생성 모델들, 디퓨전이 오면서,  
> 그 노력을 아무리 해도 안 됐거든요.  
> 그래서 그냥 다 건너갔다고 보시면 될 것 같아요.  
>
> GAN 좀 되게 중요한데, 남아있는 유산들이 많이 있어요.  
> 현재 이제 디퓨전 모델 같은 거 훈련할 때도.  
>
> 그래서 유산 많이 남겼지만,  
> 사실 현대에서, 뭐, 프로덕트 관점,  
> 꼭 연구용도 마찬가지입니다.  
>
> 근데 프로덕트 관점이 더 심한데,  
> 프로덕트 관점에서는 아예 사용하지 않는, 그런 모델이라고 생각하시면 될 것 같습니다.  
>
> 근데 되게, 한 시대의 패러다임이었었고,  
> 그리고 이제 굉장히 중요한 개념들을 많이 소개를 했었기 때문에,  
> 이제 강의에서 좀 소개를 드리는 바였고,  
> 오늘은, 뭐, 메인 콘텐츠는 좀 여기서 마무리하도록 하고요.  
>
> 일단 질문을 좀 받도록 하겠습니다.  
> 질문 있으실까요?  
>
> (질문)  
>
> 아까 정형화된 데이터 말씀해주신 거,  
> 궁금한 게 요즘 피직스 제너레이티브, 뭐 이런 것도 잘 돼 있는 거 같은데,  
> 걔도 정형화된 데이터인가요?  
>
> (답변)  
>
> 어, 피직스 데이터.  
> 그래서 피직스 데이터를 뭘로 얘기를 할까요?  
>
> 그럼 예를 들어서,  
> 제가 많이 하고 있으니까,  
> 제가 이제 피직스 데이터들을 많이 하거든요.  
>
> 피지컬이 아니라 피직스 데이터를 많이 하는데,  
> 피지컬은 보통 로봇 같은 걸 많이 얘기를 하는 거니까,  
> 피직스 AI, 피지컬 AI가 이제 좀 한 어떤 서브셋이라고 생각합니다.  
>
> 그런데, 예를 들어서  
> 그런 걸 생각해볼 수 있을 것 같아요.  
>
> 진자 운동을 하는 데이터가 있다고 생각해봅시다.  
>
> 스프링에 따라서.  
> 진자 운동은 주기성을 갖고, 계속 움직이는 거잖아요. 그죠?  
>
> 근데 그런 것들을 정형화, 정형성이 있다라고 얘기를 할 수가 있습니다.  
> 왜냐면 방정식에 따라 움직이기 때문에.  
>
> 피지컬 AI도 마찬가지예요.  
> 예를 들어서 우리가 드론이라고 생각을 하면,  
> 드론에 센서들이 굉장히 많이 있거든요.  
> 컨트롤하려고.  
>
> 근데 드론이 움직일 수 없는 형태의 센서값들이 있습니다.  
>
> 드론은 명확하게 그 피지컬 스트럭처가 고정이 돼 있잖아요.  
>
> 예를 들어서 쿼드코프트라고 하면, 날개가 네 개가 존재를 하고,  
> 걔네들이 어떻게 도느냐에 따라서, 그 회전 각도들이 정해지고,  
> 그게 다 물리적 방정식에 대해서 고려가 되는 거 아니겠습니까?  
>
> 그러니까 그런 경우 당연히 학습이 잘 됩니다.  
>
> 그거를 방정식이 보장을 하고 있고,  
> 그 방정식을 넘어선 관측을 할 수가 없기 때문에.  
>
> 그런 데이터와 그렇게 정형화되지 않는,  
> 피지컬로도 고려하고 있지 않는 데이터 같은 경우는,  
> 그럼 당연히 뭐라고 해야 될까요?  
>
> 좀 익스플로레이션을 해야 되는, 서치 스페이스가 커지기 때문에,  
> 당연히 그건 더 잘 안 될 거 같아요.  
>
> 근데 여기서 또, 이제, 조금 더 말씀드리고 싶은 게 있으면,  
> 피직스를 알아야죠.  
>
> 취득한 데이터를 방정식에 역추적하는 건 힘들고,  
>
> 피직스, 그때 제가 수업 시간에 잠깐 말씀드렸었던 거 같은데,  
> 코사인, 사인을 보여주면서, 그 방정식의 coefficient를  
> 러닝하는 게 핵심이겠죠, 그때는.  
>
> 방정식으로 유도된 데이터를 학습한다보단,  
> 그 방정식을, 예를 들어서 우리 진자 운동 같은 거 하면,  
> 뭐, 마찰계수 막 이런 거 있잖아요?  
>
> 그거를 뉴럴 네트워크 학습하게 하면, 더 잘 정형화된 데이터를 뽑아내겠죠.  
>
> 그걸 생성 모델로 만들 수도 있고, 관측을 한 다음에.  
>
> 그런 거는 훨씬 더 정형화됐다고 얘기할 수 있습니다.  
>
> 근데 이게 조금 약간, 로봇 이런, 그런 피지컬 AI에도,  
> 이거를 analogy를 적용해 볼 수 있을 것 같아요.  
>
> 이런 관점으로. 그래서, 대답이 됐을 거라고 생각을 하고,  
> 또 질문 하나 더 받고 마무리하겠습니다.  
>
> (질문)  
>
> 그 Adversarial Attack에서,  
> 혹시 파인튜닝 관점으로 뭔가 그런 데이터들이 생성됐을 때,  
> 좀 해결하는 수도 있나요?  
>
> (답변)  
>
> 어, 일단은, 일단 질문을 조금, 제가 잘 이해 못하는 것 같습니다.  
> 파인튜닝 관점이?  
>
> (질문)  
>
> 예를 들어, 뭐,  
> 그 생성된 이미지에서 속이려고 하는 데이터를 만들었을 때,  
> 그 속이려는 데이터를 추가적으로 그 네트워크에 학습을 시키면은,  
> 우선은 그런 이미지들은 좀 해결이 될 것 같긴 한데,  
> 네, 그런 입장에서 좀 생각을 해보았는데요.  
>
> (답변)  
>
> 네, 일단은 되게 좋습니다.  
>
> 그러니까 Adversarial Attack의 관점으로 또 얘기를 할 수도 있는데,  
>
> Attack을 공부하면 방어가 되거든요.  
>
> 그리고 현실세상에 그런 데이터가 들어올 수도 있잖아요.  
> 공격의 목표가 아니더라도, 내추럴 이미지 안에서도.  
>
> 그래서 그런 관점에서  
> 추가 학습을 통해 robustness를 키우겠다는,  
> 그걸 파인튜닝으로 정의하신 거라고 한다면, 그 분야가 명확하게 있습니다.  
>
> 그걸 이제, 파인튜닝이라는 건 되게 현대 LLM스러운 단어인 거고,  
>
> 조금 더 딥러닝의 원본적인 얘기로 하면은,  
> 제가 말하는 data augmentation인 거죠.  
>
> data augmentation을 통한 파인튜닝인데,  
> 그걸 이제 Attack까지 좀 합니다.  
>
> 그렇게 해서 실제로 그런 거 있잖아요. 이미지 같은 거  
> 블러가 껴있고, 안개가 껴있는 그런 데이터들이 있는데,  
>
> 그런 것들을 그런 방식으로 생성을 해가지고, 노이즈 만들어서,  
> 그런데 강건하게 움직이게끔 하거든요.  
>
> 그런데 대신에 accuracy 좀 희생은 해야 될 거 없고,  
>
> 제한된 파라미터들의 수많은 케이스를 다 학습해야 될까?  
>
> 그런데 그런 문제가 오면은 핸들을 할 수 있기는 있습니다.  
>
> 그런데 아예, 아예 핸들 못하는 것보다는 낫죠.  
> accuracy가 떨어지더라도.  
>
> 그래서 이거는 강의가 무한정 있으면 논문 단위로 설명하고 싶은 마음이 있어요.  
>
> 사실 논문 단위로 봐야 돼요, 원래는.  
> 이 AI라는 거는.  
>
> 그렇게 읽기 어렵지도 않고,  
> 핵심 키워드만 알면 저자들이 뭘 얘기하는지 알고 알 수 있기 때문에.  
>
> 아쉽게도 강의가 그런 형태는 아니기 때문에,  
> 좀 더 소개되는, 그냥 이렇게 말로만 하고,  
>
> 여러분들 한번 읽어보면 좋을 것 같은 것들, 논문 싹 정리를 해가지고  
> 한번 LMS에 올려드릴 테니까,  
>
> 한번 읽어보고  
> 현업에 쓸 수 있다, 아니면 생각해볼 만하다,  
> 그런 것도 한번 보시면 좋을 것 같아요.  
>
> 옛날 논문도 있을 것 같습니다.  
> 어떤 이런 학문의 발전상에서 되게 중요한 필라가 됐던 것들,  
> 그런 것들에 대해서 또 공을 들일 수도 있을 것 같아요.  
>
> 그런 것들은 그렇게 하면 좋을 것 같고요.  
> 오늘은 뭐 그러면  
> 여기서 강의 마무리하도록 하겠습니다.  
---
layout: post
title: "[확률과 통계] 12주차"
date: 2025-11-12 11:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. Review : Image Classification  

<img src="/assets/img/lecture/probstat/12/image_1.png" alt="image" width="600px">

---

## p3. Review : Image Generation

<img src="/assets/img/lecture/probstat/12/image_2.png" alt="image" width="600px">

---

## p4. Review : Image Generation

- 고차원 미관측 변수들(high-dimensional unobserved variables)의 모델  $P(\mathbf{X} \mid \mathbf{Y} = y)$  

- 무작위 이미지를 샘플링하는 것 이상의 많은 문제들에 유용하다!

---

## p5. Review : Generative Model

<img src="/assets/img/lecture/probstat/12/image_3.png" alt="image" width="600px">

---

## p6. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_4.png" alt="image" width="530px">

---

## p7. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_5.png" alt="image" width="600px">

---

## p8. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_6.png" alt="image" width="570px">

---

## p9. Data Preparation in Conditional Generation

<img src="/assets/img/lecture/probstat/12/image_7.png" alt="image" width="720px">

---

## p10. Challenges?

1. 출력은 고차원(high-dimensional)이며, 구조화된 객체(structured object)이다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 매핑(mapping)에 불확실성이 존재하며, 가능한 출력들이 많다.

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

---

## p11. Property of Generative Models?

1. 고차원적이고 구조화된 출력을 모델링한다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 불확실성을 모델링한다; 가능한 출력들의 전체 분포를 모델링한다.  

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

---

## p12. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_10.png" alt="image" width="600px">

---

## p13. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_11.png" alt="image" width="540px">

---

## p14. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_12.png" alt="image" width="720px">

---

## p15. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_13.png" alt="image" width="720px">

---

## p16. Motivation : GANs

<img src="/assets/img/lecture/probstat/12/image_14.png" alt="image" width="720px">

---

## p17. Actor-critic Perspective

<img src="/assets/img/lecture/probstat/12/image_15.png" alt="image" width="600px">

---

## p18. Role of discriminator : critic

<img src="/assets/img/lecture/probstat/12/image_16.png" alt="image" width="600px">

---

## p19. Role of generator : actor

<img src="/assets/img/lecture/probstat/12/image_17.png" alt="image" width="600px">

---

## p20. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_18.png" alt="image" width="600px">

---

## p21. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_19.png" alt="image" width="600px">

---

## p22. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_20.png" alt="image" width="640px">

---

## p23. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_21.png" alt="image" width="600px">

---

## p24. Conditional GANs for Image Translation

<img src="/assets/img/lecture/probstat/12/image_22.png" alt="image" width="600px">

---

## p25. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_23.png" alt="image" width="800px">

---

## p26. Edges2Cats

<img src="/assets/img/lecture/probstat/12/image_24.png" alt="image" width="600px">

---

## p27. Pix2Pix : Labels to Facades

<img src="/assets/img/lecture/probstat/12/image_25.png" alt="image" width="600px">

---

## p28. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_26.png" alt="image" width="600px">

---

## p29. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_27.png" alt="image" width="800px">

---

## p30. Theory : Global Convergence of Critic

<img src="/assets/img/lecture/probstat/12/image_28.png" alt="image" width="720px">

---

> **명제 1.**  G가 고정되었을 때, 최적의 판별기 D는  
> 
> > $$D_G^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
> 
> **증명**  
> 
> > $$V(G, D) = \int_x p_{\text{data}}(x) \log(D(x)) \, dx + \int_z p_z(z) \log(1 - D(g(z))) \, dz$$  
> 
> > $$= \int_x p_{\text{data}}(x) \log(D(x)) + p_g(x) \log(1 - D(x)) \, dx$$  
> 
> 임의의 $(a, b) \in \mathbb{R}^2 \setminus \{0, 0\}$ 에 대해,  
> 함수 $y \mapsto a\log(y) + b\log(1-y)$ 는  
> $[0,1]$ 에서 $\frac{a}{a+b}$ 일 때 최대값을 가진다.  
> 판별기(discriminator)는  
> $\text{Supp}(p_{\text{data}}) \cup \text{Supp}(p_g)$ 밖에서 정의될 필요가 없으며,  
> 이것으로 증명이 완료된다. □
>
> ---
>
> 이 정리는 “G(Generator)를 고정했을 때, 어떤 D가 가장 좋은가?”를 알려준다.  
> 즉, 생성 모델 G가 이미 정해져 있다면,  
> 판별기 D는 어떤 값을 출력해야  
> 전체 GAN 목적함수 $V(G, D)$ 가 최대가 되는지를  
> **정확히 계산한 결과**이다.  
>
> 핵심 아이디어는 다음과 같다.  
>
> > 1) GAN의 목적함수 $V(G,D)$ 는  
> >    데이터 분포와 생성 분포가 함께 등장하는  
> >    로그 형태의 합이다.  
>
> > 2) 이 적분을 $x$별로 바라보면,  
> >    각 $x$에 대해  
> >    $p_{\text{data}}(x)\log(D(x)) + p_g(x)\log(1 - D(x))$  
> >    를 최대화하는 문제가 된다.  
>
> > 3) 이는 일반적인 형태  
> >    $a\log(y) + b\log(1-y)$  
> >    의 최대화 문제와 동일하다.  
>
> > 4) 이 함수는 $y = \frac{a}{a+b}$ 일 때 최대가 된다.  
>
> 여기서 $a = p_{\text{data}}(x)$, $b = p_g(x)$ 로 두면  
> 각 $x$마다 최적의 판별기 출력은  
>
> > $$D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
>
> 이 된다.  
>
> 즉, **판별기의 최적 출력은  
> “이 $x$가 진짜 데이터일 확률의 정규화된 비율”** 이다.  
> 다시 말해, 데이터와 생성 분포의 상대적 확률비로  
> 진짜 여부를 판단하는 것이 최적이라는 뜻이다.  
>
> 마지막 문장에 따르면,  
> 판별기는 $p_{\text{data}}$ 또는 $p_g$ 가 0인 구간에서는  
> 정의될 필요가 없다.  
>
> > “두 분포가 실제로 존재하는 영역(지원집합)에서만 의미가 있으며,  
> > 그 바깥에서는 $V(G,D)$ 에 아무 영향도 없다.”  
>
> 이렇게 해서 최적 판별기 공식이 도출되며,  
> 이는 **GAN 이론의 가장 핵심적인 기반 공식**이다.

---

## p31. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_29.png" alt="image" width="600px">

---

## p32. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_30.png" alt="image" width="640px">

---

## p33. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_31.png" alt="image" width="600px">
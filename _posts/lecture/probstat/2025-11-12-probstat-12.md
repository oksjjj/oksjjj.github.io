---
layout: post
title: "[확률과 통계] 12주차"
date: 2025-11-12 11:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. Review : Image Classification  

<img src="/assets/img/lecture/probstat/12/image_1.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이제 본격적인 콘텐츠 시작하도록 하겠습니다.  
>
> 그러면 그래서 오늘 이제 어떤 걸 공부를 하냐라고 하면  
> 이제 GAN에 대해서 공부를 할 건데  
> 그 전에 이제 뭔가 리뷰를 한번 해봅시다.  
>
> 여러분들 아마 이미지 classification이 어떤 건지에 대해서는  
> 다 알고 계시는 거라고 생각을 해요.  
>
> 이미지 classification 같은 경우는  
> 인풋의 이미지 혹은 뭐 3D 이미지가 될 수도 있고  
> 2D 이미지가 될 수도 있고  
> 이미지 형태의 데이터가 들어왔을 때  
>
> classifier가 존재해서  
> classifier가 최종적으로 레이블을 이제 아웃풋으로 만들어 내는 거  
> 그게 이제 이미지 classification 모델의 정의였습니다.  
>
> classifier라고 하는 뉴럴 네트워크가  
> 이 주어진 이미지를 컨볼루셔널한 오퍼레이션을 통해 가지고  
> 실질적으로 레이블이 어떻게 되는지에 대해서 평가를 하는 거죠.  
>
> 그래서 이 레이블은 뭐 랭귀지 토큰이 될 수도 있고  
> 보통 이제 그 전통적인 classification 모델이라고 한다면  
> 원핫 벡터라고 해서  
>
> 예를 들어서 클래스가 뭐 천 개가 있다고 하면  
> 그 천 차원짜리의 벡터에  
> 그 각각의 어떤, 해당되는 컴포넌트만 1이 있고  
> 나머지 부분 0으로 삼는 형식으로  
> 원핫 벡터를 통해 가지고 classification을 하곤 합니다.  

---

## p3. Review : Image Generation

<img src="/assets/img/lecture/probstat/12/image_2.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 네 그럼 이제 이미지 제네레이션이라는 게 무엇이냐 하면  
> 뭐 전 시간에 우리가 VAE를 통해 가지고 어느 정도 맛을 봤지만  
> 그거 같은 경우는 이제 언컨디셔널한 거였죠.  
>
> 그래서 가우시안 랜덤 베리어블을 가지고  
> 디코더를 통해 가지고 생성하는 게  
> 이제 어떤 VAE의 목적이었는데  
> 뭐 여기서 뭐 예를 들어서  
> 컨디셔널한 제네레이션을 한번 생각을 해보죠.  
>
> 그래서 Fish라는 랭귀지 토큰 혹은 원핫 벡터가 존재할 때  
> 제네레이터가 그 레이블 인포메이션을 가지고  
> 그거에 해당하는 어떤 이미지를 생성해야 되는 겁니다.  
>
> 그래서 사실 우리가 하는 그 생성 모델  
> 특히나 이제 되게 많이 하는  
> 어떤 그 멀티모달 생성 모델들은  
> 사실 이미지 classification의 어떤 역순에 해당하는  
> 그 프로세스를 역으로 돌리는 거에 대한 해당하는 거다  
> 라고 생각하시면 될 것 같고.  
>
> 여기서 이제 뭐가 중요하니?라고 하면  
> 뉴럴 네트워크 스트럭처라고 하죠.  
>
> 그래서 classifier 같은 경우는  
> 원래 큰 이미지를 컨볼루션 레이어를 통해 가지고  
> 점차적으로 이제 intermediate한 그 피쳐맵들이 작아지면서  
> 최종적으로 레이블을 뱉게 되거든요.  
>
> 근데 우리 이제 뭐 VAE 스트럭처 같은 거를  
> 뭐 직접 뭐 깊게 살펴보시면은 이해를 하실 거라 생각을 하는데  
> 디코더도 마찬가지로 그렇게 생겼습니다.  
>
> 거꾸로 역순으로 생겼습니다.  
> 그 디코더 스트럭처에서  
> 이런 레이블이 들어가거나  
> 레이턴트 인포메이션이 들어가면  
> 작은 정보들을 좀 더 키워나가면서  
> 최종적으로 이미지 레졸루션에 맞게끔  
> 그렇게 뉴런네트워크가 구성이 되어 있었죠.  
>
> 그런 부분들이 좀 이제  
> classification과 제네레이션의 어떤 차이고  
> 그렇기 때문에  
> 이런 구조상의 어떤 특징점으로 인해서  
> 제너레이터 뉴럴 네트워크 아키텍쳐가 구성이 됐다.  
>
> 그래서 그런 어떤 히스토리컬한 컨텍스트가 있다고  
> 이해를 해주시면 될 것 같습니다.  

---

## p4. Review : Image Generation

- 고차원 미관측 변수들(high-dimensional unobserved variables)의 모델  $P(\mathbf{X} \mid \mathbf{Y} = y)$  

- 무작위 이미지를 샘플링하는 것 이상의 많은 문제들에 유용하다!

> **강의 내용**  
> 
> 그래서 이제 이미지 제네레이션 같은 경우는  
> High-dimensional Unobserved Variable $X$를  
> $Y$라는 컨디션에 대해서  
> probability density를 찾는 거죠.  
> conditional probability를.  
>
> 그래서 large $Y$가 있고 small $y$가 있는데  
> small $y$는 이제 어떤 deterministic하게  
> 우리가 세팅을 한 거예요.  
> $Y$는 랜덤 Variable이니까 large $Y$는.  
> large $Y$가 small $y$가 되는.  
>
> 그러니까 예를 들어서 fish.  
> 이렇게 좀 레이블을 주어졌을 때  
> 최종적으로 $X$라는 데이터를 생성을 하는 거.  
> 그거 어떻게 확률적으로 모델링하는 것이냐.  
>
> 이게 이제 이미지 생성 모델  
> 혹은 더 동형적으로 컨디셔널 생성 모델의  
> 핵심 철학이라고 생각하면 될 것 같습니다.  
>
> 그래서 이제 우리가 이 $P(X \mid Y)$를  
> 뭔가를 학습을 한다는 관점에서  
> VAE와 마찬가지로  
> maximum likelihood estimation을 하게 되는 거고요.  
>
> $P$라는 거에다가 로그를 씌우고  
> $P$를 이제 $\theta$라는 걸로 parameterization을 해서  
> $\log p_\theta$를  
> 뭔가 optimization을 통해서 학습을 하겠다는 게  
>
> 이미지 생성 모델의 주된 목표라고 보시면  
> 될 것 같습니다.  

---

## p5. Review : Generative Model

<img src="/assets/img/lecture/probstat/12/image_3.png" alt="image" width="600px">

> **강의 내용**  
> 
> 네 그러면 이제 다시 한번.  
> 다시 이건 이제 되게 추상적인 레벨에서  
> 이제 얘기를 드린 거고.  
> 생성 모델이라는 건 되게 추상적인 레벨에서  
> 컨디셔널한 정보들을 어떻게 처리할까를  
> 이제 얘기를 드린 거고.  
>
> 다시 돌아가서 저번에 VAE를  
> 너무 뭔가 중간에 설명이 없이  
> 수식으로 바로 들어온 감이 있는데  
> 그걸 조금 더 설명을 더 드리겠습니다.  
> 저번 주에 했던 게 무엇인지에 대해서.  
>
> 그러면 이제 Generative 모델이라는 게  
> 이런 걸 한다는 거죠.  
> 그래서 $z$라는 Random variable이 존재를 하고  
> Gaussian noise를 고려를 하죠.  
> Mean이 $0$이고, Variation가 $1$인.  
>
> 그래서 이제 이렇게 하얀색 박스로 표현되어 있는 게  
> 되게 cascade하게 표현이 되어 있는데  
> 이게 뭐냐면 neural network layer를  
> 여러 회에 걸쳐가지고  
> 인포메이션을 바꾸게 된다는 거고  
> 그게 결국에는 이 $x$라는 이미지를  
> 만들게 되는 겁니다.  
>
> 그래서 이 $z$를 넣었을 때 $x$가 나온  
> 이 파트가 VAE에서 어디 파트였었죠?  
> 디코더.  
> 그렇죠 디코더 파트였습니다.  
>
> 인코더는 이미지를  
> $z$라는 Random variable에게  
> 프로젝션 시키는 거였었고  
> 디코더는 거꾸로 했던 거죠.  
>
> 그래서 VAE는 정확하게 말하면  
> 생성 모델이 아닙니다.  
> VAE는 어떤 생성 모델을 랩핑하고 있는  
> 큰 파이프라인 학습 방법론이라고  
> 얘기를 하면 될 것 같고  
>
> VAE에서도 특별히 생성 모델이라고  
> 얘기할 수 있는 파트는  
> 디코더라고 얘기를 해야 되요.  
>
> 이 개념이 되게 중요한 거라,  
> 차이점, 이 개념적 차이점을  
> 이해를 하고 계시면 좋을 것 같아요.  

---

## p6. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_4.png" alt="image" width="530px">

> **강의 내용**  
> 
> 그래서 마찬가지로 앞에서 컨디셔널 제네러티브 모델을  
> 이 파이프라인, 이 디코더 파이프라인으로 생각을 하면  
> 이제 언컨디셔널한 인포메이션이  
> 컨디셔널한, bird라는 레이턴트 인포메이션으로 변하게 되고  
> 이거를 이제 통해서 뉴럴 네트워크를 통해서 생성을 한다.  
>
> 그 말은 뭐냐면 컨디셔널한 VAE 같은 경우는,  
> 우리가 컨디셔널 VAE를 보지는 않았습니다.  
> 하지만 컨디셔널 VAE를 확장하는 게 되게 쉬운데  
> 저희가 앞에서 봤었던 $z$라는 Random variable을 통해 가지고  
> 그 디코더 스트럭쳐에 넣어 가지고 이미지를 생성했는데,  
>
> 그게 아니라 $(z, y)$라는 어떤 추가적인 정보가 들어가서  
> 모델링하게 됩니다.  
>
> 그래서 이 파이프라인 이제 보면은  
> VAE도 마찬가지고  
> Generative Adversarial Network,  
> 뒤에 디퓨전 모델,  
> 그 모든 생성 모델에 대해서  
> 이 컨디셔널한 인포메이션을 어떻게 다뤄야 되는지,  
> 그에 대한 좀 철학을 보실 것 같아요.  
>
> 그래서 다 마찬가지고  
> $z$라는 하나의 어떤 언컨디셔널한,  
> 그걸 랜덤성을 주는 거기 때문에,  
> 거기에다 추가적으로 $y$라는 걸 통해 가지고  
> 어떤 어떤 시맨틱을 부여합니다.  
>
> 근데 이제 앞에서 이제 말씀드렸었던 것처럼  
> 이게 하나의 어떤 bird라는,  
> 그 이건 그냥 원핫 벡터 같은 걸 표현하려고 했던 것 같아요.  
> 여기 PPT에서는.  

---

## p7. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_5.png" alt="image" width="600px">

> **강의 내용**  
> 
> 근데 여기에서는 이제 더 정밀한 묘사를 할 수 있겠죠.  
> 그래서 어떻게 보면 원핫 벡터는 그 이 오브젝트의 이 종류에 대해서 묘사를 할 때,  
> 예를 들어서 새, 자동차, 고양이 이런 걸 표현할 때  
> 원핫 벡터가 되게 좋은 것 같고,  
>
> 새인데 더 명확하게 이게 어떤 새에 대해서 묘사를 해야 될 때는  
> $y$라는 컨디셔널이 이렇게 그 랭귀지 토큰,  
> 문장으로 표현되는 게 이제 거의 되게 중요한 그런 발전 상황이라고 보면 될 것 같습니다.  
>
> 그래서 이런 류의 생성 모델이 우리가 항상 쓰는 거죠.  
> 그래서 사실 이 스트럭처적으로 봤을 때는 굉장히 이제 쉽다.  
>
> 근데 이제 그거를 이제 굉장히 잘 발달된 인프라 스트럭처에다가  
> 그 데이터를 넣고 그 수많은 데이터들을 한꺼번에 처리할 수 있는  
> 코어 컴퓨팅들, 그리고 클라우드 컴퓨팅,  
> 그리고 전력의 사용, 큐잉, MLops 없이 이런 것들이 사실 메인인 거지.  
>
> 우리가 그걸 학습한 학습 방법론이나 이런 것들은  
> 우리가 여기서 배우는 GAN도 그렇고, VAE도 그렇고, 디퓨전 모델도 그렇고,  
> 철학은 같습니다.  
>
> 이거를 어떻게 스케일러블하게 키울 것이냐가 프로덕트까지 연결되는 것이지,  
> 철학은 같다고 보시면 될 것 같아요.  
>
> 그래서 이렇게만 보면 너무 쉽죠.  
> 근데 이제 진짜 문제는 엔지니어링에 있다.  
> 이런 어떤 theoretical part가 아니다.  
> 그렇게 생각하시면 될 것 같습니다.  
>
> 그래서 이제 이거는 랭귀지 토큰을 가지고  
> 뭔가 컨디셔닝을 한다고 가정을 하는 건데.  

---

## p8. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_6.png" alt="image" width="570px">

> **강의 내용**  
> 
> 뭐 이런 것도 생각해 볼 수 있을 것 같아요.  
> 그래서 $y$라는 흑백 이미지가 있고, 이거는 어떻게 만들었을까요?  
> 원본에 이제 오른쪽에 노란색 새 사진을 decolorization,  
> 그러니까 이건 deterministic한 알고리즘이 존재를 합니다.  
> 그래서 색깔을 없앨 수 있어요, 그냥.  
>
> 색깔을 없애는 pair를 만들어 놓고,  
> 이거를 학습하게 만들어 놓는 거죠.  
>
> 그럼 이거의 목적이 어떻게 될까요?  
> Colorization 해주는 거죠.  
> 색깔이 없는 이미지를 넣었을 때 색깔이 나오게끔.  
>
> 여러분들 옛날 영상 같은 거,  
> 필름이 막 만들어진 영화나 이런 그런 산업이 태동할 때 보면  
> 이렇게 블랙으로, 흑백으로 되어 있는 영화를 colorization 해주는  
> 그런 것들이 많이 있잖아요.  
>
> 그런 AI 모델들이  
> 이 pair를 정말 수많은 데이터셋과  
> 엄청나게 큰 인프라를 통해서 학습을 시켜 놓은 결과물이라고 보면 될 것 같아요.  
>
> 그래서 이 $y$랑 $x$에 대한 컨디셔닝을 우리가 어떻게 하느냐에 따라서  
> 생성 모델의 어떤 목적을 많이 다룰 때 할 수 있고,  
> 그건 우리 테스트, 우리의 어떤 시나리오에 따라 다른 거죠.  
>
> 우리가 생성 모델을 어떻게 훈련시켜서  
> 어디에다 사용할 것이냐가,  
> 그리고 이 컨디셔닝을 어떻게 할 것이냐랑 같은 말이니까,  
> 그걸 이제 준비하는 여러 가지 방법이 있다.  

---

## p9. Data Preparation in Conditional Generation

<img src="/assets/img/lecture/probstat/12/image_7.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그래서 이제 그 생성 모델의 초창기에는 이런 걸 굉장히 많이 했습니다.  
> 그래서 이제 첫 번째로, Object Labeling도 이런 페어링,  
> 컨디셔널 페어링 만드는 데 되게 많이 했었던 거거든요.  
>
> 여러분들 뭐 Segmentation 이런 거 들어보셨나요?  
> 예를 들어서 어떤 사람을 주면, 뭐 머리는 머리, 팔이면 팔,  
> 이렇게 나눠주는 Segmentation 모델도 있고,  
> 요즘에 굉장히 발달을 많이 해가지고,  
> 이미지를 던져주면 얘가 색깔을 칠해줍니다.  
>
> 이 시멘틱이 여기 어디에,  
> 그래서 우리 삼성 카메라 같은 거 보면 이미지 보고 어디를 알려주고 하잖아요.  
> 거기를 막 다른 물체로 채워주고,  
> 그걸 하기 위해서는 우리 뭐 흔한 말로 누끼를 뜬다고 했죠?  
> 누끼를 뜨려면 이런 Segmentation이 들어가야 되거든요.  
>
> 그래서 그런 생성 모델에는 기본적으로 Segmentation 하는 데가 들어가 있고,  
> 그 파트를 이제 바꿔주는 형태가 되는 거죠.  
>
> 그래서 뭐 예를 들어서  
> 이렇게 말타는 이미지가 오리지널 이미지인데,  
> 이 Object Labeling이라는 Segmentation 알고리즘을 통해가지고  
> 우측에 마스크를 찾습니다.  
> 이렇게 페어링을 만들어요.  
>
> 그럼 실질적으로 훈련을 할 때는 훈련을 진행을 하고,  
> 우리가 Inference 할 때는 이 Label을 주고  
> 왼쪽에 이미지를 생성하게 하는 거죠.  
>
> 그러면 이게 뭐 말 사진도 있고, 강아지 사진도 있고,  
> 사람의 형체들도 많이 있을 텐데,  
> 우리가 상상하는 건 그런 거죠.  
>
> 그러면 이렇게 말 모양이나 고양이 모양 같은 거,  
> 이렇게 비슷하게 사람이 핸드드로잉 하면  
> 거기에 맞는, 뭔가 어울리는 이미지가 생성되지 않을까?  
> 라는 게 사실 지금 현대 뭐 나노바나나 같은,  
> 현대 생성 모델들에 다 들어가 있는 기능이라고 보면 됩니다.  
>
> 뭐 지브리 풍을 바꿔서 제가 되게 예제로 많이 드는데,  
> 그런 것도 사실 이런 거의 합성 버전이라고 생각하시면 될 것 같아요.  
>
> 그리고 이건 이제 Object Label을 통해서  
> 데이터와 컨디셔널 페어를 만드는 거였고,  
> 두 번째는 이제 Edge Detection을 한번 생각해 볼 수 있을 것 같아요.  
>
> 그래서 Edge Detection은 사실 되게 고전적인,  
> 컨디셔너링 방법론으로 만들 수 있는,  
> 컨디셔닝하는 이 이미지를 생각할 수 있거든요.  
>
> 왼쪽에 이제 되게 복잡한 동물들이 있고,  
> 내추럴 오브젝트들이 있는 거에 대해서  
> Edge Filter를 가하게 되면 오른쪽과 같이,  
> 이 동물이나 어떤 내추럴 오브젝트의 겉만 나오게 됩니다.  
>
> 그럼 이렇게 만들어서 훈련을 한 다음에 Inference를 하면 어떻게 될까요?  
> 그럼 오른쪽에 어떤 엣지만 그려주면  
> 그 안에 컨텐츠를 채워주겠죠.  
> 왼쪽에 오브젝트 세그멘테이션이 들어가가지고.  
>
> 그리고 이제 뭐 세 번째,  
> 텍스트 투 포토는 방금 말씀드렸었고  
> 이게 또 이런 컨디셔널 모델이 되게 중요하게 생각되고,  
> 여러분들 비디오 생성, 생성 모델을 많이 하잖아요.  
>
> 그거에 대한 어떤 철학이 무엇이냐.  
> 그것도 컨디셔널하게 생성을 하거든요.  
>
> 그래서 바로 전 프레임이 주어졌을 때,  
> 그 다음 프레임에 대해서 생성하는,  
> 그러니까 전 프레임이 비디오의 컨디션이 되는 거고,  
> 거기에 해당하는 다음 프레임을 만들어내는 게 생성 모델의 목표인 거죠.  
>
> 그러면 이거를 여러 번 concatenation 하면 어떻게 될까요?  
> 그러면 주어진, 처음 이미지에 대해서 순서대로 만들어주는 거죠.  
>
> 마찬가지로 이것도 비디오 생성 모델들에 대해서  
> 철학을 제공해주는 거고,  
> 그래 가지고 파이프라인적으로 봤을 때는,  
> 물론 엄청나게 많은 엔지니어링이 있다고 말씀드렸습니다.  
>
> 근데 파이프라인적으로 봤을 때는,  
> 사실 이런 거 하는 거와 다름이 없다.  
> 이 기술이 사실 극한으로 발달돼서  
> 그런 형태까지 간 거겠죠.  
>
> 그래서 이런 컨디셔널 제네레이션을 할 수 있다.  

---

## p10. Challenges?

1. 출력은 고차원(high-dimensional)이며, 구조화된 객체(structured object)이다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 매핑(mapping)에 불확실성이 존재하며, 가능한 출력들이 많다.

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

---

## p11. Property of Generative Models?

1. 고차원적이고 구조화된 출력을 모델링한다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 불확실성을 모델링한다; 가능한 출력들의 전체 분포를 모델링한다.  

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

---

## p12. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_10.png" alt="image" width="600px">

---

## p13. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_11.png" alt="image" width="540px">

---

## p14. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_12.png" alt="image" width="720px">

---

## p15. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_13.png" alt="image" width="720px">

---

## p16. Motivation : GANs

<img src="/assets/img/lecture/probstat/12/image_14.png" alt="image" width="720px">

---

## p17. Actor-critic Perspective

<img src="/assets/img/lecture/probstat/12/image_15.png" alt="image" width="600px">

---

## p18. Role of discriminator : critic

<img src="/assets/img/lecture/probstat/12/image_16.png" alt="image" width="600px">

---

## p19. Role of generator : actor

<img src="/assets/img/lecture/probstat/12/image_17.png" alt="image" width="600px">

---

## p20. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_18.png" alt="image" width="600px">

---

## p21. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_19.png" alt="image" width="600px">

---

## p22. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_20.png" alt="image" width="640px">

---

## p23. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_21.png" alt="image" width="600px">

---

## p24. Conditional GANs for Image Translation

<img src="/assets/img/lecture/probstat/12/image_22.png" alt="image" width="600px">

---

## p25. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_23.png" alt="image" width="800px">

---

## p26. Edges2Cats

<img src="/assets/img/lecture/probstat/12/image_24.png" alt="image" width="600px">

---

## p27. Pix2Pix : Labels to Facades

<img src="/assets/img/lecture/probstat/12/image_25.png" alt="image" width="600px">

---

## p28. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_26.png" alt="image" width="600px">

---

## p29. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_27.png" alt="image" width="800px">

---

## p30. Theory : Global Convergence of Critic

<img src="/assets/img/lecture/probstat/12/image_28.png" alt="image" width="720px">

---

> **명제 1.**  G가 고정되었을 때, 최적의 판별기 D는  
> 
> > $$D_G^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
> 
> **증명**  
> 
> > $$V(G, D) = \int_x p_{\text{data}}(x) \log(D(x)) \, dx + \int_z p_z(z) \log(1 - D(g(z))) \, dz$$  
> 
> > $$= \int_x p_{\text{data}}(x) \log(D(x)) + p_g(x) \log(1 - D(x)) \, dx$$  
> 
> 임의의 $(a, b) \in \mathbb{R}^2 \setminus \{0, 0\}$ 에 대해,  
> 함수 $y \mapsto a\log(y) + b\log(1-y)$ 는  
> $[0,1]$ 에서 $\frac{a}{a+b}$ 일 때 최대값을 가진다.  
> 판별기(discriminator)는  
> $\text{Supp}(p_{\text{data}}) \cup \text{Supp}(p_g)$ 밖에서 정의될 필요가 없으며,  
> 이것으로 증명이 완료된다. □
>
> ---
>
> 이 정리는 “G(Generator)를 고정했을 때, 어떤 D가 가장 좋은가?”를 알려준다.  
> 즉, 생성 모델 G가 이미 정해져 있다면,  
> 판별기 D는 어떤 값을 출력해야  
> 전체 GAN 목적함수 $V(G, D)$ 가 최대가 되는지를  
> **정확히 계산한 결과**이다.  
>
> 핵심 아이디어는 다음과 같다.  
>
> > 1) GAN의 목적함수 $V(G,D)$ 는  
> >    데이터 분포와 생성 분포가 함께 등장하는  
> >    로그 형태의 합이다.  
>
> > 2) 이 적분을 $x$별로 바라보면,  
> >    각 $x$에 대해  
> >    $p_{\text{data}}(x)\log(D(x)) + p_g(x)\log(1 - D(x))$  
> >    를 최대화하는 문제가 된다.  
>
> > 3) 이는 일반적인 형태  
> >    $a\log(y) + b\log(1-y)$  
> >    의 최대화 문제와 동일하다.  
>
> > 4) 이 함수는 $y = \frac{a}{a+b}$ 일 때 최대가 된다.  
>
> 여기서 $a = p_{\text{data}}(x)$, $b = p_g(x)$ 로 두면  
> 각 $x$마다 최적의 판별기 출력은  
>
> > $$D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
>
> 이 된다.  
>
> 즉, **판별기의 최적 출력은  
> “이 $x$가 진짜 데이터일 확률의 정규화된 비율”** 이다.  
> 다시 말해, 데이터와 생성 분포의 상대적 확률비로  
> 진짜 여부를 판단하는 것이 최적이라는 뜻이다.  
>
> 마지막 문장에 따르면,  
> 판별기는 $p_{\text{data}}$ 또는 $p_g$ 가 0인 구간에서는  
> 정의될 필요가 없다.  
>
> > “두 분포가 실제로 존재하는 영역(지원집합)에서만 의미가 있으며,  
> > 그 바깥에서는 $V(G,D)$ 에 아무 영향도 없다.”  
>
> 이렇게 해서 최적 판별기 공식이 도출되며,  
> 이는 **GAN 이론의 가장 핵심적인 기반 공식**이다.

---

## p31. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_29.png" alt="image" width="600px">

---

## p32. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_30.png" alt="image" width="640px">

---

## p33. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_31.png" alt="image" width="600px">
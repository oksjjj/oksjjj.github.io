---
layout: post
title: "[확률과 통계] 12주차"
date: 2025-11-12 11:00:00 +0900
categories:
  - "대학원 수업"
  - "확률과 통계"
tags: []
---

> 출처: 확률과 통계 – 박성우 교수님, 고려대학교 (2025)

## p2. Review : Image Classification  

<img src="/assets/img/lecture/probstat/12/image_1.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이제 본격적인 콘텐츠 시작하도록 하겠습니다.  
>
> 그러면 그래서 오늘 이제 어떤 걸 공부를 하냐라고 하면  
> 이제 GAN에 대해서 공부를 할 건데  
> 그 전에 이제 뭔가 리뷰를 한번 해봅시다.  
>
> 여러분들 아마 이미지 classification이 어떤 건지에 대해서는  
> 다 알고 계시는 거라고 생각을 해요.  
>
> 이미지 classification 같은 경우는  
> 인풋의 이미지 혹은 뭐 3D 이미지가 될 수도 있고  
> 2D 이미지가 될 수도 있고  
> 이미지 형태의 데이터가 들어왔을 때  
>
> classifier가 존재해서  
> classifier가 최종적으로 레이블을 이제 아웃풋으로 만들어 내는 거  
> 그게 이제 이미지 classification 모델의 정의였습니다.  
>
> classifier라고 하는 뉴럴 네트워크가  
> 이 주어진 이미지를 컨볼루셔널한 오퍼레이션을 통해 가지고  
> 실질적으로 레이블이 어떻게 되는지에 대해서 평가를 하는 거죠.  
>
> 그래서 이 레이블은 뭐 랭귀지 토큰이 될 수도 있고  
> 보통 이제 그 전통적인 classification 모델이라고 한다면  
> 원핫 벡터라고 해서  
>
> 예를 들어서 클래스가 뭐 천 개가 있다고 하면  
> 그 천 차원짜리의 벡터에  
> 그 각각의 어떤, 해당되는 컴포넌트만 1이 있고  
> 나머지 부분 0으로 삼는 형식으로  
> 원핫 벡터를 통해 가지고 classification을 하곤 합니다.  

---

## p3. Review : Image Generation

<img src="/assets/img/lecture/probstat/12/image_2.png" alt="image" width="600px">  

> **강의 내용**  
> 
> 네 그럼 이제 이미지 제네레이션이라는 게 무엇이냐 하면  
> 뭐 전 시간에 우리가 VAE를 통해 가지고 어느 정도 맛을 봤지만  
> 그거 같은 경우는 이제 언컨디셔널한 거였죠.  
>
> 그래서 가우시안 랜덤 베리어블을 가지고  
> 디코더를 통해 가지고 생성하는 게  
> 이제 어떤 VAE의 목적이었는데  
> 뭐 여기서 뭐 예를 들어서  
> 컨디셔널한 제네레이션을 한번 생각을 해보죠.  
>
> 그래서 Fish라는 랭귀지 토큰 혹은 원핫 벡터가 존재할 때  
> 제네레이터가 그 레이블 인포메이션을 가지고  
> 그거에 해당하는 어떤 이미지를 생성해야 되는 겁니다.  
>
> 그래서 사실 우리가 하는 그 생성 모델  
> 특히나 이제 되게 많이 하는  
> 어떤 그 멀티모달 생성 모델들은  
> 사실 이미지 classification의 어떤 역순에 해당하는  
> 그 프로세스를 역으로 돌리는 거에 대한 해당하는 거다  
> 라고 생각하시면 될 것 같고.  
>
> 여기서 이제 뭐가 중요하니?라고 하면  
> 뉴럴 네트워크 스트럭처라고 하죠.  
>
> 그래서 classifier 같은 경우는  
> 원래 큰 이미지를 컨볼루션 레이어를 통해 가지고  
> 점차적으로 이제 intermediate한 그 피쳐맵들이 작아지면서  
> 최종적으로 레이블을 뱉게 되거든요.  
>
> 근데 우리 이제 뭐 VAE 스트럭처 같은 거를  
> 뭐 직접 뭐 깊게 살펴보시면은 이해를 하실 거라 생각을 하는데  
> 디코더도 마찬가지로 그렇게 생겼습니다.  
>
> 거꾸로 역순으로 생겼습니다.  
> 그 디코더 스트럭처에서  
> 이런 레이블이 들어가거나  
> 레이턴트 인포메이션이 들어가면  
> 작은 정보들을 좀 더 키워나가면서  
> 최종적으로 이미지 레졸루션에 맞게끔  
> 그렇게 뉴런네트워크가 구성이 되어 있었죠.  
>
> 그런 부분들이 좀 이제  
> classification과 제네레이션의 어떤 차이고  
> 그렇기 때문에  
> 이런 구조상의 어떤 특징점으로 인해서  
> 제너레이터 뉴럴 네트워크 아키텍쳐가 구성이 됐다.  
>
> 그래서 그런 어떤 히스토리컬한 컨텍스트가 있다고  
> 이해를 해주시면 될 것 같습니다.  

---

## p4. Review : Image Generation

- 고차원 미관측 변수들(high-dimensional unobserved variables)의 모델  $P(\mathbf{X} \mid \mathbf{Y} = y)$  

- 무작위 이미지를 샘플링하는 것 이상의 많은 문제들에 유용하다!

> **강의 내용**  
> 
> 그래서 이제 이미지 제네레이션 같은 경우는  
> High-dimensional Unobserved Variable $X$를  
> $Y$라는 컨디션에 대해서  
> probability density를 찾는 거죠.  
> conditional probability를.  
>
> 그래서 large $Y$가 있고 small $y$가 있는데  
> small $y$는 이제 어떤 deterministic하게  
> 우리가 세팅을 한 거예요.  
> $Y$는 랜덤 Variable이니까 large $Y$는.  
> large $Y$가 small $y$가 되는.  
>
> 그러니까 예를 들어서 fish.  
> 이렇게 좀 레이블을 주어졌을 때  
> 최종적으로 $X$라는 데이터를 생성을 하는 거.  
> 그거 어떻게 확률적으로 모델링하는 것이냐.  
>
> 이게 이제 이미지 생성 모델  
> 혹은 더 동형적으로 컨디셔널 생성 모델의  
> 핵심 철학이라고 생각하면 될 것 같습니다.  
>
> 그래서 이제 우리가 이 $P(X \mid Y)$를  
> 뭔가를 학습을 한다는 관점에서  
> VAE와 마찬가지로  
> maximum likelihood estimation을 하게 되는 거고요.  
>
> $P$라는 거에다가 로그를 씌우고  
> $P$를 이제 $\theta$라는 걸로 parameterization을 해서  
> $\log p_\theta$를  
> 뭔가 optimization을 통해서 학습을 하겠다는 게  
>
> 이미지 생성 모델의 주된 목표라고 보시면  
> 될 것 같습니다.  

---

## p5. Review : Generative Model

<img src="/assets/img/lecture/probstat/12/image_3.png" alt="image" width="600px">

> **강의 내용**  
> 
> 네 그러면 이제 다시 한번.  
> 다시 이건 이제 되게 추상적인 레벨에서  
> 이제 얘기를 드린 거고.  
> 생성 모델이라는 건 되게 추상적인 레벨에서  
> 컨디셔널한 정보들을 어떻게 처리할까를  
> 이제 얘기를 드린 거고.  
>
> 다시 돌아가서 저번에 VAE를  
> 너무 뭔가 중간에 설명이 없이  
> 수식으로 바로 들어온 감이 있는데  
> 그걸 조금 더 설명을 더 드리겠습니다.  
> 저번 주에 했던 게 무엇인지에 대해서.  
>
> 그러면 이제 Generative 모델이라는 게  
> 이런 걸 한다는 거죠.  
> 그래서 $z$라는 Random variable이 존재를 하고  
> Gaussian noise를 고려를 하죠.  
> Mean이 $0$이고, Variation가 $1$인.  
>
> 그래서 이제 이렇게 하얀색 박스로 표현되어 있는 게  
> 되게 cascade하게 표현이 되어 있는데  
> 이게 뭐냐면 neural network layer를  
> 여러 회에 걸쳐가지고  
> 인포메이션을 바꾸게 된다는 거고  
> 그게 결국에는 이 $x$라는 이미지를  
> 만들게 되는 겁니다.  
>
> 그래서 이 $z$를 넣었을 때 $x$가 나온  
> 이 파트가 VAE에서 어디 파트였었죠?  
> 디코더.  
> 그렇죠 디코더 파트였습니다.  
>
> 인코더는 이미지를  
> $z$라는 Random variable에게  
> 프로젝션 시키는 거였었고  
> 디코더는 거꾸로 했던 거죠.  
>
> 그래서 VAE는 정확하게 말하면  
> 생성 모델이 아닙니다.  
> VAE는 어떤 생성 모델을 랩핑하고 있는  
> 큰 파이프라인 학습 방법론이라고  
> 얘기를 하면 될 것 같고  
>
> VAE에서도 특별히 생성 모델이라고  
> 얘기할 수 있는 파트는  
> 디코더라고 얘기를 해야 되요.  
>
> 이 개념이 되게 중요한 거라,  
> 차이점, 이 개념적 차이점을  
> 이해를 하고 계시면 좋을 것 같아요.  

---

## p6. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_4.png" alt="image" width="530px">

> **강의 내용**  
> 
> 그래서 마찬가지로 앞에서 컨디셔널 제네러티브 모델을  
> 이 파이프라인, 이 디코더 파이프라인으로 생각을 하면  
> 이제 언컨디셔널한 인포메이션이  
> 컨디셔널한, bird라는 레이턴트 인포메이션으로 변하게 되고  
> 이거를 이제 통해서 뉴럴 네트워크를 통해서 생성을 한다.  
>
> 그 말은 뭐냐면 컨디셔널한 VAE 같은 경우는,  
> 우리가 컨디셔널 VAE를 보지는 않았습니다.  
> 하지만 컨디셔널 VAE를 확장하는 게 되게 쉬운데  
> 저희가 앞에서 봤었던 $z$라는 Random variable을 통해 가지고  
> 그 디코더 스트럭쳐에 넣어 가지고 이미지를 생성했는데,  
>
> 그게 아니라 $(z, y)$라는 어떤 추가적인 정보가 들어가서  
> 모델링하게 됩니다.  
>
> 그래서 이 파이프라인 이제 보면은  
> VAE도 마찬가지고  
> Generative Adversarial Network,  
> 뒤에 디퓨전 모델,  
> 그 모든 생성 모델에 대해서  
> 이 컨디셔널한 인포메이션을 어떻게 다뤄야 되는지,  
> 그에 대한 좀 철학을 보실 것 같아요.  
>
> 그래서 다 마찬가지고  
> $z$라는 하나의 어떤 언컨디셔널한,  
> 그걸 랜덤성을 주는 거기 때문에,  
> 거기에다 추가적으로 $y$라는 걸 통해 가지고  
> 어떤 어떤 시맨틱을 부여합니다.  
>
> 근데 이제 앞에서 이제 말씀드렸었던 것처럼  
> 이게 하나의 어떤 bird라는,  
> 그 이건 그냥 원핫 벡터 같은 걸 표현하려고 했던 것 같아요.  
> 여기 PPT에서는.  

---

## p7. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_5.png" alt="image" width="600px">

> **강의 내용**  
> 
> 근데 여기에서는 이제 더 정밀한 묘사를 할 수 있겠죠.  
> 그래서 어떻게 보면 원핫 벡터는 그 이 오브젝트의 이 종류에 대해서 묘사를 할 때,  
> 예를 들어서 새, 자동차, 고양이 이런 걸 표현할 때  
> 원핫 벡터가 되게 좋은 것 같고,  
>
> 새인데 더 명확하게 이게 어떤 새에 대해서 묘사를 해야 될 때는  
> $y$라는 컨디셔널이 이렇게 그 랭귀지 토큰,  
> 문장으로 표현되는 게 이제 거의 되게 중요한 그런 발전 상황이라고 보면 될 것 같습니다.  
>
> 그래서 이런 류의 생성 모델이 우리가 항상 쓰는 거죠.  
> 그래서 사실 이 스트럭처적으로 봤을 때는 굉장히 이제 쉽다.  
>
> 근데 이제 그거를 이제 굉장히 잘 발달된 인프라 스트럭처에다가  
> 그 데이터를 넣고 그 수많은 데이터들을 한꺼번에 처리할 수 있는  
> 코어 컴퓨팅들, 그리고 클라우드 컴퓨팅,  
> 그리고 전력의 사용, 큐잉, MLops 없이 이런 것들이 사실 메인인 거지.  
>
> 우리가 그걸 학습한 학습 방법론이나 이런 것들은  
> 우리가 여기서 배우는 GAN도 그렇고, VAE도 그렇고, 디퓨전 모델도 그렇고,  
> 철학은 같습니다.  
>
> 이거를 어떻게 스케일러블하게 키울 것이냐가 프로덕트까지 연결되는 것이지,  
> 철학은 같다고 보시면 될 것 같아요.  
>
> 그래서 이렇게만 보면 너무 쉽죠.  
> 근데 이제 진짜 문제는 엔지니어링에 있다.  
> 이런 어떤 theoretical part가 아니다.  
> 그렇게 생각하시면 될 것 같습니다.  
>
> 그래서 이제 이거는 랭귀지 토큰을 가지고  
> 뭔가 컨디셔닝을 한다고 가정을 하는 건데.  

---

## p8. Review : Conditional Generative Model

<img src="/assets/img/lecture/probstat/12/image_6.png" alt="image" width="570px">

> **강의 내용**  
> 
> 뭐 이런 것도 생각해 볼 수 있을 것 같아요.  
> 그래서 $y$라는 흑백 이미지가 있고, 이거는 어떻게 만들었을까요?  
> 원본에 이제 오른쪽에 노란색 새 사진을 decolorization,  
> 그러니까 이건 deterministic한 알고리즘이 존재를 합니다.  
> 그래서 색깔을 없앨 수 있어요, 그냥.  
>
> 색깔을 없애는 pair를 만들어 놓고,  
> 이거를 학습하게 만들어 놓는 거죠.  
>
> 그럼 이거의 목적이 어떻게 될까요?  
> Colorization 해주는 거죠.  
> 색깔이 없는 이미지를 넣었을 때 색깔이 나오게끔.  
>
> 여러분들 옛날 영상 같은 거,  
> 필름이 막 만들어진 영화나 이런 그런 산업이 태동할 때 보면  
> 이렇게 블랙으로, 흑백으로 되어 있는 영화를 colorization 해주는  
> 그런 것들이 많이 있잖아요.  
>
> 그런 AI 모델들이  
> 이 pair를 정말 수많은 데이터셋과  
> 엄청나게 큰 인프라를 통해서 학습을 시켜 놓은 결과물이라고 보면 될 것 같아요.  
>
> 그래서 이 $y$랑 $x$에 대한 컨디셔닝을 우리가 어떻게 하느냐에 따라서  
> 생성 모델의 어떤 목적을 많이 다룰 때 할 수 있고,  
> 그건 우리 테스트, 우리의 어떤 시나리오에 따라 다른 거죠.  
>
> 우리가 생성 모델을 어떻게 훈련시켜서  
> 어디에다 사용할 것이냐가,  
> 그리고 이 컨디셔닝을 어떻게 할 것이냐랑 같은 말이니까,  
> 그걸 이제 준비하는 여러 가지 방법이 있다.  

---

## p9. Data Preparation in Conditional Generation

<img src="/assets/img/lecture/probstat/12/image_7.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그래서 이제 그 생성 모델의 초창기에는 이런 걸 굉장히 많이 했습니다.  
> 그래서 이제 첫 번째로, Object Labeling도 이런 페어링,  
> 컨디셔널 페어링 만드는 데 되게 많이 했었던 거거든요.  
>
> 여러분들 뭐 Segmentation 이런 거 들어보셨나요?  
> 예를 들어서 어떤 사람을 주면, 뭐 머리는 머리, 팔이면 팔,  
> 이렇게 나눠주는 Segmentation 모델도 있고,  
> 요즘에 굉장히 발달을 많이 해가지고,  
> 이미지를 던져주면 얘가 색깔을 칠해줍니다.  
>
> 이 시멘틱이 여기 어디에,  
> 그래서 우리 삼성 카메라 같은 거 보면 이미지 보고 어디를 알려주고 하잖아요.  
> 거기를 막 다른 물체로 채워주고,  
> 그걸 하기 위해서는 우리 뭐 흔한 말로 누끼를 뜬다고 했죠?  
> 누끼를 뜨려면 이런 Segmentation이 들어가야 되거든요.  
>
> 그래서 그런 생성 모델에는 기본적으로 Segmentation 하는 데가 들어가 있고,  
> 그 파트를 이제 바꿔주는 형태가 되는 거죠.  
>
> 그래서 뭐 예를 들어서  
> 이렇게 말타는 이미지가 오리지널 이미지인데,  
> 이 Object Labeling이라는 Segmentation 알고리즘을 통해가지고  
> 우측에 마스크를 찾습니다.  
> 이렇게 페어링을 만들어요.  
>
> 그럼 실질적으로 훈련을 할 때는 훈련을 진행을 하고,  
> 우리가 Inference 할 때는 이 Label을 주고  
> 왼쪽에 이미지를 생성하게 하는 거죠.  
>
> 그러면 이게 뭐 말 사진도 있고, 강아지 사진도 있고,  
> 사람의 형체들도 많이 있을 텐데,  
> 우리가 상상하는 건 그런 거죠.  
>
> 그러면 이렇게 말 모양이나 고양이 모양 같은 거,  
> 이렇게 비슷하게 사람이 핸드드로잉 하면  
> 거기에 맞는, 뭔가 어울리는 이미지가 생성되지 않을까?  
> 라는 게 사실 지금 현대 뭐 나노바나나 같은,  
> 현대 생성 모델들에 다 들어가 있는 기능이라고 보면 됩니다.  
>
> 뭐 지브리 풍을 바꿔서 제가 되게 예제로 많이 드는데,  
> 그런 것도 사실 이런 거의 합성 버전이라고 생각하시면 될 것 같아요.  
>
> 그리고 이건 이제 Object Label을 통해서  
> 데이터와 컨디셔널 페어를 만드는 거였고,  
> 두 번째는 이제 Edge Detection을 한번 생각해 볼 수 있을 것 같아요.  
>
> 그래서 Edge Detection은 사실 되게 고전적인,  
> 컨디셔너링 방법론으로 만들 수 있는,  
> 컨디셔닝하는 이 이미지를 생각할 수 있거든요.  
>
> 왼쪽에 이제 되게 복잡한 동물들이 있고,  
> 내추럴 오브젝트들이 있는 거에 대해서  
> Edge Filter를 가하게 되면 오른쪽과 같이,  
> 이 동물이나 어떤 내추럴 오브젝트의 겉만 나오게 됩니다.  
>
> 그럼 이렇게 만들어서 훈련을 한 다음에 Inference를 하면 어떻게 될까요?  
> 그럼 오른쪽에 어떤 엣지만 그려주면  
> 그 안에 컨텐츠를 채워주겠죠.  
> 왼쪽에 오브젝트 세그멘테이션이 들어가가지고.  
>
> 그리고 이제 뭐 세 번째,  
> 텍스트 투 포토는 방금 말씀드렸었고  
> 이게 또 이런 컨디셔널 모델이 되게 중요하게 생각되고,  
> 여러분들 비디오 생성, 생성 모델을 많이 하잖아요.  
>
> 그거에 대한 어떤 철학이 무엇이냐.  
> 그것도 컨디셔널하게 생성을 하거든요.  
>
> 그래서 바로 전 프레임이 주어졌을 때,  
> 그 다음 프레임에 대해서 생성하는,  
> 그러니까 전 프레임이 비디오의 컨디션이 되는 거고,  
> 거기에 해당하는 다음 프레임을 만들어내는 게 생성 모델의 목표인 거죠.  
>
> 그러면 이거를 여러 번 concatenation 하면 어떻게 될까요?  
> 그러면 주어진, 처음 이미지에 대해서 순서대로 만들어주는 거죠.  
>
> 마찬가지로 이것도 비디오 생성 모델들에 대해서  
> 철학을 제공해주는 거고,  
> 그래 가지고 파이프라인적으로 봤을 때는,  
> 물론 엄청나게 많은 엔지니어링이 있다고 말씀드렸습니다.  
>
> 근데 파이프라인적으로 봤을 때는,  
> 사실 이런 거 하는 거와 다름이 없다.  
> 이 기술이 사실 극한으로 발달돼서  
> 그런 형태까지 간 거겠죠.  
>
> 그래서 이런 컨디셔널 제네레이션을 할 수 있다.  

---

## p10. Challenges?

1. 출력은 고차원(high-dimensional)이며, 구조화된 객체(structured object)이다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 매핑(mapping)에 불확실성이 존재하며, 가능한 출력들이 많다.

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

> **강의 내용**  
> 
> 그래서 이제 그러면, 이런 제너러티브 모델의 문제가 뭐냐?  
> 라고 하면은, 좀 여러 가지가 있는데,  
> 일단 제너러티브 모델에서 가장 문제가 되는 거는 뭐냐면,  
> 이 맵핑에 대한 one-to-one 맵핑, one-to-many 맵핑이라는 문제가 있습니다.  
>
> 그게 뭐냐면,  
> 우리가 그 $z$라는, 그러니까 예를 들어서,  
> 이렇게 지워졌을 때, 이런 어떤 컨디셔널 페어가 존재할 때,  
> 계속 똑같은 이미지만 생성을 하면,  
> 우리가 생성 모델을 쓸 필요가 없는 거잖아요.  
>
> 그러면 이런 어떤 레이블을 줬을 때,  
> 생성할 때마다 들어가는 컨텐츠는 조금씩 조금씩 다르지만,  
> 유저가 만족감을 얻는 정도의 퀄리티가 나와야 될 겁니다.  
>
> 그건 뭐냐면,  
> 분명히 컨디셔닝은 똑같은데,  
> 나와야 되는 아웃풋은 여러 개라는 거.  
> 그게 one-to-many correspondence라는 거거든요.  
>
> 그래서 컨디셔널 생성 모델,  
> 그리고 생성 모델의 되게 중요한 특성 중 하나는,  
> one-to-many의 어떤 correspondence를 만들어야 되는,  
> 그런 프로퍼티를 유지를 해야 됩니다.  
>
> 그렇기 때문에 우리가 어떤 probabilistic한 관점을 갖고 가는 거예요.  
> 랜덤성이라는 걸 그래서 갖고 가는 거거든요.  
> 뭔가 계속 새롭게 만들어야 되기 때문에.  
>
> 그리고, 그런 부분으로 해서 정리할 수 있을 것 같고, 

---

## p11. Property of Generative Models?

1. 고차원적이고 구조화된 출력을 모델링한다.

    <img src="/assets/img/lecture/probstat/12/image_8.png" alt="image" width="200px">

2. 불확실성을 모델링한다; 가능한 출력들의 전체 분포를 모델링한다.  

    <img src="/assets/img/lecture/probstat/12/image_9.png" alt="image" width="200px">

---

## p12. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_10.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이제, 뭐, Image-to-image Translation을 한번 생각을 해봅시다.  
> 전통적인 관점의.  
>
> 여기서는 잠깐, Generative Model적인 사정들이 있고,  
> Image-to-Image Translation, 아까 제가 pair를 만든다고 했었어요.  
> 그걸 이제, Generative Model의 관점이 아니라,  
> 혹은 Generative Model이라고 하더라도,  
> 되게 좀 제네럴한 뭔가로 이제 그 문제를 정의를 하고 싶은 거,  
> 수학적인 공식을 통해가지고.  
>
> 그래서 이제, Training Data는  
> black, decolorized에 대한 data,  
> 그리고 color가 있는 거,  
> 그래서 $x, y$ pair를 만들게 되고,  
> 그러면 이제 우리가 뭘 목표로 하느냐 하면,  
> Image-to-Image Translation에서는  
> 이런 수학 수식 같은 거를 이제 목표로 합니다.  
>
> 그래서 그 $F$는 neural network가 되는 거고,  
> $L$ 같은 경우는 objective function이 되는 거죠.  
>
> 그래서 neural network를 $X$가 통과시켜가지고,  
> 그걸 $Y$랑 어떤 차이점을 통해가지고,  
> $L$이라는 어떤 차이점을 통해가지고 measure를 하고,  
> 그거를 expectation 취했을 때,  
> 가장 이거를 작게 만드는 그런 function,  
> neural network를 찾게 됩니다.  

---

## p13. Image-to-Image Translation

<img src="/assets/img/lecture/probstat/12/image_11.png" alt="image" width="540px">

> **강의 내용**  
> 
> 그래서 뭐, 그 외에 조금 더 뭐, 관점적으로 해석을 해보자면,  
> $F$ 같은 경우는, 어떠한 방식으로 우리가 $x$라는 걸 $y$로 만들 것이냐,  
> How should I do it?  
> 이라는 어떤 이런 질문에 대한 거를 묘사를 하는 거라고 보고,  
>
> $L$ 같은 경우는, 어떻게 하는 건지는 알았는데,  
> 우리가 뭘 해야 되는 것이냐,  
> 어떻게 줄이고, 뭘 줄일 것이냐,  
> 라는 질문에 대한 요소라고 보시면 될 것 같습니다.  
>
> 그래서 뭐, $F$는 neural network을 통해서 output이 나오면,  
> $L$은 뭐, 예를 들어서 우리가 $L2$ distance 같은 걸 생각을 하면,  
> $x$가 뭔가 $y'$로 되고,  
> true $y$와의 어떤 거리를 줄임으로써,  
> color가 생성이 되기를 원하는 거죠.  

---

## p14. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_12.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그래서 뭐, 여러 가지 뭐, 이 Loss Function을 고려해 볼 수 있는데,  
> 여기서 이제 뭐, $L2$라는, 제가 방금 전에 말씀드린, 그런 Euclidean Distance를 고려했을 때의,  
> 어떤 결과물을 한번 생각해 볼 수 있을 것 같아요.  
> 그리고 요거는 뭐, 최적은 아니고, 요런 식으로 나오는 게, 되게 많이 관찰되는 형태다, 이런 겁니다.  
>
> 이거 Neural Network을 되게 잘 설계를 하면, Output이 ground truth랑 되게 비슷할 수도 있어요.  
> 근데 요런 어떤, output regime에 빠지게 된다는 거죠.  
> 보통의 경우는, Neural Network을 키워더라도.  
>
> 그래서 어떤 $y'$이라는, 어떤 target이 존재를 하고,  
> $y$는 이제 Neural Network가 만들어 내는 거라고 생각합시다.  
>
> 그래서 $h$랑 $w$는, Image는 이제, height와 width를 갖고 있잖아요.  
> 그래서 $h$랑 $w$는, 그 Image의 X축, Y축의 좌표에 대해서 표현을 한다고 생각하면 될 것 같고,  
> 지금 요 수식에 대해서 설명을 하는 거는, 각각의 pixel-wise로 L2 distance를 재서,  
> 그걸 square를 한 다음에, 다 더하게 됩니다.  
>
> 그러면 요 이미지가 얼마나 다른지에 대해서 묘사가 되는 거겠죠.  
> 그래서, Input을 넣고, Neural Network를 나왔을 때, Output이 요 중간 같은 느낌이고,  
> 근데 ground truth는 오른쪽과 같습니다.  
>
> 그럼 이런 느낌의 Output이 나오면 이게 지금, 결과가 잘 나온 것이냐면,  
> 잘 안 나왔다고 생각할 수 있는데, 노란색이 아니니까.  
>
> 근데 요렇게 L2 loss로 보통 이렇게, deterministic하게,  
> 생성 모델적으로 하지 않는 애들은, 이렇게 색깔의 차이가 되게,  
> 요 pixel space 위에서는, optimization이 잘 안 됩니다.  
>
> 그래서 보통 요런 colorization 해주는 방법론들 같은 경우는,  
> 생성 모델을 되게 많이 사용하는 것도, 요런 문제가 있기 때문에,  
> 요런, 그렇게 사용하는 거고,  
>
> 요건 이제, 그, conditional함, 그런 것들에 대한,  
> 그, 자꾸 그, 예제만 앞에서 말씀드렸으니까,  
> 이게 실질적으로 어떤 식으로 학습되는지, deep neural net을 가지고,  
> 설명드리려고 하는 예제고, 더 진행을 한번 해보도록 하겠습니다.  

---

## p15. Image-to-Image Translation : Objective Function

<img src="/assets/img/lecture/probstat/12/image_13.png" alt="image" width="720px">

> **강의 내용**  
> 
> 네, 그래서 요렇게, 페어링을 하는 것 중에, 아까 말씀드렸었던, Colorization, 컬러를 채우는 것이 있고,  
> Super Resolution이라는 되게 중요한, 컴퓨터 비전, 그, task도 있죠.  
>
> 그, 이제, conditioning을 걸 때, resolution이 줄어드는 것,  
> resolution이 줄어든 이미지를, resolution이 키워진 이미지로 만들어야 되는 거,  
> 그러니까 정보를 채우는 거거든요.  
>
> 그래서 요런 류의 것들도, 사실, 뭐, image-to-image translation에서 많이 사용을 하고,  
> image-to-image translation을, 생성 모델들이 잘 하다 보니까,  
> 요런 것들이 생성 모델로 많이 해요.  
>
> 요즘에, 그, Nano Banana 제가 자꾸 말씀드리는데,  
> 되게 유명한 교수님이, super resolution을 해봤어요.  
> 되게 이제, 중국 교수님인데, 되게 뭔가 화질이 안 좋은 카메라로 찍은 다음에,  
> Nano Banana 모델로, super resolution을 해 줘, 하니까,  
> 그, 전광판 같은 거, 한자들이 되게 blurry해서 안 보이는데,  
> 그걸 자기네가 모델이 만들어서, 창조를 해 가지고,  
> 어떤, 새로운 정보를 만들어야 될 것 같거든요.  
>
> 사실, 그런 걸 보면, 생성 모델은 다 요런 프레임워크 안에서 해석할 수 있다.  
> 특히나 이제, 컴퓨터 비전적인 입장에서 봤을 때,  
> 우리가 이제 생성 모델을 컴퓨터 비전에만 쓰진 않지만, 이미지에만 쓰진 않지만,  
> 이미지의 예제로 봤을 때는, 요런 것들을 생각해 볼 수 있다는 거죠.  

---

## p16. Motivation : GANs

<img src="/assets/img/lecture/probstat/12/image_14.png" alt="image" width="720px">

> **강의 내용**  
> 
> 그러면 이제, 여기까지가 되게, 이거가 GAN이랑 뭔 상관이냐,  
> 이게 생성 모델이랑 뭔 상관이냐, 이거 되게 weak한 어떤 관계였는데,  
> 이건 그냥 다 문맥에 대해서 여러분들이 잘 모르시기 때문에,  
> 설명을 드리려고 얘기한 거고,  
> 오늘 우리의 목표는 뭐였었죠?  
> Generative Adversarial Network를 정의를 하는 거였었잖아요.  
>
> 그래서, 그러면 이제 Generative Adversarial Network라고 하는,  
> 이 생성 모델을 이제 정의를 해 봅시다.  
>
> 그래서 이제, 그, 왼쪽 그림 같은 경우는, 페어가 있습니다.  
> 그래서, 그 $y$라는 페어, 그리고 $x$라는 페어가,  
> 우리가 이제 다 생성할 수 있다고 했었죠.  
>
> 페어링을 만들어 놓고,  
> 요거는 이제 어떻게 보면, 그, 생성된 데이터라고 생각을 하면,  
> 그럼 이거와 구별되는 어떤 리얼 포토들을 준비를 해 놓습니다.  
>
> 그래서 왼쪽은 $x$에서 $y$로 가는 명확한 어떤 가이드라인이 존재를 하는데,  
> 그, 이거를 세트로 보는 거예요.  
>
> 그래서, 아까 앞에서 봤을 때는, 이게 one-to-one correspondence가 되는 건데,  
> 생성 모델은 그게 아니라고 했었잖아요.  
>
> 그래서 앞에서 그냥 우리가 deterministic한 알고리즘을 통해서  
> 이렇게 고려를 해서 이제 학습을 하게 되면,  
> 블랙 이미지 하나가 들어가면,  
> 무조건 같은 색깔 distribution을 갖는 같은 이미지만 나올 텐데,  
> 그게 싫으니까, 그런 거를 이제 페어링을 다 한 다음에,  
> 그 리얼 포토랑 전체적으로 비교를 하는 거예요.  
>
> 데이터셋 전체끼리.  
>
> 되게 복잡한 개념인데,  
> 뒤에서 이제 수학적으로 그걸 조금 더 명명하게 정리를 하도록 하겠습니다.  
>
> 그래서 이제 그 Generative Adversarial Network가 뭐냐면,  
> 이렇게 set of fake 이미지,  
> 그 set of real 이미지 같은 것들을 구별을 하는  
> 어떤 classifier가 들어간 생성 모델이라고 생각하시면 될 것 같아요.  
>
> 이거는 이제 2014년도에 Ian Goodfellow라는 분이 만들었고,  
> 되게 유명한 딥러닝 책의 저자이기도 하죠.  
>
> 그래서 되게 한때, 이 생성 모델의 흐름을 아주 휩쓸었었던  
> 되게 중요한 그런 모델 중에 하나라고 생각을 합니다.  

---

## p17. Actor-critic Perspective

<img src="/assets/img/lecture/probstat/12/image_15.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그럼 이제 조금 더 들어가서,  
> 그럼 GAN이라는 모델이 어떻게 작동을 하냐,  
> 이렇게 한번 생각을 해볼게요.  
>
> 그래서 일단 그 $x$라는 이미지가,  
> $x$라는 컨디션이 $G$라는 generator라는  
> 그 뉴럴 네트워크에 일단 들어가게 됩니다.  
>
> 그래서 generator의 목적은 뭐냐면,  
> 어떤 이미지를 그냥 생성을 하는 거예요.  
>
> 그래서 generator가 $G(x)$라는 이미지를 생성했을 때,  
> 뒤에 또 다른 뉴럴 네트워크가 존재를 합니다.  
>
> discriminator라는, 혹은 critic이라 불리는  
> 뉴럴 네트워크가 존재를 하는데,  
> 그 뉴럴 네트워크는 앞에서 generator가 만든  
> 생성된 데이터가 진짜냐 가짜냐  
> 판별을 해주는 그런 뉴럴 네트워크입니다.  
>
> 그래서 generator가 만약에 만든 데이터가  
> discriminator가 보기에 만약에 fake라고 판단이 된다?  
> 라고 하면, 이건 fake라고 해서  
> generator한테 벌을 가한다고 해야 될까요?  
> negative signal을 주게 됩니다.  
>
> 그럼 generator 입장에서는  
> discriminator가 negative signal을 못 주게끔  
> 속여야 되는 거거든요.  
>
> 그래서 generator와 discriminator가  
> 서로 이제 공통된 자원,  
> $G(x)$라는 걸 어떻게 판별할 것이냐는  
> 공통된 자원을 가지고 서로 싸우게 됩니다.  
>
> 수학에서는 이걸 min-max, zero-sum 게임이라고 하거든요.  
>
> 그런 어떤 수학적 formulation이 있는데,  
> 여러분들 그 죄수의 딜레마 이런 거 아실 거라고 생각하는데,  
> 그것도 이제 게임이론 시나리오 중에 하나거든요.  
>
> 그런 것처럼 이 generative adversarial network에서,  
> 특히 actor-critic perspective하게 봤을 때는,  
> 이 두 개의 뉴럴 네트워크,  
> 이게 학습에 다 사용이 되는데,  
> generator와 discriminator는  
> 서로 하나의 자원, 생성된 데이터에 대해서  
> 싸우는 min-max, zero-sum 게임을 한다.  
>
> 밑에 이제 영어로 표현이 되어 있는데,  
> $G$는 $D$를 속이기 위해서 가짜 이미지를 만들고,  
> $D$는 최대한 가짜 이미지가 가짜인지 진짜인지  
> discrimination을 하는 그런 목표를 갖고 있습니다.  
>
> 그래서 뭐 그런 예제가 되게 많더라고요.  
> 도둑이 위조지폐를 만들면,  
> 범죄집단이 위조지폐를 만들면,  
> 그 위조지폐를 경찰들이 검사를 해서  
> 이게 진짜인지 아닌지 판별을 해야 되는데,  
> 이런 예제들도 되게 설명을 하는데 많이 쓰이는데,  
> 그것도 actor-critic perspective하게 보면  
> 되게 비슷한 문제로 생각해 볼 수 있을 것 같아요.  
>
> 그럼 이제 앞에서 generator와 discriminator  
> 두 개의 뉴럴 네트워크가 있다고 가정을 했는데,  
> 이게 VAE로 보면 되게 신기해요.  
>
> VAE로 보면 뒤집혀진 VAE거든요.  
>
> 이게 무슨 뜻이냐면,  
> 원래 VAE에서 인코더는 데이터가 들어가고  
> latent variable이 나오잖아요.  
>
> 그리고 decoder 같은 경우는 latent variable이 들어가고  
> 이미지가 나오죠.  
>
> 근데 여기서 $G$ 같은 경우는 앞에 있는데,  
> latent variable이 들어가고 데이터가 나오거든요.  
> 이게 사실 decoder랑 비슷한 역할이었고,  
>
> discriminator는 지금 데이터가 들어가고  
> latent variable 같은 게 나오거든요.  
>
> 그래서 인코더, 디코더를  
> 거꾸로 꽂아놓은 구조라고 보면 될 것 같아요.  

---

## p18. Role of discriminator : critic

<img src="/assets/img/lecture/probstat/12/image_16.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 그러면 discriminator의 목적과 훈련 방식이 어떻게 되어 있느냐,  
> 여기서 좀 설명을 드리도록 하겠습니다.  
>
> 그러면 generator가 존재를 하고,  
> 먼저 위에 그림을 한번 생각해 봅시다.  
> $G(x)$라는 generator가 생성한 데이터를 가지고  
> discriminator에 넣게 됩니다.  
>
> 그러면 이 밑에와 같은 objective function을 고려한다고 가정하면,  
> 이 discriminator의 값이 크면 클수록  
> 이거 fake라고 discriminator가 생각을 하는 거고,  
> discriminator의 값이 낮으면 낮을수록  
> real value라고 생각하는 거예요.  
>
> 그래서 discriminator 입장에서 보면,  
> 이렇게 fake 이미지가 들어왔을 때는  
> discriminator가 뱉어내는 값을 크게 만들어야 되는 거고,  
> 그리고 real 데이터가 왔을 때는  
> discriminator가 뱉어내는 데이터를 0으로 만들도록  
> 훈련을 해야 되는 거거든요.  
>
> 그래서 밑에 보면 그런 역할이  
> 밑에 그림과 같이 표현이 되어 있습니다.  
>
> 그래서 $1 - D(y)$를 maximizing을 하면  
> $D$는 최대한 값을 줄이도록 학습이 되는 거고,  
> 그건 두 번째 초록색 term이고,  
> $G$가 만들어낸 fake 데이터가 $G(x)$로 표현되잖아요.  
> $G(x)$ 데이터가 $\log D(\cdot)$에 들어가면  
> 이거를 maximizing하게끔 옵티마이징이 되면  
> 최대한 discriminator의 output이 커지게끔 됩니다.  
>
> 그래서 이 두 개를 더 해놨으니까  
> 이 두 개의 purpose를 동시에 만족시키는  
> 그런 neural network parameter,  
> 어떤 $\theta$를 찾는다라는 거죠.  
>
> 근데 이거 되게 재밌어요.  
> 이런 것들은 사실 기존의 머신러닝 알고리즘,  
> 인공지능 알고리즘에서 흔하지 않습니다.  
>
> 되게 재밌게 생긴 거라서,  
> 흔하지 않다는 건 뭐냐면,  
> 왜 흔하지 않았냐고 얘기를 해야 되는데,  
> 옵티마이징이 굉장히 불안합니다.  
>
> 그래서 트레이닝을 하다 보면  
> converge되는 형상을 보기가 힘들어요.  
>
> 그래서 discriminator와 generator의  
> 어떤 parameter라든지,  
> 어떤 representation power에 대한 비율이 깨지게 되면  
> 이 트레이닝한 것들이 되게 diverge되면서  
> 학습이 실패하는 경우가 굉장히 많습니다.  
>
> 그래서 GAN 같은 경우 모든 게 다 좋아요.  
> 훈련이 끝나면, 물론 discriminator는 버리게 되지만,  
> $G$라는 생성 모델에 그냥 input을 넣게 되면  
> output이 바로 나오는 형상이고,  
>
> 보통 VAE는 reconstruction loss에 대한  
> 이 constraint가  
> neural network 학습하기에 좋도록 되어 있는  
> 모양은 아니거든요.  
> 그런 수학 수식은 아니거든요.  
>
> 그래서 평균적으로 비슷한 정도의  
> parameter의 숫자를 갖고 있다고 했을 때,  
> VAE보다 GAN이 훨씬 더 좋은 것 같아요.  
> 학습만 되면은.  
>
> 그런데 문제는 뭐냐면,  
> 이런 식으로 $\log D(\cdot)$ 안에 $G$가 물려있고,  
> 두 개의 loss에 대해서  
> $\log$ function이 또 미분하면  
> 되게 곤란한 성질이 있거든요.  
>
> $\log x$를 미분하면 $1/x$인가요?  
> 그럼 $x$가 0에 가까워지면 어떻게 되죠?  
> 폭발하겠죠, 미분값이.  
>
> gradient explosion 문제가  
> 굉장히 쉽게 생깁니다.  
>
> 그러니까 그런 문제들이 있어서  
> 이런 object function을  
> 그냥 direct하게 고려하기 너무 힘듭니다.  
>
> 여하튼 간에,  
> 그건 이제 더 구체적인 얘기인 거고,  
> 이 discriminator, critic의 목표를 봤을 때는  
> 이런 행동을 하는 거다.  
>
> 잘 보면은 그러면  
> 이 그림, 위에 그림과 밑에 그림을  
> 어떻게 좀 뭐랄까요,  
> 방법론적으로 해석을 해보면,  
>
> 이게 의미가 뭐냐라고 하면,  
> 공부를 하는 거죠, 그러니까 discriminator가.  
>
> 진짜 공부하고,  
> 진짜는 진짜라고 공부하고,  
> 가짜는 가짜라고 공부하는 거죠.  
>
> 가짜 시그널을 받고 공부하는 게 아니에요.  
> real에 대한 어떤 pivot이 있는 거죠.  
>
> real을 배우지 않고는  
> fake인지 모른다는 거죠, discriminator는.  
>
> 그래서 그 부분이 되게 중요하다는 거.  

---

## p19. Role of generator : actor

<img src="/assets/img/lecture/probstat/12/image_17.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그런 거고, 그럼 이제 actor.  
> generator의 role, 어떤 것을 하는 것이냐라고 한다면,  
> 이 위에서 이 object function은 $D$에 대해서 $\arg\max$를 해가지고,  
> fake면 숫자가 커지도록, real이면 숫자가 작아지도록  
> 훈련이 된다고 했었잖아요.  
>
> 그럼 generator는 그거의 역방향으로  
> 훈련을 하면 되겠죠.  
>
> 그러면 fake일 때 real처럼 만들게 속이고,  
> real일 때 fake가 되게끔 속이면 되는 거잖아요.  
>
> 그죠?  
>
> 근데 이제 문제는 뭐냐면,  
> 이 뒤에 object function을 해봤을 때,  
> discriminator를 속일 수,  
> 그러니까 discriminator가  
> 진짜 샘플에 대해서 학습하는 걸 속일 수는 없습니다.  
>
> 거기는 $G$라는 게 개입하지 않기 때문에.  
>
> $G$라는 거 개입하는 거는,  
> 이 수식에서 첫 번째 term,  
> 내가 만든 거를 이제 $D$라는 애한테 주기 전에  
> 최대한 그걸 속여야 되는 거죠.  
>
> 그럼 잘 속이면 discriminator는 혼란이 올 거예요.  
>
> $G$가 만들어 낸 가짜 데이터에 대해서  
> 최대한 원래 fake여서 값이 높아져야 되는데,  
> 값이 낮아지게끔 설계를 했잖아요.  
>
> 그러면 discriminator 입장에서는  
> 분명히 내가 공부한 거랑 다른데,  
> 내가 공부했던 거는 진짜 이미지가 있는데,  
> 왜 네가 만든 게 진짜라고 얘기하느냐처럼  
> 되게 교란이 되는 거죠.  
>
> 그래서 그걸 fool한다라고 표현을 하는 거예요.  
> objective function 입장에서.  
>
> 그럼 이제 똑같은 objective function,  
> 모양이 똑같아요, 잘 보면.  
>
> 여기 $\arg\max$랑 $\arg\min$을 취한다는 것만 다르고,  
> 그 안에 있는 내용은 똑같습니다.  
>
> 그러니까 이 안에 expectation 취해져 있는 게  
> 공통의 자원인 거고,  
>
> discriminator는 그거를 크게 하도록,  
> 그리고 generator는 그걸 작게 하도록  
> 서로가 싸운다는 거죠.  

---

## p20. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_18.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 이런 식으로 min-max game으로 고려한 겁니다.  
>
> 근데 우리의 목표가 뭐죠?  
> 생성 모델.  
>
> 이 Generative Adversarial Network의 목표가 뭐가 돼야 될까요?  
> 잘 판별하는 게 목표가 될까요?  
> 아니면 잘 생성하는 게 목표가 돼야 될까요?  
>
> 생성하는.  
> 그렇죠.  
>
> 그러면 이 싸움은 무조건 discriminator가 지게끔 설계를 해야 됩니다.  
> 최종적으로는.  
>
> discriminator는 generator가 최종적으로  
> 정말 좋은 퀄리티의 샘플을 만들어내도록  
> 독려를 하고 도와줘야 되는 의무는 있지만,  
> 가장 마지막 순간에는 generator가 승리를 하게 만들어야 돼요.  
>
> 그게 지금 이렇게 표현되어 있는 거거든요.  
>
> 우리 mathematical operation을 할 때  
> 오른쪽에 있는 걸 먼저 합니다.  
>
> 그래서 maximization을 $D$가 먼저 했죠.  
>
> $D$가 최대한 잘 판별한 거에 대해서,  
> 최대 판별에 대해서,  
> generative가 최소로 그걸 만드는 거죠.  
>
> 네가 아무리 최대 노력을 하더라도  
> 난 그걸 줄일 것이다.  
>
> 라고 objective function이 고려가 되어 있는 거예요.  
>
> 이 전체가 어떻게 보면  
> 모든 GAN 모델, Adversarial Training의  
> 핵심 철학이라고 보면 될 것 같아요.  
>
> 그래서 이걸 그냥 단순히 생성 모델에 국한된 거냐,  
> 이렇게 볼 수도 있는데, 그게 아니고  
> 이게 굉장히 많은 신뢰성 이런 거에도 연결이 되면서  
> 되게 중요합니다.  
>
> 예를 들어서 이런 걸 생각을 할 수 있거든요.  
> 여러분들 혹시 Adversarial Attack이라고 들어봤어요?  
>
> Adversarial Attack이… 그런 게 있어요.  
> 내가 이미 classifier에 이미지를 넣게 돼요.  
>
> 그런데 이미지를 넣었을 때,  
> 이거는 예를 들어서 앞에 예제를 보면서 얘기를 해보죠.  
> classifier에 생선 사진을 넣었으면  
> 생선에 대한 레이블이 나와야 되잖아요.  
>
> 그런데 Adversarial Attack은 뭐냐면,  
> 이 classifier를 최대한 속일 수 있는 생성 모델이  
> 이 이미지에다가 픽셀 레벨에서 굉장히 작은 값,  
> $0.00001$을 넣고  
> 이 이미지에 대한 output 값을 바꿔버릴 수 있어요.  
>
> 그걸 이런 min-max 게임 형식으로 forging을 해가지고  
> 이 GAN의 어떤 트레이닝 objective로 사용하거든요.  
>
> 사람의 눈으로 볼 때는 구별이 불가능합니다.  
> 왜냐하면 픽셀 레벨에서 $0.00001$은  
> 사람 눈으로 구별이 안 되니까.  
>
> 그런데 데이터로는 다르거든요.  
> Neural Network는 우리가 long bit도 쓰고 하지만  
> 일단 기본적으로가 double bit를 쓴다고 해서,  
> double은 컴퓨테이셔널 precision을 의미하는데  
> $0.00001$도 표현이 되거든요.  
>
> 그런데 그 값이 이런 min-max operation을 통해  
> 이미지에 injection이 되고  
> classifier를 속이게끔 생성이 될 수 있어요.  
>
> 그런 걸 Adversarial Attack이라고 하거든요.  
>
> 사람 눈에는 전혀 구별 못하고  
> 실제로 $L2$ norm 같은 걸로도 구별하기 힘듭니다.  
>
> 그래서 가장 최근에 나오는 classifier도  
> Adversarial Attack을 하면 다 attack이 돼요.  
>
> 그런데 그런 게 이제 엄청난 문제겠죠.  
>
> 그러면 이제 공격자가 이미지에다가  
> 악성 코드를 넣어가지고,  
> 우리가 이미지를 인터넷에 막 뿌려서  
> 누군가 그걸 classifier나 서비스에 업로드하면  
> 그게 output 값을 완전히 뒤집어 버리는 거예요.  
>
> 그게 뭔가 생명과 관련된 문제,  
> 예를 들어서 테슬라 이미지 classifier 같은 데서  
> detection을 한다고 해봅시다.  
>
> 만약 테슬라 센서에 adversarial 픽셀을 주입하면  
> 앞에 사람을 표지판이라고 생각할 수 있겠죠.  
>
> 그래서 보안 이슈에서 굉장히 큰 문제였습니다.  
> 아직도 해결이 안 됐어요.  
>
> Neural Network structure의 한계 때문에  
> 근본적으로 해결이 안 되고,  
> 접근을 못하게 wrapping하는 방식만 존재합니다.  
>
> 그래서 그런 되게 재밌는 문제들을 만들 수 있다.  
> 이런 생성 모델의 min-max 게임 구조를 통해서.  
>
> 그래서 다시 돌아가자면,  
> 우리가 하는 것은 이제  
> 최대한 노력을 한 discriminator를 속일 수 있는 generator를 만드는 것,  
> 그게 목표고,  
>
> 그거는 $\arg\min_G\, \max_D$  
> 그리고 뒤에 objective function을 통해서 표현을 한다.  

---

## p21. Min-max game : Game theory

<img src="/assets/img/lecture/probstat/12/image_19.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 G의 입장에서 봤을 때 D는 loss function입니다.  
> 왜냐하면, G가 지금 $G(x)$가 D의 input으로 들어갔잖아요.  
> 그래서 $\log D(\cdot)$가 G의 입장에서 봤을 때 loss function처럼 거동을 하는 거죠.  
>
> 왜냐, 우리가 앞에서 이렇게 얘기를 했습니다.  
> 그래서 Neural Network의 output이 뭔가의 objective function으로 래핑이 돼가지고 고려가 됐는데,  
> 이 모양이 똑같이 생겼잖아요 밑에가.  
>
> 그래서, 그...  
> generator 입장에서 봤을 때 D는 loss function이다.  
>
> 근데 이게 조금 재밌는 거죠.  
> 앞에서 우리가 Image-to-Image Translation 같은 거 할 때는  
> 이 $L$이라는 거를 Pixel-wise L2 Distance로 정의했었는데,  
> 이거는 움직이는 loss function인 거예요.  
>
> G 입장에서 보면.  
> D가 계속 학습되면서 바뀌니까.  
> G 입장에서 그걸 계속 풀어야 되고,  
> 그걸 계속 옵티마이제이션 해야 되니까,  
> G 입장에서는 시간에 따라 변하는 loss function이라고 볼 수 있어요.  
>
> 그래서 그렇게 생각하면 될 것 같고.  
>
> 그럼 이거를 실질적으로 훈련을 할 때는  
> 어떤 식으로 훈련을 하느냐.  
> 이제 앞으로 저희가 GAN 코드도 볼 겁니다.  
> 코드 implementation 하면서 확인을 할 텐데,  
> 이게 사실 Maximum D를 취한 다음에 Min G를 하면은,  
> 이게 사실 이게 정확하게 수학적으로는 잘 정리가 돼있지만,  
> 이거를 실질적인 어떤 코드 입장에서 우리가,  
> 코드 레벨에서 이걸 구현을 해서 학습시킨다는 건 사실 거의 불가능해요.  
>
> Maximizing D를 어떻게 할 것이냐.  
> $G$는 처음에 Initialization이 어떻게 되어 있을까요?  
> 파라미터를 만들면, Neural Network를 그냥 만들면.  
> 쓰레기 값으로 차 있거든요, 파라미터들이.  
>
> 그럼 그거를 아무리 속여봤자 아무런 의미가 없는 거잖아요.  
> 서로 발전하면서 뭔가 표현이 되어야 되는데.  
>
> 그리고 이 수학 수식이 그거를 묘사를 하고 있는데,  
> 그래서 실질적으로 우리가 이런 Neural Network의 어떤 두 개의 중첩에 대해서,  
> 하나는 Gradient Ascent를 하고,  
> 하나는 Gradient Descent를 하는 거를 반복하게 됩니다.  
>
> 그래서 이 discriminator 입장에서는  
> 어떤 Objective Function을 Maximizing 하는 거니까,  
> Gradient Descent는 Optimization의 Loss Function 값을 줄이는 거였잖아요.  
>
> 근데 discriminator 입장에서는 Maximization을 하니까  
> Gradient Ascent를 합니다.  
> 그러니까 Gradient가 원래 Minus 방향으로 줄이는 건데,  
> 역방향으로 하는 거죠.  
>
> 그럼 전체 Objective Function의 값이 커질 테니까.  
>
> 그래서 먼저 discriminator를 업데이트를 하고,  
> 그 다음에 Generator를 업데이트를 합니다.  
>
> 근데 Generator 업데이트를 할 때는  
> 우리가 이 Objective Function을 줄이는 게 목적이기 때문에,  
> Gradient Descent를 하는 거죠.  
>
> 그래서 discriminator는 Gradient Descent 한 번 하고  
> Generator를 잠그고,  
> Gradient Descent를 Generator가 하고,  
> 그때 또 discriminator를 잠그고 파라미터들을.  
>
> 그걸 무한 반복을 하는 거예요.  
>
> 그러면 이게, 아까 말씀드렸던 것처럼  
> 이런 식으로 학습을 하면 뭔가 좀 불안하지 않을까요?  
> 우리가 그걸 어떻게 컨트롤 할 수 있죠?  
>
> 이 큰 블랙박스 모델이  
> 그런 식으로 Gradient Ascent와 Descent가 번갈아가면서 표현됐을 때,  
> 그게 뭔가 우리가 원하는 대로 수렴할 거라고 믿는 건  
> 되게 바보인 거죠.  
>
> 그래서 바보들이었습니다.  
> 그래서 이게 잘 안 돼, 이게 힘들었어요.  
> 이걸 자꾸 Optimizing하고 결과를 뽑아낸 거예요.  
> 이거 갖고 Product 만드는 사람 없습니다.  
>
> 그래서 Image 생성 Model 같은 경우는  
> 요즘에 엄청나게 Product화 되는 거거든요.  
> 그 인프라를 유지하는 인력들은,  
> 그러니까 돈이 모이기 시작한 건 Diffusion Model 시대가 와서인 거예요.  
>
> 이 트레이닝을 한 번 하는데  
> 엄청난 돈이 들거든요.  
> 예를 들어서 여러분들 H100 20만장에다가  
> 이거 올려가지고 훈련을 하면,  
> 전기료만 해도 1초에 얼마가 나올까요?  
>
> 그거 생각해보면 끔찍해집니다.  
>
> 그리고 그 인프라를 유지보수하는 인력들의 인건비,  
> 그리고 그 인프라를 빌려온 걸 거 아니에요?  
> 임대료부터 시작해서.  
>
> 여러 가지가 이제 다 문제가 되는 건데,  
> 그래서 근데 그렇게 해서 훈련을 했는데,  
> 훈련 결과가 Converge 되지 않고  
> 이상한 값을 고려할 수 있고,  
> 그렇게 나온다고 한다면,  
> 그럼 그 비용은 어떻게 할 거에요?  
>
> 그죠?  
> 그래서 그런 문제가 굉장히 심각합니다, 사실.  
>
> 그래서 여러분들 Objective Function 막 설계를 하고  
> 이런 것도 되게 쉽게 볼 수도 있는데,  
> 여러분들 그냥 Colab에서 할 때는 아무런 문제 없지만,  
> 이게 진짜 우리가 뭔가 의미 있는 Semantic을 갖고,  
> 뭔가 사람처럼 행동하는 그런 스케일로 커지면은,  
>
> 이런 작은 Objective Function을 다르게 설계를 하는  
> 이 디테일의 차이가,  
> 사실 엄청난 비용의 문제가 생길 수가 있더라고요.  
>
> 제가 직접 경험을 해보니까.  
>
> 그래서 그런 것들을 실제로 스케일링 업하는 세계에서는  
> 되게 중요하다.  
>
> 그래서 GAN 모델은 이제  
> 현실 세상에서 잘 쓰지 않는 모델로 전락을 했다.  
>
> 아까 말씀드렸었던 Adversal Attack 이런 건 연구가 계속 됩니다.  
> 어떻게 공격할 것인가?  
>
> 이미지가 커지면 커질수록 더 쉬워져요.  
> 채울 수 있는 디테일이 많으니까.  
>
> 이미지 퀄리티가 높아지면 높아질수록 더 쉽습니다.  
> 되게 웃긴 거에요.  
>
> 그런데는 많이 연구되지만,  
> GAN 모델이 이런 어떤 트레이닝 스테이빌레이티의 문제 때문에  
> 좀 많이 사용되지는 않습니다.  
>
> 그래서 아까 다시 돌아가서,  
> Gradient Ascent와 Gradient Descent를  
> 번갈아 가면서 한다고 했는데,  
>
> 그럼 여기서 또 틀이 있어요.  
> 이거를 한 번씩 하면, 결과적으로,  
> 이것도 굉장히 노가다로 찾은 건데,  
>
> Gradient Descent 한 번 하고,  
> Gradient Ascent 한 번 하면은  
> 보통은 어떻게 되냐면,  
> 그냥 트레이닝 스킴이 다 망가져 버립니다.  
>
> 보통의 경우.  
> 최대한 수많은 노력을 해서,  
> discriminator와 generator의 파라미터 숫자를 막 조절하고 해봐도,  
>
> 1대1의 업데이트 룰을 갖고 가면,  
> 이 트레이닝의 전체가 다 collapse되요.  
>
> 그래서 보통은 어떻게 하냐면,  
> discriminator 5번 업데이트를 하고,  
> 그리고 generator를 한 번 업데이트하고,  
> 이거를 번갈아가면서 합니다.  
>
> 그리고 여기서 또 중요한 게 뭐냐면,  
> 이 파라미터, Representation Power를 잴 수 있거든요.  
>
> 어떤 특별한 metric을 써가지고,  
> Representation Power의 비율도 되게 잘 정의를 해야 돼요.  
>
> 우리가 러닝하는 트레이닝 데이터에 따라,  
> 우리가 러닝하는 아키텍처에 따라,  
> 그런 거에 따라 그것도 잘 조정을 해야 돼요.  
>
> 그래서 원래 스테이블한 어떤 GAN 러닝을 보장을 하려면,  
> 앞에서 웜업이라고 해야 되나요?  
>
> 우리가 그런 최적의 비율을 찾는 거를  
> 10번 만큼 해야 돼요.  
>
> 이 최종적으로, 아 이제 이 정도면 준비가 됐다.  
> 이제 우리 훈련 끝까지 다 돌려봐도  
> 뭔가 결과가 잘 나오겠다.  
>
> 이거 판단하는 데까지  
> 최소 10번 정도 돌려봐야 돼요.  
>
> 그래서 모든 생성 모델 하는 사람들이  
> 이것 때문에 엄청난 고통을 받아서요.  
>
> 그래서 그런 치명적인 단점이 있다는 거.  
>
> 그럼 그게 어디서 유발이 됐냐?  
> 이 min-max 게임을 이론적으로,  
> 솔루션이 없기 때문에,  
>
> 우리가 numerical하게 갖고 왔기 때문에,  
> 간접적인 방향으로 그걸 그냥 물 떠다 놓고  
> 되기를 기도했기 때문에 그런 거고,  
>
> 뭔가 명확한 이론적 솔루션이 존재한 게 아니라.  
>
> 그래서 여러분들 그런 거에 대한 문제들도  
> 잘 생각을 해보셔야 될 것 같아요.  
>
> VAE나 어떤 그 GAN 같은 경우는  
> 그런 성격이 되게 강해요.  
>
> 어떤 수학적인 contraint는 명확하게 주어지지 않고,  
> 뉴럴 네트워크로 그냥 모든 걸 다 풀어라.  
>
> 그 variation equation 배웠었는데 저번에.  
> 저저번 주에.  
>
> variation equation도 사실  
> 내가 upper bound 이러면서 막 뭐 생략한다고 했잖아요.  
>
> 근데 그게 제가 그때 뭐라고 했었죠?  
> 원래는 그거를 명확하게 계산을 할 수 있고,  
> 좀 어렵지만, 계산을 해야 정확하게 나오는데  
>
> 그걸 날렸다고 했잖아요.  
>
> 그것도 사실 이거랑 되게 비슷한 이유입니다.  
>
> 더 이론적으로 뭔가 파고들고,  
> 그걸 모델링했을 때의 어떤 complexity가 커지기 때문에  
> 다 날리고, upper bound만 러닝을 했기 때문에,  
>
> 걔네들도 instability가 똑같이 있고  
> 퀄리티도 떨어지고 하거든요.  
>
> 근데 이제 앞으로 배울  
> Normalizing Flow 라던지 디퓨전 모델은  
> 그런 거에 대한 어떤 mathmatical constraint를  
>
> 더 명확하게, 인간이 더 다루기 쉽게,  
> 컴퓨터 코드로 더 호환성 있게끔 설계를 해 놨습니다.  
>
> 그런 것들을 목적으로 오히려 만들었기 때문에.  
>
> 그래서 실제로 훈련을 하고 퀄리티를 재 보면,  
> 다른 모델들에 비해서  
> 굉장히 더 좋은 퀄리티,  
> 그리고 좋은 트레이닝 landscape를 볼 수가 있어요.  
>
> 그래서 그런 어떤 백그라운드의,  
> 엔지니어링적인 문제들도 존재한다.  
>
> 이 PPT에서는 알 수가 없는.  

---

## p22. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_20.png" alt="image" width="640px">

> **강의 내용**  
> 
> 네, 그래서 이제 앞에서 컨디셔널한 그런 것들을 고려했었는데,  
> 컨디셔널 GAN 같은 걸 어떻게 하느냐, 이걸 한번 생각해보자면,  
> $x$는 인풋 이미지였잖아요.  
>
> 그래서 인풋 이미지를 고려하고,  
> $G(x)$는 $G$가 만들어낸 페이크 데이터라고 했습니다.  
>
> 그럼 discriminator가,  
> 이 컨디셔널 GAN 같은 경우는,  
> 페이크 이미지랑,  
> 아니 그 인풋으로 간 컨디션 이미지랑,  
> 페이크 이미지 그 두 개를 동시에 받습니다.  
> 인풋으로.  
>
> 그리고 마찬가지로 리얼 데이터를 배울 때는,  
> 컨디셔널 리얼 데이터랑,  
> 그리고 이제 타겟 리얼 데이터를 페어링을 해가지고,  
> discriminator 인풋에 넣게 돼서,  
> 요것도 학습하게 되고요.  
>
> 그리고 이제 argmin하고 argmax 하는 거는 똑같습니다.  
> 리얼 페이크에 대해서,  
> 앞에서 마찬가지로,  
> 1에 가깝게 되면 discriminator가 가짜라고 판별을 하는 거고,  
> 0에 가까우면 리얼이라고 판별을 하는 거죠.  
>
> 근데 컨디셔닝만,  
> 요 인풋에 이렇게 들어간다.  
> 이렇게 보시면 될 것 같아요.  

---

## p23. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_21.png" alt="image" width="600px">

---

## p24. Conditional GANs for Image Translation

<img src="/assets/img/lecture/probstat/12/image_22.png" alt="image" width="600px">

> **강의 내용**  
> 
> 뭐 그 GAN이, 제가 앞에 말씀드렸었던 것처럼, generator와 discriminator가  
> 그 그래디언트 descent, ascent를 번갈아가면서, 굉장히 unstable 해진다고  
> 얘기를 드렸었고, 그러면 엔지니어들도 그걸 어쨌든, 봉합을 해야 될 거 아니에요.  
> 방법은 되게끔 만들면.  
>
> 그래서 이 Image Translation 같은 경우는, 뒤에 이제 $\mathcal{L}_{L1}$이라고 써있는데,  
> 요거를 이제 추가를 합니다.  
>
> 요거를 이제, regularization term이라고 얘기를 하는데,  
> 이제 $G(x)$, 만들어낸 데이터가, $y$라는 어떤 타겟 데이터가,  
> 서로 이제, L1 distance적으로 갖게끔 하는,  
> 요런 추가 regularization term을 둬요.  
>
> 그래서, generator와 discriminator가 좀 diverge 되려고 할 때,  
> 요 term이 발동을 해서, 그 diverge 되는 그, 형태를 최대한 막아주는 거죠.  
>
> 그래서 스테이블 트레이닝을 보장을 하고, 수렴도 빨리 됩니다.  
> 요거를 하면.

---

> 이 장표는 컨디셔널 GAN을 이용한 이미지 변환 과정을 설명한 것이다.  
> 먼저 입력 이미지 $x$가 주어지면, 생성기 $G$는 이를 입력받아 $G(x)$라는 출력 이미지를 생성한다.  
> 이후 생성된 이미지 $G(x)$와 실제 타깃 이미지 $y$를 비교하여, 두 이미지 간의 차이를 최소화하도록 학습이 이루어진다.  
>
> 상단의 수식은 생성기 $G$와 판별기 $D$가 서로 경쟁하는 구조를 나타낸다.  
> 판별기 $D$는 진짜 이미지와 생성된 이미지를 구분하기 위해 최대한 정확히 판별하려 하고,  
> 생성기 $G$는 판별기를 속이기 위해 진짜와 유사한 이미지를 생성하려 한다.  
> 이러한 경쟁 관계는 일반적으로 min-max 문제로 표현된다.  
>
> 또한 기본적인 GAN 손실인 $L_{\text{cGAN}}(G, D)$에 더하여  
> $\lambda \, \mathcal{L}_{L1}(G)$ 항이 추가되어 있다.  
> 여기에서 L1 정규화 항은 다음과 같이 정의된다.  
> $$\mathcal{L}_{L1}(G) = \mathbb{E}\left[\lVert y - G(x) \rVert_1 \right]$$  
> 이 항은 생성된 이미지가 실제 이미지 $y$와 픽셀 단위에서 가까워지도록 유도하는 역할을 한다.  
>
> 이러한 L1 항을 추가함으로써 학습의 안정성이 크게 향상되고,  
> 모델이 더 빠르게 수렴할 수 있게 된다.  
> 따라서 장표 하단에는 “Stable training + fast convergence”라는 문구가 제시되어 있다.  
>
> 정리하면, 입력 이미지 $x$는 생성기 $G$를 거쳐 $G(x)$로 변환되고,  
> 이 결과는 실제 이미지 $y$와 L1 기준으로 비교되며,  
> 동시에 판별기 $D$는 진짜와 가짜를 판별하는 과정에 참여한다.  
> 이러한 구성은 안정적이고 실용적인 이미지 변환 모델을 구현하기 위한 구조라고 할 수 있다.  

---

## p25. Conditional GANs

<img src="/assets/img/lecture/probstat/12/image_23.png" alt="image" width="800px">

> **강의 내용**  
> 
> 그래서 요거는 앞에서 말씀드렸었던 것처럼,  
> 블랙 앤 화이트에서, 컬러로 되는, 어떤 그런 예제들인 거고,  
> 이게 한 18년도 쯤에 나오는, 나왔었던 논문들의 퀄리티거든요?  
> 근데 지금은 뭐 어마어마하겠죠.  
> 이 colorization 뿐만 아니라, 정말 많은 conditional한 생성을,  
> 하나의 파운데이션 모델에서, 모두 처리할 수 있습니다.  
> 그래서 그런 정말, 획기적인 모델들이 많이 존재합니다.  

---

## p26. Edges2Cats

<img src="/assets/img/lecture/probstat/12/image_24.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그러면, 아까 전에, 그 엣지 디텍션 훈련된 모양들이,  
> 그럼 어떻게 결과물을 만들어낼까? 하는 생각을 해볼 수 있는데,  
> 이런 거 하는 거예요.  
> 그냥.  
>
> 고양이 사진을 실컷 훈련을 해놓고,  
> 엉뚱하게, 이 식빵처럼 생긴 거를, 엣지로 주고, 생성을 하라고 한 거죠.  
>
> 근데 생성은 고양이로 했지 않습니까?  
> 그럼 얘가 어떻게든, 내가 학습했었던, 고양이의 모양에  
> 어떤 위치를, 잘 배치를 해가지고 표현을 해요.  
>
> 그리고 되게 재밌는 게, 저게 눈이 있어야 될 것 같거든요?  
> 근데 눈이 있네요.  
>
> 동그라미로 그려주면, 거기 눈이 안 채워질 수도 있는데, 사실.  
> 근데 눈이 채워집니다.  
>
> 그게 고양이의 어떤, 얼굴에 기하학적인 걸 보면,  
> 눈이 항상 저기 있었기 때문에, 그 확률이 높았었던 거.  
> 그냥.  
>
> 그래서 이렇게 표현이 되는 거고,  
> 다른 모양들에 대해서 다 해도,  
> 되게 엉뚱하게, 재밌게, 잘 표현이 되는, 겁니다.  

---

## p27. Pix2Pix : Labels to Facades

<img src="/assets/img/lecture/probstat/12/image_25.png" alt="image" width="600px">

> **강의 내용**  
> 
> 요거 이제 생성 모델의, 픽스 투 픽스라는 되게 유명한, Image Translation,  
> 그, 하는 모델인데, 하여튼 요 인풋에 대해서, 요 캐스케이드한 요런 이미지들,  
> 그니까, 그 각각의 층들에 대해서, 뭐 창문이라던지, 틀 같은 거에 대해서,  
> 레이블링을 해주면, 오른쪽과 같이, 이제 행동을 해준다는 거죠.  
>
> 이제 뭐, 방이나 가구, 이런 각진 것들은, 생성이 더 잘 돼요.  
> 왜냐면 딱 정형화는 틀이 있기 때문에.  
>
> 그래서 여러분들 보면은, 생성 모델에서도 훈련을 하다 보면은,  
> 그리고 실제로 현대 생성 모델들도 그래요.  
> 여러분들은 잘 못 느끼겠지만, 자연에 있을 만한, 있을 법한,  
> 그리고 되게 각지고, 되게 정형화된, 그런 내추럴 오브젝트들 있잖아요.  
> 그런 것들을 이미지 생성을 해보면, 현대 생성 모델들도 퀄리티가 굉장히 더 높습니다.  
>
> 근데 이제 뭔가, 내가 잘 생각해봤을 때, 이제 정형화되지 않은, 그런 데이터라던지,  
> 약간 데이터를 취득하기 힘든 데이터의, 어떤 그런 내추럴 오브젝트의 모양이라던지,  
> 그런 것들을 생성하라고 하면은, 이 생성 모델을 평가를 하는 메트릭이 존재하거든요.  
> FID라고 있는데, Fresh Inception Distance를, Inception Distance라는 메트릭이 있는데,  
> 그런 메트릭이 또 압도적으로 떨어집니다.  
>
> 단순히 사람이 눈으로 보는 것 뿐만 아니라, 눈으로 보는 건 괜찮아도,  
> 수치적으로 보면 굉장히 떨어집니다.  
>
> 그래서 이런 정형화된 거를 되게 잘 만들기 시작합니다.  
> 그럼 뭘 잘 만들까요, 그러면?  
>
> 그러니까 어떤, 그런 사람의 얼굴 같은 거 되게 잘 만듭니다.  
> 그래서 어떤 정형화된 위치들이 있잖아요.  
> 어떤 눈, 코, 입 같은 거.  
> 명확하게 기학적으로 뒤틀리면 안 됩니다.  
> 입이 코의 위치에 있으면 안 되잖아요.  
>
> 그래서 여러분들 AI로 만든 사람을 보면, 평균 이미지라는 얘기를 많이 해요.  
> 뭔가 이질적인 게 있잖아요.  
> AI로 만든 사람을 보면.  
>
> 결국에는 그런 기하학적 패턴들을 확률적으로 정형화시켰기 때문에,  
> 우리가 느끼기에는 약간 이상하고 이질적인 것들이 평균치로 표현이 되는 건데요.  
> 컨볼루션 필터에 화상처럼 남게 되면서.  
>
> 그런 큰 모델들 컨볼루션 필터 들어가면,  
> 기하학적 위치에 따라 컨볼루션 필터들이 다 이렇게 배치가 되는 걸 볼 수가 있어요.  
>
> 실제로 되게 재밌는 현상들이다.  
> 확률적인 현상들이다.  
> 그런 것들이 다.  
> 이렇게 생각하시면 될 것 같아요.  

---

## p28. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_26.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그럼 이제 마지막으로 GAN과 VAE를 한번 비교해보도록 하겠습니다.  
> 그래서 GAN은 뭐였죠?  
> 데이터라는, 앞에서는 이제 다 재미를 위해서 컨디셔널 생성 모델을 주로 했는데,  
> 원래 GAN의 초창기는 언컨디셔널 한 거라,  
> $z$라는 가우시안 디스트리뷰션이 들어갔을 때,  
> 데이터가 $x$라는 게 나왔고,  
> 이 가우시안 디스트리뷰션에서 데이터 디스트리뷰션으로 맵핑을 해 주는 게  
> generator라는 거다.  
> 라는 거고, 그리고 이제 그 min-max 게임을 통해 가지고 학습이 되는 거고  

---

## p29. GANs vs VAEs

<img src="/assets/img/lecture/probstat/12/image_27.png" alt="image" width="800px">

> **강의 내용**  
> 
> 그 생성 퀄리티를 볼까요?  
> 이게 제 기억, 이것도 굉장히 오래된 논문인데,  
> 한 16년도, 17년도 논문에서 나왔었던 그 피규어라고 저는 기억을 하고 있어요.  
>
> 근데 VAE 같은 경우는 블러리한 모양이 많이 나오죠.  
> 이게 그 reconstruction loss의 upper bound를 무시를 하고,  
> approximation된 걸 사용했기 때문에 표현되는 거예요.  
> 그 정보들이 다 날라간 형태라고 보시면 될 것 같습니다.  
>
> 이거는 뉴럴 네트워크가 아무리 잘 구성이 되더라도,  
> 일정 수준 이상의 블러를 피할 수, 피할 수 있는 방법이 없어요.  
>
> 여기 보면은 제가 아까 말씀드렸었던,  
> 정형화된 패턴이 있는 얼굴 쪽은 되게 잘 생성이 되는데,  
> 뒤에 배경은 고주파수잖아요.  
> 사람이 사진 찍으면 배경이 막 달라지잖아요.  
> 어떤 데는 빨간색 배경이 있고, 어떤 데는 뭐,  
> 뒤에는 뭐 없고, 그냥 막혀있는 방일 수도 있고,  
> 그래서 얼굴 쪽은 그냥 명확하게 다 표현이 되는데,  
> 뒤에 고주파수는 다 날라갑니다.  
>
> 근데 GAN은 그래도 그런 게 조금 해결이 되는 거죠.  
>
> 근데 이것도 제가 말씀드렸었던 것처럼,  
> 그래도 훈련 퀄리티가 괜찮고,  
> 앞에 그 웜업하는 시간을 다 지나가고,  
> 스테이블한 트레이닝이 보장된 형태의 생성 모델을,  
> GAN을 고려했을 때, 그때 샘플 퀄리티인 거예요.  
> 여기까지 보기가 되게 힘듭니다.  
>
> 근데 VAE는 샘플 퀄리티가 이렇게 조금 나아질 수는 있지만,  
> 훈련하기에 그렇게 어렵진 않고요.  
>
> 그래서 이거 두 개의 차이점이 있다.  
> 이해하시면 될 것 같습니다.  

---

## p30. Theory : Global Convergence of Critic

<img src="/assets/img/lecture/probstat/12/image_28.png" alt="image" width="720px">

> **강의 내용**  
> 
> 글로벌 컨버전스, 이런 수학적인 얘기는 있는데, 이건 좀 생략을 하고

---

> **명제 1.**  G가 고정되었을 때, 최적의 판별기 D는  
> 
> > $$D_G^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
> 
> **증명**  
> 
> > $$V(G, D) = \int_x p_{\text{data}}(x) \log(D(x)) \, dx + \int_z p_z(z) \log(1 - D(g(z))) \, dz$$  
> 
> > $$= \int_x p_{\text{data}}(x) \log(D(x)) + p_g(x) \log(1 - D(x)) \, dx$$  
> 
> 임의의 $(a, b) \in \mathbb{R}^2 \setminus \{0, 0\}$ 에 대해,  
> 함수 $y \mapsto a\log(y) + b\log(1-y)$ 는  
> $[0,1]$ 에서 $\frac{a}{a+b}$ 일 때 최대값을 가진다.  
> 판별기(discriminator)는  
> $\text{Supp}(p_{\text{data}}) \cup \text{Supp}(p_g)$ 밖에서 정의될 필요가 없으며,  
> 이것으로 증명이 완료된다. □
>
> ---
>
> 이 정리는 “G(Generator)를 고정했을 때, 어떤 D가 가장 좋은가?”를 알려준다.  
> 즉, 생성 모델 G가 이미 정해져 있다면,  
> 판별기 D는 어떤 값을 출력해야  
> 전체 GAN 목적함수 $V(G, D)$ 가 최대가 되는지를  
> **정확히 계산한 결과**이다.  
>
> 핵심 아이디어는 다음과 같다.  
>
> > 1) GAN의 목적함수 $V(G,D)$ 는  
> >    데이터 분포와 생성 분포가 함께 등장하는  
> >    로그 형태의 합이다.  
>
> > 2) 이 적분을 $x$별로 바라보면,  
> >    각 $x$에 대해  
> >    $p_{\text{data}}(x)\log(D(x)) + p_g(x)\log(1 - D(x))$  
> >    를 최대화하는 문제가 된다.  
>
> > 3) 이는 일반적인 형태  
> >    $a\log(y) + b\log(1-y)$  
> >    의 최대화 문제와 동일하다.  
>
> > 4) 이 함수는 $y = \frac{a}{a+b}$ 일 때 최대가 된다.  
>
> 여기서 $a = p_{\text{data}}(x)$, $b = p_g(x)$ 로 두면  
> 각 $x$마다 최적의 판별기 출력은  
>
> > $$D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$$  
>
> 이 된다.  
>
> 즉, **판별기의 최적 출력은  
> “이 $x$가 진짜 데이터일 확률의 정규화된 비율”** 이다.  
> 다시 말해, 데이터와 생성 분포의 상대적 확률비로  
> 진짜 여부를 판단하는 것이 최적이라는 뜻이다.  
>
> 마지막 문장에 따르면,  
> 판별기는 $p_{\text{data}}$ 또는 $p_g$ 가 0인 구간에서는  
> 정의될 필요가 없다.  
>
> > “두 분포가 실제로 존재하는 영역(지원집합)에서만 의미가 있으며,  
> > 그 바깥에서는 $V(G,D)$ 에 아무 영향도 없다.”  
>
> 이렇게 해서 최적 판별기 공식이 도출되며,  
> 이는 **GAN 이론의 가장 핵심적인 기반 공식**이다.

---

## p31. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_29.png" alt="image" width="600px">

---

## p32. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_30.png" alt="image" width="640px">

---

## p33. Theory : Global Convergence of Distribution

<img src="/assets/img/lecture/probstat/12/image_31.png" alt="image" width="600px">

> **강의 내용**  
> 
> 그래서 뭐 오늘은 이 정도 얘기를 하면 될 것 같은데요.  
> 이 그림에 대해서 얘기를 좀 해보자면,  
> 이게 앞에서 로그 펑션으로 되어 있었잖아요.  
> 로그 펑션으로 고려를 한 다음에 훈련을 해서,  
> 미분을 했을 때 나온 그 문제, 때문에  
> 정말 심각한 문제가 생깁니다.  
> 그게 되게 바닐라 형태로 훈련을 하게 되면.  
>
> 그래서 지금 보면,  
> GAN discriminator라고 빨간색으로 표현되는 경우가 있어요.  
> 근데 GAN discriminator 같은 경우는,  
> 로그 펑션에 물려있는 그 discriminator loss 항을  
> 표현을 하는 거거든요.  
>
> 그래서 어떤 특별한 경우에는,  
> loss가 그냥 0이 되는 vanishing gradient 현상이 나타난다.  
> 그런 거로 표현을 하는 거고,  
> 그래서 이제 GAN 말고,  
> GAN의 어떤 확장 버전들이 있어요.  
>
> GAN을 수학 형식으로,  
> 또 generalized된 폼으로 표현된  
> Wasserstein GAN 같은 거, F-GAN  
> 이런 것들이 나오기 시작하는 거고요.  
>
> 그런 것들이 이제,  
> 어떻게 보면 KL divergence의  
> 되게 general한 형태인  
> Wasserstein distance라는 어떤 매트릭을 통해 가지고,  
> 고려했었던 GAN 모양 같은 것들이 있는데,  
> 그런 것들을 고려하면은,  
> 이제 critic, discriminator function이  
> gradient vanishing이 안 된다.  
>
> 그래서 GAN 같은 경우도,  
> 그런 instability를,  
> instability, 트레이닝에서 instability한  
> 그런 프로퍼티를 컨트롤 하려고,  
> 수학하시는 분들, AI 리서처들이  
> 정말 지대한 노력을 많이 했습니다.  
> 정말 오랫동안.  
>
> 근데 이제 이 이후에  
> Normalizing Flow라는,  
> 지금 생성 모델들, 디퓨전이 오면서,  
> 그 노력을 아무리 해도 안 됐거든요.  
> 그래서 그냥 다 건너갔다고 보시면 될 것 같아요.  
>
> GAN 좀 되게 중요한데,  
> 남아있는 유산들이 많이 있어요.  
> 현재 이제 디퓨전 모델 같은 거 훈련할 때도.  
>
> 그래서 유산 많이 남겼지만,  
> 사실 현대에서, 뭐, 프로덕트 관점,  
> 꼭 연구용도 마찬가지입니ㄷ.  
>
> 근데 프로덕트 관점이 더 심한데,  
> 프로덕트 관점에서는 아예 사용하지 않는,  
> 그런 모델이라고 생각하시면 될 것 같습니다.  
>
> 근데 되게, 한 시대의 패러다임이었었고,  
> 그리고 이제 굉장히 중요한 개념들을  
> 많이 소개를 했었기 때문에,  
> 이제 강의에서 좀 소개를 드리는 바였고,  
> 오늘은, 뭐, 메인 콘텐츠는  
> 좀 여기서 마무리하도록 하고요.  
>
> 일단 질문을 좀 받도록 하겠습니다.  
> 질문 있으실까요?  
>
> (질문)  
>
> 아까 정형화된 데이터 말씀해주신 거,  
> 궁금한 게 요즘 피직스 제너레이티브,  
> 뭐 이런 것도 잘 돼 있는 거 같은데,  
> 걔도 정형화된 데이터인가요?  
>
> (답변)  
>
> 어, 피직스 데이터.  
> 그래서 피직스 데이터를 뭘로 얘기를 할까요?  
>
> 그럼 예를 들어서,  
> 제가 많이 하고 있으니까,  
> 제가 이제 피직스 데이터들을 많이 하거든요.  
>
> 피지컬이 아니라 피직스 데이터를 많이 하는데,  
> 피지컬은 보통 로봇 같은 걸 많이 얘기를 하는 거니까,  
> 피직스 AI, 피지컬 AI가  
> 이제 좀 한 어떤 서브셋이라고 생각합니다.  
>
> 그런데, 예를 들어서  
> 그런 걸 생각해볼 수 있을 것 같아요.  
>
> 진자 운동을 하는 데이터가  
> 있다고 생각해봅시다.  
>
> 스프링에 따라서.  
> 진자 운동은 주기성을 갖고  
> 계속 움직이는 거잖아요. 그죠?  
>
> 근데 그런 것들을  
> 정형화, 정형성이 있다라고  
> 얘기를 할 수가 있습니다.  
> 왜냐면 방정식에 따라 움직이기 때문에.  
>
> 피지컬 AI도 마찬가지예요.  
> 예를 들어서 우리가  
> 드론이라고 생각을 하면,  
> 드론에 센서들이 굉장히 많이 있거든요.  
> 컨트롤하려고.  
>
> 근데 드론이 움직일 수 없는 형태의  
> 센서값들이 있습니다.  
>
> 드론은 명확하게 그 피지컬 스트럭처가  
> 고정이 돼 있잖아요.  
>
> 예를 들어서 쿼드코프트라고 하면  
> 날개가 네 개가 존재를 하고,  
> 걔네들이 어떻게 도느냐에 따라서  
> 그 회전 각도들이 정해지고,  
> 그게 다 물리적 방정식에  
> 대해서 고려가 되는 거 아니겠습니까?  
>
> 그러니까 그런 경우  
> 당연히 학습이 잘 됩니다.  
>
> 그거를 방정식이 보장을 하고 있고,  
> 그 방정식을 넘어선  
> 관측을 할 수가 없기 때문에.  
>
> 그런 데이터와  
> 그렇게 정형화되지 않는,  
> 피지컬로도 고려하고 있지 않는  
> 데이터 같은 경우는,  
> 그럼 당연히 뭐라고 해야 될까요?  
>
> 좀 익스플로레이션을 해야 되는,  
> 서치 스페이스가 커지기 때문에,  
> 당연히 그건 더 잘 안 될 거 같아요.  
>
> 근데 여기서 또,  
> 이제, 조금 더 말씀드리고 싶은 게 있으면,  
> 피직스를 알아야죠.  
>
> 취득한 데이터를  
> 방정식에 역추적하는 건 힘들고,  
>
> 피직스, 그때 제가 수업 시간에  
> 잠깐 말씀드렸었던 거 같은데,  
> 코사인, 사인을 보여주면서,  
> 그 방정식의 coefficient를  
> 러닝하는 게 핵심이겠죠, 그때는.  
>
> 방정식으로 유도된 데이터를  
> 학습한다보단,  
> 그 방정식을,  
> 예를 들어서 우리 진자 운동 같은 거 하면,  
> 뭐, 마찰계수 막 이런 거 있잖아요?  
>
> 그거를 뉴럴 네트워크 학습하게 하면,  
> 더 잘 정형화된 데이터를 뽑아내겠죠.  
>
> 그걸 생성 모델로 만들 수도 있고,  
> 관측을 한 다음에.  
>
> 그런 거는 훨씬 더  
> 정형화됐다고 얘기할 수 있습니다.  
>
> 근데 이게 조금 약간,  
> 로봇 이런, 그런 피지컬 AI에도,  
> 이거를 analogy를  
> 적용해 볼 수 있을 것 같아요.  
>
> 이런 관점으로.  
> 그래서, 대답이 됐을 거라고 생각을 하고,  
> 또 질문 하나 더 받고 마무리하겠습니다.  
>
> (질문)  
>
> 그 Adversarial Attack에서,  
> 혹시 파인튜닝 관점으로  
> 뭔가 그런 데이터들이 생성됐을 때,  
> 좀 해결하는 수도 있나요?  
>
> (답변)  
>
> 어, 일단은,  
> 일단 질문을 조금,  
> 제가 잘 이해 못하는 것 같습니다.  
> 파인튜닝 관점이.  
>
> (질문)  
>
> 예를 들어, 뭐,  
> 그 생성된 이미지에서  
> 속이려고 하는 데이터를 만들었을 때,  
> 그 속이려는 데이터를  
> 추가적으로 그 네트워크에  
> 학습을 시키면은,  
> 우선은 그런 이미지들은  
> 좀 해결이 될 것 같긴 한데,  
> 네, 그런 입장에서  
> 좀 생각을 해보았는데요.  
>
> (답변)  
>
> 네, 일단은 되게 좋습니다.  
>
> 그러니까 Adversarial Attack의  
> 관점으로 또 얘기를 할 수도 있는데,  
>
> Attack을 공부하면  
> 방어가 되거든요.  
>
> 그리고 현실세상에  
> 그런 데이터가 들어올 수도 있잖아요.  
> 공격의 목표가 아니더라도,  
> 내추럴 이미지 안에서도.  
>
> 그래서 그런 관점에서  
> 추가 학습을 통해  
> robustness를 키우겠다는,  
> 그걸 파인튜닝으로 정의하신 거라고  
> 한다면, 그 분야가 명확하게 있습니다.  
>
> 그걸 이제, 파인튜닝이라는 건  
> 되게 현대 LLM스러운 단어인 거고,  
>
> 조금 더 딥러닝의  
> 원본적인 얘기로 하면은,  
> 제가 말하는 data augmentation인 거죠.  
>
> data augmentation을 통한  
> 파인튜닝인데,  
> 그걸 이제 Attack까지 좀 합니다.  
>
> 그렇게 해서 실제로 그런 거 있잖아요.  
> 이미지 같은 거  
> 블러가 껴있고, 안개가 껴있는  
> 그런 데이터들이 있는데,  
>
> 그런 것들을 그런 방식으로  
> 생성을 해가지고  
> 노이즈 만들어서,  
> 그런데 강건하게  
> 움직이게끔 하거든요.  
>
> 그런데 대신에  
> accuracy 좀 희생은 해야 될 거 없고,  
>
> 제한된 파라미터들의  
> 수많은 케이스를 다 학습해야 될까?  
>
> 그런데 그런 문제가 오면은  
> 핸들을 할 수 있기는 있습니다.  
>
> 그런데 아예,  
> 아예 핸들 못하는 것보다는 낫죠.  
> accuracy가 떨어지더라도.  
>
> 그래서 이거는  
> 강의가 무한정 있으면  
> 논문 단위로 설명하고 싶은 마음이 있어요.  
>
> 사실 논문 단위로 봐야 돼요, 원래는.  
> 이 AI라는 거는.  
>
> 그렇게 읽기 어렵지도 않고,  
> 핵심 키워드만 알면  
> 저자들이 뭘 얘기하는지 알고  
> 알 수 있기 때문에.  
>
> 아쉽게도 강의가  
> 그런 형태는 아니기 때문에,  
> 좀 더 소개되는,  
> 그냥 이렇게 말로만 하고,  
>
> 여러분들 한번 읽어보면 좋을 것 같은 것들  
> 논문 싹 정리를 해가지고  
> 한번 LMS에 올려드릴 테니까,  
>
> 한번 읽어보고  
> 현업에 쓸 수 있다,  
> 아니면 생각해볼 만하다,  
> 그런 것도 한번 보시면 좋을 것 같아요.  
>
> 옛날 논문도 있을 것 같습니다.  
> 어떤 이런 학문의 발전상에서  
> 되게 중요한 필라가 됐던 것들,  
> 그런 것들에 대해서  
> 또 공을 들일 수도 있을 것 같아요.  
>
> 그런 것들은 그렇게 하면 좋을 것 같고요.  
> 오늘은 뭐 그러면  
> 여기서 강의 마무리하도록 하겠습니다.  
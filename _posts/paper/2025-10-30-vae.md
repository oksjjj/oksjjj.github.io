---
layout: post
title: "[논문] Auto-Encoding Variational Bayes"
date: 2025-10-30 17:00:00 +0900
categories:
  - "논문"
tags: []
---
> 논문 출처  
> Kingma, D. P., & Welling, M.  
> *Auto-Encoding Variational Bayes.*  
> *arXiv preprint* arXiv:1312.6114 (2013).  
> <a href="https://arxiv.org/abs/1312.6114" target="_blank">🔗 원문 링크 (arXiv: 1312.6114)</a>

저자  
- Diederik P. Kingma (Machine Learning Group, Universiteit van Amsterdam) – dpkingma@gmail.com  
- Max Welling (Machine Learning Group, Universiteit van Amsterdam) – welling.max@gmail.com  

---

## 초록 (Abstract)  

연속적인 잠재 변수(continuous latent variables)를 포함한  
유향 확률적 모델(directed probabilistic models) 에서  
계산 불가능한 사후분포(intractable posterior distributions) 와  
대규모 데이터셋이 존재하는 상황에서  
효율적인 추론(inference)과 학습(learning)을 수행하려면 어떻게 해야 할까?  

본 논문에서는 대규모 데이터셋에 확장 가능하며,  
약한 미분 가능성 조건하에서도(mild differentiability conditions)  
계산 불가능한 경우(intractable case) 에도 동작하는  
확률적 변분 추론(stochastic variational inference)과  
학습 알고리즘을 제안한다.  

우리의 기여는 두 가지로 요약된다.  

첫째, 변분 하한식(variational lower bound)을  
재매개변수화(reparameterization)함으로써  
표준 확률적 경사 하강법(stochastic gradient methods)으로  
간단하게 최적화할 수 있는 하한 추정량(lower bound estimator)을 제시한다.  

둘째, i.i.d. 데이터셋에서 각 데이터 포인트마다  
연속 잠재 변수가 존재할 경우,  
제안된 하한 추정량(lower bound estimator)을 사용하여  
계산 불가능한 사후분포를 근사 추론 모델(approximate inference model,  
또는 recognition model) 에 적합시킴으로써  
사후분포 추론(posterior inference)이 특히 효율적으로 수행될 수 있음을 보인다.  

이론적 이점은 실험 결과를 통해 입증된다.

---

## 1. Introduction

연속적인 잠재 변수(continuous latent variables)나  
모델 파라미터를 가진 유향 확률적 모델(directed probabilistic models) 에서  
계산 불가능한 사후분포(intractable posterior distributions) 가 존재할 때,  
효율적인 근사 추론(approximate inference)과 학습(learning)을  
어떻게 수행할 수 있을까?  

> 대부분의 확률적 그래프 모델에서 사후분포 $p(z \mid x)$ 는  
> 베이즈 정리 $p(z \mid x) = \frac{p(x, z)}{p(x)}$ 로 표현된다.  
> 그러나 여기서 정규화 상수(normalizing constant) 인  
> $p(x) = \int p(x, z)\,dz$ 는  
> 고차원 잠재 변수 $z$ 에 대한 적분(integration) 을 포함하며,  
> 일반적으로 닫힌 형태(closed-form)로 계산할 수 없다.  
> 따라서 이 적분이 계산 불가능(intractable) 하기 때문에  
> 사후분포 $p(z \mid x)$ 역시 직접 계산할 수 없게 된다.

변분 베이즈(Variational Bayesian, VB) 접근법은  
이러한 계산 불가능한(intractable) 사후분포를 근사하는 분포(approximation) 를  
최적화하는 과정을 포함한다.  

그러나 일반적인 평균장(mean-field) 접근법은  
근사 사후분포에 대한 기댓값의 해석적 계산(analytical solution of expectations)을  
필요로 하며, 이는 일반적인 경우 역시 계산 불가능하다(intractable).  

우리는 변분 하한식(variational lower bound)을 재매개변수화(reparameterization) 함으로써,  
간단하면서도 미분 가능한(differentiable) 불편 추정량(unbiased estimator) 을  
얻을 수 있음을 보인다.  

이 추정량은  
SGVB (Stochastic Gradient Variational Bayes) 라고 불리며,  
연속 잠재 변수나 파라미터를 포함하는 거의 모든 모델에서  
효율적인 근사 사후추론(approximate posterior inference)을 수행할 수 있다.  

또한, 표준 확률적 경사 상승법(stochastic gradient ascent techniques)을 이용해  
간단히 최적화할 수 있다.

> 전통적인 평균장 변분추론(mean-field variational inference) 은  
> 근사 사후분포 $q(z)$ 를 단순한 형태(예: 독립 가우시안의 곱)로 가정하고,  
> ELBO  
> $$  
> \mathcal{L}(x) = \mathbb{E}_{q(z)}[\log p(x, z) - \log q(z)]  
> $$  
> 의 기댓값을 해석적으로(analytically) 계산하려고 한다.  
> 즉, 적분을 직접 풀어 닫힌 형태(closed form)로 얻어내야 한다.  
> 하지만 대부분의 실제 모델에서는  
> $p(x, z)$ 가 복잡한 신경망 형태이거나 비선형 구조를 가지므로  
> 이 적분을 정확히 계산할 수 없어 계산 불가능(intractable) 하다.  
>
> 반면 VAE (Variational Autoencoder) 에서는  
> 사후분포를 신경망이 파라미터화한 근사 분포  
> $q_\phi(z \mid x)$ 로 표현하고,  
> 이 분포로부터 샘플을 얻은 뒤  
> 몬테카를로(Monte Carlo) 근사 를 사용해  
> 위 기댓값을 수치적으로 근사한다.  
>
> 즉, VAE에서는  
> - 복잡한 적분을 직접 풀지 않고  
> - 샘플링을 통해 $$\mathbb{E}_{q_\phi(z \mid x)}[\cdot]$$ 를 근사하고  
> - 재매개변수화 트릭(reparameterization trick)으로  
>   이 과정에서 미분이 가능하도록 만들어  
>   확률적 경사 하강법(SGD) 으로 ELBO를 최적화한다.  
>
> 따라서 평균장 접근법은 “기댓값을 직접 계산해야 해서 어렵고(intractable)”  
> VAE는 “기댓값을 샘플링 기반으로 근사해서 tractable하게 만든다”고 요약할 수 있다.

---

독립 동일 분포(i.i.d.) 데이터셋과  
각 데이터 포인트마다 연속적인 잠재 변수(continuous latent variables)가 존재하는 경우,  
우리는 Auto-Encoding Variational Bayes (AEVB) 알고리즘을 제안한다.  

AEVB 알고리즘에서는  
SGVB 추정량(SGVB estimator)을 이용하여  
인식 모델(recognition model)을 최적화함으로써,  
매우 효율적인 근사 사후 추론(approximate posterior inference)을  
단순한 조상 샘플링(ancestral sampling) 을 통해 수행할 수 있다.  

> 조상 샘플링(ancestral sampling) 은  
> 유향 확률적 모델(directed probabilistic model) 에서  
> 그래프의 위상 순서(topological order)에 따라  
> 확률 변수들을 한 단계씩 순차적으로 샘플링하는 방법이다.  
> 예를 들어, 잠재 변수 $z$ 가 먼저 샘플링되고  
> 그 다음에 $x$ 가 $p(x \mid z)$ 로부터 샘플링되는 경우,  
> 전체 데이터 생성 과정은  
> $z \sim p(z)$ → $x \sim p(x \mid z)$ 의 순서로 이루어진다.  
>
> 즉, 부모 변수(parent variable) 로부터  
> 자식 변수(child variable) 를 순차적으로 샘플링하는 구조를  
> “조상(ancestral)”이라는 표현으로 설명한 것이다.  
>  
> VAE에서도 학습된 근사 사후분포 $q_\phi(z \mid x)$ 로부터  
> 샘플을 뽑고, 이를 디코더 $p_\theta(x \mid z)$ 에 통과시키는 과정이  
> 이러한 조상적 샘플링 절차(ancestral sampling process) 에 해당한다.

이 접근은 각 데이터 포인트마다  
고비용의 반복적 추론(iterative inference) 절차(예: MCMC)를 수행하지 않고도  
모델 파라미터를 효율적으로 학습할 수 있게 한다.  

이 접근은 각 데이터 포인트마다  
고비용의 반복적 추론(iterative inference) 절차(예: MCMC)를 수행하지 않고도  
모델 파라미터를 효율적으로 학습할 수 있게 한다.  

> MCMC(Markov Chain Monte Carlo)란?  
> 어떤 확률 분포(예: 사후확률 p(z|x))에서 무작위로 샘플을 뽑고 싶은데,  
> 그 분포의 모양이 너무 복잡해서 직접 샘플링할 수 없을 때 사용하는 방법이다.  
>
> MCMC의 기본 아이디어는 다음과 같다.  
> “복잡한 분포에서 바로 샘플을 뽑는 대신,  
> 확률이 높은 쪽으로 조금씩 이동하면서 분포를 따라가자.”  
>
> 즉, MCMC는 하나의 “현재 위치”에서 시작해서  
> 분포의 모양에 맞게 다음 위치를 하나씩 제안하고,  
> 그 제안을 받아들일지 말지를 결정하면서  
> 점점 분포 전체를 탐색해 나가는 방식으로 동작한다.  
>
> - 처음에는 임의의 위치에서 시작한다.  
> - 분포의 확률이 높은 방향으로 이동할 후보를 만든다.  
> - 후보가 더 가능성 높은 지점이면 이동하고,  
>   그렇지 않아도 일정 확률로는 이동한다.  
> - 이렇게 수천 번, 수만 번 반복하면  
>   방문한 지점들의 분포가 우리가 구하고자 하는 복잡한 확률 분포와 비슷해진다.  
>
> 직관적 비유로 보면:  
> 울퉁불퉁한 산 위를 “확률의 지형”이라고 생각하고,  
> 한 사람이 그 위를 무작위로 걸어 다닌다고 하자.  
> 그 사람은 높은 곳(확률이 높은 영역)에는 자주 머물고,  
> 낮은 곳(확률이 낮은 영역)에는 가끔만 지나간다.  
>  
> 오랫동안 걸어다니면, 그 사람의 발자국이 남은 위치들이  
> 원래 우리가 알고 싶었던 확률 분포의 모양을 자연스럽게 닮게 된다.  
>
> 하지만 이 방법은 비효율적이다.  
> - 한 걸음씩 움직여야 하므로 시간이 오래 걸린다.  
> - 시작 위치가 나쁘면 오랫동안 엉뚱한 영역에 머무를 수 있다.  
> - 산이 여러 봉우리(모드)를 가지면,  
>   다른 봉우리로 건너가기가 매우 어렵다.  
> - 결국 정확한 결과를 얻으려면  
>   수천, 수만 번의 반복이 필요해 계산 비용이 크다.  
>
> VAE는 이 문제를 다르게 해결한다.  
> MCMC처럼 일일이 걸어 다니지 않고,  
> 신경망이 “이 데이터라면 잠재변수 z는 이 근처일 것이다”라고  
> 한 번에 예측하도록 학습한다.  
> 따라서 VAE는 매번 긴 반복을 돌릴 필요 없이  
> 한 번의 순전파로 근사 사후분포를 얻을 수 있어  
> 훨씬 빠르고 효율적으로 동작한다.

또한 학습된 근사 사후 추론 모델은  
인식(recognition), 노이즈 제거(denoising),  
표현 학습(representation learning), 시각화(visualization) 등  
다양한 작업에도 활용될 수 있다.  

마지막으로,  
인식 모델이 신경망(neural network) 으로 구현될 때  
우리는 변분 오토인코더(Variational Auto-Encoder, VAE) 에 도달하게 된다.  

---

## 2. 방법(Method)  

이 절에서 제시하는 전략은  
연속적인 잠재 변수(continuous latent variables)를 갖는  
다양한 유향 그래프 모델(directed graphical models)에 대해  
하한 추정량(lower bound estimator), 즉 확률적 목적 함수(stochastic objective function)를  
유도하는 데 사용할 수 있다.  

여기서는 각 데이터 포인트마다 잠재 변수가 존재하는  
독립 동일 분포(i.i.d.) 데이터셋의 일반적인 경우에 국한한다.  
이 경우 전역 파라미터(global parameters)에 대해서는  
최대우도추정(ML) 또는 최대사후추정(MAP)을 수행하고,  
잠재 변수(latent variables)에 대해서는  
변분 추론(variational inference)을 수행한다.  

> 각 데이터 포인트마다 잠재 변수가 존재한다는 뜻은,  
> 예를 들어 여러 장의 이미지가 있을 때  
> 각 이미지마다 그 이미지를 설명하는 ‘숨겨진 원인’(예: 조명, 각도, 표정 등)이  
> 따로 존재한다는 의미이다.  
>  
> 전역 파라미터(global parameters)는  
> 모든 데이터에 공통으로 적용되는 값으로,  
> 모델이 전반적으로 데이터를 어떻게 생성하는지를 결정한다.  
> 예를 들어 신경망의 가중치나 분포의 평균·분산이 여기에 해당한다.  
>  
> 최대우도추정(ML)이나 최대사후추정(MAP)은  
> 이런 전역 파라미터를 전체 데이터셋을 보고  
> “가장 그럴듯한 값”으로 맞추는 과정이다.  
>  
> 반면 변분 추론(variational inference)은  
> 각 데이터의 잠재 변수를 직접 계산하기 어렵기 때문에,  
> 복잡한 분포 대신 계산이 쉬운 근사 분포로 대신해서  
> 그 값을 추정하는 방법이다.  
>  
> 즉, 전역 파라미터는 전체 데이터를 보고 학습하고,  
> 잠재 변수는 데이터마다 따로 근사해서 계산하는 것이다.

또한 이러한 설정은 전역 파라미터에 대해서도  
변분 추론을 함께 수행하도록 확장하기 쉽다.  
그 알고리즘은 부록(appendix)에 제시되어 있으며,  
그 경우에 대한 실험은 향후 연구로 남겨 두었다.  

본 방법은 온라인(online)이나 비정상(non-stationary) 환경,  
예를 들어 스트리밍 데이터(streaming data)에도 적용할 수 있다.  
그러나 여기서는 단순화를 위해  
고정된 데이터셋(fixed dataset)을 가정한다.

---

### 2.1 문제 시나리오 (Problem scenario)  

데이터셋 $\mathbf{X} = \{\mathbf{x}^{(i)}\}_{i=1}^N$ 가  
$N$개의 연속형 혹은 이산형 변수 $\mathbf{x}$ 의  
i.i.d. 표본들로 구성되어 있다고 가정한다.  
이 데이터는 어떤 무작위 과정(random process)에 의해 생성된다고 가정하며,  
그 과정에는 관찰되지 않는 연속형 잠재 변수 $\mathbf{z}$ 가 포함되어 있다.  

이 생성 과정은 두 단계로 이루어진다.  
(1) 잠재 변수 $$\mathbf{z}^{(i)}$$ 는  
어떤 사전분포(prior distribution) $$p_{\theta^*}(\mathbf{z})$$ 로부터 생성되고,  
(2) 관측 변수 $$\mathbf{x}^{(i)}$$ 는  
조건부 분포(conditional distribution) $$p_{\theta^*}(\mathbf{x} \mid \mathbf{z})$$ 로부터 생성된다.  

사전분포 $$p_{\theta^*}(\mathbf{z})$$ 와  
우도(likelihood) $$p_{\theta^*}(\mathbf{x} \mid \mathbf{z})$$ 가  
모두 매개변수화된(parametric) 확률분포 집합  
$$p_\theta(\mathbf{z})$$ 및 $$p_\theta(\mathbf{x} \mid \mathbf{z})$$ 에 속하며,  
이들의 확률밀도함수(PDF)는  
$$\theta$$ 와 $$\mathbf{z}$$ 에 대해 거의 모든 곳에서 미분 가능하다고 가정한다.  

하지만 실제로는 이 과정의 대부분이 관찰되지 않는다.  
즉, 진짜 파라미터 $$\theta^*$$ 와  
각 데이터 포인트의 잠재 변수 값 $$\mathbf{z}^{(i)}$$ 는  
우리에게 알려져 있지 않다.

---

매우 중요한 점은, 우리는 주변 확률(marginal probabilities)이나  
사후 확률(posterior probabilities)에 대해 흔히 사용하는  
단순화 가정을 하지 않는다는 것이다.  
대신, 우리는 다음과 같은 상황에서도 효율적으로 동작할 수 있는 일반적인 알고리즘에 관심을 둔다.  

1. 계산 불가능성(Intractability)  
   주변 우도(marginal likelihood)  
   $p_\theta(\mathbf{x}) = \int p_\theta(\mathbf{z})p_\theta(\mathbf{x}\mid \mathbf{z})\,d\mathbf{z}$  
   의 적분이 계산 불가능한 경우이다.  
   (즉, 주변 우도를 직접 계산하거나 미분할 수 없다.)  
   이때 사후 확률밀도  
   $p_\theta(\mathbf{z}\mid \mathbf{x}) = p_\theta(\mathbf{x}\mid \mathbf{z})p_\theta(\mathbf{z})/p_\theta(\mathbf{x})$  
   역시 계산 불가능하므로, EM 알고리즘을 사용할 수 없다.  
   또한 합리적인 평균장 변분 베이즈(mean-field VB) 접근에서도  
   필요한 적분들이 대부분 계산 불가능하다.  
   이러한 계산 불가능성은 꽤 일반적으로 나타나며,  
   예를 들어 비선형 은닉층을 포함한 신경망처럼  
   복잡한 우도 함수 $p_\theta(\mathbf{x}\mid \mathbf{z})$ 를 사용할 때 자주 발생한다.  

    > 베이즈 정리에 따르면 사후분포는  
    > $p_\theta(\mathbf{z}\mid \mathbf{x}) = p_\theta(\mathbf{x}\mid \mathbf{z})p_\theta(\mathbf{z})/p_\theta(\mathbf{x})$ 로 표현된다.  
    > 여기서 문제는 분모의 주변우도 $p_\theta(\mathbf{x})$ 이다.  
    >  
    > $p_\theta(\mathbf{x}) = \int p_\theta(\mathbf{x}\mid \mathbf{z})p_\theta(\mathbf{z})\,d\mathbf{z}$ 는  
    > 모든 가능한 $\mathbf{z}$ 에 대해 적분해야 하는데,  
    > $\mathbf{z}$ 가 고차원이거나 $p_\theta(\mathbf{x}\mid \mathbf{z})$ 가 복잡한 비선형 함수일 경우  
    > 이 적분을 닫힌 형태로 계산할 수 없다.  
    >  
    > 따라서 $p_\theta(\mathbf{x})$ 를 정확히 구할 수 없고,  
    > 결과적으로 사후분포 $p_\theta(\mathbf{z}\mid \mathbf{x})$ 도 계산할 수 없게 된다.  
    >  
    > EM 알고리즘(E-step)은 바로 이 사후분포 $p_\theta(\mathbf{z}\mid \mathbf{x})$ 의 기댓값을 계산해야 하는데,  
    > 그것을 구할 수 없으므로 EM 알고리즘을 적용할 수 없게 되는 것이다.

2. 대규모 데이터셋(A large dataset)  
   데이터가 너무 많아서 배치(batch) 단위로 최적화하기에는 계산 비용이 너무 크다.  
   따라서 작은 미니배치(minibatch)나  
   심지어 단일 데이터 포인트만을 사용해서  
   파라미터를 갱신할 수 있어야 한다.  
   예를 들어 Monte Carlo EM 같은 샘플링 기반 방법은  
   각 데이터 포인트마다 비싼 샘플링 루프가 필요하기 때문에  
   일반적으로 매우 느리게 동작한다.

---

우리는 위의 시나리오에서 세 가지 관련된 문제에 관심을 가지며,  
그들에 대한 해결책을 제안한다.  

1. 파라미터 $\theta$ 에 대한 효율적인 근사 최대우도추정(ML) 또는 최대사후추정(MAP).  
   파라미터들은 그 자체로 흥미로운 대상일 수 있다.  
   예를 들어 우리가 어떤 자연적 과정을 분석하고 있다면 그렇다.  
   또한 이들은 숨겨진 확률적 과정을 모방하고  
   실제 데이터와 유사한 인공 데이터를 생성할 수 있게 해준다.  

2. 주어진 관측값 $\mathbf{x}$ 에 대해  
   선택된 파라미터 $\theta$ 에 대한 잠재 변수 $\mathbf{z}$ 의  
   효율적인 근사 사후 추론(efficient approximate posterior inference).  
   이것은 부호화(coding)나 데이터 표현(data representation) 작업에 유용하다.  

3. 변수 $\mathbf{x}$ 에 대한 효율적인 근사 주변 추론(efficient approximate marginal inference).  
   이는 $\mathbf{x}$ 에 대한 사전분포(prior)가 필요한  
   모든 종류의 추론 작업을 수행할 수 있게 해준다.  
   컴퓨터 비전의 일반적인 응용으로는  
   이미지 복원(denoising), 인페인팅(inpainting),  
   그리고 초해상도(super-resolution)가 포함된다.

---

위의 문제들을 해결하기 위한 목적으로,  
우리는 인식 모델(recognition model) $q_\phi(\mathbf{z}\mid\mathbf{x})$ 를 도입한다.  
이는 계산 불가능한 실제 사후분포(intractable true posterior)  
$p_\theta(\mathbf{z}\mid\mathbf{x})$ 에 대한 근사(approximation)이다.  

평균장 변분 추론(mean-field variational inference)의 근사 사후분포와 달리,  
이 분포는 반드시 독립적(factorial)일 필요는 없으며,  
그 파라미터 $\phi$ 또한 어떤 닫힌 형태의 기댓값(closed-form expectation)으로부터  
계산되는 것은 아니다.  

> 평균장(mean-field) 접근법에서는  
> 복잡한 다변량 확률분포 $q(\mathbf{z})$ 를 단순화하기 위해  
> 잠재 변수들 사이의 독립성(independence) 을 가정한다.  
> 즉,  
> $$q(\mathbf{z}) = \prod_i q_i(z_i)$$  
> 와 같이 각 잠재 변수 $z_i$ 가 서로 독립적으로 분포한다고 가정한다.  
>  
> 이렇게 하면 원래는 고차원 공간에서의 복잡한 적분 문제를  
> 각 변수별로 나눠서 계산할 수 있어 수학적으로 훨씬 단순해진다.  
> 그러나 이 독립성 가정 때문에  
> 실제 잠재 변수들 간의 상호 의존 관계(correlation)를 표현할 수 없게 되어  
> 근사 성능이 떨어지는 단점이 있다.  
>  
> 반면, VAE에서는 이런 인위적인 독립성 제약을 두지 않고  
> 신경망이 학습을 통해  
> 잠재 변수들 간의 의존 관계를 자연스럽게 학습하도록 한다.

대신, 우리는 생성 모델의 파라미터 $\theta$ 와 함께  
인식 모델의 파라미터 $\phi$ 를 공동으로 학습(jointly learn) 하는 방법을 제시한다.

---

부호화 이론(coding theory)의 관점에서 보면,  
관측되지 않은 변수 $\mathbf{z}$ 는  
잠재 표현(latent representation) 또는 코드(code) 로 해석될 수 있다.  

따라서 본 논문에서는 인식 모델 $q_\phi(\mathbf{z}\mid\mathbf{x})$ 을  
확률적 인코더(probabilistic encoder)라고 부르기로 한다.  
이는 주어진 데이터 포인트 $\mathbf{x}$ 에 대해  
그 데이터 포인트 $\mathbf{x}$ 가 생성되었을 법한  
코드 $\mathbf{z}$ 의 가능한 값들에 대한 분포(예: 가우시안 분포)를  
생성하기 때문이다.  

비슷한 맥락에서,  
$p_\theta(\mathbf{x}\mid\mathbf{z})$ 는 확률적 디코더(probabilistic decoder) 라고 부른다.  
이는 주어진 코드 $\mathbf{z}$ 로부터  
해당하는 데이터 $\mathbf{x}$ 의 가능한 값들에 대한 분포를  
생성하기 때문이다.  

---

**그림 1:** 본 논문에서 다루는 유향 확률 그래프 모델(directed graphical model) 의 형태를 나타낸다.  
실선(solid line)은 생성 모델 $p_\theta(\mathbf{z})p_\theta(\mathbf{x}\mid\mathbf{z})$ 을,  
점선(dashed line)은 계산 불가능한 사후분포  
$p_\theta(\mathbf{z}\mid\mathbf{x})$ 에 대한 변분 근사  
$q_\phi(\mathbf{z}\mid\mathbf{x})$ 을 나타낸다.  

변분 파라미터 $\phi$ 는 생성 모델의 파라미터 $\theta$ 와 함께  
공동으로 학습된다(jointly learned).

<img src="/assets/img/paper/vae/image_1.png" alt="image" width="360px"> 

---

### 2.2 변분 하한 (The variational bound)  

주변 우도(marginal likelihood)는 각 데이터 포인트의 주변 우도의 합으로 구성된다.  

$$
\log p_\theta(\mathbf{x}^{(1)}, \cdots, \mathbf{x}^{(N)}) 
= \sum_{i=1}^N \log p_\theta(\mathbf{x}^{(i)})
$$  

각 항은 다음과 같이 다시 쓸 수 있다.  

$$
\log p_\theta(\mathbf{x}^{(i)}) 
= D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)}) \Vert p_\theta(\mathbf{z}\mid\mathbf{x}^{(i)})) 
+ \mathcal{L}(\theta, \phi; \mathbf{x}^{(i)}) \tag{1}
$$  

> 위 식은 변분 추론(variational inference) 의 기본적인 분해(분리) 과정을 통해 얻어진다.  
>
> 1. 주변 우도는 다음과 같이 정의된다.  
>
>    $$p_\theta(\mathbf{x}) = \int p_\theta(\mathbf{x}, \mathbf{z})\,d\mathbf{z}$$  
>
>    이는 잠재 변수 $\mathbf{z}$ 를 적분하여 관측 데이터 $\mathbf{x}$ 의 확률을 구한 것이다.  
>  
> 2. 직접 계산이 어려우므로, 계산 가능한 근사 분포 $q_\phi(\mathbf{z}\mid\mathbf{x})$ 를 곱하고 나눈다.  
>
>    $$\log p_\theta(\mathbf{x}) 
>    = \log \int q_\phi(\mathbf{z}\mid\mathbf{x}) 
>    \frac{p_\theta(\mathbf{x}, \mathbf{z})}{q_\phi(\mathbf{z}\mid\mathbf{x})}\,d\mathbf{z}$$  
>
>    이렇게 하면 $q_\phi$ 를 기대값 형태로 활용할 수 있게 된다.  
>  
> 3. $\log p_\theta(\mathbf{x})$ 의 항을 분해하기 위해  
>    KL 발산의 정의를 사용한다.  
>
>    $$D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}) \Vert p_\theta(\mathbf{z}\mid\mathbf{x}))
>    = \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
>    \left[\log \frac{q_\phi(\mathbf{z}\mid\mathbf{x})}{p_\theta(\mathbf{z}\mid\mathbf{x})}\right]$$  
>  
>    베이즈 정리  
>
>    $$p_\theta(\mathbf{z}\mid\mathbf{x}) = \frac{p_\theta(\mathbf{x}, \mathbf{z})}{p_\theta(\mathbf{x})}$$  
>
>    를 대입하면,  
>
>    $$\begin{align*}
>    D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}) \Vert p_\theta(\mathbf{z}\mid\mathbf{x}))
>    &= \mathbb{E}_{q_\phi}
>    \left[\log q_\phi(\mathbf{z}\mid\mathbf{x}) 
>    - \log p_\theta(\mathbf{x}, \mathbf{z}) + \log p_\theta(\mathbf{x})\right] \\
>    &= \mathbb{E}_{q_\phi}
>    [\log q_\phi(\mathbf{z}\mid\mathbf{x}) - \log p_\theta(\mathbf{x}, \mathbf{z})] 
>    + \log p_\theta(\mathbf{x})
>    \end{align*}$$  
>  
> 4. 위 식을 $\log p_\theta(\mathbf{x})$ 에 대해 정리하면,  
>
>    $$\log p_\theta(\mathbf{x}) 
>    = D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}) \Vert p_\theta(\mathbf{z}\mid\mathbf{x}))
>    + \mathbb{E}_{q_\phi}
>    [\log p_\theta(\mathbf{x}, \mathbf{z}) - \log q_\phi(\mathbf{z}\mid\mathbf{x})]$$  
>  
>    두 번째 항을  
>
>    $$\mathcal{L}(\theta, \phi; \mathbf{x}) 
>    = \mathbb{E}_{q_\phi}
>    [\log p_\theta(\mathbf{x}, \mathbf{z}) - \log q_\phi(\mathbf{z}\mid\mathbf{x})]$$  
>
>    로 정의하면,  
>
>    $$\log p_\theta(\mathbf{x}) 
>    = D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}) \Vert p_\theta(\mathbf{z}\mid\mathbf{x})) 
>    + \mathcal{L}(\theta, \phi; \mathbf{x})$$  
>
>    즉, 식 (1)이 도출된다.  

오른쪽 첫 번째 항은 근사 분포와 실제 사후분포 간의 KL 발산(KL divergence) 이다.  

이 KL 발산은 항상 0 이상이므로,  
오른쪽 두 번째 항 $\mathcal{L}(\theta, \phi; \mathbf{x}^{(i)})$ 는  
데이터 포인트 $i$에 대한 주변 우도의 (변분) 하한(variational lower bound) 이 된다.  

즉, 다음이 성립한다.  

$$
\log p_\theta(\mathbf{x}^{(i)}) 
\geq \mathcal{L}(\theta, \phi; \mathbf{x}^{(i)}) 
= \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
[-\log q_\phi(\mathbf{z}\mid\mathbf{x}) + \log p_\theta(\mathbf{x}, \mathbf{z})] \tag{2}
$$  

이 식은 다음과 같이 다시 표현할 수도 있다.  

$$
\mathcal{L}(\theta, \phi; \mathbf{x}^{(i)}) 
= -D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)}) \Vert p_\theta(\mathbf{z})) 
+ \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
[\log p_\theta(\mathbf{x}^{(i)}\mid\mathbf{z})] \tag{3}
$$  

> 식 (2)에서 식 (3)으로 바꿔 쓸 수 있는 이유는  
> 결합 확률의 분해  
> $p_\theta(\mathbf{x}, \mathbf{z}) = p_\theta(\mathbf{z})\,p_\theta(\mathbf{x}\mid\mathbf{z})$  
> 를 대입했기 때문이다.  
>  
> 이 항을 ELBO의 정의에 대입하면 다음과 같이 된다.  
>
> $$
> \begin{align*}
> \mathcal{L}(\theta, \phi; \mathbf{x}) 
> &= \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
> [\log p_\theta(\mathbf{x}, \mathbf{z}) - \log q_\phi(\mathbf{z}\mid\mathbf{x})] \\
> &= \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
> [\log p_\theta(\mathbf{z}) + \log p_\theta(\mathbf{x}\mid\mathbf{z}) - \log q_\phi(\mathbf{z}\mid\mathbf{x})]
> \end{align*}
> $$  
>  
> 이 식을 두 개의 기대값으로 분리하면,  
>
> $$
> \mathcal{L}(\theta, \phi; \mathbf{x})
> = \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
> [\log p_\theta(\mathbf{x}\mid\mathbf{z})]
> + \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
> [\log p_\theta(\mathbf{z}) - \log q_\phi(\mathbf{z}\mid\mathbf{x})]
> $$  
>  
> 두 번째 기대값 항은 바로  
> $-D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}) \Vert p_\theta(\mathbf{z}))$  
> 와 동일하므로,  
>
> $$
> \mathcal{L}(\theta, \phi; \mathbf{x})
> = -D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}) \Vert p_\theta(\mathbf{z}))
> + \mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}
> [\log p_\theta(\mathbf{x}\mid\mathbf{z})]
> $$  
>
> 를 얻는다.  

우리는 변분 파라미터 $\phi$ 와 생성 파라미터 $\theta$ 에 대해  
하한식 $\mathcal{L}(\theta, \phi; \mathbf{x}^{(i)})$ 를 미분하고 최적화하고자 한다.  

그러나 하한식의 $\phi$ 에 대한 그래디언트는 다소 문제가 있다.  
일반적인 (단순한, naïve) 몬테카를로 그래디언트 추정식은 다음과 같다.  

$$
\nabla_\phi \mathbb{E}_{q_\phi(\mathbf{z})}[f(\mathbf{z})]
= \mathbb{E}_{q_\phi(\mathbf{z})}[f(\mathbf{z}) \nabla_{q_\phi(\mathbf{z})} \log q_\phi(\mathbf{z})]
\simeq \frac{1}{L} \sum_{l=1}^L f(\mathbf{z}^{(l)}) \nabla_\phi \log q_\phi(\mathbf{z}^{(l)})
$$  

여기서 $\mathbf{z}^{(l)} \sim q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)})$ 이다.  

하지만 이러한 그래디언트 추정량은  
분산(variance) 이 매우 크기 때문에 (참고: [BJP12])  
실제 계산에서는 비효율적이며 본 연구의 목적에는 적합하지 않다.

> 이 식은 기대값 안에 파라미터 $\phi$ 가 포함되어 있을 때,  
> 그 기대값을 미분하는 과정을 보여주는 것이다.  
>  
> 먼저 기본 항등식은 다음과 같다.  
>
> $$
> \nabla_\phi \log q_\phi(\mathbf{z}) = \frac{\nabla_\phi q_\phi(\mathbf{z})}{q_\phi(\mathbf{z})}
> $$  
>
> 이는 고등학교 수준의 로그 미분 공식  
>
> $$
> (\log f(x))' = \frac{f'(x)}{f(x)}
> $$  
>
> 을 그대로 확률밀도 함수에 적용한 것이다.  
>  
> 양변에 $q_\phi(\mathbf{z})$ 를 곱하면,  
>
> $$
> \nabla_\phi q_\phi(\mathbf{z}) = q_\phi(\mathbf{z}) \nabla_\phi \log q_\phi(\mathbf{z})
> $$  
>
> 이 식은 항상 성립하는 로그 미분 항등식이다.  
>
> 이 항등식을 기대값의 미분에 적용하면,  
>
> $$
> \mathbb{E}_{q_\phi}[f(\mathbf{z})] = \int f(\mathbf{z}) q_\phi(\mathbf{z})\, d\mathbf{z}
> $$  
>
> 와 같이 표현할 수 있으므로,  
> 양변을 $\phi$ 로 미분하면  
>
> $$
> \nabla_\phi \mathbb{E}_{q_\phi}[f(\mathbf{z})]
> = \int f(\mathbf{z}) \nabla_\phi q_\phi(\mathbf{z})\, d\mathbf{z}
> $$  
>
> 가 된다.  
> 여기에 앞서의 항등식을 대입하면,  
>
> $$
> \nabla_\phi \mathbb{E}_{q_\phi}[f(\mathbf{z})]
> = \int f(\mathbf{z}) q_\phi(\mathbf{z}) \nabla_\phi \log q_\phi(\mathbf{z})\, d\mathbf{z}
> $$  
>
> 적분 형태를 다시 기대값 형태로 쓰면,  
>
> $$
> \nabla_\phi \mathbb{E}_{q_\phi}[f(\mathbf{z})]
> = \mathbb{E}_{q_\phi}[f(\mathbf{z}) \nabla_\phi \log q_\phi(\mathbf{z})]
> $$  
>
> 이 된다.  
>
> 실제 계산에서는 이 적분을 직접 구하기 어렵기 때문에,  
> 분포 $q_\phi(\mathbf{z})$ 에서 샘플을 여러 개 뽑아 평균으로 근사한다.  
>  
> 예를 들어,  
>
> $$
> \mathbb{E}_{q_\phi}[f(\mathbf{z}) \nabla_\phi \log q_\phi(\mathbf{z})]
> \approx \frac{1}{L} \sum_{l=1}^L f(\mathbf{z}^{(l)}) \nabla_\phi \log q_\phi(\mathbf{z}^{(l)}),
> \quad \mathbf{z}^{(l)} \sim q_\phi
> $$  
>
> 이렇게 적분 대신 분포에서 표본을 뽑아 평균을 내는 방법을  
> 몬테카를로 근사(Monte Carlo approximation) 라고 한다.  
> 즉, 적분을 직접 계산하지 않고  
> 무작위 샘플링을 통해 기대값을 근사하는 방식이다.  
>
> 하지만 이 방법의 문제는 분산(variance) 이 크다는 것이다.  
>  
> 샘플마다 $f(\mathbf{z})$ 의 값이 들쭉날쭉하고,  
> $\nabla_\phi \log q_\phi(\mathbf{z})$ 의 크기와 방향도 불안정하다면,  
> 그 곱의 평균이 쉽게 요동친다.  
>  
> 예를 들어, 일부 샘플에서는 $f(\mathbf{z})$ 가 매우 크고  
> 다른 샘플에서는 거의 0이라면  
> 평균을 내도 결과가 크게 변동한다.  
>  
> 이렇게 되면 학습 시 그래디언트가 불안정해지고,  
> 학습 속도가 느려지며 최적화가 어렵게 된다.  

---

### 2.3 SGVB 추정량과 AEVB 알고리즘  

이 절에서 우리는 하한식(lower bound)의 실용적인 추정량(practical estimator)과  
그 파라미터들에 대한 미분(derivatives)을 소개한다.

우리는 $q_\phi(\mathbf{z}\mid\mathbf{x})$ 형태의  
근사 사후분포(approximate posterior)를 가정한다.  
그러나 이 기법은 $\mathbf{x}$ 에 조건화하지 않는,  
즉 $q_\phi(\mathbf{z})$ 인 경우에도 적용될 수 있음을 주의하라.  

파라미터들에 대한 사후분포를 추론하기 위한  
완전한 변분 베이즈 방법(fully variational Bayesian method)은  
부록(appendix)에 제시되어 있다.

---

특정한 완만한 조건들(under certain mild conditions) 하에서,  
선택된 근사 사후분포 $q_\phi(\mathbf{z}\mid\mathbf{x})$ 에 대해  
우리는 보조 잡음 변수(auxiliary noise variable) $\boldsymbol{\epsilon}$ 의  
미분 가능한 변환 $g_\phi(\boldsymbol{\epsilon}, \mathbf{x})$ 을 이용하여  
랜덤 변수 $\tilde{\mathbf{z}} \sim q_\phi(\mathbf{z}\mid\mathbf{x})$ 를  
다시 매개변수화(reparameterize)할 수 있다.  

$$
\tilde{\mathbf{z}} = g_\phi(\boldsymbol{\epsilon}, \mathbf{x}) 
\quad \text{where} \quad \boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon}) \tag{4}
$$  

> “특정한 완만한 조건들(under certain mild conditions)” 이란,  
> 함수 $g_\phi(\boldsymbol{\epsilon}, \mathbf{x})$ 가  
> 연속적이고 미분 가능한(smooth and differentiable) 형태를 가지며,  
> $\boldsymbol{\epsilon}$ 이 따르는 분포 $p(\boldsymbol{\epsilon})$ 가  
> 충분히 단순하고 샘플링 가능한 경우를 의미한다.  
>  
> 예를 들어, $\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)$ 와 같이  
> 정규분포를 사용하는 것이 일반적이다.  
> 이러한 조건이 충족되어야  
> $\tilde{\mathbf{z}} = g_\phi(\boldsymbol{\epsilon}, \mathbf{x})$ 의  
> 미분 가능성이 보장되어,  
> 역전파를 통해 $\phi$ 에 대한 그래디언트를 계산할 수 있다.  
>  
> 즉, 확률적 샘플링 과정을  
> 미분 가능한 결정적 함수 형태로 변환(reparameterize) 함으로써  
> 학습 과정에서 안정적이고 효율적인 그래디언트 추정이 가능해진다.

적절한 분포 $p(\boldsymbol{\epsilon})$ 과 함수 $g_\phi(\boldsymbol{\epsilon}, \mathbf{x})$ 를 선택하는  
일반적인 전략에 대해서는 2.4절을 참조하라.  

이제 우리는 함수 $f(\mathbf{z})$ 의 기댓값(expectation)을  
$q_\phi(\mathbf{z}\mid\mathbf{x})$ 에 대해 몬테카를로 추정(Monte Carlo estimation)으로 근사할 수 있다.  

$$
\mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)})}[f(\mathbf{z})] 
= \mathbb{E}_{p(\boldsymbol{\epsilon})}\!\left[f(g_\phi(\boldsymbol{\epsilon}, \mathbf{x}^{(i)}))\right] 
\simeq \frac{1}{L}\sum_{l=1}^L f(g_\phi(\boldsymbol{\epsilon}^{(l)}, \mathbf{x}^{(i)})), 
\quad \text{where} \quad \boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon}) \tag{5}
$$  

우리는 이 기법을 변분 하한식(식 (2))에 적용하여,  
일반적인 확률적 그래디언트 변분 베이즈(SGVB) 추정량  
$\tilde{\mathcal{L}}^{A}(\theta,\phi;\mathbf{x}^{(i)}) \simeq \mathcal{L}(\theta,\phi;\mathbf{x}^{(i)})$ 를 얻는다.

$$
\tilde{\mathcal{L}}^{A}(\theta,\phi;\mathbf{x}^{(i)}) 
= \frac{1}{L}\sum_{l=1}^{L}
\left[\log p_\theta(\mathbf{x}^{(i)}, \mathbf{z}^{(i,l)}) 
- \log q_\phi(\mathbf{z}^{(i,l)}\mid \mathbf{x}^{(i)})\right]
\tag{6}
$$

여기서 $\mathbf{z}^{(i,l)} = g_\phi(\boldsymbol{\epsilon}^{(l)}, \mathbf{x}^{(i)})$ 이고,  
$\boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon})$ 이다.

> $\tilde{\mathcal{L}}^{A}$ 는 재매개변수화로 얻은 샘플들을 사용해  
> ELBO(식 (2))의 기댓값을 몬테카를로 평균으로 근사한 추정치이다.  
> 이 추정치는 샘플 수 $L$ 개를 사용한 불편향(unbiased) SGVB 추정값이며,  
> $L$ 을 늘릴수록 분산이 줄어들어  
> 보다 안정적인 그래디언트 추정을 가능하게 한다.

---

종종 식 (3)의 KL 발산  
$D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)}) \Vert p_\theta(\mathbf{z}))$ 은  
분석적으로 적분(integrated analytically)될 수 있다(부록 B 참조).  
따라서 기대 재구성 오차(expected reconstruction error)  
$$\mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)})}
[\log p_\theta(\mathbf{x}^{(i)}\mid\mathbf{z})]$$ 만이  
샘플링을 통해 추정될 필요가 있다.  

이때 KL 발산 항은  
근사 사후분포 $q_\phi(\mathbf{z}\mid\mathbf{x})$ 가  
사전분포 $p_\theta(\mathbf{z})$ 와 가깝도록 유도하는  
정규화(regularization) 항으로 해석될 수 있다.  

이로써 식 (3)에 대응하는,  
두 번째 형태의 SGVB 추정량  

$$
\tilde{\mathcal{L}}^{B}(\theta, \phi; \mathbf{x}^{(i)}) 
\simeq \mathcal{L}(\theta, \phi; \mathbf{x}^{(i)})
$$  

을 얻으며,  
이는 일반적인 추정량보다  
보통 더 작은 분산을 갖는다.  

$$
\tilde{\mathcal{L}}^{B}(\theta, \phi; \mathbf{x}^{(i)}) 
= -D_{KL}(q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)}) \Vert p_\theta(\mathbf{z}))
+ \frac{1}{L}\sum_{l=1}^{L}
\log p_\theta(\mathbf{x}^{(i)} \mid \mathbf{z}^{(i,l)})
\tag{7}
$$

여기서  
$\mathbf{z}^{(i,l)} = g_\phi(\boldsymbol{\epsilon}^{(l)}, \mathbf{x}^{(i)})$,  
$\boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon})$ 이다.

$N$개의 데이터 포인트를 가진 데이터셋 $\mathbf{X}$ 로부터  
여러 개의 데이터 포인트가 주어질 때,  
우리는 미니배치(minibatch)에 기반하여  
전체 데이터셋의 주변 우도 하한(marginal likelihood lower bound)의  
추정량(estimator)을 구성할 수 있다.

$$
\mathcal{L}(\theta, \phi; \mathbf{X}) 
\simeq \tilde{\mathcal{L}}^{M}(\theta, \phi; \mathbf{X}^{M})
= \frac{N}{M} \sum_{i=1}^{M} 
\tilde{\mathcal{L}}(\theta, \phi; \mathbf{x}^{(i)}) \tag{8}
$$

> 식에서 $\frac{N}{M}$ 이 곱해지는 이유는,  
> 전체 데이터셋의 하한값 $\mathcal{L}(\theta, \phi; \mathbf{X})$ 를  
> 전체 $N$개의 데이터포인트에 대한 합으로 근사해야 하기 때문이다.  
>  
> 하지만 실제 학습에서는 모든 데이터($N$개)를 한 번에 쓰기 어렵기 때문에,  
> 대신 그중 $M$개만 임의로 뽑은 미니배치(minibatch) 로 계산한다.  
>  
> 이때 미니배치의 합 $\sum_{i=1}^{M}\tilde{\mathcal{L}}(\theta, \phi; \mathbf{x}^{(i)})$ 은  
> 전체 데이터셋의 일부($M/N$)에 해당하므로,  
> 이를 전체 데이터에 맞게 스케일링하려면  
> $\frac{N}{M}$ 배를 곱해줘야 한다.  
>  
> 즉, $\frac{N}{M}$ 은  
> “미니배치 평균을 전체 데이터셋 수준의 추정값으로 확장하는 비율”이며,  
> 이렇게 하면 전체 데이터셋을 사용했을 때와  
> 동일한 기댓값(expectation)을 가지게 된다.

여기서 미니배치 $\mathbf{X}^{M} = \{\mathbf{x}^{(i)}\}_{i=1}^{M}$ 는  
$N$ 개의 데이터 포인트를 가진 전체 데이터셋 $\mathbf{X}$ 로부터  
임의로 추출된 $M$ 개의 데이터 포인트 샘플이다.

실험에서는 데이터 포인트당 샘플 수 $L$ 을 1로 설정해도,  
미니배치 크기 $M$ 이 충분히 클 경우(예: $M = 100$)  
좋은 성능을 보였다.  

$\nabla_{\theta,\phi}\tilde{\mathcal{L}}(\theta; \mathbf{X}^{M})$ 의  
도함수를 계산하여 얻은 그래디언트는  
SGD나 Adagrad [DHS10] 같은 확률적 최적화 방법과 함께 사용될 수 있다.  
확률적 그래디언트를 계산하는 기본적인 접근법은 알고리즘 1에 제시되어 있다.

---

**알고리즘 1**  
*Auto-Encoding VB (AEVB) 알고리즘의 미니배치(minibatch) 버전*  

섹션 2.3에서 제시된 두 가지 SGVB 추정기 중 어느 것이든 사용할 수 있다.  
실험에서는 $M = 100$, $L = 1$ 설정을 사용한다.  

---

$\theta, \phi \; \leftarrow$ 파라미터 초기화  

**반복 (repeat)**  
 $\mathbf{X}^{M} \; \leftarrow$ 전체 데이터셋에서 무작위로 선택된 $M$ 개의 데이터포인트  
 $\boldsymbol{\epsilon} \; \leftarrow$ 잡음 분포 $p(\boldsymbol{\epsilon})$ 로부터 무작위 샘플링  
 $\mathbf{g} \; \leftarrow \; \nabla_{\theta, \phi} \tilde{\mathcal{L}}^{M}(\theta, \phi; \mathbf{X}^{M}, \boldsymbol{\epsilon})$  
      (식 (8)의 미니배치 추정기(minibatch estimator)의 그래디언트 계산)  
 $\theta, \phi \; \leftarrow$ 그래디언트 $\mathbf{g}$ 를 사용하여 파라미터 갱신  
      (예: SGD 또는 Adagrad [DHS10])  

**until** 파라미터 $(\theta, \phi)$ 가 수렴할 때까지  

**return** $\theta, \phi$

---

오토인코더(auto-encoder)와의 연관성은  
식 (7)에 주어진 목적함수를 살펴볼 때 명확해진다.  

첫 번째 항은  
“근사 사후분포 $q_\phi(\mathbf{z}\mid\mathbf{x})$ 와  
사전분포 $p_\theta(\mathbf{z})$ 사이의 KL 발산(KL divergence)”으로,  
정규화항(regularizer) 역할을 한다.  

두 번째 항은  
기대값 형태의 음의 재구성 오차(expected negative reconstruction error)이다.  

> ELBO는 최대화해야 하는 값이지만,  
> 실제 학습에서는 손실(loss)을 최소화하도록 구현하기 때문에  
> 부호를 반전시켜 $-\mathcal{L}$ 형태로 사용한다.  
>  
> 따라서 $$\mathbb{E}_{q_\phi(\mathbf{z}\mid\mathbf{x})}[\log p_\theta(\mathbf{x}\mid\mathbf{z})]$$ 항은  
> 원래는 커질수록 좋은 값(재구성 확률이 높을수록 좋음)이지만,  
> 손실함수로 쓸 때는 부호가 바뀌어  
> 음의 로그 우도(negative log-likelihood) 로 표현된다.  
>  
> 이런 이유로 이 항을 “음의 재구성 오차(negative reconstruction error)”라고 부른다.  
> 즉, 재구성 확률이 높을수록 오차는 작아지는 형태가 된다.

함수 $g_\phi(\cdot)$ 는  
데이터 포인트 $\mathbf{x}^{(i)}$ 와  
무작위 잡음 벡터 $\boldsymbol{\epsilon}^{(l)}$ 를  
해당 데이터 포인트의 근사 사후분포로부터의 샘플에 매핑하도록 선택된다:  

$$
\mathbf{z}^{(i,l)} = g_\phi(\boldsymbol{\epsilon}^{(l)}, \mathbf{x}^{(i)}),
\quad \text{where} \quad \mathbf{z}^{(i,l)} \sim q_\phi(\mathbf{z}\mid\mathbf{x}^{(i)}).
$$

그 다음, 샘플 $\mathbf{z}^{(i,l)}$ 은  
함수 $\log p_\theta(\mathbf{x}^{(i)} \mid \mathbf{z}^{(i,l)})$ 의 입력으로 사용되며,  
이것은 생성 모델 하에서  
$\mathbf{z}^{(i,l)}$ 가 주어졌을 때  
데이터 포인트 $\mathbf{x}^{(i)}$ 의 확률밀도(probability density 또는 mass)에 해당한다.  

이 항은 오토인코더 용어로는  
음의 재구성 오차(negative reconstruction error)이다.

---

### 2.4 재매개변수화 트릭(The reparameterization trick)

우리의 문제를 해결하기 위해  
$q_\phi(\mathbf{z}\mid\mathbf{x})$ 로부터 샘플을 생성하기 위한  
대체 방법(alternative method)을 도입하였다.  

이 핵심적인 매개변수화 트릭(parameterization trick)은 매우 단순하다.  
$\mathbf{z}$ 를 연속 확률변수(continuous random variable)라 하고,  
$\mathbf{z} \sim q_\phi(\mathbf{z}\mid\mathbf{x})$ 가 어떤 조건부 분포라고 하자.  

그러면 확률변수 $\mathbf{z}$ 를  
결정론적 변수(deterministic variable)  
$\mathbf{z} = g_\phi(\boldsymbol{\epsilon}, \mathbf{x})$ 로 표현할 수 있는 경우가 자주 있다.  

여기서 $\boldsymbol{\epsilon}$ 은  
독립된 주변분포(independent marginal) $p(\boldsymbol{\epsilon})$ 를 가지는  
보조 변수(auxiliary variable)이며,  
$g_\phi(\cdot)$ 는 파라미터 $\phi$ 로 매개변수화된  
벡터값 함수(vector-valued function)이다.

---
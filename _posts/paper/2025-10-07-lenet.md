---
layout: post
title: "[논문] Gradient-Based Learning Applied to Document Recognition"
date: 2025-10-07 16:00:00 +0900
categories:
  - "논문"
tags: []
---

> 논문 출처  
> LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P.  
> *Gradient-Based Learning Applied to Document Recognition.*  
> *Proceedings of the IEEE*, 86(11), 2278–2324 (1998).  
> <a href="https://doi.org/10.1109/5.726791" target="_blank">🔗 원문 링크 (DOI: 10.1109/5.726791)</a>

저자  
- Yann LeCun (AT&T Labs–Research, Holmdel, NJ, USA) – yann@cs.nyu.edu  
- Léon Bottou (AT&T Labs–Research, Holmdel, NJ, USA) – leonb@research.att.com  
- Yoshua Bengio (Université de Montréal, Canada) – yoshua.bengio@umontreal.ca  
- Patrick Haffner (AT&T Labs–Research, Holmdel, NJ, USA) – haffner@research.att.com

---

>저자들은 모두 AT&T 연구소(AT&T Labs-Research) 내  
>음성 및 영상 처리 연구소(Speech and Image Processing Services Research Laboratory) 에 소속되어 있다.  
>주소는 다음과 같다.  
>
>AT&T Labs-Research  
>100 Schulz Drive, Red Bank, NJ 07701, USA  
>E-mail: {yann, leonb, yoshua, haffner}@research.att.com  
>
>또한 Yoshua Bengio 교수는  
>몬트리올 대학교(Université de Montréal)  
>정보학 및 운영연구학과(Département d’Informatique et de Recherche Opérationelle) 에도 소속되어 있다.  
>
>주소:  
>C.P. 6128 Succ. Centre-Ville,  
>2920 Chemin de la Tour,  
>Montréal, Québec, Canada H3C 3J7

---

## 초록 (Abstract)  

역전파 알고리즘으로 학습된 다층 신경망(Multilayer Neural Networks)은  
성공적인 그래디언트 기반 학습(Gradient-Based Learning) 기법의  
가장 대표적인 예를 이룬다.  

적절한 네트워크 구조가 주어졌을 때,  
그래디언트 기반 학습 알고리즘은 복잡한 결정 경계(complex decision surface)를  
구성할 수 있으며,  
이를 통해 손으로 쓴 문자(handwritten characters) 와 같은  
고차원 패턴을 최소한의 전처리로 분류할 수 있다.  

이 논문은 필기 문자 인식(handwritten character recognition)에 적용된  
여러 기존 방법들을 검토하고,  
이를 표준 필기 숫자 인식(handwritten digit recognition) 과제에서  
서로 비교한다.  

특히, 2차원 형태의 변동성(variability of 2D shapes) 에  
대처하도록 특별히 설계된 합성곱 신경망(Convolutional Neural Networks) 은  
다른 모든 기법을 능가하는 성능을 보인다.  

실제 문서 인식(document recognition) 시스템은  
필드 추출(field extraction), 분할(segmentation), 인식(recognition),  
언어 모델링(language modeling) 등  
여러 모듈들로 구성되어 있다.  

본 논문에서는 그래프 변환기 네트워크(Graph Transformer Networks, GTN) 라는  
새로운 학습 패러다임을 제안한다.  

이 접근법은 여러 모듈로 구성된 시스템이  
그래디언트 기반 방법(Gradient-Based methods) 을 통해  
전역적으로(global) 학습되도록 하여,  
전체 성능 척도(overall performance measure)를 최소화하도록 설계된다.  

이 논문에서는 온라인 필기 인식(on-line handwriting recognition) 을 위한  
두 가지 시스템을 설명한다.  

실험 결과는 전역 학습(global training) 의 장점과  
그래프 변환기 네트워크(Graph Transformer Networks) 의 유연성을 보여준다.  

또한, 은행 수표(bank check) 판독용 그래프 변환기 네트워크 도 제안한다.  

이 시스템은 합성곱 신경망(CNN) 기반의 문자 인식기(character recognizer)와  
전역 학습 기법(global training techniques)을 결합하여  
업무용 및 개인용 수표에 대해  
기록적인 인식 정확도를 달성한다.  

이 시스템은 상용화되어 있으며,  
하루에 수백만 건의 수표를 처리한다.  

---

키워드(Keywords) —  
Neural Networks, OCR, Document Recognition,  
Machine Learning, Gradient-Based Learning,  
Convolutional Neural Networks, Graph Transformer Networks,  
Finite State Transducers.

## 용어 정리 (Nomenclature)  

- GT — 그래프 변환기 (Graph Transformer)  
- GTN — 그래프 변환기 네트워크 (Graph Transformer Network)  
- HMM — 은닉 마르코프 모델 (Hidden Markov Model)  
- HOS — 휴리스틱 과분할 (Heuristic Oversegmentation)  
- K-NN — K-최근접 이웃 (K-Nearest Neighbor)  
- NN — 신경망 (Neural Network)  
- OCR — 광학 문자 인식 (Optical Character Recognition)  
- PCA — 주성분 분석 (Principal Component Analysis)  
- RBF — 방사형 기저 함수 (Radial Basis Function)  
- RS-SVM — 축소 집합 서포트 벡터 방법 (Reduced-Set Support Vector Method)  
- SDNN — 공간 변위 신경망 (Space Displacement Neural Network)  
- SVM — 서포트 벡터 방법 (Support Vector Method)  
- TDNN — 시간 지연 신경망 (Time Delay Neural Network)  
- V-SVM — 가상 서포트 벡터 방법 (Virtual Support Vector Method)

## 1. 서론 (Introduction)  

지난 몇 년 동안, 특히 신경망(Neural Networks) 에 적용된  
머신러닝(Machine Learning) 기법은  
패턴 인식 시스템(pattern recognition systems) 설계에서  
점점 더 중요한 역할을 담당하게 되었다.  

실제로, 학습 기법의 발전은  
최근 연속 음성 인식(continuous speech recognition) 및  
필기 인식(handwriting recognition) 과 같은  
패턴 인식 응용 분야의 성공에  
결정적인 요인으로 작용했다고 볼 수 있다.  

이 논문의 핵심 메시지는 다음과 같다.  

보다 우수한 패턴 인식 시스템은  
수작업으로 설계된 휴리스틱(heuristics)에 덜 의존하고,  
자동 학습(automatic learning)에 더 많이 의존함으로써 구축될 수 있다.  

이러한 접근이 가능해진 이유는  
최근의 머신러닝 및 컴퓨터 기술의 발전 덕분이다.  

문자 인식(character recognition)을 사례로 하여,  
본 논문은 수작업으로 설계된 특징 추출(feature extraction)을 대신해,  
픽셀 이미지(pixel images)에서 직접 작동하는  
정교하게 설계된 학습 머신(learning machines)으로  
대체할 수 있음을 보인다.  

또한, 문서 이해(document understanding)를 사례로 하여,  
전통적으로 개별적으로 설계된 모듈들을  
수동으로 통합하던 인식 시스템 구축 방식을  
하나의 통합적이고 원리 기반의 설계 패러다임으로  
대체할 수 있음을 보인다.  

그 패러다임이 바로  
그래프 변환기 네트워크(Graph Transformer Networks) 이며,  
이는 모든 모듈들을  
전역적인(global) 성능 기준을 최적화하도록  
동시에 학습시킬 수 있게 한다.

패턴 인식의 초창기 시절부터,  
자연 데이터(natural data)의 다양성과 풍부함—  
즉 음성(speech), 문자 기호(glyphs), 혹은 다른 형태의 패턴들—으로 인해  
정확한 인식 시스템을 완전히 수작업으로 구축하는 것이  
거의 불가능하다는 사실이 알려져 왔다.  

그 결과, 대부분의 패턴 인식 시스템은  
자동 학습 기법(automatic learning techniques)과  
수작업으로 제작된 알고리즘(hand-crafted algorithms)의  
결합으로 구성된다.  

일반적인 개별 패턴 인식 방법은  
시스템을 두 개의 주요 모듈로 나누는 것으로 이루어진다  
(그림 1 참조).  

---

**그림 1.**

전통적인 패턴 인식은 두 개의 모듈로 수행된다:  
고정된 특징 추출기(fixed feature extractor)와  
학습 가능한 분류기(trainable classifier).

<img src="/assets/img/paper/lenet/image_1.png" alt="image" width="450px"> 

---

첫 번째 모듈은 특징 추출기(feature extractor) 로 불리며,  
입력 패턴을 변환하여  
저차원 벡터나 짧은 기호 문자열로 표현할 수 있도록 한다.  

이때 다음 두 가지 성질을 만족해야 한다.  

(a) 쉽게 비교하거나 매칭될 수 있어야 하고,  
(b) 입력 패턴의 본질을 바꾸지 않는 변환이나 왜곡에 대해  
상대적으로 불변(invariant)이어야 한다.  

특징 추출기(feature extractor)는  
대부분의 사전 지식(prior knowledge)을 담고 있으며  
대개 특정 작업(task)에 특화되어 있다.  
또한 설계 노력의 대부분이 여기에 집중되며,  
이는 보통 전적으로 수작업으로 만들어지기 때문이다.  

반면 분류기(classifier)는  
일반 목적(general-purpose)이며 학습 가능(trainable)한 경우가 많다.  

이 접근법의 주요 문제 중 하나는  
인식 정확도(recognition accuracy)가  
설계자가 적절한 특징(feature) 집합을  
얼마나 잘 찾아내는가에 의해  
크게 좌우된다는 점이다.  

이것은 매우 어려운 과제이며,  
불행히도 새로운 문제마다 다시 수행되어야 한다.  

패턴 인식 연구의 상당 부분은  
특정 작업(task)에 대해  
서로 다른 특징 집합(feature sets)의  
상대적 장점(merits)을 기술하고 비교하는 데  
할애되어 있다.

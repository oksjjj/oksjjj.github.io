---
layout: post
title: "[논문] R-CNN : Rich feature hierarchies for accurate object detection and semantic segmentation
Tech report (v5)"
date: 2026-01-02 13:00:00 +0900
categories:
  - "논문"
tags: []
---
> 논문 출처  
> Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik.  
> Rich feature hierarchies for accurate object detection and semantic segmentation.  
> UC Berkeley.  
> {rbg, jdonahue, trevor, malik}@eecs.berkeley.edu
> <a href="https://arxiv.org/abs/1311.2524" target="_blank">🔗 원문 링크 (arXiv: 1311.2524)</a>

저자  
- Ross Girshick  
- Jeff Donahue  
- Trevor Darrell  
- Jitendra Malik  

(UC Berkeley)

---

## 초록 (Abstract)

정형적인 PASCAL VOC 데이터셋에서 측정된 객체 검출 성능은  
지난 몇 년 동안 정체 상태에 머물러 왔다.  

> PASCAL VOC 데이터셋은  
> 객체 인식(object recognition)과 객체 검출(object detection) 연구를 위해  
> 널리 사용된 대표적인 컴퓨터 비전 벤치마크 데이터셋이다.  
>  
> PASCAL은  
> Pattern Analysis, Statistical Modelling and Computational Learning의 약자이며,  
> VOC는  
> Visual Object Classes의 약자이다.  
>  
> 이 데이터셋은 자연 이미지 내에 존재하는 여러 객체들을 대상으로  
> 객체 분류(classification), 객체 검출(detection),  
> 의미 분할(semantic segmentation)과 같은  
> 다양한 비전 과제를 평가하기 위해 설계되었다.  
>  
> PASCAL VOC는 사람, 동물, 차량 등을 포함한  
> 총 20개의 객체 클래스를 정의하며,  
> 각 객체에 대해 경계 상자(bounding box)와  
> 픽셀 단위 분할 어노테이션을 제공한다.  
>  
> 특히 PASCAL VOC 2007과 2012는  
> 객체 검출 성능을 비교하는 표준 벤치마크로 활용되었으며,  
> 평균 정밀도(mean average precision, mAP) 지표를  
> 널리 사용하게 만드는 데 중요한 역할을 했다.  

가장 높은 성능을 보이는 방법들은  
일반적으로 다수의 저수준 이미지 특징들과  
고수준 컨텍스트를 결합하는 복잡한 앙상블 시스템들이다.  

본 논문에서 우리는  
단순하면서도 확장 가능한 검출 알고리즘을 제안하며,  
VOC 2012에서 이전 최고 성능 대비  
평균 정밀도(mean average precision, mAP)를  
상대적으로 30% 이상 향상시켜 53.3%의 mAP를 달성한다.  

우리의 접근법은 두 가지 핵심 통찰을 결합한다.  

(1) 객체를 위치 지정하고 분할하기 위해  
상향식 영역 제안(bottom-up region proposals)에  
고용량 합성곱 신경망(convolutional neural networks, CNNs)을  
적용할 수 있다는 점과  

(2) 레이블이 부여된 학습 데이터가 부족할 때,  
보조 과제(auxiliary task)에 대한  
지도 사전 학습(supervised pre-training)을 수행한 뒤  
도메인 특화 미세 조정(domain-specific fine-tuning)을 적용하면  
유의미한 성능 향상을 얻을 수 있다는 점이다.  

우리는 영역 제안(region proposals)과 CNN을 결합하므로,  
우리의 방법을  
"R-CNN: CNN 특징을 갖는 영역(Regions with CNN features)"이라 부른다.  

또한 우리는 유사한 CNN 구조를 기반으로 한  
최근 제안된 슬라이딩 윈도우 기반 검출기(detector)인  
OverFeat과 R-CNN을 비교한다.  

우리는 R-CNN이  
200개 클래스를 갖는 ILSVRC2013 검출 데이터셋에서  
OverFeat을 큰 격차로 능가함을 발견한다.  

전체 시스템에 대한 소스 코드는 다음 주소에서 제공된다.  

https://www.cs.berkeley.edu/~rbg/rcnn

---

## 1. 서론 (Introduction)

특징(features)은 중요하다.  

다양한 시각 인식 과제들에서 지난 10년간의 진보는  
SIFT [29]와 HOG [7]의 사용에 상당 부분 기반해 왔다.  

> SIFT는  
> Scale-Invariant Feature Transform의 약자로,  
> 이미지 내에서 크기 변화(scale), 회전(rotation), 일부 조명 변화에 강인한  
> 국소 특징(local feature)을 추출하는 방법이다.  
>  
> SIFT는  
> 키포인트(keypoint)를 검출한 뒤,  
> 각 키포인트 주변의 그래디언트 분포를 기반으로  
> 고정 길이의 특징 벡터를 생성하여  
> 이미지 간 대응점 매칭과 객체 인식에 활용된다.  
>  
> HOG는  
> Histogram of Oriented Gradients의 약자로,  
> 이미지 영역을 작은 셀(cell) 단위로 나눈 뒤  
> 각 셀에서의 그래디언트 방향 분포를  
> 히스토그램 형태로 표현하는 특징 기술자이다.  
>  
> HOG는  
> 물체의 형태(shape)와 윤곽(edge) 정보를 효과적으로 포착하며,  
> 특히 보행자 검출과 같은  
> 객체 검출 문제에서 널리 사용되었다.  

그러나 정형적인 시각 인식 과제인  
PASCAL VOC 객체 검출 [15]에서의 성능을 살펴보면,  
2010년부터 2012년까지의 기간 동안  
진보가 전반적으로 느렸다는 점이 널리 인식되고 있으며,  
성공적인 방법들의 사소한 변형을 사용하거나  
앙상블 시스템을 구축함으로써 작은 성능 향상만이 얻어졌다.  

---

SIFT와 HOG는 블록 단위 방향 히스토그램(blockwise orientation histograms)이며,  
이는 영장류 시각 경로에서 첫 번째 피질 영역인  
V1의 복합 세포(complex cells)와  
대략적으로 연관 지어 생각할 수 있는 표현이다.  

> 이 문장은  
> SIFT와 HOG가 이미지의 작은 영역(블록)마다  
> 경계의 방향 정보를 히스토그램 형태로 요약하는 특징이라는 점을 설명한다.  
>  
> 이러한 방식은  
> 영장류의 시각 피질에서 가장 초기 단계인 V1 영역의 복합 세포들이  
> 특정 방향의 선이나 에지에 반응하는 특성과  
> 개념적으로 유사하다는 뜻이다.  
>  
> 즉, SIFT와 HOG는  
> 생물학적 시각 시스템의 초기 처리 방식에서 영감을 받은  
> 비교적 저수준(low-level)의 시각 표현이라고 이해할 수 있다.

그러나 우리는 또한  
인식이 여러 단계 아래쪽에서 발생한다는 사실을 알고 있으며,  
(recognition occurs several stages downstream)
이는 시각 인식에 대해 더 많은 정보를 제공하는 특징들을 계산하기 위한  
계층적이고 다단계적인 과정들이 존재할 수 있음을 시사한다.  

> 이 문장은  
> 객체 인식이 이미지 처리의 아주 초기 단계에서  
> 바로 이루어지는 것이 아니라,  
> 여러 처리 단계를 거친 이후에 이루어진다는 점을 말한다.  
>  
> 따라서 단순한 저수준 특징만으로는 충분하지 않으며,  
> 점점 더 복잡하고 추상적인 특징들을 단계적으로 만들어 가는  
> 계층적이고 다단계적인 처리 구조가 시각 인식에 필요하다는 의미이다.  

---

후쿠시마(Fukushima)의 “네오코그니트론(neocognitron)” [19]은  
패턴 인식을 위한 생물학적 영감을 받은  
계층적이고 이동 불변(shift-invariant)적인 모델로서,  
바로 그러한 과정에 대한 초기의 시도였다.  

그러나 네오코그니트론은 지도 학습 알고리즘을 결여하고 있었다.  

Rumelhart 등 [33]의 연구를 바탕으로,  
LeCun 등 [26]은 역전파를 통한 확률적 경사 하강법이  
네오코그니트론을 확장한 모델 계열인  
합성곱 신경망(convolutional neural networks, CNNs)을  
학습시키는 데 효과적임을 보였다.  

---

CNN은 1990년대에 많이 사용되었으나(예: [27]),  
이후 서포트 벡터 머신의 부상과 함께 인기를 잃게 되었다.  

2012년에 Krizhevsky 등 [25]은  
ImageNet 대규모 시각 인식 챌린지  
(ImageNet Large Scale Visual Recognition Challenge, ILSVRC) [9, 10]에서  
현저히 더 높은 이미지 분류 정확도를 보여줌으로써  
CNN에 대한 관심을 다시 불러일으켰다.  

그들의 성공은  
120만 개의 레이블이 부여된 이미지들로 대규모 CNN을 학습시킨 것과,  
LeCun의 CNN에 대한 몇 가지 변형들  
(예: max(x, 0) 형태의 정류 비선형성과 “드롭아웃(dropout)” 정규화)을  
함께 사용한 데에서 비롯되었다.

---

ImageNet 결과의 중요성은  
ILSVRC 2012 워크숍 동안 격렬하게 논의되었다.  

중심적인 쟁점은 다음과 같이 요약될 수 있다.  

ImageNet에서의 CNN 분류 결과는  
어느 정도까지 PASCAL VOC 챌린지에서의  
object detection 결과로 일반화될 수 있는가?  

---

우리는 이미지 분류와 객체 검출 사이의  
간극을 메움으로써 이 질문에 답한다.  

본 논문은 CNN이  
단순한 HOG 유사 특징들에 기반한 시스템들과 비교하여  
PASCAL VOC에서 현저히 더 높은 객체 검출 성능으로  
이어질 수 있음을 처음으로 보여준다.  

이러한 결과를 달성하기 위해,  
우리는 두 가지 문제에 초점을 맞추었다.  

하나는 심층 네트워크를 사용하여  
객체를 위치 지정(localizing)하는 것이며,  

다른 하나는 소량의 주석이 달린 객체 검출 데이터만을 사용하여  
고용량 모델을 학습시키는 것이다.

---

이미지 분류와는 달리, 검출은 이미지 내에서  
(대개는 여러 개의) 객체들을  
위치 지정(localizing)하는 것을 요구한다.  

한 가지 접근법은 위치 지정을 회귀 문제로 정식화하는 것이다.  

그러나 우리 연구와 동시에 수행된 Szegedy 등 [38]의 연구는  
이러한 전략이 실제로는 좋은 성능을 내지 못할 수 있음을 보여준다  
(그들은 VOC 2007에서 우리 방법이 달성한 58.5%에 비해  
30.5%의 mAP를 보고하였다).  

대안적인 방법은 슬라이딩 윈도우 기반 검출기를 구축하는 것이다.  

CNN은 최소 20년 이상 이러한 방식으로 사용되어 왔으며,  
일반적으로 얼굴 [32, 40]이나 보행자 [35]와 같이  
제약된 객체 범주에 적용되어 왔다.  

높은 공간 해상도를 유지하기 위해,  
이러한 CNN들은 일반적으로  
두 개의 합성곱 계층과 풀링 계층만을 갖는다.  

우리 또한 슬라이딩 윈도우 접근법을 채택하는 것을 고려하였다.  

그러나 다섯 개의 합성곱 계층을 갖는  
우리 네트워크의 상위 계층에 위치한 유닛들은 입력 이미지 상에서  
매우 큰 수용 영역(receptive fields)(195 × 195 픽셀)과  
큰 스트라이드(strides)(32 × 32 픽셀)를 가지며,  

이는 슬라이딩 윈도우 패러다임 내에서  
정확한 위치 지정을 수행하는 것을  
여전히 해결되지 않은 기술적 과제로 만든다.

---


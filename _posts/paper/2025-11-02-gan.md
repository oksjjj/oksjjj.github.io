---
layout: post
title: "Generative Adversarial Nets"
date: 2025-11-02 07:00:00 +0900
categories:
  - "논문 번역"
tags: []
---
> 논문 출처  
> Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., & Bengio, Y.  
> Generative Adversarial Nets.  
> Advances in Neural Information Processing Systems (NeurIPS), 2014.  
> <a href="https://arxiv.org/abs/1406.2661" target="_blank">🔗 원문 링크 (arXiv: 1406.2661)</a>

저자  
- Ian J. Goodfellow  
- Jean Pouget-Abadie*  
- Mehdi Mirza  
- Bing Xu  
- David Warde-Farley  
- Sherjil Ozair<sup>†</sup>  
- Aaron Courville  
- Yoshua Bengio<sup>‡</sup>  

(Université de Montréal, Département d’informatique et de recherche opérationnelle)

> <sup>*</sup>Jean Pouget-Abadie는 École Polytechnique에서  
> Université de Montréal을 방문 중이다.  
> 
> <sup>†</sup>Sherjil Ozair는 인도 공과대학 델리(Indian Institute of Technology Delhi)에서  
> Université de Montréal을 방문 중이다.  
> 
> <sup>‡</sup>Yoshua Bengio는 CIFAR 선임 연구원(Senior Fellow)이다.

---

## 초록 (Abstract)

본 논문에서는 적대적(adversarial) 과정을 통해  
생성 모델(generative models)을 추정하는 새로운 프레임워크를 제안한다.  
이 프레임워크에서는 두 개의 모델을 동시에 학습시킨다:   

데이터 분포를 포착하는 생성 모델 $G$,  
그리고 주어진 샘플이 실제 데이터로부터 왔는지  
혹은 $G$에 의해 생성된 것인지를 판별하는  
판별 모델(discriminative model) $D$ 이다.  

$G$의 학습 목표는 $D$가 오판(making a mistake)할  
확률을 최대화하는 것이다.  

이 프레임워크는 미니맥스(minimax) 형태의 2인 게임(two-player game)에 해당한다.  

임의의 함수 공간에서 $G$와 $D$에 대해  
유일한 해(unique solution)가 존재하며,  
그때 $G$는 데이터 분포를 완벽히 복원하고  
$D$는 모든 지점에서 $\frac{1}{2}$의 확률을 출력한다.  

$G$와 $D$가 다층 퍼셉트론(multilayer perceptron)으로 정의된 경우,  
전체 시스템은 역전파(backpropagation)를 통해 학습이 가능하다.  

또한 이 프레임워크는 학습이나 샘플 생성 중에  
마르코프 연쇄(Markov chain)나  
전개형 근사 추론 네트워크(unrolled approximate inference network)를  
사용할 필요가 없다.  

마지막으로, 본 논문은  
정성적(qualitative) 및 정량적(quantitative) 평가를 통해  
이 프레임워크의 잠재력을 입증한다.

---

## 1 서론 (Introduction)

딥러닝의 가능성(promise)은  
자연 이미지, 음성 신호를 포함한 오디오 파형,  
자연어 코퍼스(말뭉치)의 기호(symbol) 등  
인공지능 응용에서 접하게 되는 다양한 데이터 유형들에 대한  
확률 분포를 표현하는  
풍부하고 계층적인(hierarchical) 모델 [2]을 발견하는 데 있다.  

지금까지 딥러닝의 가장 두드러진 성공 사례들은  
주로 고차원적이고 풍부한 센싱 입력(sensory input)을  
클래스 레이블로 매핑하는 판별 모델(discriminative model) [14, 22]에 있었다.  

이러한 두드러진 성공들은 주로  
잘 동작하는 그래디언트를 가지는  
부분 선형 유닛(piecewise linear units) [19, 9, 10]을 사용하는,  
역전파(backpropagation)와 드롭아웃(dropout) 알고리즘에 기반해왔다.  

반면, 생성 모델(generative model)은  
최대우도추정(maximum likelihood estimation) 및 관련 전략에서  
발생하는 계산 불가능한(intractable) 확률 계산들을 근사하기 어려운 점,  
그리고 생성 맥락에서 부분 선형 단위의 이점을 활용하기 어려운 점 때문에  
상대적으로 덜 큰 영향을 미쳐왔다.  

이에 우리는 이러한 어려움을 우회하는  
새로운 생성 모델 추정 절차를 제안한다.<sup>1</sup>  

> <sup>1</sup>모든 코드와 하이퍼파라미터는  
> <a href="https://www.github.com/goodfeli/adversarial" target="_blank">https://www.github.com/goodfeli/adversarial</a>  
> 에서 확인할 수 있다.  

---

제안된 적대적 네트워크(adversarial nets) 프레임워크에서,  
생성 모델은 하나의 적수(adversary)와 맞서게 된다:  

샘플이 모델 분포로부터 온 것인지  
혹은 데이터 분포로부터 온 것인지를  
판별하도록 학습하는 판별 모델(discriminative model).    

생성 모델은 위조지폐를 만들어  
들키지 않고 사용하는 것을 시도하는  
위조범 집단에 비유할 수 있으며,  
판별 모델은 이러한 위조지폐를 탐지하려는  
경찰에 비유할 수 있다.  

이 게임에서의 경쟁은  
양쪽 모두가 자신들의 방법을 개선하도록 유도하며,  
결국 위조지폐가 진짜와 구별되지 않을 때까지  
서로의 능력을 향상시키게 된다.  

---

이 프레임워크는 다양한 종류의 모델과 최적화 알고리즘에 대해  
특정한 학습 알고리즘들을 도출할 수 있다.  

본 논문에서는  
생성 모델이 무작위 잡음을  
다층 퍼셉트론(multilayer perceptron)을 통해 전달함으로써  
샘플을 생성하고,  
판별 모델 또한 다층 퍼셉트론인 특수한 경우를 탐구한다.  

우리는 이 특수한 경우를 적대적 네트워크(adversarial nets)라 부른다.  

이 경우, 두 모델 모두  
매우 성공적인 역전파(backpropagation)와  
드롭아웃(dropout) 알고리즘 [17]만을 사용하여 학습할 수 있으며,  
생성 모델로부터의 샘플링은  
순전파(forward propagation)만으로 수행할 수 있다.  

근사 추론(approximate inference)이나  
마르코프 연쇄(Markov chain)는 필요하지 않다.  

---

## 2 관련 연구 (Related work)

잠재 변수를 포함한 유향 그래프 모델(directed graphical model)에 대한  
대안(alternative)으로는,  
제한 볼츠만 머신(restricted Boltzmann machines, RBMs) [27, 16],  
딥 볼츠만 머신(deep Boltzmann machines, DBMs) [26] 및  
그 수많은 변형들(variants)과 같은  
잠재 변수를 가진 무향 그래프 모델(undirected graphical model)이 있다.  

> 볼츠만 머신(Boltzmann Machine)은  
> 에너지 기반 모델(Energy-based model)의 한 종류로,  
> 확률적 방식으로 데이터를 모델링하는 생성 신경망이다.  
>  
> 뉴런들이 완전 연결되어 있으며,  
> 각 상태(state)의 확률은 해당 상태의 에너지에 의해 결정된다.  
>  
> 학습의 목표는  
> 데이터에서 관찰된 패턴이 낮은 에너지 값을 가지도록  
> 가중치(weight)를 조정하는 것이다.  
>  
> 확률 분포는  
>
> $$P(x) = \frac{1}{Z} \exp(-E(x))$$  
>
> 의 형태로 정의되며,  
> 여기서 $E(x)$는 에너지 함수(energy function),  
> $Z$는 분할 함수(partition function)이다.  
>  
> 볼츠만 머신은 강력한 표현력을 가지지만,  
> 모든 뉴런 간 연결로 인해 계산량이 매우 크다.  
> 이러한 한계를 완화하기 위해  
> 가시층과 은닉층 사이의 연결만 허용한  
> 제한 볼츠만 머신(Restricted Boltzmann Machine, RBM)이 제안되었다.  

이러한 모델 내의 상호작용(interaction)은  
정규화되지 않은 퍼텐셜 함수(unnormalized potential functions)의 곱으로 표현되며,  
이는 모든 확률 변수 상태에 대한  
전역적인 합산/적분(global summation/integration)에 의해  
정규화(normalized)된다.  

> 이 문장은 에너지 기반 모델(Energy-based model) 의 핵심 구조를 설명한다.  
> 모델 내의 모든 변수 간 관계는 퍼텐셜 함수(potential function) 로 표현되며,  
> 이 함수들은 각 변수 조합의 "에너지" 또는 "적합도"를 나타낸다.  
>  
> 하지만 이러한 퍼텐셜 함수들은 정규화되지 않은 상태(unnormalized) 이므로  
> 확률 분포로 사용하기 위해서는  
> 가능한 모든 상태 조합에 대한 합 또는 적분을 계산하여  
> 분할 함수(partition function) 로 정규화해야 한다.  
>  
> 아래에서 $Z$가 바로 이러한 전역적인 합산/적분(global summation/integration)이다.   
>
> $$P(x) = \frac{1}{Z} \exp(-E(x))$$  

이 양(quantity, 즉, 분할 함수(partition function))과  
그 그래디언트는 가장 단순한 경우를 제외하고는  
계산 불가능(intractable)하다.  
그러나 마르코프 연쇄 몬테카를로(Markov chain Monte Carlo, MCMC) 방법을 통해  
이를 추정할 수는 있다.  

혼합(mixing)은 MCMC에 의존하는 학습 알고리즘들 [3, 5]에  
중대한 문제를 제기한다.  

> 여기서 말하는 혼합(mixing)은  
> 마르코프 연쇄 몬테카를로(MCMC) 샘플링 과정에서  
> 연쇄(chain)가 전체 확률 공간을 얼마나 잘 탐색하는지를 의미한다.  
>  
> 이상적인 경우, MCMC 샘플러는 충분히 빠르게 섞여(mix)  
> 표본들이 서로 독립적이고 분포 전체를 잘 대표해야 한다.  
> 그러나 실제로는 고차원 모델이나 복잡한 에너지 지형(energy landscape)에서는  
> 연쇄가 특정 지역(local mode)에 머무르거나,  
> 분포의 다른 부분으로 잘 이동하지 못하는 문제가 발생한다.  
>  
> 이러한 느린 혼합(slow mixing) 문제는  
> MCMC 기반 학습 알고리즘의 수렴을 어렵게 만들고,  
> 학습된 모델의 품질을 떨어뜨리는 주요 원인이 된다.  

---

딥 빌리프 네트워크(Deep Belief Networks, DBNs) [16]는  
하나의 무향층(undirected layer)과  
여러 개의 유향층(directed layers)을 포함하는  
혼합 모델(hybrid model)이다.  

빠른 근사적 층별(layer-wise) 학습 기준이 존재하지만,  
DBN은 무향 모델과 유향 모델 모두에 관련된  
계산상의 어려움을 겪는다.  

> 딥 빌리프 네트워크(DBN)는  
> 제한 볼츠만 머신(RBM)을 여러 층으로 쌓아 올린 형태의  
> 심층 생성 신경망(deep generative neural network)이다.  
>  
> 맨 아래층은 무향 구조(RBM)로 되어 있어  
> 입력 데이터의 확률 분포를 학습하고,  
> 그 위의 상위 층들은 유향 구조로 되어 있어  
> 상위 특징 표현(higher-level representation)을 학습한다.  
>  
> 학습은 일반적으로 층별(layer-wise) 사전학습(pre-training)으로 수행되며,  
> 이후 전체 네트워크를 미세 조정(fine-tuning)한다.  
>  
> 그러나 무향 모델과 유향 모델의 결합 구조 때문에  
> 계산 복잡도가 높고,  
> 근사 추론(approximate inference)이 필요하다는 단점이 있다.  

---

로그 가능도(log-likelihood)를 근사하거나 경계(bound)하지 않는  
대안적 기준(alternative criteria)들도 제안되어 왔다.  
예를 들어, 스코어 매칭(score matching) [18]과  
노이즈 대비 추정(noise-contrastive estimation, NCE) [13]이 있다.  

이 두 방법 모두,  
학습된 확률 밀도(probability density)가  
정규화 상수(normalization constant)를 제외하고  
해석적으로 명시될 수 있어야 한다.  

여러 층의 잠재 변수(latent variables)를 포함한  
많은 흥미로운 생성 모델들(예: DBN, DBM)에서는  
계산 가능한 형태의 정규화되지 않은 확률 밀도  
(tractable unnormalized probability density)를  
도출하는 것조차 불가능하다.  

노이즈 제거(autoencoder) [30]나  
수축 오토인코더(contractive autoencoder)와 같은  
일부 모델들은,  
RBM에 적용된 스코어 매칭(score matching)과  
매우 유사한 학습 규칙을 가진다.  

NCE에서는, 본 연구와 마찬가지로  
생성 모델을 적합시키기 위해  
판별적 학습 기준(discriminative training criterion)이 사용된다.  
그러나 별도의 판별 모델을 학습하는 대신,  
생성 모델 자체를 이용하여  
고정된 잡음 분포(fixed noise distribution)로부터의 샘플과  
생성된 데이터를 구분한다.  

하지만 NCE는 고정된 잡음 분포를 사용하기 때문에,  
모델이 관측된 변수들의 작은 부분 집합에 대해  
대략적으로 올바른 분포를 학습하고 나면  
학습 속도가 급격히 느려지는 단점을 가진다.  

---

마지막으로, 일부 기법들은  
확률 분포를 명시적으로 정의하지 않고,  
대신 원하는 분포로부터 샘플을 뽑아내도록  
생성 기계(generative machine)를 학습시킨다.  

이 접근법의 장점은  
이러한 생성 기계가 역전파(back-propagation)를 통해  
학습되도록 설계될 수 있다는 점이다.  

이 영역의 대표적인 최근 연구로는  
일반화된 노이즈 제거 오토인코더(generalized denoising auto-encoders) [4]를 확장한  
생성 확률적 네트워크(generative stochastic network, GSN) 프레임워크 [5]가 있다.  
이 두 가지 모두,  
매개변수화된 마르코프 연쇄(parameterized Markov chain)를 정의하는 것으로 볼 수 있다.  
즉, 생성적 마르코프 연쇄의 한 단계를 수행하는 기계의  
매개변수를 학습하는 것이다.  

GSN과 비교했을 때,  
적대적 네트워크(adversarial nets) 프레임워크는  
샘플링을 위해 마르코프 연쇄를 필요로 하지 않는다.  

적대적 네트워크는  
생성 과정에서 피드백 루프(feedback loop)를 필요로 하지 않기 때문에,  
역전파의 성능을 향상시키지만  
피드백 루프에서 사용될 경우  
비한정 활성(unbounded activation) 문제를 가지는  
부분 선형 유닛(piecewise linear units) [19, 9, 10]의 이점을  
더 잘 활용할 수 있다.  

보다 최근의 예로는,  
역전파를 생성 기계 내부로 전파하여 학습시키는  
오토인코딩 변분 베이즈(auto-encoding variational Bayes) [20] 및  
확률적 역전파(stochastic backpropagation) [24]에 대한 연구가 있다.  

---

## 3 적대적 네트워크 (Adversarial nets)

적대적 모델링 프레임워크(adversarial modeling framework)는  
두 모델이 모두 다층 퍼셉트론(multilayer perceptron)일 때  
가장 직접적으로(straightforward) 적용할 수 있다.  

데이터 $x$에 대한 생성자(generator)의 분포 $p_g$를 학습하기 위해,  
입력 잡음 변수(input noise variables) $p_z(z)$에 대한 사전분포(prior)를 정의한 후,  
데이터 공간(data space)으로의 매핑(mapping)을  
$G(z; \theta_g)$로 표현한다.  

여기서 $G$는  
파라미터 $\theta_g$를 가진  
다층 퍼셉트론으로 표현되는  
미분 가능한 함수(differentiable function)이다.  

또한,  
하나의 스칼라(scalar)를 출력하는  
두 번째 다층 퍼셉트론 $D(x; \theta_d)$를 정의한다.  
$D(x)$는  
입력 $x$가 모델 분포 $p_g$가 아니라  
데이터로부터 왔을 확률을 나타낸다.  

$D$는 학습 데이터와 $G$로부터 생성된 샘플 모두에 대해  
올바른 레이블을 할당할 확률을  
최대화하도록 학습된다.  

동시에,  
$G$는 $$\log(1 - D(G(z)))$$ 을 최소화하도록 학습된다: 

다시 말해,  
$D$와 $G$는 다음의 2인 미니맥스(two-player minimax) 게임을 수행한다.  
그 가치 함수(value function) $V(G, D)$는 다음과 같다.

$$
\min_G \max_D V(D, G)
= \mathbb{E}_{x \sim p_{\text{data}}(x)} [\log D(x)]
+ \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))].
\tag{1}
$$

---

다음 절에서 우리는 적대적 네트워크(adversarial nets)에 대한  
이론적 분석을 제시한다.  

이는 본질적으로,  
$G$와 $D$가 충분한 표현 능력(capacity)을 가질 경우,  
즉 비모수적 한계(non-parametric limit)에서,  
학습 기준(training criterion)이  
데이터를 생성하는 분포(data generating distribution)를  
복원할 수 있도록 해준다는 것을 보여준다.  

그 접근 방식에 대한 좀 더 비형식적이며 교육적인 설명은  
그림 1(Figure 1)에 제시되어 있다.  

실제적으로는, 우리는 이 게임을  
반복적(iterative)이고 수치적인(numerical) 접근법으로 구현해야 한다.  

학습의 내부 루프(inner loop)에서  
$D$를 완전히 최적화하는 것은  
계산적으로 매우 부담스럽고,  
유한한 데이터셋(finite datasets)에서는 과적합(overfitting)을 초래할 것이다.  

대신, 우리는 $D$를 $k$ 단계 동안 최적화한 후  
$G$를 한 단계 최적화하는 과정을 번갈아 수행한다.  

이 방법은 $D$가  
그의 최적 해(optimal solution) 근처에서 유지되도록 하며,  
$G$가 충분히 천천히 변화하는 한 안정적으로 작동한다.  

이 전략은 SML/PCD [31, 29]에서  
하나의 학습 단계에서 다음 단계로 넘어갈 때  
마르코프 연쇄(Markov chain)로부터의 샘플을 유지하여  
연쇄의 초기화(burning-in)를 방지하는 방식과 유사하다.  

이 절차는 알고리즘 1(Algorithm 1)에 정식으로 제시되어 있다.  

---

**그림 1:**  
생성적 적대 신경망(generative adversarial nets)은  
판별 분포(discriminative distribution) $D$ (파란색, 점선)를  
동시에 갱신(update)하면서 학습된다.  
이때 $D$는 데이터 생성 분포(data generating distribution) (검정색, 점선) $p_x$로부터의 샘플과  
생성 분포(generative distribution) $p_g$ (녹색, 실선)으로부터의 샘플을  
구별하도록 학습된다.  

아래쪽의 수평선은 $z$가 샘플링되는 영역(domain)을 나타내며,  
이 경우 균등 분포(uniform distribution)이다.  
위쪽의 수평선은 $x$의 영역 일부를 나타낸다.  

위쪽 화살표들은 매핑(mapping) $x = G(z)$이  
변환된 샘플들 위에서 비등 분포(non-uniform distribution) $p_g$를  
어떻게 형성하는지를 보여준다.  

$G$는 $p_g$의 높은 밀도(high density) 영역에서는 수축(contract)하고,  
낮은 밀도(low density) 영역에서는 확장(expand)한다.  

(a) 수렴 근처(convergence near)에서의 적대적 쌍(adversarial pair)을 고려하자.  
이때 $p_g$는 $p_{\text{data}}$와 유사하며,  
$D$는 부분적으로 정확한 분류기(partially accurate classifier)이다.  

(b) 알고리즘의 내부 루프(inner loop)에서  
$D$는 데이터로부터의 샘플을 구별하도록 학습되며,  
그 결과 다음과 같이 수렴한다.  

$$
D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
$$  

(c) $G$가 갱신된 후,  
$D$의 그래디언트(gradient)는  
$G(z)$가 데이터로 분류될 가능성이 높은 영역으로 이동하도록 유도한다.  

(d) 여러 단계의 학습 이후,  
$G$와 $D$가 충분한 용량(capacity)을 가진다면,  
두 모델은 더 이상 개선될 수 없는 지점에 도달한다.  
이때 $p_g = p_{\text{data}}$가 된다.  

판별자(discriminator)는 두 분포를 구별할 수 없으며,  
즉 $D(x) = \frac{1}{2}$가 된다.  

<img src="/assets/img/paper/gan/image_1.png" alt="image" width="800px"> 

> 그림 1은 GAN이 실제로 학습되는 과정을 시각적으로 보여주는 예시다.  
>  
> 검정색 점선은 진짜 데이터의 분포 $p_x$ (또는 $p_{\text{data}}$)를 나타낸다.  
> 즉, 우리가 모델이 닮게 만들고 싶은 "정답 분포"다.  
>  
> 녹색 실선은 생성자 $G$가 만들어내는 가짜 데이터의 분포 $p_g$를 의미한다.  
> 처음에는 이 분포가 진짜 데이터 분포와 전혀 다르다.  
>  
> 파란색 점선은 판별자 $D$가 예측하는 “진짜일 확률”을 나타낸다.  
> 예를 들어 $D(x)=1$에 가까우면 “진짜 데이터일 것 같다”는 뜻이고,  
> $D(x)=0$에 가까우면 “가짜 데이터일 것 같다”는 의미다.  
>  
> 아래쪽의 수평선은 생성자의 입력인 $z$의 공간이다.  
> 이 $z$는 보통 균등 분포(예: -1~1)에서 무작위로 뽑는다.  
>  
> 위쪽의 수평선은 $x=G(z)$를 통해 만들어진 실제 데이터 공간이다.  
> 화살표는 $z$가 $G$를 거쳐 어떻게 $x$로 변환되는지를 나타낸다.  
>  
> $G$는 샘플을 변환하면서,  
> 진짜 데이터가 많은 구간(즉, $p_g$의 밀도가 높은 구간)은 압축(contract) 하고,  
> 데이터가 적은 구간(밀도가 낮은 구간)은 확장(expand) 한다.  
>  
> (a) 학습 초반에는 $p_g$가 아직 $p_{\text{data}}$와 다르기 때문에  
> $D$는 대체로 정확하게 “이건 진짜 / 이건 가짜”를 맞출 수 있다.  
> 이때 $D$는 부분적으로 올바른 분류기(partially accurate classifier)이다.  
>  
> (b) 내부 학습 루프에서 $D$는 진짜와 가짜 샘플을 구별하도록 갱신된다.  
> 최적의 판별자는 다음과 같은 형태를 가진다:  
>  
> $$
> D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
> $$  
>  
> 즉, 어떤 점 $x$가 진짜 데이터에서 나왔을 확률을 계산하는 식이다.  
>  
> (c) 이후 생성자 $G$가 갱신되면,  
> $D$의 그래디언트(gradient)를 참고해  
> $G(z)$가 “진짜처럼 보이는” 구간으로 이동하도록 유도된다.  
> 이 과정을 반복하면서 $G$는 점점 더 진짜 분포에 가까워진다.  
>  
> (d) 여러 번의 반복 학습이 끝나면,  
> $G$와 $D$가 서로를 속이거나 구별할 수 없는 상태에 도달한다.  
> 이때 $p_g = p_{\text{data}}$가 되고,  
> 판별자는 모든 입력에 대해 $D(x) = \frac{1}{2}$,  
> 즉 “진짜일 확률도, 가짜일 확률도 반반”이라고 판단하게 된다.  
>  
> 결과적으로, 생성자는 진짜 데이터와 완전히 구분되지 않는  
> 완벽한 샘플을 만들어낼 수 있게 된다.  

---

**알고리즘 1**  
미니배치 확률적 경사 하강법(minibatch stochastic gradient descent)을 이용한  
생성적 적대 신경망(Generative Adversarial Nets, GAN)의 학습  

판별자(discriminator)에 적용되는 단계 수 $k$는 하이퍼파라미터이며,  
본 논문에서는 계산 비용이 가장 적은 $k = 1$을 사용하였다.  

---

**for** 학습 반복 횟수(number of training iterations) **do**  

 **for** $k$ 단계 **do**  
  - 잡음 사전분포(noise prior) $p_g(z)$로부터 $m$개의 잡음 샘플 $\lbrace z^{(1)}, \ldots, z^{(m)}\rbrace$을 샘플링한다.  

  - 데이터 생성 분포(data generating distribution) $p_{\text{data}}(x)$로부터 $m$개의 실제 데이터 샘플 $\lbrace x^{(1)}, \ldots, x^{(m)}\rbrace$을 샘플링한다.  

  - 판별자(discriminator)를 다음의 확률적 경사(stochastic gradient)를 따라 **상승(ascending)** 방향으로 갱신한다.  

   $$\nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^{m} [\log D(x^{(i)}) + \log(1 - D(G(z^{(i)})))].$$  

 **end for**  

 - 잡음 사전분포 $p_g(z)$로부터 $m$개의 잡음 샘플 $\lbrace z^{(1)}, \ldots, z^{(m)}\rbrace$을 샘플링한다.  

 - 생성자(generator)를 다음의 확률적 경사를 따라 **하강(descending)** 방향으로 갱신한다.  

  $$\nabla_{\theta_g} \frac{1}{m} \sum_{i=1}^{m} \log(1 - D(G(z^{(i)}))).$$  

**end for**  

---

경사 기반의 업데이트(gradient-based update)는  
표준 경사 학습 규칙(standard gradient-based learning rule) 중  
어느 것이든 사용할 수 있다.  
본 논문에서는 모멘텀(momentum)을 사용하였다.  

---

실제로는, 식 (1)은 생성자 $G$가 충분히 잘 학습하기에  
충분한 그래디언트(gradient)를 제공하지 못할 수 있다.  

학습 초기에 $G$의 성능이 나쁠 때,  
판별자 $D$는 훈련 데이터와 명확히 다른 샘플들을  
높은 확신(high confidence)으로 쉽게 거부할 수 있다.  

이 경우, $\log(1 - D(G(z)))$ 항이 포화(saturate)되어  
그래디언트가 거의 사라진다.  

따라서 $G$를 $\log(1 - D(G(z)))$를 최소화하도록 학습시키는 대신,  
$\log D(G(z))$를 최대화하도록 학습시킬 수 있다.  

이 목적 함수(objective function)는  
$G$와 $D$의 동적 과정(dynamics)에서  
동일한 고정점(fixed point)을 가지지만,  
학습 초기에 훨씬 더 강한 그래디언트(stronger gradient)를 제공한다.  

---

## 4 이론적 결과 (Theoretical Results)

생성자 $G$는 암묵적으로 확률 분포 $p_g$를 정의하는데,  
이는 $z \sim p_z$일 때 얻어지는 샘플 $G(z)$의 분포로 정의된다.  

따라서, 충분한 표현 능력(capacity)과 학습 시간(training time)이 주어진다면,  
알고리즘 1이 $p_{\text{data}}$의 좋은 추정치(estimator)에  
수렴(converge)하기를 원한다.  

이 절의 결과들은 비모수적(non-parametric) 설정에서 수행된다.  
즉, 확률 밀도 함수(probability density function)의 공간에서  
수렴을 연구함으로써,  
무한한 표현 능력을 가진 모델을 가정하여 분석을 수행한다.  

섹션 4.1에서는, 이 미니맥스 게임이  
$p_g = p_{\text{data}}$일 때 전역 최적해(global optimum)를 가진다는 것을 보일 것이다.  

그리고 섹션 4.2에서는  
알고리즘 1이 식 (1)을 최적화함으로써  
원하는 결과(desired result)를 얻는다는 것을 보일 것이다.  

---

### 4.1 $p_g = p_{\text{data}}$의 전역 최적성 (Global Optimality)

우선, 주어진 생성자 $G$에 대해  
최적의 판별자(discriminator) $D$를 고려한다.  

**명제 1 (Proposition 1).**  
$G$가 고정되어 있을 때, 최적의 판별자 $D$는 다음과 같다.  

$$
D_G^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} \tag{2}
$$

**증명 (Proof).**  
임의의 생성자 $G$가 주어졌을 때,  
판별자 $D$의 학습 기준(training criterion)은  
다음 식의 양(Quantity) $V(G, D)$를 최대화하는 것이다.  

$$
\begin{aligned}
V(G, D) 
&= \int_x p_{\text{data}}(x) \log D(x) \, dx 
   + \int_z p_z(z) \log(1 - D(G(z))) \, dz \\
&= \int_x 
   \big[
   p_{\text{data}}(x) \log D(x)
   + p_g(x) \log(1 - D(x))
   \big]
   \, dx
\end{aligned} \tag{3}
$$

임의의 $(a, b) \in \mathbb{R}^2 \setminus \{0, 0\}$에 대해,  
함수 $y \to a \log(y) + b \log(1 - y)$는  
구간 $[0, 1]$에서 $y = \frac{a}{a + b}$일 때 최대값을 갖는다.  

판별자 $D$는  
$\text{Supp}(p_{\text{data}}) \cup \text{Supp}(p_g)$의 영역 밖에서는  
정의될 필요가 없으며,  
이로써 증명이 완료된다. □  

> 함수 $y \to a\log(y) + b\log(1 - y)$의 최대값이  
> $y = \frac{a}{a + b}$에서 나오는 이유는,  
> 이 함수가 볼록(convex) 함수의 음수 형태이기 때문이다.  
>  
> 미분을 통해 이를 확인할 수 있다.  
>  
> 먼저, 미분하면 다음과 같다.  
>  
> $$\frac{d}{dy} [a\log(y) + b\log(1 - y)] = \frac{a}{y} - \frac{b}{1 - y}$$  
>  
> 이를 0으로 두면,  
>  
> $$\frac{a}{y} = \frac{b}{1 - y} \Rightarrow y = \frac{a}{a + b}$$  
>  
> 따라서 $y = \frac{a}{a + b}$에서 극값(critical point)이 발생한다.  
>  
> 두 번째 미분은  
>
> $$\frac{d^2}{dy^2} [a\log(y) + b\log(1 - y)] = -\frac{a}{y^2} - \frac{b}{(1 - y)^2}$$  
> 
> 이므로  
> 항상 음수이다.  
> 따라서 해당 점은 최대값(maximum) 을 준다.  
>  
>  
> 한편, 판별자 $D$가 $\text{Supp}(p_{\text{data}}) \cup \text{Supp}(p_g)$  
> (즉, 실제 데이터 분포와 생성 분포가 정의된 영역) 밖에서  
> 정의될 필요가 없는 이유는 다음과 같다.  
>  
> - 적분식 $V(G, D)$는 두 분포의 지지 집합(support) 위에서만 정의된다.  
> - 데이터가 존재하지 않는 구간에서는 $p_{\text{data}}(x)$와 $p_g(x)$가 둘 다 0이므로,  
>   $D(x)$가 어떤 값을 가지든 학습에 영향을 주지 않는다.  
>  
> 따라서 $D$는 실제 데이터나 생성된 샘플이 존재하는 구간 안에서만  
> 정의하면 충분하며, 그 외의 영역은 모델의 목적 함수에 기여하지 않는다.  

---

또한, 판별자 $D$의 학습 목적은  
조건부 확률 $P(Y = y | x)$의 로그 가능도(log-likelihood)를  
최대화하는 것으로 해석할 수 있다.  
여기서 $Y$는 입력 $x$가 $p_{\text{data}}$에서 온 경우 $y = 1$,  
$p_g$에서 온 경우 $y = 0$을 의미한다.  

따라서 식 (1)의 미니맥스(minimax) 게임은  
다음과 같이 다시 표현될 수 있다.  

$$
\begin{aligned}
C(G) 
&= \max_D V(G, D) \\
&= \mathbb{E}_{x \sim p_{\text{data}}} [\log D_G^*(x)] 
 + \mathbb{E}_{z \sim p_z} [\log(1 - D_G^*(G(z)))] \\
&= \mathbb{E}_{x \sim p_{\text{data}}} [\log D_G^*(x)] 
 + \mathbb{E}_{x \sim p_g} [\log(1 - D_G^*(x))] \\
&= \mathbb{E}_{x \sim p_{\text{data}}} 
   \left[
   \log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}
   \right]
   + 
   \mathbb{E}_{x \sim p_g} 
   \left[
   \log \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)}
   \right]
\end{aligned} \tag{4}
$$

---

**정리 1 (Theorem 1).**  
가상의 학습 기준 함수 $C(G)$의 전역 최소값(global minimum)은  
$p_g = p_{\text{data}}$일 때, 그리고 그때에만 달성된다.  
그 시점에서 $C(G)$는 값 $-\log 4$를 갖는다.  

**증명 (Proof).**  
$p_g = p_{\text{data}}$일 때, 식 (2)에 의해  
$$D_G^*(x) = \frac{1}{2}$$가 된다.  
따라서 식 (4)를 $$D_G^*(x) = \frac{1}{2}$$인 경우로 살펴보면,  
$$C(G) = \log \frac{1}{2} + \log \frac{1}{2} = -\log 4$$임을 알 수 있다.  

이 값이 $C(G)$의 가능한 최솟값임을 보이기 위해,  
$p_g = p_{\text{data}}$일 때 다음을 관찰한다.  

$$
\mathbb{E}_{x \sim p_{\text{data}}}[-\log 2] + \mathbb{E}_{x \sim p_g}[-\log 2] = -\log 4
$$  

그리고 이 식을 $C(G) = V(D_G^*, G)$에서 빼면 다음을 얻는다.  

$$
C(G) = -\log(4)
+ KL\left(p_{\text{data}} \; \bigg\| \; \frac{p_{\text{data}} + p_g}{2}\right)
+ KL\left(p_g \; \bigg\| \; \frac{p_{\text{data}} + p_g}{2}\right)
\tag{5}
$$  

> 식 (5)는 식 (4)의 각 항을 KL 발산(Kullback–Leibler divergence) 형태로  
> 변환함으로써 얻어진 결과이다.  
>  
> 먼저 식 (4)에서  
>  
> $$
> C(G) =
> \mathbb{E}_{x \sim p_{\text{data}}}
> \left[
> \log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}
> \right]
> +
> \mathbb{E}_{x \sim p_g}
> \left[
> \log \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)}
> \right]
> $$
>  
> 를 고려한다.  
>  
> 분모에 $\frac{1}{2}$를 곱해 $\tfrac{1}{2}[p_{\text{data}}(x) + p_g(x)]$로 두면,  
> 로그 항에 $-\log 2$가 추가된다.  
>  
> 즉,  
>  
> $$
> \log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}
> = \log \frac{p_{\text{data}}(x)}{\frac{1}{2}(p_{\text{data}}(x) + p_g(x))} - \log 2
> $$
>  
> 같은 방식으로 $p_g$ 항에도 적용하면,  
>  
> $$\mathbb{E}_{x \sim p_{\text{data}}}[-\log 2] + \mathbb{E}_{x \sim p_g}[-\log 2] = -\log 4$$가 되고,  
> 나머지 항들은 각각 KL 발산으로 표현된다.  
>  
> $$
> C(G) = -\log(4)
> + KL\left(p_{\text{data}} \;\Big\|\; \frac{p_{\text{data}} + p_g}{2}\right)
> + KL\left(p_g \;\Big\|\; \frac{p_{\text{data}} + p_g}{2}\right)
> $$
>  
> 따라서 $C(G)$는 두 분포가 공통 평균 분포 $\frac{p_{\text{data}} + p_g}{2}$로부터  
> 얼마나 다른지를 측정하는 두 개의 KL 발산의 합으로 나타낼 수 있다.  

여기서 $KL$은 쿨백-라이블러 발산(Kullback–Leibler divergence)을 의미한다.  
위 식은 모델의 분포와 데이터 생성 과정 사이의  
젠센–샤넌 발산(Jensen–Shannon divergence, JSD)을 나타내는 식으로  
다시 쓸 수 있다.  

$$
C(G) = -\log(4) + 2 \cdot JSD(p_{\text{data}} \; \| \; p_g)
\tag{6}
$$  

두 분포 사이의 젠센–샤넌 발산은 항상 0 이상이며,  
두 분포가 동일할 때에만 0이 된다.  
따라서 $C^* = -\log(4)$가 $C(G)$의 전역 최소값이며,  
유일한 해는 $p_g = p_{\text{data}}$이다.  
즉, 생성 모델이 데이터 생성 과정을 완벽하게 복제(perfectly replicate)할 때  
최적 상태에 도달한다는 것을 의미한다. □

---

### 4.2 알고리즘 1의 수렴 (Convergence of Algorithm 1)

**명제 2 (Proposition 2).**  
만약 $G$와 $D$가 충분한 용량(capacity)을 가지고 있고,  
알고리즘 1의 각 단계에서 판별자(discriminator)가  
주어진 $G$에 대해 자신의 최적값(optimum)에 도달할 수 있으며,  
$p_g$가 다음 기준을 개선하도록 업데이트된다면

$$
\mathbb{E}_{x \sim p_{\text{data}}}[\log D_G^*(x)] 
+ \mathbb{E}_{x \sim p_g}[\log(1 - D_G^*(x))]
$$

그렇다면 $p_g$는 $p_{\text{data}}$로 수렴한다.  

---

**증명 (Proof).**  
위의 기준에서 정의된 대로,  
$V(G, D) = U(p_g, D)$를 $p_g$의 함수로 고려하자.  
$U(p_g, D)$는 $p_g$에 대해 볼록(convex)함을 주목하라.  

볼록 함수들의 상한(supremum)에 대한 부분도함수(subderivative)는  
최대값이 달성되는 지점에서의 함수의 도함수를 포함한다.  
즉, $f(x) = \sup_{\alpha \in \mathcal{A}} f_\alpha(x)$이고  
$f_\alpha(x)$가 모든 $\alpha$에 대해 $x$에 대해 볼록(convex)하다면,  
$\partial f_\beta(x) \in \partial f$가 성립한다.  
(단, $\beta = \arg\sup_{\alpha \in \mathcal{A}} f_\alpha(x)$인 경우)  

이는 대응하는 $G$가 주어졌을 때  
최적의 $D$에서 $p_g$에 대해  
경사 하강법(gradient descent) 업데이트를 계산하는 것과 같다.  

$\sup_D U(p_g, D)$는 $p_g$에 대해 볼록(convex)하며,  
정리 1(Theorem 1)에서 증명된 바와 같이  
유일한 전역 최적해(global optima)를 가진다.  
따라서 $p_g$를 충분히 작은 단계로 업데이트한다면,  
$p_g$는 $p_x$로 수렴한다.  
이로써 증명이 완료된다. □  

> 이 증명은 “GAN의 학습이 실제로 수렴하는가?”를  
> 수학적으로 보여주는 핵심 부분이다.  
>  
> 즉, 생성 분포 $p_g$가 반복적인 학습 과정을 통해  
> 실제 데이터 분포 $p_{\text{data}}$에 점점 가까워진다는 것을  
> 이론적으로 증명하려는 것이다.  
>  
> ---
>  
> ① $V(G, D)$를 $p_g$의 함수로 본다는 의미  
>  
> $V(G, D) = U(p_g, D)$라는 표현은  
> 생성자가 만들어내는 분포 $p_g$를  
> 하나의 수학적 변수로 보고 분석한다는 뜻이다.  
>  
> 즉, 파라미터 $\theta_g$를 직접 다루는 대신,  
> “이 파라미터들이 만들어내는 분포 $p_g$”를  
> 수학적으로 다루는 형태로 바꾼 것이다.  
>  
> 이렇게 하면 “GAN 학습이 분포 공간(distribution space)에서  
> 어떻게 움직이는지”를 수학적으로 해석할 수 있게 된다.  
>  
> ---
>  
> ② $U(p_g, D)$가 $p_g$에 대해 볼록(convex)하다는 의미  
>  
> $U(p_g, D)$가 볼록이라는 말은,  
> 이 함수가 여러 개의 지역 최소값(local minima)이 아니라  
> 하나의 전역 최소값(global minimum) 만 가진다는 뜻이다.  
>  
> 즉, 학습이 어느 지점에서 시작하든  
> 결국 동일한 해에 수렴한다는 것을 보장한다.  
>  
> GAN의 경우 이 전역 최소값은  
> $p_g = p_{\text{data}}$일 때 달성된다.  
>  
> ---
>  
> ③ “볼록 함수들의 상한(supremum)에 대한 부분도함수(subderivative)”란?  
>  
> 이 부분은 조금 수학적으로 보이지만,  
> GAN의 수렴성을 증명하기 위한 핵심 원리이다.  
>  
> 여러 개의 함수 $f_\alpha(x)$가 있고,  
> 그중 최댓값을 택해 만든 함수를 다음과 같이 정의하자.
>  
> $$
> f(x) = \sup_{\alpha \in \mathcal{A}} f_\alpha(x)
> $$
>  
> 여기서 $\sup$는 “상한(supremum)” 즉, 가능한 최대값을 의미한다.  
>  
> 각 $f_\alpha(x)$가 모두 볼록(convex)하다면,  
> 그 중 최댓값을 주는 함수의 기울기(도함수) 가  
> 전체 함수 $f(x)$의 부분도함수(subderivative)에 포함된다는 성질이 있다.  
>  
> 즉,  
>
> $$
> \partial f_\beta(x) \in \partial f(x)
> \quad \text{단,} \quad
> \beta = \arg\sup_{\alpha \in \mathcal{A}} f_\alpha(x)
> $$
>  
> 쉽게 말해,  
> “여러 함수 중 최댓값을 만드는 함수의 기울기 방향이  
> 전체 함수의 기울기 방향과 동일하다”는 뜻이다.  
>  
> ---
>  
> ④ GAN에 이 개념을 적용하면?  
>  
> GAN에서의 목적 함수는  
>  
> $$
> V(G, D) = U(p_g, D)
> $$
>  
> 로 쓸 수 있으며,  
> 여기서 $\sup_D U(p_g, D)$는  
> 각 $p_g$에 대해 최적의 판별자 $D$를 선택했을 때의  
> 최대값을 의미한다.  
>  
> 위의 일반 성질에 따라,  
> $\sup_D U(p_g, D)$는 $p_g$에 대해 여전히 볼록(convex)하다.  
>  
> 따라서 $p_g$를 경사 하강법(gradient descent)으로  
> 조금씩 업데이트하면,  
> 항상 전역 최적점(global optimum) 쪽으로 이동하게 된다.  
>  
> 즉, 잘못된 방향으로 수렴하거나  
> 지역 최소값에 빠질 위험이 없다.  
>  
> ---
>  
> ⑤ 경사 하강법으로의 연결  
>  
> “$G$가 주어졌을 때 최적의 $D$에서 $p_g$를 업데이트한다”는 말은,  
> $p_g$가 다음 식의 기울기(gradient)를 따라  
> 갱신된다는 뜻이다.
>  
> $$
> p_g \leftarrow p_g - \eta \nabla_{p_g} U(p_g, D^*)
> $$
>  
> ($\eta$는 학습률)  
>  
> 이 업데이트 방향은  
> “현재의 $p_g$가 진짜 데이터 분포 $p_{\text{data}}$에 더 가까워지도록”  
> 유도한다.  
>  
> 따라서 작은 학습률로 반복적으로 업데이트하면,  
> $p_g$는 점진적으로 $p_{\text{data}}$로 수렴한다.  
>  
> ---
>  
> ⑥ 실제 구현과의 연결  
>  
> 실제로는 $p_g$를 직접 다루지 않고  
> 생성자 $G(z; \theta_g)$의 파라미터 $\theta_g$를 업데이트한다.  
>  
> 그러나 $G$가 만들어내는 분포 $p_g$는  
> $\theta_g$의 함수이므로,  
> $\theta_g$를 업데이트하는 것은 곧  
> $p_g$를 변화시키는 것과 동일하다.  
>  
> 따라서 이론적으로는  
> “$p_g$를 직접 경사 하강법으로 갱신하는 것”과  
> “$G$의 파라미터를 학습시키는 것”이  
> 같은 의미를 가진다.  
>  
> ---
>  
> ⑦ 결론  
>  
> 결국 이 증명은 다음을 보여준다.  
>  
> - $U(p_g, D)$는 $p_g$에 대해 볼록하므로 안정적인 수렴 구조를 가진다.  
> - 최적의 $D$를 사용할 경우,  
>   $p_g$의 업데이트 방향은 항상 $p_{\text{data}}$ 쪽을 향한다.  
> - 충분히 작은 학습률로 반복하면  
>   $p_g$는 점차 $p_{\text{data}}$로 수렴한다.  
>  
> 따라서 GAN의 학습 과정은 수학적으로도 안정된 수렴 구조를 가지며,  
> 생성 분포가 점점 실제 데이터 분포로 가까워지는  
> 최적화 절차임을 이 증명이 보여준다.  

---

실제로는, 적대적 신경망(adversarial nets)은  
함수 $G(z; \theta_g)$를 통해  
$p_g$ 분포의 제한된 집합(limited family)을 표현한다.  
그리고 우리는 $p_g$ 자체를 직접 최적화하지 않고,  
대신 $\theta_g$를 최적화한다.  

다층 퍼셉트론(multilayer perceptron)을 이용하여 $G$를 정의하면,  
매개변수 공간(parameter space)에서  
여러 개의 임계점(critical points)이 생기게 된다.  

그러나 실제 실험에서 다층 퍼셉트론의 탁월한 성능은  
이론적 보장이 부족함에도 불구하고,  
이들이 충분히 합리적인 모델임을 시사한다.  

---

## 5 실험 (Experiments)

우리는 MNIST [23], Toronto Face Database (TFD) [28], CIFAR-10 [21]을 포함한  
다양한 데이터셋에서 적대적 신경망(adversarial nets)을 학습시켰다.  

생성자 네트워크(generator net)는  
렐루(Rectified Linear Unit, ReLU) [19, 9] 활성화 함수와  
시그모이드(sigmoid) 활성화 함수를 혼합하여 사용하였으며,  
판별자 네트워크(discriminator net)는  
맥스아웃(maxout) [10] 활성화 함수를 사용하였다.  

드롭아웃(dropout) [17]은  
판별자 네트워크의 학습 과정에서 적용되었다.  

우리의 이론적 프레임워크는  
생성자의 중간 계층(intermediate layers)에서도  
드롭아웃이나 기타 잡음을 사용하는 것을 허용하지만,  
본 실험에서는 생성자 네트워크의 가장 하위(bottommost) 계층에만  
잡음(noise)을 입력으로 주었다.  

---

테스트 세트의 데이터가 $p_g$ 하에서  
나타날 확률(probability)을 추정하기 위해,  
생성자 $G$로부터 생성된 샘플에  
가우시안 파르젠 윈도우(Gaussian Parzen window)를 적합시켜(fit)  
그 분포 하에서의 로그가능도(log-likelihood)를 계산하였다.  

> 위 문장은 “GAN이 생성한 분포가 실제 데이터와 얼마나 비슷한가?”를  
> 수치적으로 평가하는 방법을 설명한 것이다.  
>  
> GAN은 명시적인 확률 분포 $p_g(x)$를 직접 계산할 수 없기 때문에  
> 생성된 샘플들을 이용해 가짜로 근사한 확률 밀도 함수(probability density function) 를 만든다.  
>  
> 이를 위해 사용하는 방법이 가우시안 파르젠 윈도우(Gaussian Parzen window) 다.  
>  
> 이 방법은 다음과 같은 아이디어를 기반으로 한다.  
>  
> (1) 생성자 $G$로부터 다수의 샘플 $\{x_1, x_2, ..., x_n\}$ 을 생성한다.  
> (2) 각 샘플 주위에 가우시안(정규분포) 커널을 하나씩 배치한다.  
> (3) 모든 커널의 합으로 하나의 근사 확률 분포 $\hat{p}_g(x)$를 만든다.  
>  
> 수식으로는 다음과 같다.  
>  
> $$
> \hat{p}_g(x) = \frac{1}{n} \sum_{i=1}^n 
> \frac{1}{(2\pi\sigma^2)^{d/2}}
> \exp\left(-\frac{\|x - x_i\|^2}{2\sigma^2}\right)
> $$
>  
> 여기서 $\sigma$는 각 가우시안 커널의 너비(분산)이며,  
> 검증 세트(validation set)를 이용해 교차 검증으로 결정한다.  
>  
> 이후, 이 근사 분포 $\hat{p}_g$를 이용해  
> 테스트 세트의 데이터가 이 분포에서 얼마나 잘 설명되는지를  
> 로그가능도(log-likelihood)로 평가한다.  
>  
> 즉,  
> - 파르젠 윈도우(Parzen window) 는 “샘플들을 통해 분포를 추정하는 방법”이고,  
> - 로그가능도(log-likelihood) 는 “테스트 데이터가 이 추정된 분포에서 나올 확률의 로그값”이다.  
>  
> 따라서 이 절차는 “GAN이 생성한 분포가 실제 데이터 분포를 얼마나 잘 근사하고 있는지”를  
> 수치적으로 평가하기 위한 통계적 측정 과정이라 할 수 있다.

가우시안의 $\sigma$ 매개변수는  
검증 세트(validation set)를 사용한 교차 검증(cross validation)을 통해 결정하였다.  

이 절차는 Breuleux et al. [8]에 의해 처음 제안되었으며,  
정확한 가능도(exact likelihood)를 계산할 수 없는  
여러 생성 모델들 [25, 3, 5]에 적용되어 왔다.  

결과는 표 1(Table 1)에 보고하였다.  

---

**표 1:** 파르젠 윈도우(Parzen window) 기반 로그가능도(log-likelihood) 추정치.  

MNIST에 대해 보고된 수치는  
테스트 세트의 샘플들에 대한 평균 로그가능도(mean log-likelihood)이며,  
각 샘플에 대해 계산된 평균의 표준오차(standard error of the mean)가 함께 제시되어 있다.  

TFD의 경우,  
데이터셋의 각 폴드(fold)에 대해 표준오차를 계산하였으며,  
각 폴드의 검증 세트(validation set)를 이용해  
서로 다른 $\sigma$ 값을 선택하였다.  

TFD에서는 각 폴드마다 $\sigma$를 교차 검증(cross validation)을 통해 선택하였고,  
각 폴드의 평균 로그가능도(mean log-likelihood)를 계산하였다.  

MNIST의 경우,  
이진(binary) 데이터셋이 아닌  
실수(real-valued) 버전의 데이터셋을 사용한  
다른 모델들과의 비교를 수행하였다.  

<img src="/assets/img/paper/gan/image_2.png" alt="image" width="400px"> 

---

이러한 가능도 추정 방식은  
분산(variance)이 다소 높고,  
고차원(high-dimensional) 공간에서는 성능이 좋지 않지만,  
현재로서는 사용 가능한 방법 중 가장 적절한 접근법이다.  

직접적인 가능도 계산은 불가능하지만  
샘플링은 가능한 생성 모델의 발전은  
이러한 모델들을 어떻게 평가할 것인가에 대한  
추가적인 연구 필요성을 제시한다.  

---

그림 2와 그림 3에는  
학습 이후 생성자 네트워크로부터 샘플링된 결과를 보여준다.  

이 샘플들이 기존 방법들로 생성된 샘플보다  
우수하다고 주장하는 것은 아니지만,  
적어도 현재 문헌에 보고된  
우수한 생성 모델들과 경쟁할 만한 수준이라고 생각한다.  

또한 이러한 결과는  
적대적 학습(adversarial framework)의 잠재력을 잘 보여준다.

---

**그림 2:** 모델로부터 생성된 샘플의 시각화.  

가장 오른쪽 열(rightmost column)은  
각 샘플과 가장 가까운 학습 예시(nearest training example)를 보여주며,  
이를 통해 모델이 학습 데이터를 단순히 암기(memorize)한 것이 아님을 입증한다.  

샘플들은 공정한(random) 추출 결과이며,  
임의로 선택된(cherry-picked) 예시가 아니다.  

대부분의 다른 심층 생성 모델(deep generative models)의 시각화와 달리,  
이 그림들은 은닉 유닛(hidden units)의 샘플이 주어졌을 때의  
조건부 평균(conditional mean)이 아니라,  
모델 분포(model distribution) 로부터 실제로 샘플링된 결과를 보여준다.  

또한, 이 샘플들은  
마르코프 연쇄 혼합(Markov chain mixing)에 의존하지 않기 때문에  
상호 독립적(uncorrelated)이다.  

(a) MNIST  
(b) TFD  
(c) CIFAR-10 (완전 연결 모델, fully connected model)  
(d) CIFAR-10 (합성곱 판별자(convolutional discriminator)와  
“디컨볼루셔널(deconvolutional)” 생성자(generator))

<img src="/assets/img/paper/gan/image_3.png" alt="image" width="800px"> 

---

**그림 3:** 완전 모델(full model)의 $z$ 공간에서  
좌표들 사이를 선형적으로 보간(linearly interpolating)하여 얻은 숫자들(digits).  

<img src="/assets/img/paper/gan/image_4.png" alt="image" width="800px"> 

---

## 6 장점과 단점 (Advantages and Disadvantages)

이 새로운 프레임워크는  
기존의 모델링 프레임워크들에 비해  
장점과 단점을 모두 가진다.  

단점은 주로  
$p_g(x)$의 명시적인 표현이 존재하지 않는다는 점과,  
학습 중에 $D$가 $G$와 잘 동기화되어야 한다는 점이다.  

특히, $G$가 $D$를 업데이트하지 않은 채  
너무 오래 학습되면,  
“Helvetica 시나리오(Helvetica scenario)”라고 불리는 현상이 발생할 수 있다.  

이 경우, $G$는  
$p_{\text{data}}$를 충분히 다양하게 모델링하지 못하고,  
너무 많은 $z$ 값들을 동일한 $x$ 값으로 붕괴(collapse)시킨다.  

이 문제는  
볼츠만 머신(Boltzmann machine)의 음의 연쇄(negative chains)가  
학습 단계 사이에서 꾸준히 최신 상태로 유지되어야 하는 것과 유사하다.  

---

장점은 마르코프 연쇄(Markov chains)를 전혀 사용할 필요가 없고,  
그래디언트(gradient)는 오직 역전파(backpropagation)를 통해 얻을 수 있으며,  
학습 중에 추론(inference)이 필요하지 않으며,  
다양한 함수들을 모델에 통합할 수 있다는 점이다.  

표 2는  
생성적 적대 신경망(generative adversarial nets)과  
다른 생성 모델링 접근법들을 비교하여 요약한다.  

---

**표 2**: 생성 모델링에서의 과제들(Challenges in generative modeling):  
모델이 관련된 주요 연산들 각각에 대해,  
심층 생성 모델링(deep generative modeling)의  
다양한 접근 방식들이 직면하는 어려움(difficulties)을 요약한 것.  

| 구분 | 심층 유향 그래프 모델 | 심층 무향 그래프 모델 | 생성 오토인코더 | 적대적 모델 |
|:--|:--|:--|:--|:--|
| 학습 | 학습 중 추론이 필요함 | 학습 중 추론이 필요하며,<br>MCMC가 분할 함수의<br>그래디언트를<br>근사하는 데 필요함 | 혼합과 재구성 생성력 사이의<br>균형이 강제됨 | 판별자와 생성자의<br>동기화가 필요함.<br>Helvetica |
| 추론 | 학습된 근사 추론 | 변분 추론 | MCMC 기반 추론 | 학습된 근사 추론 |
| 샘플링 | 어려움 없음 | 마르코프 연쇄가 필요함 | 마르코프 연쇄가 필요함 | 어려움 없음 |
| 확률분포 평가 $p(x)$ | 계산 불가능하며,<br>AIS로 근사 가능 | 계산 불가능하며,<br>AIS로 근사 가능 | 명시적으로 표현되지 않으며,<br>파르젠 밀도 추정으로 근사 가능 | 명시적으로 표현되지 않으며,<br>파르젠 밀도 추정으로 근사 가능 |
| 모델 설계 | 거의 모든 모델이<br>극도로 어려움을 겪음 | 여러 특성을 보장하기 위해<br>신중한 설계가 필요함 | 미분 가능한 어떤 함수라도<br>이론적으로 허용됨 | 미분 가능한 어떤 함수라도<br>이론적으로 허용됨 |

---

앞서 언급한 장점들은 주로 계산적(computational) 이점이다.  

그러나 적대적 모델(adversarial models)은  
통계적(statistical) 측면에서도 이점을 가질 수 있다.  

생성자 네트워크(generator network)는  
데이터 예시(data examples)로 직접 업데이트되지 않고,  
판별자를 통과한 그래디언트(gradient)에 의해서만 업데이트되기 때문이다.  

이는 입력의 구성 요소들이  
생성자의 파라미터에 직접 복사(copy)되지 않음을 의미한다.  

또한 적대적 네트워크(adversarial networks)는  
매우 날카롭거나(sharp), 심지어 퇴화(degenerate)된 분포까지도 표현할 수 있다.  

반면, 마르코프 연쇄에 기반한 방법들은  
연쇄(chain)들이 모드(mode) 간을 혼합(mix)할 수 있도록 하기 위해  
분포가 어느 정도 흐릿해야(blurry) 한다.

---

## 7 결론 및 향후 연구 (Conclusions and future work)

이 프레임워크는 여러 가지 직접적인 확장을 허용한다.

1. 조건부 생성 모델 $p(x \mid c)$은  
$c$를 생성자 $G$와 판별자 $D$ 모두의 입력으로 추가함으로써 얻을 수 있다.

2. 학습된 근사 추론(learned approximate inference)은  
$x$가 주어졌을 때 $z$를 예측하도록  
보조 네트워크(auxiliary network)를 학습시킴으로써 수행될 수 있다.  
이는 웨이크-슬립 알고리즘(wake-sleep algorithm) [15]에 의해  
학습된 추론 네트워크와 유사하지만,  
생성 네트워크 학습이 완료된 후  
고정된 생성자 네트워크에 대해  
추론 네트워크를 학습시킬 수 있다는 장점이 있다.

3. $x$의 인덱스 집합 중 일부인 $S$에 대해  
모든 조건부 분포 $p(x_S \mid x_{\not S})$를 근사적으로 모델링할 수 있다.  
이는 파라미터를 공유하는 조건부 모델들의 집합을 학습함으로써 가능하다.  
본질적으로, 적대적 네트워크(adversarial nets)를 사용하여  
결정론적(deteministic) MP-DBM [11]의  
확률적 확장(stochastic extension)을 구현할 수 있다.

   > 이 부분은 GAN을 조건부 확률 모델로 확장할 수 있다는 의미이다.  
   >  
   > 예를 들어, 입력 벡터 $x = (x_1, x_2, ..., x_n)$ 중 일부 요소 $x_S$만 관측되고  
   > 나머지 $x_{\not S}$는 가려져 있을 때,  
   > “관측된 값으로부터 가려진 값을 예측하는 분포”,  
   > 즉 조건부 분포 $p(x_S \mid x_{\not S})$를 학습할 수 있다는 뜻이다.  
   >  
   > 이때 모든 가능한 부분 집합 $S$에 대해 각각의 조건부 분포를  
   > 따로 학습하는 대신,  
   > 공통된 파라미터를 공유하는 조건부 모델들의 집합을  
   > 동시에 학습시켜 효율적으로 근사할 수 있다.  
   >  
   > 다시 말해, GAN을 이용하면  
   > “입력의 일부를 주었을 때 나머지를 생성하는”  
   > 확률적(stochastic) 모델을 구축할 수 있으며,  
   > 이는 기존의 결정론적(deteministic) 모델인  
   > MP-DBM (Multi-Prediction Deep Boltzmann Machine)을  
   > 확률적 형태로 확장한 것이라고 볼 수 있다.  

4. 준지도 학습(semi-supervised learning):  
판별자(discriminator) 또는 추론 네트워크(inference net)에서  
얻은 특징(feature)은  
라벨이 제한된 데이터가 주어졌을 때  
분류기의 성능 향상에 도움을 줄 수 있다.

5. 효율성 개선(Efficiency improvements):  
생성자 $G$와 판별자 $D$의 조정을 더 잘 수행하거나,  
학습 중 $z$를 샘플링할 더 적절한 분포를 결정하기 위한  
더 나은 방법을 고안함으로써  
훈련 속도를 크게 가속화할 수 있다.

이 논문은 적대적 모델링 프레임워크(adversarial modeling framework)의 실행 가능성을 입증하였으며,  
이러한 연구 방향들이 유용함을 시사한다.

---

## 감사의 글 (Acknowledgments)

우리는 유익한 논의를 제공한  
Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume Alain,  
그리고 Jason Yosinski에게 감사를 표한다.  

Yann Dauphin은 자신의 파르젠 윈도우(Parzen window) 평가 코드를 공유해 주었다.  

우리는 또한 Pylearn2 [12]와 Theano [7, 1]의 개발자들에게 감사를 드리며,  
특히 Frédéric Bastien에게는  
본 프로젝트를 지원하기 위해 Theano 기능을 신속하게 추가해 준 점에  
깊이 감사드린다.  

Arnaud Bergeron은 LaTeX 조판(typesetting)에 있어  
필요했던 지원을 제공하였다.  

우리는 또한  
연구 자금을 지원해 준 CIFAR와 캐나다 리서치 체어(Canada Research Chairs),  
그리고 계산 자원을 제공한 Compute Canada와 Calcul Québec에  
감사의 뜻을 전한다.  

Ian Goodfellow는 2013년 Google 딥러닝 펠로우십(Google Fellowship in Deep Learning)의  
지원을 받았다.  

마지막으로, 우리의 창의력을 자극해 준  
Les Trois Brasseurs에게 감사의 마음을 전한다.  

---

## 참고문헌 (References)

[1] Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., 그리고 Bengio, Y. (2012).  
*Theano: new features and speed improvements.*  
Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.  

[2] Bengio, Y. (2009).  
*Learning deep architectures for AI.*  
Now Publishers.  

[3] Bengio, Y., Mesnil, G., Dauphin, Y., 그리고 Rifai, S. (2013a).  
*Better mixing via deep representations.*  
In *ICML’13.*  

[4] Bengio, Y., Yao, L., Alain, G., 그리고 Vincent, P. (2013b).  
*Generalized denoising auto-encoders as generative models.*  
In *NIPS26.* NIPS Foundation.  

[5] Bengio, Y., Thibodeau-Laufer, E., 그리고 Yosinski, J. (2014a).  
*Deep generative stochastic networks trainable by backprop.*  
In *ICML’14.*  

[6] Bengio, Y., Thibodeau-Laufer, E., Alain, G., 그리고 Yosinski, J. (2014b).  
*Deep generative stochastic networks trainable by backprop.*  
In *Proceedings of the 30th International Conference on Machine Learning (ICML’14).*  

[7] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., 그리고 Bengio, Y. (2010).  
*Theano: a CPU and GPU math expression compiler.*  
In *Proceedings of the Python for Scientific Computing Conference (SciPy).* Oral Presentation.  

[8] Breuleux, O., Bengio, Y., 그리고 Vincent, P. (2011).  
*Quickly generating representative samples from an RBM-derived process.*  
*Neural Computation*, 23(8), 2053–2073.  

[9] Glorot, X., Bordes, A., 그리고 Bengio, Y. (2011).  
*Deep sparse rectifier neural networks.*  
In *AISTATS’2011.*  

[10] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., 그리고 Bengio, Y. (2013a).  
*Maxout networks.*  
In *ICML’2013.*  

[11] Goodfellow, I. J., Mirza, M., Courville, A., 그리고 Bengio, Y. (2013b).  
*Multi-prediction deep Boltzmann machines.*  
In *NIPS’2013.*  

[12] Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra, J., Bastien, F., 그리고 Bengio, Y. (2013c).  
*Pylearn2: a machine learning research library.*  
*arXiv preprint* [arXiv:1308.4214](https://arxiv.org/abs/1308.4214){:target="_blank"}.  

[13] Gutmann, M., 그리고 Hyvarinen, A. (2010).  
*Noise-contrastive estimation: A new estimation principle for unnormalized statistical models.*  
In *AISTATS’2010.*  

[14] Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T., 그리고 Kingsbury, B. (2012a).  
*Deep neural networks for acoustic modeling in speech recognition.*  
*IEEE Signal Processing Magazine*, 29(6), 82–97.  

[15] Hinton, G. E., Dayan, P., Frey, B. J., 그리고 Neal, R. M. (1995).  
*The wake-sleep algorithm for unsupervised neural networks.*  
*Science*, 268, 1558–1161.  

[16] Hinton, G. E., Osindero, S., 그리고 Teh, Y. (2006).  
*A fast learning algorithm for deep belief nets.*  
*Neural Computation*, 18, 1527–1554.  

[17] Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., 그리고 Salakhutdinov, R. (2012b).  
*Improving neural networks by preventing co-adaptation of feature detectors.*  
Technical report, *arXiv:1207.0580*.  

[18] Hyvärinen, A. (2005).  
*Estimation of non-normalized statistical models using score matching.*  
*Journal of Machine Learning Research*, 6.  

[19] Jarrett, K., Kavukcuoglu, K., Ranzato, M., 그리고 LeCun, Y. (2009).  
*What is the best multi-stage architecture for object recognition?*  
In *Proceedings of the International Conference on Computer Vision (ICCV’09)*, pp. 2146–2153. IEEE.  

[20] Kingma, D. P., 그리고 Welling, M. (2014).  
*Auto-encoding variational bayes.*  
In *Proceedings of the International Conference on Learning Representations (ICLR).*  

[21] Krizhevsky, A., 그리고 Hinton, G. (2009).  
*Learning multiple layers of features from tiny images.*  
Technical report, University of Toronto.  

[22] Krizhevsky, A., Sutskever, I., 그리고 Hinton, G. (2012).  
*ImageNet classification with deep convolutional neural networks.*  
In *NIPS’2012.*  

[23] LeCun, Y., Bottou, L., Bengio, Y., 그리고 Haffner, P. (1998).  
*Gradient-based learning applied to document recognition.*  
*Proceedings of the IEEE*, 86(11), 2278–2324.  

[24] Rezende, D. J., Mohamed, S., 그리고 Wierstra, D. (2014).  
*Stochastic backpropagation and approximate inference in deep generative models.*  
Technical report, *arXiv:1401.4082*.  

[25] Rifai, S., Bengio, Y., Dauphin, Y., 그리고 Vincent, P. (2012).  
*A generative process for sampling contractive auto-encoders.*  
In *ICML’12.*  

[26] Salakhutdinov, R., 그리고 Hinton, G. E. (2009).  
*Deep Boltzmann machines.*  
In *AISTATS’2009*, pp. 448–455.  

[27] Smolensky, P. (1986).  
*Information processing in dynamical systems: Foundations of harmony theory.*  
In D. E. Rumelhart and J. L. McClelland (Eds.), *Parallel Distributed Processing*, Vol. 1, Ch. 6, pp. 194–281. MIT Press, Cambridge.  

[28] Susskind, J., Anderson, A., 그리고 Hinton, G. E. (2010).  
*The Toronto face dataset.*  
Technical Report UTML TR 2010-001, University of Toronto.  

[29] Tieleman, T. (2008).  
*Training restricted Boltzmann machines using approximations to the likelihood gradient.*  
In W. W. Cohen, A. McCallum, 그리고 S. T. Roweis (Eds.), *ICML 2008*, pp. 1064–1071. ACM.  

[30] Vincent, P., Larochelle, H., Bengio, Y., 그리고 Manzagol, P.-A. (2008).  
*Extracting and composing robust features with denoising autoencoders.*  
In *ICML 2008.*  

[31] Younes, L. (1999).  
*On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates.*  
*Stochastics and Stochastic Reports*, 65(3), 177–228.  
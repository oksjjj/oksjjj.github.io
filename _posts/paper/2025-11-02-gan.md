---
layout: post
title: "[논문] Generative Adversarial Nets"
date: 2025-11-02 07:00:00 +0900
categories:
  - "논문"
tags: []
---
> 논문 출처  
> Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., & Bengio, Y.  
> Generative Adversarial Nets.  
> Advances in Neural Information Processing Systems (NeurIPS), 2014.  
> <a href="https://arxiv.org/abs/1406.2661" target="_blank">🔗 원문 링크 (arXiv: 1406.2661)</a>

저자  
- Ian J. Goodfellow  
- Jean Pouget-Abadie*  
- Mehdi Mirza  
- Bing Xu  
- David Warde-Farley  
- Sherjil Ozair<sup>†</sup>  
- Aaron Courville  
- Yoshua Bengio<sup>‡</sup>  

(Université de Montréal, Département d’informatique et de recherche opérationnelle)

> <sup>*</sup>Jean Pouget-Abadie는 École Polytechnique에서  
> Université de Montréal을 방문 중이다.  
> 
> <sup>†</sup>Sherjil Ozair는 인도 공과대학 델리(Indian Institute of Technology Delhi)에서  
> Université de Montréal을 방문 중이다.  
> 
> <sup>‡</sup>Yoshua Bengio는 CIFAR 선임 연구원(Senior Fellow)이다.

---

## 초록 (Abstract)

본 논문에서는 적대적(adversarial) 과정을 통해  
생성 모델(generative models)을 추정하는 새로운 프레임워크를 제안한다.  
이 프레임워크에서는 두 개의 모델을 동시에 학습한다:  
데이터 분포를 포착하는 생성 모델 $G$,  
그리고 주어진 샘플이 실제 데이터로부터 왔는지  
혹은 $G$에 의해 생성된 것인지를 판별하는  
판별 모델(discriminative model) $D$ 이다.  

$G$의 학습 목표는 $D$가 오판(making a mistake)할  
확률을 최대화하는 것이다.  
이 프레임워크는 미니맥스(minimax) 형태의 2인 게임(two-player game)에 해당한다.  

임의의 함수 공간에서 $G$와 $D$에 대해  
유일한 해(unique solution)가 존재하며,  
그때 $G$는 데이터 분포를 완벽히 복원하고  
$D$는 모든 지점에서 $\frac{1}{2}$의 확률을 출력한다.  

$G$와 $D$가 다층 퍼셉트론(multilayer perceptron)으로 정의된 경우,  
전체 시스템은 역전파(backpropagation)를 통해 학습이 가능하다.  

또한 이 프레임워크는 학습이나 샘플 생성 중에  
마르코프 체인(Markov chain)이나  
전개형 근사 추론 네트워크(unrolled approximate inference network)를  
사용할 필요가 없다.  

마지막으로, 본 논문은  
정성적(qualitative) 및 정량적(quantitative) 평가를 통해  
이 프레임워크의 잠재력을 입증한다.

---

## 1 서론 (Introduction)

딥러닝의 가능성(promise)은  
자연 이미지, 음성 신호를 포함한 오디오 파형,  
자연어 코퍼스의 기호(symbol) 등  
인공지능 응용에서 접하게 되는 다양한 데이터 유형들에 대한  
확률 분포를 표현하는  
풍부하고 계층적인(hierarchical) 모델 [2]을 발견하는 데 있다.  

지금까지 딥러닝의 가장 두드러진 성공 사례들은  
주로 고차원적이고 풍부한 센싱 입력(sensory input)을  
클래스 레이블로 매핑하는 판별 모델(discriminative model) [14, 22]에 있었다.  

이러한 두드러진 성공들은 주로  
잘 동작하는 그래디언트를 가지는  
부분 선형 유닛(piecewise linear units) [19, 9, 10]을 사용하는,  
역전파(backpropagation)와 드롭아웃(dropout) 알고리즘에 기반해왔다.  

반면, 생성 모델(generative model)은  
최대우도추정(maximum likelihood estimation) 및 관련 전략에서  
발생하는 계산 불가능한(intractable) 확률 계산들을 근사하기 어려운 점,  
그리고 생성 맥락에서 부분 선형 단위의 이점을 활용하기 어려운 점 때문에  
상대적으로 덜 큰 영향을 미쳐왔다.  

이에 우리는 이러한 어려움을 우회하는  
새로운 생성 모델 추정 절차를 제안한다.<sup>1</sup>  

> <sup>1</sup>모든 코드와 하이퍼파라미터는  
> <a href="http://www.github.com/goodfeli/adversarial" target="_blank">http://www.github.com/goodfeli/adversarial</a>  
> 에서 확인할 수 있다.  

---

제안된 적대적 네트워크(adversarial nets) 프레임워크에서,  
생성 모델은 하나의 적수(adversary)와 맞서게 된다:  
샘플이 모델 분포로부터 온 것인지  
혹은 데이터 분포로부터 온 것인지를  
판별하도록 학습하는 판별 모델(discriminative model).    

생성 모델은 위조지폐를 만들어  
들키지 않고 사용하는 것을 시도하는  
위조범 집단에 비유할 수 있으며,  
판별 모델은 이러한 위조지폐를 탐지하려는  
경찰에 비유할 수 있다.  

이 게임에서의 경쟁은  
양쪽 모두가 자신들의 방법을 개선하도록 유도하며,  
결국 위조지폐가 진짜와 구별되지 않을 때까지  
서로의 능력을 향상시키게 된다.  

---

이 프레임워크는 다양한 종류의 모델과 최적화 알고리즘에 대해  
특정한 학습 알고리즘들을 도출할 수 있다.  

본 논문에서는 생성 모델이 무작위 잡음을  
다층 퍼셉트론(multilayer perceptron)을 통해 전달함으로써  
샘플을 생성하고, 판별 모델 또한  
다층 퍼셉트론인 특수한 경우를 탐구한다.  

우리는 이 특수한 경우를 적대적 네트워크(adversarial nets)라 부른다.  

이 경우, 두 모델 모두  
매우 성공적인 역전파(backpropagation)와  
드롭아웃(dropout) 알고리즘 [17]만을 사용하여 학습할 수 있으며,  
생성 모델로부터의 샘플링은  
순전파(forward propagation)만으로 수행할 수 있다.  

근사 추론(approximate inference)이나  
마르코프 연쇄(Markov chain)는 필요하지 않다.  

---

## 2 관련 연구 (Related work)

잠재 변수를 포함한 유향 그래프 모델(directed graphical model)에 대한  
대안(alternative)으로는,  
제한 볼츠만 머신(restricted Boltzmann machines, RBMs) [27, 16],  
딥 볼츠만 머신(deep Boltzmann machines, DBMs) [26] 및  
그 수많은 변형들(variants)과 같은  
잠재 변수를 가진 무향 그래프 모델(undirected graphical model)이 있다.  

> 볼츠만 머신(Boltzmann Machine)은  
> 에너지 기반 모델(Energy-based model)의 한 종류로,  
> 확률적 방식으로 데이터를 모델링하는 생성 신경망이다.  
>  
> 뉴런들이 완전 연결되어 있으며,  
> 각 상태(state)의 확률은 해당 상태의 에너지에 의해 결정된다.  
>  
> 학습의 목표는  
> 데이터에서 관찰된 패턴이 낮은 에너지 값을 가지도록  
> 가중치(weight)를 조정하는 것이다.  
>  
> 확률 분포는  
>
> $$P(x) = \frac{1}{Z} \exp(-E(x))$$  
>
> 의 형태로 정의되며,  
> 여기서 $E(x)$는 에너지 함수(energy function),  
> $Z$는 분할 함수(partition function)이다.  
>  
> 볼츠만 머신은 강력한 표현력을 가지지만,  
> 모든 뉴런 간 연결로 인해 계산량이 매우 크다.  
> 이러한 한계를 완화하기 위해  
> 가시층과 은닉층 사이의 연결만 허용한  
> 제한 볼츠만 머신(Restricted Boltzmann Machine, RBM)이 제안되었다.  

이러한 모델 내의 상호작용(interaction)은  
정규화되지 않은 퍼텐셜 함수(unnormalized potential functions)의 곱으로 표현되며,  
이는 모든 확률 변수 상태에 대한  
전역적인 합산/적분(global summation/integration)에 의해  
정규화(normalized)된다.  

> 이 문장은 에너지 기반 모델(Energy-based model) 의 핵심 구조를 설명한다.  
> 모델 내의 모든 변수 간 관계는 퍼텐셜 함수(potential function) 로 표현되며,  
> 이 함수들은 각 변수 조합의 "에너지" 또는 "적합도"를 나타낸다.  
>  
> 하지만 이러한 퍼텐셜 함수들은 정규화되지 않은 상태(unnormalized) 이므로  
> 확률 분포로 사용하기 위해서는  
> 가능한 모든 상태 조합에 대한 합 또는 적분을 계산하여  
> 분할 함수(partition function) 로 정규화해야 한다.  
>  
> 아래에서 $Z$가 바로 이러한 전역적인 합산/적분(global summation/integration)이다.   
>
> $$P(x) = \frac{1}{Z} \exp(-E(x))$$  

이 양(quantity, 즉, 분할 함수(partition function))과  
그 그래디언트는 가장 단순한 경우를 제외하고는  
계산 불가능(intractable)하다.  
그러나 마르코프 연쇄 몬테카를로(Markov chain Monte Carlo, MCMC) 방법을 통해  
이를 추정할 수는 있다.  

혼합(mixing)은 MCMC에 의존하는 학습 알고리즘들 [3, 5]에  
중대한 문제를 제기한다.  

> 여기서 말하는 혼합(mixing)은  
> 마르코프 연쇄 몬테카를로(MCMC) 샘플링 과정에서  
> 연쇄(chain)가 전체 확률 공간을 얼마나 잘 탐색하는지를 의미한다.  
>  
> 이상적인 경우, MCMC 샘플러는 충분히 빠르게 섞여(mix)  
> 표본들이 서로 독립적이고 분포 전체를 잘 대표해야 한다.  
> 그러나 실제로는 고차원 모델이나 복잡한 에너지 지형(energy landscape)에서는  
> 연쇄가 특정 지역(local mode)에 머무르거나,  
> 분포의 다른 부분으로 잘 이동하지 못하는 문제가 발생한다.  
>  
> 이러한 느린 혼합(slow mixing) 문제는  
> MCMC 기반 학습 알고리즘의 수렴을 어렵게 만들고,  
> 학습된 모델의 품질을 떨어뜨리는 주요 원인이 된다.  

---

딥 빌리프 네트워크(Deep Belief Networks, DBNs) [16]는  
하나의 무향층(undirected layer)과  
여러 개의 유향층(directed layers)을 포함하는  
혼합 모델(hybrid model)이다.  

빠른 근사적 층별(layer-wise) 학습 기준이 존재하지만,  
DBN은 무향 모델과 유향 모델 모두에 관련된  
계산상의 어려움을 겪는다.  

> 딥 빌리프 네트워크(DBN)는  
> 제한 볼츠만 머신(RBM)을 여러 층으로 쌓아 올린 형태의  
> 심층 생성 신경망(deep generative neural network)이다.  
>  
> 맨 아래층은 무향 구조(RBM)로 되어 있어  
> 입력 데이터의 확률 분포를 학습하고,  
> 그 위의 상위 층들은 유향 구조로 되어 있어  
> 상위 특징 표현(higher-level representation)을 학습한다.  
>  
> 학습은 일반적으로 층별(layer-wise) 사전학습(pre-training)으로 수행되며,  
> 이후 전체 네트워크를 미세 조정(fine-tuning)한다.  
>  
> 그러나 무향 모델과 유향 모델의 결합 구조 때문에  
> 계산 복잡도가 높고,  
> 근사 추론(approximate inference)이 필요하다는 단점이 있다.  

---

로그 가능도(log-likelihood)를 근사하거나 경계(bound)하지 않는  
대안적 기준(alternative criteria)들도 제안되어 왔다.  
예를 들어, 스코어 매칭(score matching) [18]과  
노이즈 대비 추정(noise-contrastive estimation, NCE) [13]이 있다.  

이 두 방법 모두,  
학습된 확률 밀도(probability density)가  
정규화 상수(normalization constant)를 제외하고  
해석적으로 명시될 수 있어야 한다.  

여러 층의 잠재 변수(latent variables)를 포함한  
많은 흥미로운 생성 모델들(예: DBN, DBM)에서는  
계산 가능한 형태의 정규화되지 않은 확률 밀도  
(tractable unnormalized probability density)를  
도출하는 것조차 불가능하다.  

노이즈 제거(autoencoder) [30]나  
수축 오토인코더(contractive autoencoder)와 같은  
일부 모델들은,  
RBM에 적용된 스코어 매칭(score matching)과  
매우 유사한 학습 규칙을 가진다.  

NCE에서는, 본 연구와 마찬가지로  
생성 모델을 적합시키기 위해  
판별적 학습 기준(discriminative training criterion)이 사용된다.  
그러나 별도의 판별 모델을 학습하는 대신,  
생성 모델 자체를 이용하여  
고정된 잡음 분포(fixed noise distribution)로부터의 샘플과  
생성된 데이터를 구분한다.  

하지만 NCE는 고정된 잡음 분포를 사용하기 때문에,  
모델이 관측된 변수들의 작은 부분 집합에 대해  
대략적으로 올바른 분포를 학습하고 나면  
학습 속도가 급격히 느려지는 단점을 가진다.  

---

마지막으로, 일부 기법들은  
확률 분포를 명시적으로 정의하지 않고,  
대신 원하는 분포로부터 샘플을 뽑아내도록  
생성 기계(generative machine)를 학습시킨다.  

이 접근법의 장점은  
이러한 생성 기계가 역전파(back-propagation)를 통해  
학습되도록 설계될 수 있다는 점이다.  

이 영역의 대표적인 최근 연구로는  
일반화된 노이즈 제거 오토인코더(generalized denoising auto-encoders) [4]를 확장한  
생성 확률적 네트워크(generative stochastic network, GSN) 프레임워크 [5]가 있다.  
이 두 가지 모두,  
매개변수화된 마르코프 연쇄(parameterized Markov chain)를 정의하는 것으로 볼 수 있다.  
즉, 생성적 마르코프 연쇄의 한 단계를 수행하는 기계의  
매개변수를 학습하는 것이다.  

GSN과 비교했을 때,  
적대적 네트워크(adversarial nets) 프레임워크는  
샘플링을 위해 마르코프 연쇄를 필요로 하지 않는다.  

적대적 네트워크는  
생성 과정에서 피드백 루프(feedback loop)를 필요로 하지 않기 때문에,  
역전파의 성능을 향상시키지만  
피드백 루프에서 사용될 경우  
비한정 활성(unbounded activation) 문제를 가지는  
부분 선형 유닛(piecewise linear units) [19, 9, 10]의 이점을  
더 잘 활용할 수 있다.  

보다 최근의 예로는,  
역전파를 생성 기계 내부로 전파하여 학습시키는  
오토인코딩 변분 베이즈(auto-encoding variational Bayes) [20] 및  
확률적 역전파(stochastic backpropagation) [24]에 대한 연구가 있다.  

---

## 3 적대적 네트워크 (Adversarial nets)

적대적 모델링 프레임워크(adversarial modeling framework)는  
두 모델이 모두 다층 퍼셉트론(multilayer perceptron)일 때  
가장 직접적으로(straightforward) 적용할 수 있다.  

데이터 $x$에 대한 생성자(generator)의 분포 $p_g$를 학습하기 위해,  
입력 잡음 변수(input noise variables) $p_z(z)$에 대한 사전분포(prior)를 정의한 후,  
데이터 공간(data space)으로의 매핑(mapping)을  
$G(z; \theta_g)$로 표현한다.  

여기서 $G$는  
파라미터 $\theta_g$를 가진  
다층 퍼셉트론으로 표현되는  
미분 가능한 함수(differentiable function)이다.  

또한,  
하나의 스칼라(scalar)를 출력하는  
두 번째 다층 퍼셉트론 $D(x; \theta_d)$를 정의한다.  
$D(x)$는  
입력 $x$가 모델 분포 $p_g$가 아니라  
데이터로부터 왔을 확률을 나타낸다.  

$D$는 학습 데이터와 $G$로부터 생성된 샘플 모두에 대해  
올바른 레이블을 할당할 확률을  
최대화하도록 학습된다.  

동시에,  
$G$는 $$\log(1 - D(G(z)))$$ 을 최소화하도록 학습된다: 

다시 말해,  
$D$와 $G$는 다음의 2인 미니맥스(two-player minimax) 게임을 수행한다.  
그 가치 함수(value function) $V(G, D)$는 다음과 같다.

$$
\min_G \max_D V(D, G)
= \mathbb{E}_{x \sim p_{\text{data}}(x)} [\log D(x)]
+ \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))].
\tag{1}
$$

---

다음 절에서 우리는 적대적 네트워크(adversarial nets)에 대한  
이론적 분석을 제시한다.  

이는 본질적으로,  
$G$와 $D$가 충분한 표현 능력(capacity)을 가질 경우,  
즉 비모수적 한계(non-parametric limit)에서,  
학습 기준(training criterion)이  
데이터를 생성하는 분포(data generating distribution)를  
복원할 수 있도록 해준다는 것을 보여준다.  

그 접근 방식에 대한 좀 더 비형식적이며 교육적인 설명은  
그림 1(Figure 1)에 제시되어 있다.  

실제적으로는, 우리는 이 게임을  
반복적(iterative)이고 수치적인(numerical) 접근법으로 구현해야 한다.  

학습의 내부 루프(inner loop)에서  
$D$를 완전히 최적화하는 것은  
계산적으로 매우 부담스럽고,  
유한한 데이터셋(finite datasets)에서는 과적합(overfitting)을 초래할 것이다.  

대신, 우리는 $D$를 $k$ 단계 동안 최적화한 후  
$G$를 한 단계 최적화하는 과정을 번갈아 수행한다.  

이 방법은 $D$가  
그의 최적 해(optimal solution) 근처에서 유지되도록 하며,  
$G$가 충분히 천천히 변화하는 한 안정적으로 작동한다.  

이 전략은 SML/PCD [31, 29]에서  
하나의 학습 단계에서 다음 단계로 넘어갈 때  
마르코프 연쇄(Markov chain)로부터의 샘플을 유지하여  
연쇄의 초기화(burning-in)를 방지하는 방식과 유사하다.  

이 절차는 알고리즘 1(Algorithm 1)에 정식으로 제시되어 있다.  

---

**그림 1:**  
생성적 적대 신경망(generative adversarial nets)은  
판별 분포(discriminative distribution) $D$ (파란색, 점선)를  
동시에 갱신(update)하면서 학습된다.  
이때 $D$는 데이터 생성 분포(data generating distribution) (검정색, 점선) $p_x$로부터의 샘플과  
생성 분포(generative distribution) $p_g$ (녹색, 실선)으로부터의 샘플을  
구별하도록 학습된다.  

아래쪽의 수평선은 $z$가 샘플링되는 영역(domain)을 나타내며,  
이 경우 균등 분포(uniform distribution)이다.  
위쪽의 수평선은 $x$의 영역 일부를 나타낸다.  

위쪽 화살표들은 매핑(mapping) $x = G(z)$이  
변환된 샘플들 위에서 비등 분포(non-uniform distribution) $p_g$를  
어떻게 형성하는지를 보여준다.  

$G$는 $p_g$의 높은 밀도(high density) 영역에서는 수축(contract)하고,  
낮은 밀도(low density) 영역에서는 확장(expand)한다.  

(a) 수렴 근처(convergence near)에서의 적대적 쌍(adversarial pair)을 고려하자.  
이때 $p_g$는 $p_{\text{data}}$와 유사하며,  
$D$는 부분적으로 정확한 분류기(partially accurate classifier)이다.  

(b) 알고리즘의 내부 루프(inner loop)에서  
$D$는 데이터로부터의 샘플을 구별하도록 학습되며,  
그 결과 다음과 같이 수렴한다.  

$$
D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
$$  

(c) $G$가 갱신된 후,  
$D$의 그래디언트(gradient)는  
$G(z)$가 데이터로 분류될 가능성이 높은 영역으로 이동하도록 유도한다.  

(d) 여러 단계의 학습 이후,  
$G$와 $D$가 충분한 용량(capacity)을 가진다면,  
두 모델은 더 이상 개선될 수 없는 지점에 도달한다.  
이때 $p_g = p_{\text{data}}$가 된다.  

판별자(discriminator)는 두 분포를 구별할 수 없으며,  
즉 $D(x) = \frac{1}{2}$가 된다.  

<img src="/assets/img/paper/gan/image_1.png" alt="image" width="800px"> 

> 그림 1은 GAN이 실제로 학습되는 과정을 시각적으로 보여주는 예시다.  
>  
> 검정색 점선은 진짜 데이터의 분포 $p_x$ (또는 $p_{\text{data}}$)를 나타낸다.  
> 즉, 우리가 모델이 닮게 만들고 싶은 "정답 분포"다.  
>  
> 녹색 실선은 생성자 $G$가 만들어내는 가짜 데이터의 분포 $p_g$를 의미한다.  
> 처음에는 이 분포가 진짜 데이터 분포와 전혀 다르다.  
>  
> 파란색 점선은 판별자 $D$가 예측하는 “진짜일 확률”을 나타낸다.  
> 예를 들어 $D(x)=1$에 가까우면 “진짜 데이터일 것 같다”는 뜻이고,  
> $D(x)=0$에 가까우면 “가짜 데이터일 것 같다”는 의미다.  
>  
> 아래쪽의 수평선은 생성자의 입력인 $z$의 공간이다.  
> 이 $z$는 보통 균등 분포(예: -1~1)에서 무작위로 뽑는다.  
>  
> 위쪽의 수평선은 $x=G(z)$를 통해 만들어진 실제 데이터 공간이다.  
> 화살표는 $z$가 $G$를 거쳐 어떻게 $x$로 변환되는지를 나타낸다.  
>  
> $G$는 샘플을 변환하면서,  
> 진짜 데이터가 많은 구간(즉, $p_g$의 밀도가 높은 구간)은 압축(contract) 하고,  
> 데이터가 적은 구간(밀도가 낮은 구간)은 확장(expand) 한다.  
>  
> (a) 학습 초반에는 $p_g$가 아직 $p_{\text{data}}$와 다르기 때문에  
> $D$는 대체로 정확하게 “이건 진짜 / 이건 가짜”를 맞출 수 있다.  
> 이때 $D$는 부분적으로 올바른 분류기(partially accurate classifier)이다.  
>  
> (b) 내부 학습 루프에서 $D$는 진짜와 가짜 샘플을 구별하도록 갱신된다.  
> 최적의 판별자는 다음과 같은 형태를 가진다:  
>  
> $$
> D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
> $$  
>  
> 즉, 어떤 점 $x$가 진짜 데이터에서 나왔을 확률을 계산하는 식이다.  
>  
> (c) 이후 생성자 $G$가 갱신되면,  
> $D$의 그래디언트(gradient)를 참고해  
> $G(z)$가 “진짜처럼 보이는” 구간으로 이동하도록 유도된다.  
> 이 과정을 반복하면서 $G$는 점점 더 진짜 분포에 가까워진다.  
>  
> (d) 여러 번의 반복 학습이 끝나면,  
> $G$와 $D$가 서로를 속이거나 구별할 수 없는 상태에 도달한다.  
> 이때 $p_g = p_{\text{data}}$가 되고,  
> 판별자는 모든 입력에 대해 $D(x) = \frac{1}{2}$,  
> 즉 “진짜일 확률도, 가짜일 확률도 반반”이라고 판단하게 된다.  
>  
> 결과적으로, 생성자는 진짜 데이터와 완전히 구분되지 않는  
> 완벽한 샘플을 만들어낼 수 있게 된다.  

---

**알고리즘 1**  
미니배치 확률적 경사 하강법(minibatch stochastic gradient descent)을 이용한  
생성적 적대 신경망(Generative Adversarial Nets, GAN)의 학습  

판별자(discriminator)에 적용되는 단계 수 $k$는 하이퍼파라미터이며,  
본 논문에서는 계산 비용이 가장 적은 $k = 1$을 사용하였다.  

**for** 학습 반복 횟수(number of training iterations) **do**  

 **for** $k$ 단계 **do**  
  - 잡음 사전분포(noise prior) $p_g(z)$로부터 $m$개의 잡음 샘플 $\lbrace z^{(1)}, \ldots, z^{(m)}\rbrace$을 샘플링한다.  

  - 데이터 생성 분포(data generating distribution) $p_{\text{data}}(x)$로부터 $m$개의 실제 데이터 샘플 $\lbrace x^{(1)}, \ldots, x^{(m)}\rbrace$을 샘플링한다.  

  - 판별자(discriminator)를 다음의 확률적 경사(stochastic gradient)를 따라 **상승(ascending)** 방향으로 갱신한다.  

   $$\nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^{m} [\log D(x^{(i)}) + \log(1 - D(G(z^{(i)})))].$$  

 **end for**  

 - 잡음 사전분포 $p_g(z)$로부터 $m$개의 잡음 샘플 $\{z^{(1)}, \ldots, z^{(m)}\}$을 샘플링한다.  

 - 생성자(generator)를 다음의 확률적 경사를 따라 **하강(descending)** 방향으로 갱신한다.  

  $$\nabla_{\theta_g} \frac{1}{m} \sum_{i=1}^{m} \log(1 - D(G(z^{(i)}))).$$  

**end for**  

경사 기반의 업데이트(gradient-based update)는  
표준 경사 학습 규칙(standard gradient-based learning rule) 중  
어느 것이든 사용할 수 있다.  
본 논문에서는 모멘텀(momentum)을 사용하였다.  

---

실제로는, 식 (1)은 생성자 $G$가 충분히 잘 학습하기에  
충분한 그래디언트(gradient)를 제공하지 못할 수 있다.  

학습 초기에 $G$의 성능이 나쁠 때,  
판별자 $D$는 훈련 데이터와 명확히 다른 샘플들을  
높은 확신(high confidence)으로 쉽게 거부할 수 있다.  

이 경우, $\log(1 - D(G(z)))$ 항이 포화(saturate)되어  
그래디언트가 거의 사라진다.  

따라서 $G$를 $\log(1 - D(G(z)))$를 최소화하도록 학습시키는 대신,  
$\log D(G(z))$를 최대화하도록 학습시킬 수 있다.  

이 목적 함수(objective function)는  
$G$와 $D$의 동적 과정(dynamics)에서  
동일한 고정점(fixed point)을 가지지만,  
학습 초기에 훨씬 더 강한 그래디언트(stronger gradient)를 제공한다.  

---

## 4 이론적 결과 (Theoretical Results)

생성자 $G$는 암묵적으로 확률 분포 $p_g$를 정의하는데,  
이는 $z \sim p_z$일 때 얻어지는 샘플 $G(z)$의 분포로 정의된다.  

따라서, 충분한 표현 능력(capacity)과 학습 시간(training time)이 주어진다면,  
알고리즘 1이 $p_{\text{data}}$의 좋은 추정치(estimator)에  
수렴(converge)하기를 원한다.  

이 절의 결과들은 비모수적(non-parametric) 설정에서 수행된다.  
즉, 확률 밀도 함수(probability density function)의 공간에서  
수렴을 연구함으로써,  
무한한 표현 능력을 가진 모델을 가정하여 분석을 수행한다.  

섹션 4.1에서는, 이 미니맥스 게임이  
$p_g = p_{\text{data}}$일 때 전역 최적해(global optimum)를 가진다는 것을 보일 것이다.  

그리고 섹션 4.2에서는  
알고리즘 1이 식 (1)을 최적화함으로써  
원하는 결과(desired result)를 얻는다는 것을 보일 것이다.  

---
---
layout: post
title: "확률과 통계 기본 개념"
date: 2025-09-23 09:01:00 +0900
categories: ["수학의 기초"]
tags: []
---

## **표본공간 (sample space)**

어떤 실험 또는 시행에서 일어날 수 있는 모든 가능한 결과의 집합을 그 시행에 의한 **표본공간(sample space, $\Omega$)** 이라 한다.  

표본공간을 구성하는 개개의 원소를 **표본점(sample point)** 이라 하고, $n$개의 표본점 $w_1, w_2, \dots, w_n$으로 구성된 표본공간은 다음과 같이 나타낸다.

$$
\Omega = \{ w_1, w_2, \dots, w_n \}
$$

> **예시**  
> - 주사위를 한 번 던질 때 표본공간은  
>   $\Omega = \{1, 2, 3, 4, 5, 6\}$  
> - 동전을 한 번 던질 때 표본공간은  
>   $\Omega = \{\text{앞}, \text{뒤}\}$

---

## **사건 (event)**

표본공간 $\Omega$의 임의의 **부분집합** 을 **사건(event)** 이라 한다.  

- **근원사건(elementary event)** : 원소 한 개만으로 이루어진 사건 $\{w_i\}$  
- **전사건(certain event)** : 표본공간 전체와 동일한 사건  
- **공사건(empty event)** : 아무 원소도 포함하지 않는 사건 $\varnothing$

> **예시**  
> - 주사위를 던질 때 짝수가 나오는 사건  
>   $A = \{2, 4, 6\}$  
> - 동전을 던질 때 앞면이 나오는 사건  
>   $B = \{\text{앞}\}$  
> - 주사위를 던질 때 7이 나오는 사건  
>   $C = \varnothing \quad (\text{공사건})$

---

## **표본공간의 구분**

- **이산 표본공간 (discrete sample space)**  
  표본공간에 속하는 원소가 유한하거나, 무한히 많더라도 countable(셀 수 있는) 경우.  
  예: 주사위를 던졌을 때의 결과, 불량품 개수.

- **연속 표본공간 (continuous sample space)**  
  표본공간에 속하는 원소가 실수 구간처럼 uncountable(셀 수 없는) 경우.  
  예: 전구의 수명, 특정 사건이 발생하기까지의 시간.

---

## **사건의 연산**

- **합사건 (union event)**  

  $$
  A \cup B = \{ w \mid w \in A \ \text{또는}\ w \in B \}
  $$

- **곱사건 (product event)**  

  $$
  A \cap B = \{ w \mid w \in A \ \text{그리고}\ w \in B \}
  $$

- **여사건 (complement event)**  

  $$
  A^c = \{ w \mid w \notin A \}
  $$

- **배반사건 (exclusive event)**  

  $$
  A \cap B = \varnothing
  $$

---

## **사건의 연산 법칙**

1. **교환법칙 (commutative law)**  

   $$
   A \cup B = B \cup A, \quad A \cap B = B \cap A
   $$

2. **결합법칙 (associative law)**  

   $$
   A \cup (B \cup C) = (A \cup B) \cup C
   $$  

   $$
   A \cap (B \cap C) = (A \cap B) \cap C
   $$

3. **분배법칙 (distributive law)**  

   $$
   A \cap (B \cup C) = (A \cap B) \cup (A \cap C)
   $$  

   $$
   A \cup (B \cap C) = (A \cup B) \cap (A \cup C)
   $$

4. **드 모르간 법칙 (De Morgan's law)**  

   $$
   (A \cup B)^c = A^c \cap B^c, \quad (A \cap B)^c = A^c \cup B^c
   $$

---

## **확률을 정의하는 2가지 방법**

### **라플라스 확률 (Laplace probability)**

표본공간의 모든 근원사건이 발생할 가능성이 같을 때, 사건 $A$의 확률은 다음과 같이 정의한다.

$$
P(A) = \frac{n}{N}
$$

- $n$: 사건 $A$에 속하는 경우의 수  
- $N$: 전체 경우의 수  
 
>라플라스 확률은 **고전적 정의(classical definition)** 로, 모든 결과가 동등하게 일어날 가능성이 있다고 가정한다.  
즉, **경험적(empirical)** 상황에서 경우의 수를 세어 확률을 정의하는 방식이다.  
예: 주사위를 던질 때 각 눈금이 동일한 확률로 나온다고 보는 가정.

---

### **확률의 공리 (Kolmogorov axioms)**

라플라스 정의는 경우의 수를 셀 수 있는 단순한 상황에서는 잘 적용되지만,  
표본공간이 **무한하거나** 결과의 발생 가능성이 동일하지 않은 경우에는 사용할 수 없다.  
이 한계를 극복하기 위해 확률을 수학적으로 엄밀하게 정의한 것이 **콜모고로프(Kolmogorov)** 의 **확률 공리적 정의(axiomatic probability)** 이다.

확률 $P$는 다음 조건을 만족한다.

1. $0 \leq P(A) \leq 1$  
2. $P(\Omega) = 1$  
3. 서로 배반인 $A_1, A_2, \dots$ 에 대해  

   $$
   P(A_1 \cup A_2 \cup \cdots) = P(A_1) + P(A_2) + \cdots
   $$

즉, **위 공리적 조건들을 모두 만족하는 함수 $P$를 확률(probability)이라고 부른다.**

> 콜모고로프의 정의는 **수학적 공리 체계**를 기반으로 한다.  
따라서 경우의 수를 세기 어려운 상황, 무한 집합, 연속 확률 변수, 측도(measure) 이론에 의한 확률 등  
보다 일반적인 확률론의 전개가 가능하다.

---

## **확률의 기본 성질**

1. 공사건의 확률: $P(\varnothing) = 0$  
2. 여사건의 확률: $P(A^c) = 1 - P(A)$  
3. 포함관계: $A \subseteq B \ \Rightarrow\ P(A) \leq P(B)$  
4. 덧셈정리 (addition theorem):  

   $$
   P(A \cup B) = P(A) + P(B) - P(A \cap B)
   $$

---

## **조건부 확률 (conditional probability)**

조건 $B$가 일어난 상황에서 사건 $A$가 일어날 확률은  

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) \neq 0
$$

예: 불량품 중에서 생산라인 A에서 생산된 것일 확률  

$$
P(A \mid 불량) = \frac{P(A \cap 불량)}{P(불량)} = \frac{0.07}{0.10} = 0.7
$$

---

## **곱셈정리 (multiplication rule)**

조건부 확률의 정의에서 출발하면 다음이 성립한다.  

$$
P(A \cap B) = P(A) \, P(B \mid A) = P(B) \, P(A \mid B)
$$

이는 **조건부 확률의 대칭적 관계**를 보여주며, 이후 베이즈 정리의 기초가 된다.

---

### **일반화된 곱셈정리**

일반적으로 사건 $A_1, A_2, \dots, A_n$에 대해서  

$$
P(A_1 \cap A_2 \cap \cdots \cap A_n) 
$$  

$$
= P(A_1) \, P(A_2 \mid A_1) \, P(A_3 \mid A_1 \cap A_2) \cdots P(A_n \mid A_1 \cap A_2 \cap \cdots \cap A_{n-1})
$$


---

## **독립사건 (independent events)**

두 사건 $A, B$에 대하여 **조건부 확률**의 정의를 적용하면  

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) \neq 0
$$

이때 $A$와 $B$가 서로 영향을 주지 않는다고 가정하면  

$$
P(A \mid B) = P(A)
$$

> - $B$가 발생했을 때의 $A$의 확률과  
>   $B$를 고려하지 않았을 때의 $A$의 확률이 동일하면 두 사건은 독립이다.  
> - 즉,  
>
>   $$
>   P(A \mid B) = P(A)
>   $$

따라서 위 식을 대입하면  

$$
P(A) = \frac{P(A \cap B)}{P(B)}
$$

양변에 $P(B)$를 곱하면  

$$
P(A \cap B) = P(A)P(B)
$$

---

마찬가지로 조건을 바꾸어 생각하면  

$$
P(B \mid A) = \frac{P(A \cap B)}{P(A)} = P(B)
$$

---

즉,  
두 사건 $A, B$에 대하여  

$$
P(A \mid B) = P(A), \quad P(B \mid A) = P(B)
$$  
가 성립할 때, $A$와 $B$는 서로 **독립(independent)** 이라 하고  
그 결과는 다음과 같이 정리된다.

$$
P(A \cap B) = P(A)P(B)
$$
 
---

## **복원추출과 비복원추출**

- **복원추출 (sampling with replacement)**  
  추출한 대상을 다시 원래 자리로 돌려놓고 다음 대상을 추출하는 방법.

- **비복원추출 (sampling without replacement)**  
  추출한 대상을 다시 넣지 않고 다음 대상을 추출하는 방법.

예: 흰 구슬 7개, 검은 구슬 3개가 있는 주머니에서 2개를 뽑을 때  
- 복원추출: 첫 번째 흰 구슬 확률 = $7/10$, 두 번째도 다시 $7/10$  
- 비복원추출: 첫 번째 흰 구슬 확률 = $7/10$, 두 번째는 $6/9 = 2/3$

---

## **(난이도 상) 베이즈 정리 (Bayes' theorem)**

18세기 영국의 수학자인 토머스 베이즈(Thomas Bayes)는 확률이 항상 일정하다는 당시 이론에서 벗어나,  
확률은 상황에 따라 변할 수 있다고 생각하고 이를 공식으로 나타냈다.  
그가 사망한 후인 1763년에 친구인 철학자 리처드 프라이스(Richard Price)가 베이즈의 연구 결과를 정리하여 책으로 내면서  
이 공식을 베이즈 정리라고 부르게 되었다.  

베이즈 정리는 주어진 조건에서 어떤 사건이 실제로 일어날 확률을 산출하는 기법을 정리한 것으로,  
불확실한 상황에서 의사결정 문제를 다룰 때 중요하게 사용된다.

---

### **베이즈 정리의 기본 아이디어**

조건부 확률과 곱셈정리에서 출발한다.

조건부 확률 정의:  

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad
P(B \mid A) = \frac{P(A \cap B)}{P(A)}
$$

이를 각각 정리하면 곱셈정리의 대칭 형태가 얻어진다:  

$$
P(A \cap B) = P(A) P(B \mid A) = P(B) P(A \mid B)
$$

따라서 두 조건부 확률은 다음 관계로 연결된다:  

$$
P(A \mid B) = \frac{P(A) P(B \mid A)}{P(B)}
$$

이것이 **베이즈 정리의 기본 식**이다.  
즉, 어떤 사건 $B$가 발생했을 때, $A$의 확률을 $A$의 사전 정보와 $B$가 $A$일 때의 조건부 확률을 이용해 갱신할 수 있다.

---

### **분할 (partition)**

공집합이 아닌 어떤 집합 $A$에 대하여 집합 $A$의 부분집합 $A_1, A_2, \dots, A_n$을 원소로 하는 집합족(family of set) $\{A_1, A_2, \dots, A_n\}$이 다음을 만족할 때, $\{A_1, A_2, \dots, A_n\}$을 집합 $A$의 **분할(partition)** 이라고 한다.

1. $A_i \subseteq A \ (i = 1, 2, \dots, n)$  
2. $A_i \cap A_j = \varnothing \ (i \neq j, \ i,j = 1,2,\dots,n)$  
3. $A_1 \cup A_2 \cup \cdots \cup A_n = A$

---

### **전확률 (total probability)**

사건 $A_1, A_2, \dots, A_n$이 표본공간 $\Omega$의 분할을 이룬다고 하자.  
이때 사건 $B$를 임의의 사건이라 하면,

$$
P(B) = P(A_1 \cap B) + P(A_2 \cap B) + \cdots + P(A_n \cap B)
$$

확률의 곱셈정리에 의해 다음과 같이 쓸 수 있다.

$$
P(B) = P(A_1)P(B \mid A_1) + P(A_2)P(B \mid A_2) + \cdots + P(A_n)P(B \mid A_n)
$$

이를 **전확률 공식(total probability)** 이라 한다.

---

### **일반형 베이즈 정리**

사건 $A_1, A_2, \dots, A_n$이 표본공간 $\Omega$의 분할이고 $P(A_i) > 0, P(B) > 0$이면 다음이 성립한다.

$$
P(A_i \mid B) 
= \frac{P(A_i \cap B)}{P(B)} 
= \frac{P(A_i) P(B \mid A_i)}{\sum_{k=1}^n P(A_k) P(B \mid A_k)} \quad (i=1,2,\dots,n)
$$

- $P(A_i)$ : 사건 $A_i$의 **사전확률(prior probability)**  
- $P(A_i \mid B)$ : 사건 $A_i$의 **사후확률(posterior probability)**  

> 베이즈 정리는 초기의 적은 정보로 사전확률 $P(A_i)$를 추측했지만,  
> 새로운 정보 $B$를 반영하여 사후확률 $P(A_i \mid B)$을 갱신할 수 있도록 한다.  
> 통계적 추론, 의학적 진단, 기계학습, 컴퓨터공학 전반에서 폭넓게 이용된다.

---

### **베이즈 정리의 기계학습적 해석**

확률적 모델링에서는 **데이터 $X$** 와 **모델의 파라미터 $\theta$** 를 고려한다.  
이때 베이즈 정리는 다음과 같이 표현된다.

$$
P(\theta \mid X) = \frac{P(X \mid \theta) \, P(\theta)}{P(X)}
$$

- $P(\theta \mid X)$ : **사후확률(posterior)**  
  → 데이터를 관측한 이후, 파라미터 $\theta$가 어떤 값을 가질지에 대한 분포  

- $P(X \mid \theta)$ : **가능도(likelihood)**  
  → 특정 파라미터 $\theta$를 가정했을 때, 현재 관측한 데이터 $X$가 얼마나 잘 설명되는가?  

- $P(\theta)$ : **사전확률(prior)**  
  → 데이터를 보기 전에, 파라미터 $\theta$가 어떤 분포(예: 가우시안 분포 등)에서 왔다고 가정하는가?  

- $P(X)$ : **증거(evidence, marginal likelihood)**  
  → 데이터 $X$ 자체가 나타날 전체 확률, 정규화 상수 역할을 한다.  

---

### **해석**

데이터를 관측한 상태에서 $\theta$를 직접 추정하는 것은 어렵다.  
그러나 베이즈 정리를 통해 **우리가 아는 것(likelihood, prior)** 을 결합하여  
**알고 싶은 것(posterior)** 을 계산할 수 있다.

> **정리하면**  
> - likelihood: “$\theta$를 가정했을 때, 현재 관측된 데이터가 얼마나 그럴듯한가?”  
> - prior: “데이터를 보기 전에 $\theta$는 어떤 확률분포를 따른다고 믿는가?”  
> - posterior: “데이터를 본 후, $\theta$에 대한 믿음을 어떻게 갱신할 것인가?”  



---

## **확률변수 (random variable)**

자연현상 또는 사회현상을 과학적으로 분석하기 위해서는 관찰 대상이 되는 어떤 특성을 수학적으로 모형화해야 한다.  
이때, 각 시행에서 발생한 결과를 수치로 나타내는 변수를 **확률변수(random variable)** 라고 한다.

---

### **확률변수의 정의**

표본공간은 통계실험의 결과로 이루어지기 때문에 수치적으로 표현되는 경우가 많다.  
따라서 표본공간을 쉽게 이해하기 위해 표본공간의 각 원소에 수치를 대응시켜 수학적으로 다루기 편리하게 만든 것이 확률변수이다.

> **예시**  
> - 동전을 던지는 시행에서 앞면(H)이 나오면 1, 뒷면(T)이 나오면 0으로 정의한 함수 $X$.  
>   이때 $X$는 확률변수이다.  
> - 주사위를 던져 나온 눈의 수를 확률변수 $X$로 정의할 수 있다.

> “확률변수(random variable)”라는 용어 때문에, 마치 변수 자체가 어떤 불확실한 속성을 직접 가진 것처럼 오해할 수 있다.  
> 그러나 실제로 확률변수는 **불확실한 자연 현상이나 시행 결과(표본점)를 입력으로 받아, 이를 확률적 결과인 수치로 대응시키는 함수**이다.  
> 즉, 확률변수는 불확실성을 “숫자”로 표현하는 도구이다.

---

## **확률질량함수 (probability mass function, pmf)**

이산확률변수 $X$에 대하여 $X$의 값이 $x$일 확률을 나타내는 함수 $f(x)$를 **확률질량함수(pmf)** 라 한다.

$$
f(x) = P(X = x)
$$

---

### **확률질량함수의 성질**

1. 모든 실수 $x$에 대해 $0 \leq f(x) \leq 1$  
2. $\sum_{x \in R} f(x) = 1$  
3. 임의의 $A \subset R$에 대하여  

   $$
   P(X \in A) = \sum_{x \in A} f(x)
   $$

---

> **왜 pmf는 이산(discrete) 확률변수에서만 성립하는가?**  
> - 확률변수가 **연속형(continuous)** 인 경우에는 개별 점 하나에 확률을 부여할 수 없다.  
>   즉, $P(X = x) = 0$ 이므로 “어떤 값이 정확히 나올 확률”은 정의되지 않는다.  
> - 반면 **이산(discrete)** 경우에는 확률변수가 가질 수 있는 값의 집합이 유한하거나 countable하므로,  
>   각 값에 대해 $P(X = x)$를 직접 정의할 수 있다.  
> - 따라서 “개별 값에 확률을 배분”하는 방식은 이산형에서만 가능하며,  
>   연속형에서는 대신 **확률밀도함수(pdf)** 를 사용하여 구간 단위로 확률을 정의한다.


---

## **확률밀도함수 (probability density function, pdf)**

연속확률변수 $X$에 대하여 $a \leq X \leq b$일 확률은

$$
P(a \leq X \leq b) = \int_a^b f(x) \, dx
$$

이때 연속함수 $f(x)$를 $X$의 **확률밀도함수(pdf)** 라 한다.

---

### **확률밀도함수의 성질**

1. 모든 $x$에 대하여 $f(x) \geq 0$  
2. $\int_{-\infty}^{\infty} f(x) dx = 1$  
3. $P(a \leq X \leq b) = \int_a^b f(x) dx$

---

> **왜 pdf는 연속형 확률변수에서만 성립하는가?**  
> - 연속형 확률변수에서는 $P(X = x) = 0$이므로, 개별 값에 확률을 직접 배분할 수 없다.  
> - 따라서 “구간 단위”의 확률을 정의해야 하며, 이를 위해 적분 형태의 누적값으로 확률을 표현한다.  
> - 즉, 확률은 점이 아닌 **구간**에서만 의미를 가진다.

> **밀도(density)의 의미**  
> - 확률밀도함수 $f(x)$는 특정 점에서의 “확률값”을 직접 주는 것이 아니라,  
>   그 주변 구간에서의 확률 분포가 얼마나 **빽빽하게 분포되어 있는지**를 나타내는 척도이다.  
> - 예를 들어 $f(x)$가 크면, 그 근처의 작은 구간에서 확률이 상대적으로 높다는 의미이다.  
> - 따라서 pdf는 “확률의 밀집 정도(probability per unit length)”를 보여주며,  
>   실제 확률은 반드시 구간 적분으로 계산해야 한다.

---

## **확률분포 (probability distribution)**

확률변수 $X$가 가질 수 있는 값과 그 값에 대응하는 확률의 분포를 **확률분포**라 한다.  
확률분포는 이산확률분포(discrete)와 연속확률분포(continuous)로 나뉜다.

---

### **이산확률분포**

확률변수 $X$가 $x_1, x_2, \dots, x_n$ 값을 가질 때, 확률질량함수는

$$
f(x) = P(X = x), \quad (x = x_1, x_2, \dots, x_n)
$$

이산확률변수의 분포함수(CDF, cumulative distribution function)는

$$
F(x) = P(X \leq x) = \sum_{x_i \leq x} f(x_i)
$$

---

### **연속확률분포**

연속확률변수 $X$의 분포함수(CDF, cumulative distribution function)는

$$
F(x) = P(X \leq x) = \int_{-\infty}^x f(t) \, dt
$$

확률밀도함수 $f(x)$와 분포함수 $F(x)$의 관계는

$$
f(x) = \frac{d}{dx} F(x)
$$

이다.

---

### **분포함수(CDF, cumulative distribution function)의 기본 성질**

임의의 확률변수 $X$에 대해 $F(x)=P(X \le x)$라 하면,

1. **단조성**: $x_1 \le x_2 \Rightarrow F(x_1) \le F(x_2)$  
2. **극한값**: $\displaystyle \lim_{x \to -\infty} F(x)=0,\quad \lim_{x \to \infty} F(x)=1$  
3. **구간확률**: $\displaystyle P(a < X \le b) = F(b) - F(a)$ 

---

## **기대값과 분산 (Expectation and Variance)**

확률변수의 **기댓값(expected value)** 은 확률분포의 중심 위치를 나타내며,  
**분산(variance)** 은 그 값들이 평균을 중심으로 얼마나 퍼져 있는지를 나타낸다.

---

### **확률변수의 기대값**

- **이산확률변수 $X$**  
  $$
  E(X) = \sum_x x f(x)
  $$

- **연속확률변수 $X$**  
  $$
  E(X) = \int_{-\infty}^{\infty} x f(x)\, dx
  $$

> 기댓값은 확률변수를 여러 번 반복했을 때 관측되는 **평균값**에 해당한다.  

---

### **기댓값의 성질**

확률변수 $X, Y$와 임의의 상수 $k, k_1, k_2$에 대해 다음이 성립한다.

1. $E(k) = k$  
2. $E(kX) = kE(X)$  
3. $E(X + k) = E(X) + k$  
4. $E(k_1X + k_2Y) = k_1E(X) + k_2E(Y)$  

즉, **기댓값은 선형(linearity)을 가진다.**

---

### **분산**

분산은 확률변수 값이 평균 $\mu = E(X)$으로부터 얼마나 흩어져 있는지를 나타낸다.

- 정의:  

  $$
  Var(X) = E[(X - E(X))^2]
  $$

- **이산형**  

  $$
  Var(X) = \sum_x (x - \mu)^2 f(x)
  $$

- **연속형**  

  $$
  Var(X) = \int_{-\infty}^\infty (x - \mu)^2 f(x)\, dx
  $$

- 표준편차:  

  $$
  \sigma_X = \sqrt{Var(X)}
  $$

---

### **분산의 성질**

1. $Var(k) = 0$  
2. $Var(X \pm k) = Var(X)$  
3. $Var(kX) = k^2 Var(X)$  

---

### **(난이도 극상) 적률생성함수 (Moment Generating Function, MGF)**

확률변수의 분포를 특징짓는 함수로, 보통 어떤 **구간 $(-h, h)$에서 $E(e^{tX})$가 존재**할 때 정의한다.

$$
M_X(t) = E(e^{tX}) \quad (|t|<h)
$$

- **이산형**  

  $$
  M_X(t) = \sum_x e^{tx} f(x)
  $$

- **연속형**  

  $$
  M_X(t) = \int_{-\infty}^{\infty} e^{tx} f(x)\, dx
  $$

> **주의**  
> - **모든 확률분포가 적률생성함수를 갖는 것은 아니다.**  
>   즉, 어떤 분포는 $E(e^{tX})$가 $t=0$ 주변의 열린 구간에서 유한하지 않을 수 있다(예: 코시 분포).  
> - 그러나 **존재**하여 $t=0$의 근방에서 정의되면, 그 MGF는 분포를 **유일하게 결정**한다.  
> - (독립일 때) 합의 MGF는 곱으로 분해된다:  
>
>   $$
>   X_1,\dots,X_n\ \text{독립} \ \Rightarrow\ M_{X_1+\cdots+X_n}(t)=\prod_{i=1}^n M_{X_i}(t)
>   $$

---

### **적률과의 관계**

적률생성함수를 $t$에 대해 미분하면 적률(moment)을 얻는다.

- $M_X^{(1)}(0) = E(X)$ : 1차 적률 (평균)  
- $M_X^{(2)}(0) = E(X^2)$ : 2차 적률  
- $Var(X) = M_X^{(2)}(0) - \{M_X^{(1)}(0)\}^2$

---

### **예제**

확률밀도함수  

$$
f(x)=\frac{1}{2}e^{-|x|}\qquad(-\infty<x<\infty)
$$
를 갖는 연속확률변수 $X$의 적률생성함수 $M_X(t)$, $E(X)$, $Var(X)$를 구하라.

**해**  

$$
\begin{aligned}
M_X(t) &= E(e^{tX}) \\
&= \int_{-\infty}^\infty e^{tx}\,\frac{1}{2}e^{-|x|}\,dx \\
&= \frac{1}{2}\int_{-\infty}^0 e^{tx}e^{x}\,dx
 \;+\; \frac{1}{2}\int_{0}^{\infty} e^{tx}e^{-x}\,dx \\
&= \frac{1}{2}\int_{-\infty}^0 e^{(t+1)x}\,dx
 \;+\; \frac{1}{2}\int_{0}^{\infty} e^{(t-1)x}\,dx \\
&= \frac{1}{2}\cdot\frac{1}{t+1}
 \;+\; \frac{1}{2}\cdot\frac{1}{1-t} \\
&= \frac{1}{1-t^{2}}, \qquad (|t|<1).
\end{aligned}
$$

따라서

$$
M'_X(t)=\frac{2t}{(1-t^2)^2}, \quad
M''_X(t)=\frac{2(1+3t^2)}{(1-t^2)^3}.
$$

평균과 분산은

$$
E(X)=M'_X(0)=0, \qquad
Var(X)=M''_X(0)-\{M'_X(0)\}^2=2.
$$

---

## **결합확률분포 (Joint Probability Distribution)**

통계실험에서는 두 개 이상의 확률변수가 동시에 고려되는 경우가 많다.  
이때 이들 확률변수의 확률분포를 **결합확률분포**라 한다.

---

### **결합확률질량함수 (Joint PMF)**

이산확률변수 $X, Y$에 대해,  

$$
f(x,y) = P(X=x, Y=y)
$$
를 **결합확률질량함수(joint pmf)** 라 한다.  

성질:
1. $f(x,y) \geq 0$  
2. $\sum_x \sum_y f(x,y) = 1$  
3. 임의의 집합 $A$에 대해 $P((X,Y)\in A) = \sum_{(x,y)\in A} f(x,y)$

---

### **주변확률질량함수 (Marginal PMF)**

결합확률질량함수로부터 $X$ 또는 $Y$의 1차원 분포를 구할 수 있다.

- $h(x) = P(X=x) = \sum_y f(x,y)$  
- $g(y) = P(Y=y) = \sum_x f(x,y)$  

이를 각각 **주변확률질량함수(marginal pmf)** 라 한다.

---

### **결합분포함수 (Joint CDF)**

두 확률변수 $X, Y$에 대해,  

$$
F(x,y) = P(X \leq x, Y \leq y) = \sum_{u \leq x} \sum_{v \leq y} f(u,v)
$$

---

### **결합확률밀도함수 (Joint PDF)**

연속확률변수 $X, Y$에 대해서는 결합확률밀도함수 $f(x,y)$를 정의한다.

성질:
1. $f(x,y) \geq 0$  
2. $\int_{-\infty}^\infty \int_{-\infty}^\infty f(x,y)\, dx\,dy = 1$  
3. 임의의 영역 $A$에 대해 $P((X,Y)\in A) = \iint_A f(x,y)\,dx\,dy$

주변확률밀도함수는  

$$
f_X(x) = \int_{-\infty}^\infty f(x,y)\,dy, \quad
f_Y(y) = \int_{-\infty}^\infty f(x,y)\,dx
$$
로 정의된다.

---

## **공분산과 상관계수**

### **공분산 (Covariance)**

확률변수 $X, Y$가 함께 변하는 정도를 나타낸다.

$$
Cov(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] = E(XY) - \mu_X \mu_Y
$$

- $Cov(X,Y) > 0$: $X, Y$가 같은 방향으로 변동  
- $Cov(X,Y) < 0$: $X, Y$가 반대 방향으로 변동  
- $Cov(X,Y) = 0$: 선형적 상관 없음

---

### **상관계수 (Correlation Coefficient)**

공분산은 단위에 따라 값이 달라 비교가 어렵다.  
이를 표준화한 것이 **상관계수**이다.

$$
\rho_{XY} = Corr(X,Y) = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
$$

성질:
1. $-1 \leq \rho_{XY} \leq 1$  
2. $\rho_{XY} = 1$: 완전 양의 상관  
3. $\rho_{XY} = -1$: 완전 음의 상관  
4. $\rho_{XY} = 0$: 선형적 상관 없음

---

## **확률변수의 독립성**

두 확률변수 $X, Y$가 독립(mutually independent)이라는 것은  

$$
P(X=x_i, Y=y_j) = P(X=x_i)P(Y=y_j)
$$
가 모든 $x_i, y_j$에 대해 성립하는 경우이다.

- 이산형: $f(x,y) = h(x) g(y)$  
- 연속형: $f(x,y) = f_X(x) f_Y(y)$  

독립일 경우 성질:
1. $E(XY) = E(X)E(Y)$  
2. $Var(X+Y) = Var(X) + Var(Y)$  
3. $Cov(X,Y) = 0$  
4. $Corr(X,Y) = 0$

---

## **이산확률분포 (Discrete Probability Distributions)**

이산확률분포는 확률변수 $X$의 치역이 셀 수 있는 경우에 해당한다.  
통계 이론에서 자주 사용되는 대표적인 이산분포에는 **이산균등분포, 베르누이분포, 이항분포, 초기하분포, 푸아송분포, 기하분포, 음이항분포** 등이 있다.

---

### **1. 이산균등분포 (Discrete Uniform Distribution)**

모든 값이 동일한 확률로 발생하는 가장 단순한 확률분포.

- 확률질량함수:  

  $$
  f(x) = \frac{1}{n}, \quad (x=1,2,\dots,n)
  $$

- 평균과 분산:  

  $$
  E(X) = \frac{n+1}{2}, \qquad Var(X) = \frac{n^2-1}{12}
  $$

---

<img src="/assets/img/mathbasic/discrete_uniform.png" alt="이산균등분포" width="720px">

> 왼쪽 그림은 Discrete Uniform(1,…,6) 분포로, 주사위를 던지는 상황에 해당한다.  
> 각 값이 1/6의 확률로 동일하게 발생한다.  
>
> 오른쪽 그림은 Discrete Uniform(1,…,10) 분포로, 1부터 10까지의 수를 뽑는 상황에 해당한다.  
> 각 값이 1/10 확률로 동일하게 발생하며, 값의 개수가 늘어나면 개별 값의 확률은 더 작아진다.  

---

### **2. 베르누이분포 (Bernoulli Distribution)**

성공/실패 두 가지 결과만 있는 시행에서의 분포.

- 확률질량함수:  

  $$
  P(X=1)=p, \quad P(X=0)=q=1-p
  $$

- 평균과 분산:  

  $$
  E(X) = p, \qquad Var(X) = p(1-p)
  $$

---

<img src="/assets/img/mathbasic/bernoulli_example.png" alt="베르누이분포" width="720px">

> 왼쪽 그래프 (p=0.3): 성공(1)의 확률이 0.3, 실패(0)의 확률이 0.7로, 실패 쪽이 더 크게 나타난다.  
> 오른쪽 그래프 (p=0.7): 성공(1)의 확률이 0.7, 실패(0)의 확률이 0.3으로, 성공 쪽이 더 크게 나타난다.  
> 즉, 모수 p 값이 커질수록 성공(1)의 기둥이 커지고, 실패(0)의 기둥이 작아진다.

---

### **3. 이항분포 (Binomial Distribution)**

베르누이 시행을 $n$번 반복했을 때, 성공 횟수 $X$의 분포.

- 확률질량함수:  

  $$
  f(x) = {n \choose x} p^x (1-p)^{n-x}, \quad (x=0,1,\dots,n)
  $$

- 평균과 분산:  

  $$
  E(X) = np, \qquad Var(X) = np(1-p)
  $$

---

<img src="/assets/img/mathbasic/binomial_example.png" alt="이항분포" width="720px">

> 왼쪽 그래프는 $n=10, p=0.3$일 때의 이항분포 확률질량함수(PMF)를 보여준다.  
> - 성공 확률이 낮기 때문에, 성공 횟수가 적은 쪽(0~4)에 확률이 집중되어 있다.  
>
> 오른쪽 그래프는 $n=10, p=0.7$일 때의 PMF이다.  
> - 성공 확률이 높아지면서, 성공 횟수가 많은 쪽(6~10)에 확률이 집중된다.  
>
> 두 그래프를 비교하면, **성공 확률 $p$가 작으면 분포가 왼쪽으로, $p$가 크면 오른쪽으로 치우친다**는 특징을 확인할 수 있다.  

---

### **4. 초기하분포 (Hypergeometric Distribution)**

유한 모집단에서 **복원 추출(without replacement)** 없이 표본을 뽑을 때 나타나는 분포이다.  

즉, **전체 집단(N)** 중에서 **성공(success)이라고 정의된 원소가 M개** 포함되어 있고,  
여기서 **표본 크기 n개**를 임의로 뽑을 때, **그 안에 포함된 성공의 개수 X**가 따르는 분포가 초기하분포이다.

- **모집단 크기 $N$** : 전체 원소의 개수 (예: 50개의 공)  
- **성공 개수 $M$** : 모집단 안에서 성공(success)으로 정의된 원소의 개수 (예: 50개 중 흰 공이 20개)  
- **표본 크기 $n$** : 뽑는 표본의 개수 (예: 한 번에 10개 뽑기)  
- **성공 횟수 $x$** : 표본 안에서 뽑힌 성공 원소의 개수 (예: 10개 중 흰 공이 4개)

---

- **확률질량함수 (PMF):**  

  $$
  f(x) = P(X=x) 
  = \frac{\binom{M}{x}\,\binom{N-M}{\,n-x\,}}{\binom{N}{n}}, 
  \quad \max(0, n-(N-M)) \leq x \leq \min(n,M)
  $$

  → 전체 모집단에서 $n$개를 고르는 방법($\binom{N}{n}$) 중에서,  
  성공 $M$개 중에서 $x$개를 뽑고, 실패 $N-M$개 중에서 $n-x$개를 뽑는 경우의 수를 비율로 나타낸 것이다.

---

- **평균과 분산:**  

  $$
  E(X) = n\frac{M}{N}, \qquad 
  Var(X) = n\frac{M}{N}\left(1-\frac{M}{N}\right)\frac{N-n}{N-1}
  $$

  - 평균: 표본 크기 $n$에서 성공이 뽑힐 기대 개수는 모집단에서 성공 비율 $\tfrac{M}{N}$만큼 반영된다.  
  - 분산: 단순 이항분포의 분산 $np(1-p)$에 **유한 모집단 보정계수** $\tfrac{N-n}{N-1}$가 곱해진 형태.  
    (표본을 복원 없이 뽑기 때문에 분산이 줄어든다.)  

---

> **예시**  
> 모집단 $N=50$개의 공 중에서 $M=20$개가 흰 공, $30$개가 검은 공이라고 하자.  
> 이때 $n=10$개를 비복원추출했을 때, 흰 공이 $x=4$개 나올 확률은  
> $$
> P(X=4) = \frac{\binom{20}{4}\,\binom{30}{6}}{\binom{50}{10}}
> $$  
> 이다.

---

<img src="/assets/img/mathbasic/hypergeometric_example.png" alt="초기하분포" width="720px">
> 왼쪽 그래프는 모집단 크기 $N=50$, 성공 개수 $M=10$, 표본 크기 $n=5$ 인 경우의 초기하분포이다.  
> - 성공 확률이 낮기 때문에(10개 중 성공), 성공 횟수 $x$가 0 또는 1 근처에서 확률이 가장 크다.  
> 
> 오른쪽 그래프는 $N=50$, $M=30$, $n=10$ 인 경우이다.  
> - 모집단의 절반 이상이 성공 항목이므로, $x$가 5~7 근처에서 가장 높은 확률을 가진다.  
> 
> 즉, 초기하분포는 모집단의 성공 비율 $M/N$과 표본 크기 $n$에 따라 확률 분포의 중심이 크게 달라지며,  
> 복원 추출이 없기 때문에 단순한 이항분포와는 다른 분포 형태를 가진다.

---

### **5. 푸아송분포 (Poisson Distribution)**

어떤 구간 내 사건 발생 횟수를 나타내는 분포.  
이항분포 $B(n,p)$에서 $n$이 크고 $p$가 작을 때 극한으로 유도 가능하다.

- 확률질량함수:  

$$
f(x) = \frac{e^{-\lambda} \lambda^x}{x!}, \quad (x=0,1,2,\dots)
$$

- 평균과 분산:  

$$
E(X) = \lambda, \qquad Var(X) = \lambda
$$

여기서 $\lambda > 0$ 는 **주어진 구간에서 기대되는 사건의 평균 발생 횟수(평균율, rate parameter)** 를 의미한다.  
예:  
- 한 시간 동안 도착하는 고객 수의 평균  
- 하루 동안 발생하는 교통사고 건수의 평균  

---

<img src="/assets/img/mathbasic/poisson.png" alt="푸아송분포" width="600px">

> 위 그림은 $\lambda = 1, 4, 10$일 때의 푸아송분포 확률질량함수(PMF)를 비교한 것이다.  
> - **$\lambda = 1$**: 대부분의 확률이 $x=0,1,2$에 몰려 있으며, 매우 희귀한 사건을 모델링한다.  
> - **$\lambda = 4$**: 분포가 좀 더 퍼져 있고, 평균 4 근처에서 확률이 가장 크다.  
> - **$\lambda = 10$**: 분포가 오른쪽으로 치우치며, 모양이 종 모양에 가까워진다.  
> - 특징적으로, $\lambda$ 값이 커질수록 푸아송분포는 점점 **정규분포에 근사**하게 된다.  

---

### **6. 기하분포 (Geometric Distribution)**

처음으로 성공할 때까지의 시행 횟수를 나타내는 분포.

- 확률질량함수:  

  $$
  f(x) = (1-p)^{x-1}p, \quad (x=1,2,\dots)
  $$

- 평균과 분산:  

  $$
  E(X) = \frac{1}{p}, \qquad Var(X) = \frac{1-p}{p^2}
  $$

---

<img src="/assets/img/mathbasic/geometric.png" alt="기하분포" width="720px">

> **왼쪽 (p = 0.3)**  
>  - 성공 확률이 낮기 때문에 확률질량함수(PMF)가 완만하게 감소한다.  
>  - 평균 $E(X) = 1/p \approx 3.33$, 분산 $Var(X) = (1-p)/p^2 \approx 7.78$  
>  - 해석: 첫 성공까지 보통 여러 번의 시행이 필요하며, 시행 횟수의 변동도 크다.  
>
> **오른쪽 (p = 0.6)**  
>  - 성공 확률이 높아 대부분 $x=1$ 또는 $x=2$에서 성공할 가능성이 집중된다.  
>  - 평균 $E(X) = 1/p \approx 1.67$, 분산 $Var(X) = (1-p)/p^2 \approx 1.11$  
>  - 해석: 첫 성공이 빠르게 일어나며, 시행 횟수의 분포가 좁게 모인다.  
>
> **정리**  
> - 성공 확률 $p$가 커질수록 첫 성공까지 걸리는 시행 횟수는 줄어들고, 분포는 왼쪽으로 몰린다.  
> - 반대로 $p$가 작아질수록 시행 횟수는 길어지고, 분포는 오른쪽으로 퍼지며 분산도 커진다.  

---

### **7. 음이항분포 (Negative Binomial Distribution)**

성공할 때까지의 시행 횟수를 다루는 분포를 일반화한 것.  
$k$번 성공할 때까지의 시행 횟수 $X$.

- 확률질량함수:  

  $$
  f(x) = {x-1 \choose k-1} p^k (1-p)^{x-k}, \quad (x=k,k+1,\dots)
  $$

- 평균과 분산:  

  $$
  E(X) = \frac{k}{p}, \qquad Var(X) = \frac{k(1-p)}{p^2}
  $$

---

<img src="/assets/img/mathbasic/negative_binomial_two_panels.png" alt="음이항분포" width="720px">
> - **왼쪽 차트 (r=3, p=0.5)**: 성공 확률이 비교적 높고, 3번 성공할 때까지의 시행 횟수를 나타낸다. 분포가 짧은 구간에 집중되어 있으며, 작은 시행 횟수에서 확률이 높다.  
> - **오른쪽 차트 (r=5, p=0.3)**: 성공 확률이 낮고, 5번 성공할 때까지 걸리는 시행 횟수를 나타낸다. 분포가 더 넓게 퍼져 있고, 큰 시행 횟수에서 확률이 상대적으로 높다.  
> 즉, **성공 확률이 작아지거나 성공해야 하는 횟수가 많아질수록 분포는 오른쪽으로 퍼지고 긴 꼬리를 갖는다.**

---

> - 이산균등분포는 모든 값이 같은 확률을 가짐  
> - 베르누이분포는 가장 기본적인 0/1 분포  
> - 이항분포는 여러 번 반복한 베르누이 시행  
> - 초기하분포는 복원 없는 추출에서의 성공 횟수  
> - 푸아송분포는 희귀 사건의 발생 횟수  
> - 기하분포는 첫 성공까지의 시행 횟수  
> - 음이항분포는 $k$번째 성공까지의 시행 횟수

---

## **연속확률분포 (Continuous Probability Distributions)**

연속확률변수 $X$의 분포는 확률밀도함수(pdf) $f(x)$와 분포함수(cdf) $F(x)$로 정의된다.  

- **확률밀도함수(pdf)**  

$$
P(a \leq X \leq b) = \int_a^b f(x)\, dx, \quad f(x) \geq 0, \quad \int_{-\infty}^{\infty} f(x)\, dx = 1
$$

- **분포함수(cdf)**  

$$
F(x) = P(X \leq x) = \int_{-\infty}^x f(t)\, dt
$$

---

### **1. 균등분포 (Uniform Distribution)**

확률변수 $X \sim U(a,b)$ 의 확률밀도함수는  

$$
f(x) =
\begin{cases}
\frac{1}{b-a}, & a \leq x \leq b \\
0, & \text{그 외}
\end{cases}
$$

분포함수:  

$$
F(x) =
\begin{cases}
0, & x < a \\
\frac{x-a}{b-a}, & a \leq x < b \\
1, & x \geq b
\end{cases}
$$

- 평균: $E(X) = \frac{a+b}{2}$  
- 분산: $Var(X) = \frac{(b-a)^2}{12}$  

---

<img src="/assets/img/mathbasic/uniform_distribution_two.png" alt="균등분포" width="720px">
> - 균등분포는 구간 $[a,b]$ 내에서 모든 값이 동일한 확률밀도를 갖는 분포이다.  
> - 왼쪽 그림은 $U(0,1)$ 분포로, 확률밀도가 $1$로 일정하다.  
> - 오른쪽 그림은 $U(2,5)$ 분포로, 구간 길이가 3이므로 확률밀도는 $\frac{1}{3}$로 더 낮게 나타난다.  
> - 구간이 길어질수록 확률밀도는 낮아지고, 구간이 짧아질수록 확률밀도는 높아진다.  
> - 하지만 두 경우 모두 확률 전체 면적(적분값)은 항상 1이 된다.

---

### **2. 정규분포 (Normal Distribution)**

$X \sim N(\mu, \sigma^2)$ 의 확률밀도함수는  

$$
f(x) = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right), \quad -\infty < x < \infty
$$

- 평균: $E(X) = \mu$  
- 분산: $Var(X) = \sigma^2$  

성질:  
1. 종 모양(bell-shaped) 곡선  
2. $\mu$에서 최대, 대칭 구조  
3. $\mu \pm \sigma$에서 변곡점  
4. $\mu \pm 3\sigma$ 밖에서는 거의 확률이 0  

--
<img src="/assets/img/mathbasic/normal_two_panels_same_scale.png" alt="정규분포" width="720px"> 
> **왼쪽 (평균만 변화, σ 고정 = 1.5)**  
>   - 곡선의 형태(폭과 높이)는 그대로이고, **평균 μ** 값에 따라 곡선이 **좌우로 평행이동**한다.  
>   - 예: μ = -3, 0, 3 에서 각각 중심 위치만 바뀐다.  
>
> **오른쪽 (분산만 변화, μ 고정 = 0)**  
>   - **표준편차 σ** 가 작아질수록 곡선이 **더 좁고 높게**(집중) 되고, 커질수록 **더 넓고 낮게**(퍼짐) 된다.  
>   - 예: σ = 0.8, 1.5, 3.0 순으로 폭이 넓어지며 최고 높이는 낮아진다.  

---

### **3. 표준정규분포 (Standard Normal Distribution)**

정규분포 $N(\mu, \sigma^2)$를 표준화하면  

$$
Z = \frac{X - \mu}{\sigma} \sim N(0,1)
$$

확률밀도함수:  

$$
\phi(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}}, \quad -\infty < z < \infty
$$

분포함수:  

$$
\Phi(z) = P(Z \leq z) = \int_{-\infty}^z \phi(t)\, dt
$$

- 평균: $E(Z) = 0$  
- 분산: $Var(Z) = 1$   

---

### **4. 감마분포 (Gamma Distribution)**

감마분포는 **대기시간 분포**로 자주 쓰이며, 어떤 사건이 연속적으로 발생할 때  
$r$번째 사건이 일어날 때까지 걸리는 시간을 모델링한다.  

확률변수 $X \sim G(\alpha, \beta)$ 의 확률밀도함수는  

$$
f(x) =
\begin{cases}
\frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{-x/\beta}, & x \geq 0 \\
0, & x < 0
\end{cases}
$$

여기서 $\Gamma(\alpha)$는 **감마함수**로, 계승(factorial)의 일반화이다.  

$$
\Gamma(\alpha) = \int_0^\infty e^{-t} t^{\alpha-1}\, dt
$$

- 평균: $E(X) = \alpha \beta$  
- 분산: $Var(X) = \alpha \beta^2$  

---

**모수 해석**

- $\alpha$ (shape, 모양 모수): "$r$번째 사건이 발생할 때까지의 순서"  
  - 예: $\alpha=1$ → 첫 번째 사건 발생까지의 시간 (지수분포와 동일)  
  - 예: $\alpha=3$ → 세 번째 사건 발생까지의 시간  

- $\beta$ (scale, 척도 모수): 각 사건 사이의 평균 대기 시간  

- $x$: 실제 관측된 시간 값  
  - 예: $X=5$ → 세 번째 사건 발생까지 걸린 실제 시간이 5분인 경우  

---

<img src="/assets/img/mathbasic/gamma.png" alt="감마분포" width="720px"> 
> **왼쪽 (스케일 β 고정 = 2, 모양 α 변화)**  
> - 모양 모수 α가 커질수록 분포가 **오른쪽으로 이동**하면서 점점 **대칭에 가까워진다**.  
> - α = 1일 때는 지수분포와 같은 단조 감소 형태를 보인다.  
> - α가 커질수록 분포가 점점 종 모양으로 바뀌고, 평균은 $E(X)=\alpha\beta$에 따라 오른쪽으로 이동한다.  
>
> **오른쪽 (모양 α 고정 = 3, 스케일 β 변화)**  
> - 스케일 β는 분포의 **폭과 퍼짐 정도**를 조절한다.  
> - β가 작으면 그래프가 **좁고 급격하게 감소**하며, β가 크면 **넓고 완만**하게 퍼진다.  
> - 평균은 $E(X)=\alpha\beta$, 분산은 $Var(X)=\alpha\beta^2$로, β가 커질수록 두 값이 모두 커진다.  

---

### **5. 지수분포 (Exponential Distribution)**

지수분포는 감마분포의 특수한 경우($\alpha=1$)로,  
**어떤 사건이 처음으로 발생하기까지 걸리는 시간**을 모델링한다.  

예:  
- 고장이 발생하기까지의 시간  
- 고객이 도착하기까지의 대기시간  

확률변수 $X \sim Exp(\theta)$ 의 확률밀도함수는  

$$
f(x) =
\begin{cases}
\frac{1}{\theta} e^{-x/\theta}, & x \geq 0 \\
0, & x < 0
\end{cases}
$$

분포함수:  

$$
F(x) =
\begin{cases}
1 - e^{-x/\theta}, & x \geq 0 \\
0, & x < 0
\end{cases}
$$

- 평균: $E(X) = \theta$  
- 분산: $Var(X) = \theta^2$  

---

특징: **기억 없음(memoryless property)**  
즉, 이미 $a$만큼 시간이 지난 후에도 남은 시간 분포는 처음과 동일하다.  

$$
P(X > a+b \mid X > a) = P(X > b)
$$

---

<img src="/assets/img/mathbasic/exp.png" alt="지수분포" width="600px"> 
> 위 그림은 지수분포의 확률밀도함수(PDF)를 $\theta = 1, 2, 4$로 설정하여 비교한 것이다.  
> - **$\theta = 1$**: 분포가 가장 가파르게 감소하며, 짧은 시간 내 사건이 발생할 가능성이 높다.  
> - **$\theta = 2$**: 완만하게 감소하면서 평균이 커지고, 더 긴 시간이 걸릴 확률도 존재한다.  
> - **$\theta = 4$**: 분포가 가장 완만하게 감소하며, 사건이 발생하기까지 걸리는 시간이 전반적으로 길어진다.  
> - 즉, **$\theta$ 값이 커질수록 평균 대기시간이 길어지고 분포가 퍼지게 된다.**

---

### **6. 베타분포 (Beta Distribution)**

베타분포는 [0,1] 구간에서 정의되는 분포로,  
**비율이나 확률과 같은 확률변수**를 모델링할 때 사용된다.  

예:  
- 제품의 불량률 분포  
- 동전 던지기의 앞면이 나올 확률  
- 확률 $p$에 대한 사전분포 (베이지안 통계에서 매우 중요)  

---

확률변수 $X \sim Be(\alpha, \beta)$ 의 확률밀도함수는  

$$
f(x) =
\begin{cases}
\frac{1}{B(\alpha, \beta)} x^{\alpha - 1} (1-x)^{\beta - 1}, & 0 < x < 1 \\
0, & \text{그 외}
\end{cases}
$$

여기서 $B(\alpha, \beta)$는 **베타함수**:  

$$
B(\alpha, \beta) = \int_0^1 t^{\alpha-1}(1-t)^{\beta-1}\, dt 
= \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}
$$

- 평균: $E(X) = \frac{\alpha}{\alpha + \beta}$  
- 분산: $Var(X) = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$  

---

> **쉽게 이해하기**  
> - 베타분포는 “확률 $p$ 자체”가 어떻게 분포하는지를 표현하는 분포이다.  
> - $\alpha$는 "성공 횟수 + 1", $\beta$는 "실패 횟수 + 1"처럼 생각할 수 있다.  
>   예: 동전을 5번 던져 앞면이 3번, 뒷면이 2번 나오면 $Be(4,3)$으로 모델링 가능.  
> - 데이터가 많아질수록 ($\alpha, \beta$가 커질수록) 그래프는 점점 뾰족해지고,  
>   특정 확률값에 대한 **확신(credibility)** 이 강해진다.  
> - $\alpha = \beta = 1$이면 모든 확률값이 똑같이 가능하다고 보는 균등분포가 된다.  

> **핵심 비유**  
> - 감마분포가 “시간이 얼마나 걸릴까?”를 다룬다면,  
> - 베타분포는 “성공 확률이 얼마쯤 될까?”를 다룬다.  

---

<img src="/assets/img/mathbasic/beta.png" alt="베타분포" width="720px"> 
> **왼쪽 (스케일 β 고정 = 2, 모양 α 변화)**  
> - 모양 모수 α가 커질수록 분포가 **오른쪽으로 이동**하면서 점점 **대칭에 가까워진다**.  
> - α = 0.5일 때는 왼쪽 끝에 몰려 있는 형태, α = 1일 때는 균등분포(직선),  
>   α = 2 이상부터는 점점 종 모양에 가까워진다.  
> - 평균은 $E(X) = \frac{\alpha}{\alpha + \beta}$ 로, α가 커질수록 오른쪽으로 이동한다.  
>
> **오른쪽 (모양 α 고정 = 3, 스케일 β 변화)**  
> - 스케일 모수 β가 작으면 분포가 **오른쪽에 치우쳐** 있으며, β가 커질수록 분포는 **왼쪽으로 이동**한다.  
> - β가 커질수록 평균 $E(X)=\frac{\alpha}{\alpha+\beta}$ 이 작아지고,  
>   분산 $Var(X)=\frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$ 은 커진다.  
> - 즉, β는 분포의 **위치와 퍼짐**을 함께 조절하는 역할을 한다.  